\title{
GLOBAL EDITION
}
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0001.jpg?height=748&width=976&top_left_y=573&top_left_x=770)

FOURTEENTH EDITION

and

(2)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0001.jpg?height=628&width=1842&top_left_y=1664&top_left_x=1)



\section{Modern Control Systems}

This page is intentionally left blank 

\section{Modern Control Systems}

\section{FOURTEENTH EDITION GLOBAL EDITION}

Richard C. Dorf

University of California, Davis

Robert H. Bishop

University of South Florida Please contact https://support.pearson.com/getsupport/s/ with any queries on this content.

Cover Image: Nguyen Quang Ngoc Tonkin/Shutterstock

Pearson Education Limited

KAO Two

KAO Park

Hockham Way

Harlow

CM17 9SR

United Kingdom

and Associated Companies throughout the world

Visit us on the World Wide Web at: www.pearsonglobaleditions.com

(C) Pearson Education Limited 2022

The rights of Richard C. Dorf and Robert H. Bishop to be identified as the author of this work have been asserted by him in accordance with the Copyright, Designs and Patents Act 1988.

Authorized adaptation from the United States edition, entitled Modern Control Systems, 14th Edition, ISBN 978-013-730725-8 by Richard C. Dorf and Robert H. Bishop published by Pearson Education (C) 2022.

All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior written permission of the publisher or a license permitting restricted copying in the United Kingdom issued by the Copyright Licensing Agency Ltd, Saffron House, 6-10 Kirby Street, London EC1N 8TS. For information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights \& Permissions department, please visit www.pearsoned.com/permissions/.

Attributions of third-party content appear on the appropriate page within the text.

PEARSON, ALWAYS LEARNING is an exclusive trademark owned by Pearson Education, Inc. or its affiliates in the U.S. and/or other countries.

Unless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective owners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such references are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson's products by the owners of such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees, or distributors.

This eBook may be available as a standalone product or integrated with other Pearson digital products like MyLab and Mastering. This eBook may or may not include all assets that were part of the print version. The publisher reserves the right to remove any material in this eBook at any time.

ISBN 10: $1-292-42237-8$ (print)

ISBN 13: $978-1-292-42237-4$ (print)

ISBN 13: 978-1-292-42235-0 (uPDF eBook)

British Library Cataloguing-in-Publication Data

A catalogue record for this book is available from the British Library.

eBook formatted by B2R Technologies Pvt. Ltd. Dedicated to the memory of Professor Richard C. Dorf This page is intentionally left blank 

\section{Brief Contents}

Preface 15

About the Authors 27

CHAPTER 1 Introduction to Control Systems 29

CHAPTER 2 Mathematical Models of Systems 79

CHAPTER 3 State Variable Models 184

Chapter $4 \quad$ Feedback Control System Characteristics 256

Chapter 5 The Performance of Feedback Control Systems 321

CHAPTER 6 The Stability of Linear Feedback Systems 394

CHAPTER 7 The Root Locus Method 446

CHAPTER 8 Frequency Response Methods $\mathbf{5 4 5}$

CHAPTER 9 Stability in the Frequency Domain 622

ChAPTER 10 The Design of Feedback Control Systems 728

CHAPTER 11 The Design of State Variable Feedback Systems 812

ChAPTER 12 Robust Control Systems 882

Chapter 13 Digital Control Systems 945

References 997

Index 1014 This page is intentionally left blank 

\section{Contents}

\section{Preface 15}

About the Authors 27

\section{CHAPTER 1 Introduction to Control Systems 29}

1.1 Introduction 30

1.2 Brief History of Automatic Control 33

1.3 Examples of Control Systems 39

1.4 Engineering Design 46

1.5 Control System Design 47

1.6 Mechatronic Systems 50

1.7 Green Engineering 54

1.8 The Future Evolution of Control Systems 55

1.9 Design Examples 57

1.10 Sequential Design Example: Disk Drive Read System 62

1.11 Summary 63

Skills Check $63 \cdot$ Exercises 66 - Problems 68 • Advanced

Problems 73 • Design Problems $75 \bullet$ Terms and Concepts 78

\section{CHAPTER 2 Mathematical Models of Systems 79}

2.1 Introduction 80

2.2 Differential Equations of Physical Systems 80

2.3 Linear Approximations of Physical Systems 85

2.4 The Laplace Transform 88

2.5 The Transfer Function of Linear Systems 95

2.6 Block Diagram Models 107

2.7 Signal-Flow Graph Models 112

2.8 Design Examples 119

2.9 The Simulation of Systems Using Control Design Software 136

2.10 Sequential Design Example: Disk Drive Read System 150

2.11 Summary 153

Skills Check 154 • Exercises 158 • Problems 164 • Advanced

Problems 176 • Design Problems 178 • Computer Problems 180 •

Terms and Concepts 182

\section{CHAPTER 3 State Variable Models 184}

3.1 Introduction 185

3.2 The State Variables of a Dynamic System 185

3.3 The State Differential Equation 188 3.4 Signal-Flow Graph and Block Diagram Models 194

3.5 Alternative Signal-Flow Graph and Block Diagram Models 205

3.6 The Transfer Function from the State Equation 209

3.7 The Time Response and the State Transition Matrix 210

3.8 Design Examples 214

3.9 Analysis of State Variable Models Using Control Design Software 228

3.10 Sequential Design Example: Disk Drive Read System 232

3.11 Summary 235

Skills Check 236 • Exercises $239 \bullet$ Problems 242 - Advanced Problems 250 • Design Problems 252 • Computer Problems 253 • Terms and Concepts 254

\section{CHAPTER 4 Feedback Control System Characteristics 256}

4.1 Introduction 257

4.2 Error Signal Analysis 259

4.3 Sensitivity of Control Systems to Parameter Variations 261

4.4 Disturbance Signals in a Feedback Control System 264

4.5 Control of the Transient Response 269

4.6 Steady-State Error 272

4.7 The Cost of Feedback 274

4.8 Design Examples 275

4.9 Control System Characteristics Using Control Design Software 285

4.10 Sequential Design Example: Disk Drive Read System 291

4.11 Summary 295

Skills Check 296 • Exercises 300 • Problems 304 • Advanced Problems 310 • Design Problems 313 • Computer Problems 317 • Terms and Concepts 320

\section{CHAPTER 5 The Performance of Feedback Control Systems 321}

5.1 Introduction 322

5.2 Test Input Signals 322

5.3 Performance of Second-Order Systems 325

5.4 Effects of a Third Pole and a Zero on the Second-Order System Response 330

5.5 The $s$-Plane Root Location and the Transient Response 335

5.6 The Steady-State Error of Feedback Control Systems 337

5.7 Performance Indices 344

5.8 The Simplification of Linear Systems 349

5.9 Design Examples 352

5.10 System Performance Using Control Design Software 364

5.11 Sequential Design Example: Disk Drive Read System 370 5.12 Summary 372

Skills Check 373 • Exercises 376 • Problems $379 \bullet$ Advanced

Problems 385 • Design Problems 387 • Computer Problems 390 •

Terms and Concepts 393

\section{CHAPTER 6 The Stability of Linear Feedback Systems 394}

6.1 The Concept of Stability 395

6.2 The Routh-Hurwitz Stability Criterion 399

6.3 The Relative Stability of Feedback Control Systems 407

6.4 The Stability of State Variable Systems 408

6.5 Design Examples 411

6.6 System Stability Using Control Design Software 419

6.7 Sequential Design Example: Disk Drive Read System 425

6.8 Summary 427

Skills Check 428 • Exercises 431 - Problems 433 • Advanced

Problems 438 • Design Problems 441 - Computer Problems 443 •

Terms and Concepts 445

\section{CHAPTER 7 The Root Locus Method 446}

7.1 Introduction 447

7.2 The Root Locus Concept 447

7.3 The Root Locus Procedure 452

7.4 Parameter Design by the Root Locus Method 466

7.5 Sensitivity and the Root Locus 472

7.6 PID Controllers 477

7.7 Negative Gain Root Locus 488

7.8 Design Examples 493

7.9 The Root Locus Using Control Design Software 502

7.10 Sequential Design Example: Disk Drive Read System 508

7.11 Summary 510

Skills Check 514 • Exercises 518 • Problems 522 • Advanced

Problems 531 • Design Problems 535 - Computer Problems 541 •

Terms and Concepts 543

\section{CHAPTER 8 Frequency Response Methods $\mathbf{5 4 5}$}

8.1 Introduction 546

8.2 Frequency Response Plots 548

8.3 Frequency Response Measurements 569

8.4 Performance Specifications in the Frequency Domain 571

8.5 Log-Magnitude and Phase Diagrams 574

8.6 Design Examples 575

8.7 Frequency Response Methods Using Control Design Software 584 8.8 Sequential Design Example: Disk Drive Read System 589

8.9 Summary 591

Skills Check 596 • Exercises 601 • Problems 604 • Advanced

Problems 613 • Design Problems 615 • Computer Problems 618 •

Terms and Concepts 620

\section{CHAPTER 9 Stability in the Frequency Domain 622}

9.1 Introduction 623

9.2 Mapping Contours in the $s$-Plane 624

9.3 The Nyquist Criterion 630

9.4 Relative Stability and the Nyquist Criterion 641

9.5 Time-Domain Performance Criteria in the Frequency Domain 648

9.6 System Bandwidth 655

9.7 The Stability of Control Systems with Time Delays 655

9.8 Design Examples 659

9.9 PID Controllers in the Frequency Domain 677

9.10 Stability in the Frequency Domain Using Control Design Software 678

9.11 Sequential Design Example: Disk Drive Read System 686

9.12 Summary 689

Skills Check 698 • Exercises 701 • Problems 707 • Advanced

Problems 717 • Design Problems 720 • Computer Problems 725 • Terms and Concepts 727

\section{CHAPTER 10 The Design of Feedback Control Systems 728}

10.1 Introduction 729

10.2 Approaches to System Design 730

10.3 Cascade Compensators 731

10.4 Phase-Lead Design Using the Bode Plot 735

10.5 Phase-Lead Design Using the Root Locus 741

10.6 System Design Using Integration Compensators 747

10.7 Phase-Lag Design Using the Root Locus 750

10.8 Phase-Lag Design Using the Bode Plot 753

10.9 Design on the Bode Plot Using Analytical Methods 758

10.10 Systems with a Prefilter 759

10.11 Design for Deadbeat Response 762

10.12 Design Examples 764

10.13 System Design Using Control Design Software 774

10.14 Sequential Design Example: Disk Drive Read System 781

10.15 Summary 783

Skills Check 784 • Exercises 788 - Problems 792 • Advanced Problems 801 • Design Problems 804 • Computer Problems 808 • Terms and Concepts 811 

\section{CHAPTER 11 The Design of State Variable Feedback Systems 812}

11.1 Introduction 813

11.2 Controllability and Observability 813

11.3 Full-State Feedback Control Design 819

11.4 Observer Design 825

11.5 Integrated Full-State Feedback and Observer 829

11.6 Reference Inputs 835

11.7 Optimal Control Systems 837

11.8 Internal Model Design 845

11.9 Design Examples 848

11.10 State Variable Design Using Control Design Software 855

11.11 Sequential Design Example: Disk Drive Read System 860

11.12 Summary 862

Skills Check 862 • Exercises 866 • Problems 868 • Advanced Problems 872 • Design Problems 875 • Computer Problems 878 • Terms and Concepts 881

\section{CHAPTER 12 Robust Control Systems 882}

12.1 Introduction 883

12.2 Robust Control Systems and System Sensitivity 884

12.3 Analysis of Robustness 888

12.4 Systems with Uncertain Parameters 890

12.5 The Design of Robust Control Systems 892

12.6 The Design of Robust PID-Controlled Systems 896

12.7 The Robust Internal Model Control System 900

12.8 Design Examples 903

12.9 The Pseudo-Quantitative Feedback System 914

12.10 Robust Control Systems Using Control Design Software 916

12.11 Sequential Design Example: Disk Drive Read System 919

12.12 Summary 921

Skills Check 923 • Exercises 927 • Problems 929 • Advanced Problems 933 • Design Problems 936 • Computer Problems 941 • Terms and Concepts 944

\section{ChAPTER 13 Digital Control Systems 945}

13.1 Introduction 946

13.2 Digital Computer Control System Applications 946

13.3 Sampled-Data Systems 948

13.4 The $z$-Transform 951

13.5 Closed-Loop Feedback Sampled-Data Systems 955

13.6 Performance of a Sampled-Data, Second-Order System 959 13.7 Closed-Loop Systems with Digital Computer Compensation 961

13.8 The Root Locus of Digital Control Systems 964

13.9 Implementation of Digital Controllers 968

13.10 Design Examples 968

13.11 Digital Control Systems Using Control Design Software 977

13.12 Sequential Design Example: Disk Drive Read System 982

13.13 Summary 984

Skills Check 984 • Exercises 988 • Problems 990 • Advanced

Problems 992 • Design Problems 993 - Computer Problems 995 •

Terms and Concepts 996

References 997

Index 1014

\section{WEB RESOURCES}

APPENDIX A MATLAB Basics

APPENDIX B MathScript RT Module Basics

APPENDIX C Symbols, Units, and Conversion Factors

APPENDIX D Laplace Transform Pairs

APPEndix E An Introduction to Matrix Algebra

appendix F Decibel Conversion

APPENDIX G Complex Numbers

APPENDIX H $z$-Transform Pairs

APPENDIX I Discrete-Time Evaluation of the Time Response

APPENDIX J Design Aids 

\section{Preface}

\section{MODERN CONTROL SYSTEMS-THE BOOK}

Global issues such as climate change, clean water, sustainability, pandemics, waste management, emissions reduction, and minimizing raw material and energy use have led many engineers to re-think existing approaches to engineering design. One outcome of the evolving design strategy is to consider green engineering and human-centered design. The goal of these approaches to engineering is to design products that minimize pollution, reduce the risk to human health, and improve the living environment. Applying the principles of green engineering and human-centered design highlights the power of feedback control systems as an enabling technology.

To reduce greenhouse gases and minimize pollution, it is necessary to improve both the quality and quantity of our environmental monitoring systems. One example is to use wireless measurements on mobile sensing platforms to measure the external environment. Another example is to monitor the quality of the delivered power to measure leading and lagging power, voltage variations, and waveform harmonics. Many green engineering systems and components require careful monitoring of current and voltages. For example, current transformers are used in various capacities for measuring and monitoring current within the power grid network of interconnected systems used to deliver electricity. Sensors are key components of any feedback control system because the measurements provide the required information as to the state of the system so the control system can take the appropriate action.

The role of control systems will continue to expand as the global issues facing us require ever increasing levels of automation and precision. In the book, we present key examples from green engineering such as wind turbine control and modeling of a photovoltaic generator for feedback control to achieve maximum power delivery as the sunlight varies over time.

The wind and sun are important sources of renewable energy around the world. Wind energy conversion to electric power is achieved by wind energy turbines connected to electric generators. The intermittency characteristic of the wind makes smart grid development essential to bring the energy to the power grid when it is available and to provide energy from other sources when the wind dies down or is disrupted. A smart grid can be viewed as a system comprised of hardware and software that routes power more reliably and efficiently to homes, businesses, schools, and other users of power in the presence of intermittency and other disturbances. The irregular character of wind direction and power also results in the need for reliable, steady electric energy by using control systems on the wind turbines themselves. The goal of these control devices is to reduce the effects of wind intermittency and the effect of wind direction change. Energy storage systems are also critical technologies for green engineering. We seek energy storage systems that are renewable, such as fuel cells. Active control can be a key element of effective renewable energy storage systems as well. Another exciting development for control systems is the evolution of the Internet of Things - a network of physical objects embedded with electronics, software, sensors and connectivity. As envisioned, each of the millions of the devices on the network will possess an embedded computer with connectivity to the Internet. The ability to control these connected devices will be of great interest to control engineers. Indeed, control engineering is an exciting and a challenging field. By its very nature, control engineering is a multidisciplinary subject, and it has taken its place as a core course in the engineering curriculum. It is reasonable to expect different approaches to mastering and practicing the art of control engineering. Since the subject has a strong mathematical foundation, we might approach it from a strictly theoretical point of view, emphasizing theorems and proofs. On the other hand, since the ultimate objective is to implement controllers in real systems, we might take an ad hoc approach relying only on intuition and hands-on experience when designing feedback control systems. Our approach is to present a control engineering methodology that, while based on mathematical fundamentals, stresses physical system modeling and practical control system designs with realistic system specifications.

We believe that the most important and productive approach to learning is for each of us to rediscover and re-create anew the answers and methods of the past. Thus, the ideal is to present the student with a series of problems and questions and point to some of the answers that have been obtained over the past decades. The traditional method-to confront the student not with the problem but with the finished solution - is to deprive the student of all excitement, to shut off the creative impulse, to reduce the adventure of humankind to a dusty heap of theorems. The issue, then, is to present some of the unanswered and important problems that we continue to confront, for it may be asserted that what we have truly learned and understood, we discovered ourselves.

The purpose of this book is to present the structure of feedback control theory and to provide a sequence of exciting discoveries as we proceed through the text and problems. If this book is able to assist the student in discovering feedback control system theory and practice, it will have succeeded.

\section{WHAT'S NEW IN THIS EDITION}

This latest edition of Modern Control Systems incorporates the following key updates:

$\square \quad$ Available as both an eText and print book.

$\square \quad$ Video solutions for select problems throughout the text.

$\square \quad$ Interactive figures added throughout the eText to enhance student learning.

$\square \quad$ In the eText, interactive Skills Check multiple-choice questions at the end of each chapter.

$\square \quad$ Over $20 \%$ new or updated problems. There are over 980 end-of-chapter exercises, problems, advanced problems, design problems, and computer problems.

$\square \quad$ Expanded use of color for clarity of presentation.

$\square \quad$ An updated companion website available at www.pearsonglobaleditions.com for students and faculty. 

\section{THE AUDIENCE}

This text is designed for an introductory undergraduate course in control systems for engineering students. There is very little demarcation between the various engineering areas in control system practice; therefore, this text is written without any conscious bias toward one discipline. Thus, it is hoped that this book will be equally useful for all engineering disciplines and, perhaps, will assist in illustrating the utility of control engineering. The numerous problems and examples represent all fields, and the examples of the sociological, biological, ecological, and economic control systems are intended to provide the reader with an awareness of the general applicability of control theory to many facets of life. We believe that exposing students of one discipline to examples and problems from other disciplines will provide them with the ability to see beyond their own field of study. Many students pursue careers in engineering fields other than their own. We hope this introduction to control engineering will give students a broader understanding of control system design and analysis.

In its first thirteen editions, Modern Control Systems has been used in seniorlevel courses for engineering students at many colleges and universities globally. It also has been used in courses for engineering graduate students with no previous background in control engineering.

\section{THE FOURTEENTH EDITION}

With the fourteenth edition, we have created an interactive e-textbook to fully use rich, digital content for Modern Control Systems to enhance the learning experience. This version contains embedded videos, dynamic graphs, live Skills Check quizzes, and active links to additional resources. The electronic version provides a powerful interactive experience that would be difficult, if not impossible, to achieve in a print book.

A companion website is also available to students and faculty using the fourteenth edition. The website contains many resources, including the $\mathrm{m}$-files in the book, Laplace and $z$-Transform tables, written materials on matrix algebra and complex numbers, symbols, units, and conversion factors, and an introduction to MATLAB and to the LabVIEW MathScript RT Module. The MCS website is available at www.pearsonglobaleditions.com.

We continue the design emphasis that historically has characterized Modern Control Systems. Using the real-world engineering problems associated with designing a controller for a disk drive read system, we present the Sequential Design Example, which is considered sequentially in each chapter using the methods and concepts in that chapter. Disk drives are used in computers of all sizes and they represent an important application of control engineering. Various aspects of the design of controllers for the disk drive read system are considered in each chapter. For example, in Chapter 1 we identify the control goals, identify the variables to be controlled, write the control specifications, and establish the preliminary system configuration for the disk drive. Then, in Chapter 2, we obtain models of the process, sensors, and actuators. In the remaining chapters, we continue the design process, stressing the main points of the chapters.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0019.jpg?height=407&width=605&top_left_y=295&top_left_x=375)

In the same spirit as the Sequential Design Example, we present a design problem that we call the Continuous Design Problem to give students the opportunity to build upon a design problem from chapter to chapter. High-precision machinery places stringent demands on table slide systems. In the Continuous Design Problem, students apply the techniques and tools presented in each chapter to the development of a design solution that meets the specified requirements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0019.jpg?height=579&width=458&top_left_y=1063&top_left_x=373)

The computer-aided design and analysis component of the book continues to evolve and improve. Also, many of the solutions to various components of the Sequential Design Example utilize m-files with corresponding scripts included in the figures.

A Skills Check section is included at the end of each chapter. In each Skills Check section, we provide three sets of problems to test your knowledge of the chapter material. This includes True or False, Multiple Choice, and Word Match problems. To obtain direct feedback, you can check your answers with the answer key provided at the conclusion of the end-of-chapter problems. The book is organized around the concepts of control system theory as they have been developed in the frequency and time domains. An attempt has been made to make the selection of topics, as well as the systems discussed in the examples and problems, modern in the best sense. Therefore, this book includes discussions on robust control systems and system sensitivity, state variable models, controllability and observability, computer control systems, internal model control, robust PID controllers, and computer-aided design and analysis, to name a few. However, the classical topics of control theory that have proved to be so very useful in practice have been retained and expanded.

Building Basic Principles: From Classical to Modern. Our goal is to present a clear exposition of the basic principles of frequency and time-domain design techniques. The classical methods of control engineering are thoroughly covered: Laplace transforms and transfer functions; root locus design; Routh-Hurwitz stability analysis; frequency response methods, including Bode, Nyquist, and Nichols; steady-state error for standard test signals; second-order system approximations; and phase and gain margin and bandwidth. In addition, coverage of the state variable method is significant. Fundamental notions of controllability and observability for state variable models are discussed. Full state feedback design with Ackermann's formula for pole placement is presented, along with a discussion on the limitations of state variable feedback. Observers are introduced as a means to provide state estimates when the complete state is not measured.

Upon this strong foundation of basic principles, the book provides many opportunities to explore topics beyond the traditional. In the latter chapters, we present introductions into more advanced topics of robust control and digital control, as well as an entire chapter devoted to the design of feedback control systems with a focus on practical industrial lead and lag compensator structures. Problem solving is emphasized throughout the chapters. Each chapter (but the first) introduces the student to the notion of computer-aided design and analysis.

Progressive Development of Problem-Solving Skills. Reading the chapters, attending lectures and taking notes, and working through the illustrated examples are all part of the learning process. But the real test comes at the end of the chapter with the problems. The book takes the issue of problem solving seriously. In each chapter, there are five problem types:

$\square$ Exercises

$\square \quad$ Problems

$\square \quad$ Advanced Problems

$\square \quad$ Design Problems

$\square$ Computer Problems

For example, the problem set for Mathematical Models of Systems, Chapter 2 includes 31 exercises, 51 problems, 9 advanced problems, 6 design problems, and 10 computer-based problems. The exercises permit the students to readily utilize the concepts and methods introduced in each chapter by solving relatively straightforward exercises before attempting the more complex problems. The problems require an extension of the concepts of the chapter to new situations. The advanced problems represent problems of increasing complexity. The design problems emphasize the design task; the computer-based problems give the student practice with problem solving using computers. In total, the book contains more than 980 problems. The abundance of problems of increasing complexity gives students confidence in their problem solving ability as they work their way from the exercises to the design and computer-based problems. An instructor's manual, available to all adopters of the text for course use, contains complete solutions to all end-of-chapter problems.

A set of m-files, the Modern Control Systems Toolbox, has been developed by the authors to supplement the text. The m-files contain the scripts from each computer-based example in the text. You may retrieve the m-files from the companion available at www.pearsonglobaleditions.com.

Design Emphasis without Compromising Basic Principles. The all-important topic of design of real-world, complex control systems is a major theme throughout the text. Emphasis on design for real-world applications addresses interest in design by ABET and industry.

The design process consists of seven main building blocks that we arrange into three groups:

1. Establishment of goals and variables to be controlled, and definition of specifications (metrics) against which to measure performance

2. System definition and modeling

3. Control system design and integrated system simulation and analysis

In each chapter of this book, we highlight the connection between the design process and the main topics of that chapter. The objective is to demonstrate different aspects of the design process through illustrative examples.

Various aspects of the control system design process are illustrated in detail in many examples across all the chapters, including applications of control design in robotics, manufacturing, medicine, and transportation (ground, air, and space).

Each chapter includes a section to assist students in utilizing computer-aided design and analysis concepts and in reworking many of the design examples. Generally, m-files scripts are provided that can be used in the design and analyses of the feedback control systems. Each script is annotated with comment boxes that highlight important aspects of the script. The accompanying output of the script (generally a graph) also contains comment boxes pointing out significant elements. The scripts can also be utilized with modifications as the foundation for solving other related problems.

Learning Enhancement. Each chapter begins with a chapter preview describing the topics the student can expect to encounter. The chapters conclude with an end-of-chapter summary, skills check, as well as terms and concepts. These sections Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0022.jpg?height=296&width=404&top_left_y=339&top_left_x=412)

just one or two topics.
In this column remarks relate the design topics on the left to specific sections, figures, equations, and tables in the example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0022.jpg?height=113&width=49&top_left_y=336&top_left_x=1556)

(1) Establishment of goals, variables to be controlled, and specifications.

2) System definition and modeling.

(3) Control system design, simulation, and analysis.
If the performance does not meet the specifications, then iterate the configuration.
Write the specifications

Obtain a model of the process, the actuator, and the sensor

Describe a controller and select key parameters to be adjusted

Optimize the parameters and analyze the performance

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0022.jpg?height=77&width=56&top_left_y=1200&top_left_x=1202)

If the performance meets the specifications, then finalize the design.

reinforce the important concepts introduced in the chapter and serve as a reference for later use.

Color is used to add emphasis when needed and to make the graphs and figures easier to interpret. For example, consider the computer control of a robot to spray-paint an automobile. We might ask the student to investigate the closed-loop system stability for various values of the controller gain $K$ and to determine the response to a unit step disturbance, $T_{d}(s)=1 / s$, when the input $R(s)=0$. The associated figure assists the student with (a) visualizing the problem, and (b) taking the next step to develop the transfer function model and to complete the analyses.

\section{THE ORGANIZATION}

Chapter 1 Introduction to Control Systems. Chapter 1 provides an introduction to the basic history of control theory and practice. The purpose of this chapter is to describe the general approach to designing and building a control system. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0023.jpg?height=577&width=851&top_left_y=156&top_left_x=508)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0023.jpg?height=393&width=671&top_left_y=878&top_left_x=543)

(b)

Chapter 2 Mathematical Models of Systems. Mathematical models of physical systems in input-output or transfer function form are developed in Chapter 2. A wide range of systems are considered.

Chapter 3 State Variable Models. Mathematical models of systems in state variable form are developed in Chapter 3. The transient response of control systems and the performance of these systems are examined.

Chapter 4 Feedback Control System Characteristics. The characteristics of feedback control systems are described in Chapter 4. The advantages of feedback are discussed, and the concept of the system error signal is introduced.

Chapter 5 The Performance of Feedlback Control Systems. In Chapter 5, the performance of control systems is examined. The performance of a control system is correlated with the s-plane location of the poles and zeros of the transfer function of the system. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0024.jpg?height=468&width=1246&top_left_y=156&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0024.jpg?height=341&width=1016&top_left_y=695&top_left_x=637)

(b)

Chapter 6 The Stability of Linear Feedback Systems. The stability of feedback systems is investigated in Chapter 6. The relationship of system stability to the characteristic equation of the system transfer function is studied. The RouthHurwitz stability criterion is introduced.

Chapter 7 The Root Locus Method. Chapter 7 deals with the motion of the roots of the characteristic equation in the $s$-plane as one or two parameters are varied. The locus of roots in the $s$-plane is determined by a graphical method. We also introduce the popular PID controller and the Ziegler-Nichols PID tuning method.

Chapter 8 Frequency Response Methods. In Chapter 8, a steady-state sinusoid input signal is utilized to examine the steady-state response of the system as the frequency of the sinusoid is varied. The development of the frequency response plot, called the Bode plot, is considered.

Chapter 9 Stability in the Frequency Domain. System stability utilizing frequency response methods is investigated in Chapter 9. Relative stability and the Nyquist criterion are discussed. Stability is considered using Nyquist plots, Bode plots, and Nichols charts.

Chapter 10 The Design of Feedback Control Systems. Several approaches to designing and compensating a control system are described and developed in Chapter 10. Various candidates for service as compensators are presented and it is shown how they help to achieve improved performance. The focus is on lead and lag compensators.

Chapter 11 The Design of State Variable Feedback Systems. The main topic of Chapter 11 is the design of control systems using state variable models. Full-state feedback design and observer design methods based on pole placement are discussed. Tests for controllability and observability are presented, and the concept of an internal model design is discussed.

Chapter 12 Robust Control Systems. Chapter 12 deals with the design of highly accurate control systems in the presence of significant uncertainty. Five methods for robust design are discussed, including root locus, frequency response, ITAE methods for robust PID controllers, internal models, and pseudo-quantitative feedback.

Chapter 13 Digital Control Systems. Methods for describing and analyzing the performance of computer control systems are described in Chapter 13. The stability and performance of sampled-data systems are discussed.

\section{ACKNOWLEDGMENTS}

We wish to express our sincere appreciation to the following individuals who have assisted us with the development of this Fourteenth edition, as well as all previous editions: John Hung, Auburn University; Zak Kassas, University of California-Irvine; Hanz Richter, Cleveland State Universtiy; Abhishek Gupta, The Ohio State University; Darris White, Embry Riddle Aeronautical University; John K. Schueller, University of Florida; Mahmoud A. Abdallah, Central Sate University ( $\mathrm{OH})$; John N. Chiasson, University of Pittsburgh; Samy El-Sawah, California State Polytechnic University, Pomona; Peter J. Gorder, Kansas State University; Duane Hanselman, University of Maine; Ashok Iyer, University of Nevada, Las Vegas; Leslie R. Koval, University of Missouri-Rolla; L. G. Kraft, University of New Hampshire; Thomas Kurfess, Georgia Institute of Technology; Julio C. Mandojana, Mankato State University; Luigi Mariani, University of Padova; Jure Medanic, University of Illinois at Urbana- Champaign; Eduardo A. Misawa, Oklahoma State University; Medhat M. Morcos, Kansas State University; Mark Nagurka, Marquette University; D. Subbaram Naidu, Idaho State University; Ron Perez, University of Wisconsin-Milwaukee; Carla Schwartz, The MathWorks, Inc.; Murat Tanyel, Dordt College; Hal Tharp, University of Arizona; John Valasek, Texas A \& M University; Paul P. Wang, Duke University; and Ravi Warrier, GMI Engineering and Management Institute. Special thanks to Greg Mason, Seattle University, and Jonathan Sprinkle, University of Arizona, for developing the interactives and the video solutions. 

\section{ACKNOWLEDGMENTS FOR THE GLOBAL EDITION}

Pearson would like to acknowledge and thank the following for the Global Edition:

\section{CONTRIBUTORS}

Benjamin Chong, University of Leeds

Murat Doğruel, Marmara University

Quang Ha, University of Technology Sydney

Ashish Rajeshwar Kulkarni, Delhi Technological University

Savita Nema, Maulana Azad National Institute of Technology Bhopal

Mark Ovinis, Universiti Teknologi PETRONAS

Bidyadhar Subudhi, National Institute of Technology Rourkela

\section{REVIEWERS}

Quang Ha, University of Technology Sydney

Shen Hin Lim, University of Waikato

Mark Ovinis, Universiti Teknologi PETRONAS

Fuwen Yang, Griffith University

\section{OPEN LINES OF COMMUNICATION}

The authors would like to establish a line of communication with the users of Modern Control Systems. We encourage all readers to send comments and suggestions for this and future editions. By doing this, we can keep you informed of any general-interest news regarding the textbook and pass along comments of other users.

Keep in touch!

Robert H. Bishop

robertbishop@usf.edu This page is intentionally left blank 

\section{About the Authors}

Richard C. Dorf was Emeriti Faculty of Electrical and Computer Engineering at the University of California, Davis. Known as an instructor who was highly concerned with the discipline of electrical engineering and its application to social and economic needs, Professor Dorf wrote and edited several successful engineering textbooks and handbooks, including the best selling Engineering Handbook, second edition and the third edition of the Electrical Engineering Handbook. Professor Dorf was also co-author of Technology Ventures, a leading textbook on technology entrepreneurship. Professor Dorf was a Fellow of the IEEE and a Fellow of the ASEE. Dr. Dorf held a patent for the PIDA controller.

Robert H. Bishop is the Dean of Engineering at the University of South Florida, President and CEO of the Institute of Applied Engineering, and a Professor in the Department of Electrical Engineering. Prior to coming to The University of South Florida, he was the Dean of Engineering at Marquette University and before that a Department Chair and Professor of Aerospace Engineering and Engineering Mechanics at The University of Texas at Austin where he held the Joe J. King Professorship and was a Distinguished Teaching Professor. Professor Bishop started his engineering career as a member of the technical staff at the Charles Stark Draper Laboratory. He authors the well-known textbook for teaching graphical programming entitled Learning with LabVIEW and is also the editor-in-chief of the Mechatronics Handbook. Professor Bishop remains an active teacher and researcher and has authored/co-authored over one hundred and forty-five journal and conference papers. He is a Fellow of the AIAA, a Fellow of the American Astronautical Society (AAS), a Fellow of the American Association for the Advancement of Science (AAAS) and active in ASEE and in the Institute of Electrical and Electronics Engineers (IEEE). This page is intentionally left blank 

\section{CHAPTER}

\section{Introduction to Control}

\section{Systems}

1.1 Introduction 30

1.2 Brief History of Automatic Control 33

1.3 Examples of Control Systems 39

1.4 Engineering Design 46

1.5 Control System Design 47

1.6 Mechatronic Systems 50

1.7 Green Engineering 54

1.8 The Future Evolution of Control Systems 55

1.9 Design Examples 57

1.10 Sequential Design Example: Disk Drive Read System 62

1.11 Summary 63

\section{PREVIEW}

A control system consists of interconnected components to achieve a desired purpose. In this chapter, we discuss open- and closed-loop feedback control systems. We examine examples of control systems through the course of history. Early systems incorporated many of the basic ideas of feedback that are employed in modern control systems. A design process is presented that encompasses the establishment of goals and variables to be controlled, definition of specifications, system definition, modeling, and analysis. The iterative nature of design allows us to handle the design gap effectively while accomplishing necessary trade-offs in complexity, performance, and cost. Finally, we introduce the Sequential Design Example: Disk Drive Read System. This example will be considered sequentially in each chapter of this book. It represents a practical control system design problem while simultaneously serving as a useful learning tool.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 1, students should be able to:

$\square$ Give illustrative examples of control systems and describe their relationship to key contemporary issues.

$\square \quad$ Recount a brief history of control systems and their role in society.

$\square \quad$ Predict the future of controls in the context of their evolutionary pathways.

$\square \quad$ Recognize the elements of control system design and possess an appreciation of appreciate controls in the context of engineering design. 

\subsection{INTRODUCTION}

Engineers create products that help people. Our quality of life is sustained and enhanced through engineering. To accomplish this, engineers strive to understand, model, and control the materials and forces of nature for the benefit of humankind. A key area of engineering that reaches across many technical areas is the multidisciplinary field of control system engineering. Control engineers are concerned with understanding and controlling segments of their environment, often called systems, which are interconnections of elements and devices for a desired purpose. The system might be something as clear-cut as an automobile cruise control system, or as extensive and complex as a direct brain-to-computer system to control a manipulator. Control engineering deals with the design (and implementation) of control systems using linear, time-invariant mathematical models representing actual physical nonlinear, time-varying systems with parameter uncertainties in the presence of external disturbances. As computer systems-especially embedded processors - have become less expensive, require less power and space, while growing more computationally powerful, at the same time that sensors and actuators have simultaneously experienced the same evolution to more capability in smaller packages, the application of control systems has grown in number and complexity. A sensor is a device that provides a measurement of a desired external signal. For example, resistance temperature detectors (RTDs) are sensors used to measure temperature. An actuator is a device employed by the control system to alter or adjust the environment. An electric motor drive used to rotate a robotic manipulator is an example of a device transforming electric energy to mechanical torque.

The face of control engineering is rapidly changing. The age of the Internet of Things (IoT) presents many intriguing challenges in control system applications in the environment (think about more efficient energy use in homes and businesses), manufacturing (think 3D printing), consumer products, energy, medical devices and healthcare, transportation (think about automated cars!), among many others [14]. A challenge for control engineers today is to be able to create simple, yet reliable and accurate mathematical models of many of our modern, complex, interrelated, and interconnected systems. Fortunately, many modern design tools are available, as well as open source software modules and Internet-based user groups (to share ideas and answer questions), to assist the modeler. The implementation of the control systems themselves is also becoming more automated, again assisted by many resources readily available on the Internet coupled with access to relatively inexpensive computers, sensors, and actuators. Control system engineering focuses on the modeling of a wide assortment of physical systems and using those models to design controllers that will cause the closed-loop systems to possess desired performance characteristics, such as stability, relative stability, steady-state tracking with prescribed maximum errors, transient tracking (percent overshoot, settling time, rise time, and time to peak), rejection of external disturbances, and robustness to modeling uncertainties. The extremely important step of the overall design and implementation process is designing the control systems, such as PID controllers, lead and lag controllers, state variable feedback controllers, and other popular controller structures. That is what this textbook is all about! FIGURE 1.1

Process to be controlled.

FIGURE 1.2 Open-loop control system (without feedback).
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0032.jpg?height=302&width=1052&top_left_y=152&top_left_x=509)

Control system engineering is based on the foundations of feedback theory and linear system analysis, and it integrates the concepts of network theory and communication theory. It is founded on a strong mathematical foundation, yet is very practical and impacts our lives every day in almost all we do. Indeed, control engineering is not limited to any engineering discipline but is equally applicable to aerospace, agricultural, biomedical, chemical, civil, computer, industrial, electrical, environmental, mechanical, nuclear engineering, and even computer science. Many aspects of control engineering can also be found in studies in systems engineering.

A control system is an interconnection of components forming a system configuration that will provide a desired system response. The basis for analysis of a system is the foundation provided by linear system theory, which assumes a causeeffect relationship for the components of a system. A component, or process, to be controlled can be represented graphically, as shown in Figure 1.1. The input-output relationship represents the cause-and-effect relationship of the process, which in turn represents a processing of the input signal to provide a desired output signal. An open-loop control system uses a controller and an actuator to obtain the desired response, as shown in Figure 1.2. An open-loop system is a system without feedback.

\section{An open-loop control system utilizes an actuating device to control the process directly without using feedback.}

In contrast to an open-loop control system, a closed-loop control system utilizes an additional measure of the actual output to compare the actual output with the desired output response. The measure of the output is called the feedback signal. A simple closed-loop feedback control system is shown in Figure 1.3. A feedback control system is a control system that tends to maintain a prescribed relationship of one system variable to another by comparing functions of these variables and using the difference as a means of control. With an accurate sensor, the measured output is a good approximation of the actual output of the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0032.jpg?height=256&width=1244&top_left_y=1862&top_left_x=507)

FIGURE 1.3

Closed-loop feedback control system (with feedback). A feedback control system often uses a function of a prescribed relationship between the output and reference input to control the process. Often the difference between the output of the process under control and the reference input is amplified and used to control the process so that the difference is continually reduced. In general, the difference between the desired output and the actual output is equal to the error, which is then adjusted by the controller. The output of the controller causes the actuator to modulate the process in order to reduce the error. For example, if a ship is heading incorrectly to the right, the rudder is actuated to direct the ship to the left. The system shown in Figure 1.3 is a negative feedback control system, because the output is subtracted from the input and the difference is used as the input signal to the controller. The feedback concept is the foundation for control system analysis and design.

\section{A closed-loop control system uses a measurement of the output and feedback of this signal to compare it with the desired output (reference or command).}

A closed-loop control has many advantages over open-loop control, including the ability to reject external disturbances and improve measurement noise attenuation. We incorporate disturbances and measurement noise in the block diagram as external inputs, as illustrated in Figure 1.4. External disturbances and measurement noise are inevitable in real-world applications and must be addressed in practical control system designs.

The feedback systems in Figures 1.3 and 1.4 are single-loop feedback systems. Many feedback control systems contain more than one feedback loop. A common multiloop feedback control system is illustrated in Figure 1.5 with an inner loop and an outer loop. In this scenario, the inner loop has a controller and a sensor and the outer loop has a controller and sensor. Other varieties of multiloop feedback systems are considered throughout the book as they represent more practical situations found in real-world applications. However, we use the single-loop feedback system for learning about the benefits of feedback control systems since the outcomes readily scale to multiloop systems.

Due to the increasing complexity of systems under active control and the interest in achieving optimum performance, the importance of control system engineering continues to grow. Furthermore, as the systems become more complex, the interrelationship of many controlled variables must be considered in the control scheme. A block diagram depicting a multivariable control system is shown in Figure 1.6.

FIGURE 1.4

Closed-loop feedback system with external disturbances and measurement noise.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0033.jpg?height=390&width=1244&top_left_y=1729&top_left_x=375)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0034.jpg?height=440&width=1494&top_left_y=154&top_left_x=255)

FIGURE 1.5 Multiloop feedback system with an inner loop and an outer loop.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0034.jpg?height=428&width=1455&top_left_y=710&top_left_x=298)

FIGURE 1.6 Multivariable control system.

A common example of an open-loop control system is a microwave oven set to operate for a fixed time. An example of a closed-loop control system is a person steering an automobile (assuming his or her eyes are open) by looking at the auto's location on the road and making the appropriate adjustments.

The introduction of feedback enables us to control a desired output and can improve accuracy, but it requires attention to the issues of stability and performance.

\subsection{BRIEF HISTORY OF AUTOMATIC CONTROL}

The use of feedback to control a system has a fascinating history. The first applications of feedback control appeared in the development of float regulator mechanisms in Greece in the period 300 to 1 в.с. [1, 2, 3]. The water clock of Ktesibios used a float regulator. An oil lamp devised by Philon in approximately 250 B.c. used a float regulator in an oil lamp for maintaining a constant level of fuel oil. Heron of Alexandria, who lived in the first century A.D., published a book entitled Pneumatica, which outlined several forms of water-level mechanisms using float regulators [1].

The first feedback system to be invented in modern Europe was the temperature regulator of Cornelis Drebbel (1572-1633) of Holland [1]. Dennis Papin (1647-1712) invented the first pressure regulator for steam boilers in 1681. Papin's pressure regulator was a form of safety regulator similar to a pressure-cooker valve. FIGURE 1.7 Watt's flyball governor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0035.jpg?height=727&width=851&top_left_y=154&top_left_x=372)

The first automatic feedback controller used in an industrial process is generally agreed to be James Watt's flyball governor, developed in 1769 for controlling the speed of a steam engine [1,2]. The all-mechanical device, illustrated in Figure 1.7, measured the speed of the output shaft and utilized the movement of the flyball to control the steam valve and therefore the amount of steam entering the engine. As depicted in Figure 1.7, the governor shaft axis is connected via mechanical linkages and beveled gears to the output shaft of the steam engine. As the steam engine output shaft speed increases, the ball weights rise and move away from the shaft axis and through mechanical linkages the steam valve closes and the engine slows down.

The first historical feedback system is the water-level float regulator said to have been invented by I. Polzunov in 1765 [4]. The level regulator system is illustrated in Figure 1.8. The float detects the water level and controls the valve that covers the water inlet in the boiler.

The next century was characterized by the development of automatic control systems through intuition and invention. Efforts to increase the accuracy of the control system led to slower attenuation of the transient oscillations and even to unstable systems. It then became imperative to develop a theory of automatic control. In 1868, J. C. Maxwell formulated a mathematical theory related to control theory using a differential equation model of a governor [5]. Maxwell's study was concerned with the effect various system parameters had on the system performance. During the same period, I. A. Vyshnegradskii formulated a mathematical theory of regulators [6].

Prior to World War II, control theory and practice developed differently in the United States and western Europe than in Russia and eastern Europe. The main FIGURE 1.8

Water-level float regulator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0036.jpg?height=537&width=445&top_left_y=155&top_left_x=516)

impetus for the use of feedback in the United States was the development of the telephone system and electronic feedback amplifiers by Bode, Nyquist, and Black at Bell Telephone Laboratories [7-10, 12].

Harold S. Black graduated from Worcester Polytechnic Institute in 1921 and joined Bell Laboratories of American Telegraph and Telephone (AT\&T). At that time, the major task confronting Bell Laboratories was the improvement of the telephone system and the design of improved signal amplifiers. Black was assigned the task of linearizing, stabilizing, and improving the amplifiers that were used in tandem to carry conversations over distances of several thousand miles. After years of working on oscillator circuits, Black had the idea of negative feedback amplifiers as a way to avoid self-oscillations. His idea would enhance the stability of circuit stability over a wide range of frequency bands [8].

The frequency domain was used primarily to describe the operation of the feedback amplifiers in terms of bandwidth and other frequency variables. In contrast, the eminent mathematicians and applied mechanicians in the former Soviet Union inspired and dominated the field of control theory. The Russian theory tended to utilize a time-domain formulation using differential equations.

The control of an industrial process (manufacturing, production, and so on) by automatic rather than manual means is often called automation. Automation is prevalent in the chemical, electric power, paper, automobile, and steel industries, among others. The concept of automation is central to our industrial society. Automatic machines are used to increase the production of a plant. Industries are concerned with the productivity per worker of their plants. Productivity is defined as the ratio of physical output to physical input [26]. In this case, we are referring to labor productivity, which is real output per hour of work.

A large impetus to the theory and practice of automatic control occurred during World War II when it became necessary to design and construct automatic airplane piloting, gun-positioning systems, radar antenna control systems, and other military systems based on the feedback control approach. The complexity and expected performance of these military systems necessitated an extension of the available control techniques and fostered interest in control systems and the development of new insights and methods. Prior to 1940, for most cases, the design of control systems was an art involving a trial-and-error approach. During the 1940s, mathematical and analytical methods increased in number and utility, and control engineering became an engineering discipline in its own right [10-12].

Another example of the discovery of an engineering solution to a control system problem was the creation of a gun director by David B. Parkinson of Bell Telephone Laboratories. In the spring of 1940, Parkinson was intent on improving the automatic level recorder, an instrument that used strip-chart paper to plot the record of a voltage. A critical component was a small potentiometer used to control the pen of the recorder through an actuator. If a potentiometer could be used to control the pen on a level recorder, might it be capable of controlling other machines such as an antiaircraft gun? [13].

After considerable effort, an engineering model was delivered for testing to the U.S. Army on December 1, 1941. Production models were available by early 1943 , and eventually 3000 gun controllers were delivered. Input to the controller was provided by radar, and the gun was aimed by taking the data of the airplane's present position and calculating the target's future position.

Frequency-domain techniques continued to dominate the field of control following World War II with the increased use of the Laplace transform and the complex frequency plane. During the 1950s, the emphasis in control engineering theory was on the development and use of the $s$-plane methods and, particularly, the root locus approach. Furthermore, during the 1980s, the use of digital computers for control components became routine. The technology of these new control elements to perform accurate and rapid calculations was formerly unavailable to control engineers. These computers are now employed especially for process control systems in which many variables are measured and controlled simultaneously by the computer.

With the advent of Sputnik and the space age, another new impetus was imparted to control engineering. It became necessary to design complex, highly accurate control systems for missiles and space probes. Furthermore, the necessity to minimize the weight of satellites and to control them very accurately has spawned the important field of optimal control. Due to these requirements, the time-domain methods developed by Liapunov, Minorsky, and others have been met with great interest. Theories of optimal control developed by L. S. Pontryagin in the former Soviet Union and R. Bellman in the United States, as well as studies of robust systems, have contributed to the interest in time-domain methods. Control engineering must consider both the time-domain and the frequency-domain approaches simultaneously in the analysis and design of control systems.

A notable advance with worldwide impact is the U.S. space-based radionavigation system known as the Global Positioning System or GPS [82-85]. In the distant past, various strategies and sensors were developed to keep explorers on the oceans from getting lost, including following coastlines, using compasses to point north, and sextants to measure the angles of stars, the moon, and the sun above the horizon. The early explorers were able to estimate latitude accurately, but not longitude. It was not until the 1700s with the development of the chronometer that, when used with the sextant, the longitude could be estimated. Radio-based navigation systems began to appear in the early twentieth century and were used in World War II. With the advent of Sputnik and the space age, it became known that radio signals from satellites could be used to navigate on the ground by observing the Doppler shift of the received radio signals. Research and development culminated in the 1990s with 24 navigation satellites (known as the GPS) that solved the fundamental problem that explorers faced for centuries by providing a dependable mechanism to pinpoint the current location. Freely available on a continuous worldwide basis, GPS provides very reliable location and time information anytime, day or night, anywhere in the world. Using GPS as a sensor to provide position (and velocity) information is a mainstay of active control systems for transportation systems in the air, on the ground, and on the oceans. The GPS assists relief and emergency workers to save lives, and helps us with our everyday activities including the control of power grids, banking, farming, surveying, and many other tasks.

Global navigation satellite services (such as GPS, GLONASS, and Galileo) providing position, navigation, and timing data coupled with evolving wireless mobile technology, highly capable mobile computing systems and devices, global geographic information systems, and semantic web are supporting the evolving field of ubiquitous positioning [100-103]. These systems can provide information on the location of people, vehicles, and other objects as a function of time across the globe. As personal ubiquitous computing [104] contiues to push active control technology to the edge where the action is taking place, we will be faced with many opportunities to design and field autonomous systems based on the firm ground of system theoretic concepts covered in this introductory text on modern control systems.

The evolution of the Internet of Things (IoT) is having a transformational impact on the field of control engineering. The idea of the IoT, first proposed by Kevin Ashton in 1999, is the network of physical objects embedded with electronics, software, sensors, and connectivity - all elements of control engineering [14]. Each of the "things" on the network has an embedded computer with connectivity to the Internet. The ability to control connected devices is of great interest to control engineers, but there remains much work to be done, especially in establishing standards [24]. The International Data Corporation estimates that there will be 41.6 billion IoT devices generating 79.4 zettabytes (ZB) of data by the year 2025 [106]. One ZB is equal to one trillion GB! Figure 1.9 presents a technology roadmap that illustrates that in the near future control engineering is likely to play a role in creating active control applications for connected devices (adopted from [27]).

A selected history of control system development is summarized in Table 1.1. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0039.jpg?height=911&width=1493&top_left_y=161&top_left_x=110)

FIGURE 1.9 Technology roadmap to the Internet of Things enhanced with artificial intelligence with applications to control engineering (Source: SRI Business Intelligence).

\section{Table 1.1 Selected Historical Developments of Control Systems}

1769 James Watt's steam engine and governor developed.

1868 J. C. Maxwell formulates a mathematical model for a governor control of a steam engine.

1913 Henry Ford's mechanized assembly machine introduced for automobile production.

1927 H. S. Black conceives of the negative feedback amplifier and H. W. Bode analyzes feedback amplifiers.

1932 H. Nyquist develops a method for analyzing the stability of systems.

1941 Creation of first antiaircraft gun with active control.

1952 Numerical control (NC) developed at Massachusetts Institute of Technology for control of machine-tool axes.

1954 George Devol develops "programmed article transfer," considered to be the first industrial robot design.

1957 Sputnik launches the space age leading, in time, to miniaturization of computers and advances in automatic control theory.

1960 First Unimate robot introduced, based on Devol's designs. Unimate installed in 1961 for tending die-casting machines. Table 1.1 (continued)

$1980 \quad$ Robust control system design widely studied.

1983 Introduction of the personal computer (and control design software soon thereafter) brought the tools of design to the engineer's desktop.

1990 The government ARPANET (the first network to use the Internet Protocol) was decommissioned and private connections to the Internet by commercial companies rapidly spread.

$1994 \quad$ Feedback control widely used in automobiles. Reliable, robust systems demanded in manufacturing.

1995 The Global Positioning System (GPS) was operational providing positioning, navigation, and timing services worldwide.

1997 First ever autonomous rover vehicle, known as Sojourner, explores the Martian surface.

2007 The Orbital Express mission performed the first autonomous space rendezvous and docking.

2011 The NASA Robonaut R2 became the first US-built robot on the International Space Station designed to assist with crew extravehicular activities (EVAs).

2013 For the first time, a vehicle - known as BRAiVE and designed at the University of Parma, Italy-moved autonomously on a mixed traffic route open to public traffic without a passenger in the driver seat.

2014 Internet of Things (IoT) enabled by convergence of key systems including embedded systems, wireless sensor networks, control systems, and automation.

2016 Space X successfully lands the first rocket on an autonomous spaceport drone ship controllrd by an autonomus robot.

2019 Alphabet's Wing begins making first commercial drone deliveries in the US.

\subsection{EXAMPLES OF CONTROL SYSTEMS}

Control engineering is concerned with the analysis and design of goal-oriented systems. Therefore the mechanization of goal-oriented policies has grown into a hierarchy of goal-oriented control systems. Modern control theory is concerned with systems that have self-organizing, adaptive, robust, learning, and optimum qualities.

\section{EXAMPLE 1.1 Automated vehicles}

Driving an automobile is a pleasant task when the auto responds rapidly to the driver's commands. The era of autonomous or self-driving vehicles is almost upon us $[15,19$, 20]. The autonomous vehicle must be able to sense the changing environment, perform trajectory planning, prescribe the control inputs that include steering and turning, accelerating and braking, and many other functions typically handled by the driver, and actually implement the control strategy. Steering is one of the critical functions of autonomous vehicles. A simple block diagram of an automobile steering control system is shown in Figure 1.10(a). The desired course is compared with a measurement of the actual course in order to generate a measure of the error, as shown in Figure 1.10(b). This measurement is obtained by visual and tactile (body movement) feedback, as provided by the feel of the steering wheel by the hand (sensor). This feedback system is a familiar version of the steering control system in an ocean liner or the flight controls in a large airplane. A typical direction-of-travel response is shown in Figure 1.10(c). 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0041.jpg?height=252&width=1234&top_left_y=147&top_left_x=352)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0041.jpg?height=548&width=1277&top_left_y=479&top_left_x=340)

(b)

FIGURE 1.10

(a) Automobile steering control system. (b) The driver uses the difference between the actual and the desired direction of travel to generate a controlled adjustment of the steering wheel. (c) Typical direction-of-travel response.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0041.jpg?height=395&width=628&top_left_y=1127&top_left_x=669)

(c)

\section{EXAMPLE 1.2 Human-in-the-loop control}

A basic, manually controlled closed-loop system for regulating the level of fluid in a tank is shown in Figure 1.11. The input is a reference level of fluid that the operator is instructed to maintain. (This reference is memorized by the operator.) The power amplifier is the operator, and the sensor is visual. The operator compares the actual level with the desired level and opens or closes the valve (actuator), adjusting the fluid flow out, to maintain the desired level.

\section{EXAMPLE 1.3 Humanoid robots}

The use of computers integrated with machines that perform tasks like a human worker has been foreseen by several authors. In his famous 1923 play, entitled FIGURE 1.11

A manual control system for regulating the level of fluid in a tank by adjusting the output valve. The operator views the level of fluid through a port in the side of the tank.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0042.jpg?height=451&width=837&top_left_y=151&top_left_x=506)

R.U.R. [48], Karel Capek called artificial workers robots, deriving the word from the Czech noun robota, meaning "work."

A robot is a computer-controlled machine and involves technology closely associated with automation. Industrial robotics can be defined as a particular field of automation in which the automated machine (that is, the robot) is designed to substitute for human labor $[18,33]$. Thus robots possess certain humanlike characteristics. Today, the most common humanlike characteristic is a mechanical manipulator that is patterned somewhat after the human arm and wrist. Some devices even have anthropomorphic mechanisms, including what we might recognize as mechanical arms, wrists, and hands [28]. An example of an anthropomorphic robot is shown in Figure 1.12. We recognize that the automatic machine is well suited to some tasks, as noted in Table 1.2, and that other tasks are best carried out by humans [106].

\section{EXAMPLE 1.4 Electric power industry}

There has been considerable discussion recently concerning the gap between practice and theory in control engineering. However, it is natural that theory precedes the applications in many fields of control engineering. Nonetheless, it is interesting to note that in the electric power industry, the largest industry in the United States, the gap is relatively insignificant. The electric power industry is primarily interested in energy conversion, control, and distribution. It is critical that computer control be increasingly applied to the power industry in order to improve the efficient use of energy resources. Also, the control of power plants for minimum waste emission has become increasingly important. The modern, large-capacity plants, which exceed several hundred megawatts, require automatic control systems that account for the interrelationship of the process variables and optimum power production. It is common to have 90 or more manipulated variables under coordinated control. A simplified model showing several of the important control variables of a large boiler-generator system is shown in Figure 1.13. This is an example of the importance of measuring many variables, such as pressure and oxygen, to provide information to the computer for control calculations.

The electric power industry has used the modern aspects of control engineering for significant and interesting applications. It appears that in the process industry, the factor that maintains the applications gap is the lack of instrumentation to measure all the important process variables, including the quality and composition of FIGURE 1.12

The Honda ASIMO humanoid robot. ASIMO walks, climbs stairs, and turns corners. (David Coll Blanco/ Alamy Stock Photo)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0043.jpg?height=825&width=1232&top_left_y=152&top_left_x=388)

Table 1.2 Task Difficulty: Human Versus Automatic Machine Tasks Difficult for a Machine Tasks Difficult for a Human

Displaying real emotions Acting based on ethical principles Precise coordination with other robots Anticipating human actions and responses Acquiring new skills on its own
Operating in toxic environments

Highly repetitive activities

Deep underwater surveys

Outer planet space exploration

Working diligently with no breaks for long periods

the product. As these instruments become available, the applications of modern control theory to industrial systems should increase measurably.

\section{EXAMPLE 1.5 Biomedical engineering}

There have been many applications of control system theory to biomedical experimentation, diagnosis, prosthetics, and biological control systems [22, 23, 48]. The control systems under consideration range from the cellular level to the central nervous system and include temperature regulation and neurological, respiratory, and cardiovascular control. Most physiological control systems are closed-loop systems. However, we find not one controller but rather control loop within control loop, forming a hierarchy of systems. The modeling of the structure of biological processes confronts the analyst with a high-order model and a complex structure. Prosthetic devices aid millions of people worldwide. Recent advances in feedback control FIGURE 1.13 Coordinated control system for a boiler-generator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0044.jpg?height=898&width=1301&top_left_y=153&top_left_x=488)

technology will profoundly transform the lives of amputees and people living with paralysis. Much progress has been made in the restoration of sensation of touch and pain and in connecting prosthetic limb sensors with haptic feedback directly back to the brain. Figure 1.14 depicts a prosthetic had and arm with the same dexterity as a human arm. Especially fascinating are advances in brain-controlled feedback of prosthetic limbs enabling the power of the human brain to guide the movement [39]. Another fascinating advance in the development of prosthetic limbs is to make possible the sense of touch and pain [22]. Much progress has been made in the restoration of sensation of touch and pain and in connecting sensors to the prosthetic limbs with haptic feedback directly back to the brain.

\section{EXAMPLE 1.6 Social, economic, and political systems}

It is interesting and valuable to attempt to model the feedback processes prevalent in the social, economic, and political spheres. This approach is undeveloped at present but appears to have a bright future. Society is composed of many feedback systems and regulatory bodies, which are controllers exerting the forces on society necessary to maintain a desired output. A simple lumped model of the national income feedback control system is shown in Figure 1.15. This type of model helps the analyst to understand the effects of government control and the dynamic effects of government spending. Of course, many other loops not shown also exist, since, theoretically, government spending cannot exceed the tax collected without generating a deficit, which is itself a control loop containing the Internal Revenue Service and the Congress. In a socialist country, the loop due to consumers is deemphasized and government control is emphasized. In that case, the measurement FIGURE 1.15

A feedback control system model of the national income.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0045.jpg?height=598&width=1145&top_left_y=155&top_left_x=394)

FIGURE 1.14

Recent advances in electronic prosthetics have resulted in the development of a prosthetic hand and arm that has the same dexterity as a human arm. (Kuznetsov Dmitriy/Shutterstock).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0045.jpg?height=558&width=1266&top_left_y=963&top_left_x=350)

block must be accurate and must respond rapidly; both are very difficult characteristics to realize from a bureaucratic system. This type of political or social feedback model, while usually nonrigorous, does impart information and understanding.

\section{EXAMPLE 1.7 Unmanned aerial vehicles}

The ongoing area of research and development of unmanned aerial vehicles (UAVs) is full of potential for the application of control systems. These aircrafts are also known as drones. An example of a drone is shown in Figure 1.16. Drones are unmanned but are usually controlled by ground operators. Typically they do not operate autonomously, and their inability to provide the level of safety required in a complex airspace keeps them from flying freely in the commercial airspace although package delivery via drones has begun. One significant challenge is to develop control systems that will avoid in-air collisions. Ultimately, the goal is to employ the drone autonomously in FIGURE 1.16

A commercial drone (GuruXOX/ Shuttterstock).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0046.jpg?height=520&width=759&top_left_y=152&top_left_x=519)

such applications as aerial photography to assist in disaster mitigation, survey work to assist in construction projects, crop monitoring, and continuous weather monitoring. An intriguing emerging area of applied research is the integration of artificial intelligence (AI) and drones [74]. Smart unmanned aircraft will require significant deployment of advanced control systems throughout the airframe.

\section{EXAMPLE 1.8 Industrial control systems}

Other familiar control systems have the same basic elements as the system shown in Figure 1.3. A refrigerator has a temperature setting or desired temperature, a thermostat to measure the actual temperature and the error, and a compressor motor for power amplification. Other examples in the home are the oven, furnace, and water heater. In industry, there are many examples, including speed controls; process temperature and pressure controls; and position, thickness, composition, and quality controls [17, 18].

Feedback control systems are used extensively in industrial applications. Thousands of industrial and laboratory robots are currently in use. Manipulators can pick up objects weighing hundreds of pounds and position them with an accuracy of one-tenth of an inch or better [28]. Automatic handling equipment for home, school, and industry is particularly useful for hazardous, repetitious, dull, or simple tasks. Machines that automatically load and unload, cut, weld, or cast are used by industry to obtain accuracy, safety, economy, and productivity [28, 41].

Another important industry, the metallurgical industry, has had considerable success in automatically controlling its processes. In fact, in many cases, the control theory is being fully implemented. For example, a hot-strip steel mill is controlled for temperature, strip width, thickness, and quality.

There has been considerable interest recently in applying the feedback control concepts to automatic warehousing and inventory control. Furthermore, automatic control of agricultural systems (farms) is receiving increased interest. Automatically controlled silos and tractors have been developed and tested. Automatic control of wind turbine generators, solar heating and cooling, and automobile engine performance are important modern examples [20,21]. 

\subsection{ENGINEERING DESIGN}

Engineering design is the central task of the engineer. It is a complex process in which both creativity and analysis play major roles.

\section{Design is the process of conceiving or inventing the forms, parts, and details of a system to achieve a specified purpose.}

Design activity can be thought of as planning for the emergence of a particular product or system. Design is an innovative act whereby the engineer creatively uses knowledge and materials to specify the shape, function, and material content of a system. The design steps are (1) to determine a need arising from the values of various groups, covering the spectrum from public policy makers to the consumer; (2) to specify in detail what the solution to that need must be and to embody these values; (3) to develop and evaluate various alternative solutions to meet these specifications; and (4) to decide which one is to be designed in detail and fabricated.

An important factor in realistic design is the limitation of time. Design takes place under imposed schedules, and we eventually settle for a design that may be less than ideal but considered "good enough." In many cases, time is the only competitive advantage.

A major challenge for the designer is writing the specifications for the technical product. Specifications are statements that explicitly state what the device or product is to be and do. The design of technical systems aims to provide appropriate design specifications and rests on four characteristics: complexity, trade-offs, design gaps, and risk.

Complexity of design results from the wide range of tools, issues, and knowledge to be used in the process. The large number of factors to be considered illustrates the complexity of the design specification activity, not only in assigning these factors their relative importance in a particular design, but also in giving them substance either in numerical or written form, or both.

The concept of trade-off involves the need to resolve conflicting design goals, all of which are desirable. The design process requires an efficient compromise between desirable but conflicting criteria.

In making a technical device, we generally find that the final product does not appear as originally visualized. For example, our image of the problem we are solving does not appear in written description and ultimately in the specifications. Such design gaps are intrinsic in the progression from an abstract idea to its realization.

This inability to be absolutely sure about predictions of the performance of a technological object leads to major uncertainties about the actual effects of the designed devices and products. These uncertainties are embodied in the idea of unintended consequences or risk. The result is that designing a system is a risk-taking activity.

Complexity, trade-off, gaps, and risk are inherent in designing new systems and devices. Although they can be minimized by considering all the effects of a given design, they are always present in the design process.

Within engineering design, there is a fundamental difference between the two major types of thinking that must take place: engineering analysis and synthesis. Attention is focused on models of the physical systems that are analyzed to provide insight and that indicate directions for improvement. On the other hand, synthesis is the process by which these new physical configurations are created.

Design is a process that may proceed in many directions before the desired one is found. It is a deliberate process by which a designer creates something new in response to a recognized need while recognizing realistic constraints. The design process is inherently iterative-we must start somewhere! Successful engineers learn to simplify complex systems appropriately for design and analysis purposes. A gap between the complex physical system and the design model is inevitable. Design gaps are intrinsic in the progression from the initial concept to the final product. We know intuitively that it is easier to improve an initial concept incrementally than to try to create a final design at the start. In other words, engineering design is not a linear process. It is an iterative, nonlinear, creative process.

The main approach to the most effective engineering design is parameter analysis and optimization. Parameter analysis is based on (1) identification of the key parameters, (2) generation of the system configuration, and (3) evaluation of how well the configuration meets the needs. These three steps form an iterative loop. Once the key parameters are identified and the configuration synthesized, the designer can optimize the parameters. Typically, the designer strives to identify a limited set of parameters to be adjusted.

\subsection{CONTROL SYSTEM DESIGN}

The design of control systems is a specific example of engineering design. The goal of control engineering design is to obtain the configuration, specifications, and identification of the key parameters of a proposed system to meet an actual need.

The control system design process is illustrated in Figure 1.17. The design process consists of seven main building blocks, which we arrange into three groups:

1. Establishment of goals and variables to be controlled, and definition of specifications (metrics) against which to measure performance.

2. System definition and modeling.

3. Control system design and integrated system simulation and analysis.

In each chapter of this book, we will highlight the connection between the design process illustrated in Figure 1.17 and the main topics of that chapter. The objective is to demonstrate different aspects of the design process through illustrative examples. We have established the following connections between the chapters in this book and the design process block diagram:

1. Establishment of goals, control variables, and specifications: Chapters 1,3, 4, and 13.

2. System definition and modeling: Chapters 2-4, and 11-13.

3. Control system design, simulation, and analysis: Chapters 4-13.

The first step in the design process consists of establishing the system goals. For example, we may state that our goal is to control the velocity of a motor accurately. The second step is to identify the variables that we desire to control (for example, the velocity of the motor). The third step is to write the specifications in terms of the accuracy we must attain. This required accuracy of control will then lead Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0049.jpg?height=294&width=386&top_left_y=342&top_left_x=275)

Establish the control goals
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0049.jpg?height=116&width=182&top_left_y=346&top_left_x=666)

Identify the variables to be controlled

rite the specifications

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0049.jpg?height=623&width=865&top_left_y=662&top_left_x=381)

If the performance does not meet the specifications, then iterate the configuration.
In this column remarks relate the design topics on the left to specific sections, figures, equations, and tables in the example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0049.jpg?height=119&width=59&top_left_y=338&top_left_x=1405)

(1) Establishment of goals, variables to be controlled, and specifications.

(2) System definition and modeling.

(3) Control system design, simulation, and analysis.

FIGURE 1.17 The control system design process.

to the identification of a sensor to measure the controlled variable. The performance specifications will describe how the closed-loop system should perform and will include (1) good regulation against disturbances, (2) desirable responses to commands, (3) realistic actuator signals, (4) low sensitivities, and (5) robustness.

As designers, we proceed to the first attempt to configure a system that will result in the desired control performance. This system configuration will normally consist of a sensor, the process under control, an actuator, and a controller, as shown in Figure 1.3. The next step consists of identifying a candidate for the actuator. This will, of course, depend on the process, but the actuation chosen must be capable of effectively adjusting the performance of the process. For example, if we wish to control the speed of a rotating flywheel, we will select a motor as the actuator. The sensor, in this case, must be capable of accurately measuring the speed. We then obtain a model for each of these elements.

Students studying controls are often given the models, frequently represented in transfer function or state variable form, with the understanding that they represent the underlying physical systems, but without further explanation. An obvious question is, where did the transfer function or state variable model come from? Within the context of a course in control systems, there is a need to address key questions surrounding modeling. To that end, in the early chapters, we will provide insight into key modeling concerns and answer fundamental questions: How is the transfer function obtained? What basic assumptions are implied in the model development? How general are the transfer functions? However, mathematical modeling of physical systems is a subject in and of itself. We cannot hope to cover the mathematical modeling in its entirety, but interested students are encouraged to seek outside references (see, for example, [76-80]).

The next step is the selection of a controller, which often consists of a summing amplifier that will compare the desired response and the actual response and then forward this error-measurement signal to an amplifier.

The final step in the design process is the adjustment of the parameters of the system to achieve the desired performance. If we can achieve the desired performance by adjusting the parameters, we will finalize the design and proceed to document the results. If not, we will need to establish an improved system configuration and perhaps select an enhanced actuator and sensor. Then we will repeat the design steps until we are able to meet the specifications, or until we decide the specifications are too demanding and should be relaxed.

The design process has been dramatically affected by the advent of powerful and inexpensive computers, and effective control design and analysis software. For example, the Boeing 777 was the world's first $100 \%$ digitally designed civilian aircraft.The benefits of this design approach to Boeing was a 50\% saving in development costs, a 93\% reduction in design change and rework rate, and a 50-80\% reduction in problems compared with traditional manufacturing [56]. The follow-on project, known as the Boeing 787 Dreamliner, was developed without physical prototypes. In many applications, the availability of digital design tools, including the certification of the control system in realistic computer simulations, represents a significant cost reduction in terms of money and time.

Another notable innovation in design is the generative design process coupled with artificial intelligence [57]. Generative design is an iterative design process that typically utilizes a computer program to generate a (potentially large) number of designs based on a given set of constraints provided by the designer. The designer then fine-tunes the feasible solution provided by the computer program by adjusting the constraint space to reduce the number of viable solutions. For example, the generative design is revolutionizing aircraft design [58]. The application of the highly computer-intensive generative design process in feedback control theory remains an open question. However, the generative design process concept can also be applied in a more traditional (less computationally intensive) environment to enhance the design process in Figure 1.17. For example, once a single design has been found that meets the specifications, the process can be repeated by selecting different system configurations and controller structures. After a number of controllers are designed that meet the specifications, the designer can then begin to narrow the design by adjusting the constraints. There are facets of the generative design process that will be illuminated in this book as we discuss the control system design process.

In summary, the controller design problem is as follows: Given a model of the system to be controlled (including its sensors and actuators) and a set of design goals, find a suitable controller, or determine that none exists. As with most of engineering design, the design of a feedback control system is an iterative and nonlinear process. A successful designer must consider the underlying physics of the plant under control, the control design strategy, the controller design architecture (that is, what type of controller will be employed), and effective controller tuning strategies. In addition, once the design is completed, the controller is often implemented in hardware, and hence issues of interfacing with hardware can appear. When taken together, these different phases of control system design make the task of designing and implementing a control system quite challenging [73].

\subsection{MECHATRONIC SYSTEMS}

A natural stage in the evolutionary process of modern engineering design is encompassed in the area known as mechatronics [64]. The term mechatronics was coined in Japan in the 1970s [65-67]. Mechatronics is the synergistic integration of mechanical, electrical, and computer systems and has evolved over the past 30 years, leading to a new breed of intelligent products. Feedback control is an integral aspect of modern mechatronic systems. One can understand the extent that mechatronics reaches into various disciplines by considering the components that make up mechatronics [68-71]. The key elements of mechatronics are (1) physical systems modeling, (2) sensors and actuators, (3) signals and systems, (4) computers and logic systems, and (5) software and data acquisition. Feedback control encompasses aspects of all five key elements of mechatronics, but is associated primarily with the element of signals and systems, as illustrated in Figure 1.18.

Advances in computer hardware and software technology coupled with the desire to increase the performance-to-cost ratio has revolutionized engineering design. New products are being developed at the intersection of traditional disciplines of engineering, computer science, and the natural sciences. Advancements in traditional disciplines are fueling the growth of mechatronics systems by providing

FIGURE 1.18

The key elements of mechatronics [64].

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0051.jpg?height=806&width=894&top_left_y=1314&top_left_x=369)

"enabling technologies." A critical enabling technology was the microprocessor which has had a profound effect on the design of consumer products. We should expect continued advancements in cost-effective microprocessors and microcontrollers, novel sensors and actuators enabled by advancements in applications of microelectromechanical systems (MEMS), advanced control methodologies and real-time programming methods, networking and wireless technologies, and mature computer-aided engineering (CAE) technologies for advanced system modeling, virtual prototyping, and testing. The continued rapid development in these areas will only accelerate the pace of smart (that is, actively controlled) products.

An exciting area of mechatronic system development in which control systems will play a significant role is the area of alternative energy production and consumption. Hybrid fuel automobiles and efficient wind power generation are two examples of systems that can benefit from mechatronic design methods. In fact, the mechatronic design philosophy can be effectively illustrated by the example of the evolution of the modern automobile [64]. Before the 1960s, the radio was the only significant electronic device in an automobile. Today, many automobiles have many microcontrollers, and a multitude of sensors, and thousands of lines of software code. A modern automobile can no longer be classified as a strictly mechanical machine - it has been transformed into a comprehensive mechatronic system.

\section{EXAMPLE 1.9 Hybrid fuel vehicles}

A hybrid fuel automobile, depicted in Figure 1.19, utilizes a conventional internal combustion engine in combination with a battery (or other energy storage device such as a fuel cell or flywheel) and an electric motor to provide a propulsion system capable of doubling the fuel economy over conventional automobiles. Although these hybrid vehicles will never be zero-emission vehicles (since they have internal combustion engines), they can reduce the level of harmful emissions by onethird to one-half, and with future improvements, these emissions may reduce even further. As stated earlier, the modern automobile requires many advanced control systems to operate. The control systems must regulate the performance of

FIGURE 1.19

The hybrid fuel automobile can be viewed as a mechatronic system.

(Marmaduke St. John/Alamy Stock Photo.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0052.jpg?height=633&width=945&top_left_y=1485&top_left_x=504)

the engine, including fuel-air mixtures, valve timing, transmissions, wheel traction control, antilock brakes, and electronically controlled suspensions, among many other functions. On the hybrid fuel vehicle, there are additional control functions that must be satisfied. Especially necessary is the control of power between the internal combustion engine and the electric motor, determining power storage needs and implementing the battery charging, and preparing the vehicle for low-emission start-ups. The overall effectiveness of the hybrid fuel vehicle depends on the combination of power units that are selected (e.g., battery versus fuel cell for power storage). Ultimately, however, the control strategy that integrates the various electrical and mechanical components into a viable transportation system strongly influences the acceptability of the hybrid fuel vehicle concept in the marketplace.

The second example of a mechatronic system is the advanced wind power generation system.

\section{EXAMPLE 1.10 Wind power}

Many nations in the world today are faced with unstable energy supplies. Additionally, the negative effects of fossil fuel utilization on the quality of our air are well documented. Many nations have an imbalance in the supply and demand of energy, consuming more than they produce. To address this imbalance, many engineers are considering developing advanced systems to access other sources of energy, such as wind energy. In fact, wind energy is one of the fastest-growing forms of energy generation in the United States and in other locations around the world. A wind farm is illustrated in Figure 1.20.

By the end of 2019, the installed global wind energy capacity was over $650.8 \mathrm{GW}$. In the United States, there was enough energy derived from wind to power over 27.5 million homes, according to the American Wind Energy Association. For the past 40 years, researchers have concentrated on developing technologies that work well in high wind areas (defined to be areas with a wind speed of at least $6.7 \mathrm{~m} / \mathrm{s}$ at a height of $10 \mathrm{~m}$ ). Most of the easily accessible high wind sites in the United States are now utilized, and improved technology must be developed to make lower wind areas more cost effective. New developments are required in materials and

FIGURE 1.20 Efficient wind power generation. (Photo courtesy of NASA)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0053.jpg?height=600&width=889&top_left_y=1537&top_left_x=374)

aerodynamics so that longer turbine rotors can operate efficiently in the lower winds, and in a related problem, the towers that support the turbine must be made taller without increasing the overall costs. In addition, advanced controls will be required to achieve the level of efficiency required in the wind generation drive train. Newer wind turbines can operate in wind speeds less than $1 \mathrm{mph}$.

\section{EXAMPLE 1.11 Wearable computers}

Many contemporary control systems are embedded control systems [81]. Embedded control systems employ on-board special-purpose digital computers as integral components of the feedback loop. Many new wearable products include embedded computers. This includes wristwatches, eyeglasses, sports wristbands, e-textiles, and computer garments. Figure 1.21 illustrates the popular computer eyeglasses. For example, the glasses devices might enable physicians to access and manage data and display the data when they need it during a patient examination. One might imagine future applications where the device would monitor and track the doctor's eye movements and use that information in a feedback loop to very precisely control a medical instrument during a procedure. The utilization of wearable computers in feedback control applications is in its infancy and the possibilities are enormous.

Advances in sensors, actuators, and communication devices are leading to a new class of embedded control systems that are networked using wireless technology, thereby enabling spatially-distributed control. Embedded control system designers must be able to understand and work with various network protocols, diverse operating systems and programming languages. While the theory of systems and controls serves as the foundation for the modern control system design, the design process is rapidly expanding into a multi-disciplinary enterprise encompassing multiple engineering areas, as well as information technology and computer science.

Advances in alternate energy products, such as the hybrid automobile and the generation of efficient wind power generators, provide vivid examples of mechatronics development. There are numerous other examples of intelligent systems poised to enter our everyday life, including autonomous rovers, smart home appliances (e.g., dishwashers, vacuum cleaners, and microwave ovens), wireless network-enabled devices, "human-friendly machines" [72] that perform robotassisted surgery, and implantable sensors and actuators.

FIGURE 1.21

Wearable computers can assist a physician provide better healthcare delivery. (Wavebreak Media Ltd/123RF.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0054.jpg?height=473&width=661&top_left_y=1636&top_left_x=507)



\subsection{GREEN ENGINEERING}

Global issues such as climate change, clean water, sustainability, waste management, emissions reduction, and minimizing raw material and energy use have caused many engineers to re-think existing approaches to engineering design in critical areas. One outcome of the evolving design strategy is to consider an approach that has come to be known as "green engineering." The goal of green engineering is to design products that will minimize pollution, reduce the risk to human health, and improve the environment. The basic principles of green engineering are [86]:

1. Engineer processes and products holistically, use systems analysis, and integrate environmental impact assessment tools.

2. Conserve and improve natural ecosystems while protecting human health and well-being.

3. Use life-cycle thinking in all engineering activities.

4. Ensure that all material and energy inputs and outputs are as inherently safe and benign as possible.

5. Minimize depletion of natural resources.

6. Strive to prevent waste.

7. Develop and apply engineering solutions, while being cognizant of local geography, aspirations, and cultures.

8. Create engineering solutions beyond current or dominant technologies; improve, innovate, and invent technologies to achieve sustainability.

9. Actively engage communities and stakeholders in development of engineering solutions.

Putting the principles of green engineering into practice leads us to a deeper understanding of the power of feedback control systems as an enabling technology. For example, in Section 1.9, we present a discussion on smart grids. Smart grids aim to deliver electrical power more reliably and efficiently in an environmentally friendly fashion. This in turn will potentially enable the large-scale use of renewable energy sources, such as wind and solar, that are naturally intermittent. Sensing and feedback are key technology areas that enable the smart grids [87]. Green engineering applications can be classified into one of five categories [88]:

1. Environmental Monitoring

2. Energy Storage Systems

3. Power Quality Monitoring

4. Solar Energy

5. Wind Energy

As the field of green engineering matures, it is almost certain that more applications will evolve, especially as we apply the eighth principle (listed above) of green engineering to create engineering solutions beyond current or dominant technologies and improve, innovate, and invent technologies. In the subsequent chapters, we present examples from each of these areas. There is a global effort underway to reduce greenhouse gases from all sources. To accomplish this, it is necessary to improve both the quality and quantity of our environmental monitoring systems. An example is using wireless measurements on a cabled robotic controlled mobile sensing platform moving along the forest understory to measure key environmental parameters in a rain forest.

Energy storage systems are critical technologies for green engineering. There are many types of energy storage systems. The energy storage system we are most familiar with is the battery. Batteries are used to power most of the electronic devices in use today; some batteries are rechargeable and some are single-use throwaways. To adhere to green engineering principles, we would favor energy storage systems that are renewable. A very important energy storage device for green engineering systems is the fuel cell.

The problems associated with power quality monitoring are varied and can include leading and lagging power, voltage variations, and waveform harmonics. Many of the green engineering systems and components require careful monitoring of current and voltages. An interesting example would be the modeling of current transformers that are used in various capacities for measuring and monitoring within the power grid network of interconnected systems used to deliver electricity.

Efficiently converting solar energy into electricity is an engineering challenge. Two technologies for generation of electricity using sunshine are solar photovoltaic and solar thermal. With photovoltaic systems the sunlight is converted directly to electricity, and with solar thermal the sun heats water to create steam that is used to power steam engines. Designing and deploying solar photovoltaic systems for solar power generation is one approach employing green engineering principles to utilize the sun's energy to power our homes, offices, and businesses.

Power derived from wind is an important source of renewable energy around the world. Wind energy conversion to electric power is achieved by wind energy turbines connected to electric generators. The intermittency characteristic of wind energy makes the smart grid development essential to bring the energy to the power grid when it is available and to provide energy from other sources when the wind dies down or is disrupted. The irregular character of wind direction and power also results in the need for reliable, steady electric energy by using control systems on the wind turbines themselves. The goal of these control devices is to reduce the effects of wind intermittency and the effect of wind direction change.

The role of control systems in green engineering will continue to expand as the global issues facing us require ever increasing levels of automation and precision.

\subsection{THE FUTURE EVOLUTION OF CONTROL SYSTEMS}

The continuing goal of control systems is to provide extensive flexibility and a high level of autonomy. Two system concepts are approaching this goal by different evolutionary pathways, as illustrated in Figure 1.22. Today's industrial robot is perceived as quite autonomous-once it is programmed, further intervention is not normally required. Because of sensory limitations, these robotic systems have limited flexibility in adapting to work environment changes; improving perception is the motivation of computer vision research. The control system is very adaptable, FIGURE 1.22

Evolution of control systems and autonomy.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0057.jpg?height=731&width=1075&top_left_y=152&top_left_x=375)

but it relies on human supervision. Advanced robotic systems are striving for task adaptability through enhanced sensory feedback. Research areas concentrating on artificial intelligence, sensor integration, computer vision, and off-line CAD/CAM programming will make systems more universal and economical. Control systems are moving toward autonomous operation as an enhancement to human control. Research in supervisory control, human-machine interface methods, and computer database management are intended to reduce operator burden and improve operator efficiency. Many research activities are common to robotics and control systems and are aimed at reducing implementation cost and expanding the realm of application. These include improved communication methods and advanced programming languages.

The easing of human labor by technology, a process that began in prehistory, is entering a new stage. The acceleration in the pace of technological innovation inaugurated by the Industrial Revolution has until recently resulted mainly in the displacement of human muscle power from the tasks of production. The current revolution in computer technology is causing an equally momentous social change, the expansion of information gathering and information processing as computers extend the reach of the human brain [16].

Control systems are used to achieve (1) increased productivity and (2) improved performance of a device or system. Automation is used to improve productivity and obtain high-quality products. Automation is the automatic operation or control of a process, device, or system. We use automatic control of machines and processes to produce a product reliably and with high precision [28]. With the demand for flexible, custom production, a need for flexible automation and robotics is growing [17, 25].

The theory, practice, and application of automatic control is a large, exciting, and extremely useful engineering discipline. One can readily understand the motivation for a study of modern control systems. 

\subsection{DESIGN EXAMPLES}

In this section we present illustrative design examples. This is a pattern that we will follow in all subsequent chapters. Each chapter will contain a number of interesting examples in a special section entitled Design Examples meant to highlight the main topics of the chapter. At least one example among those presented in the Design Example section will be a more detailed problem and solution that demonstrates one or more of the steps in the design process shown in Figure 1.17. In the first example, we discuss the development of the smart grid as a concept to deliver electrical power more reliably and efficiently as part of a strategy to provide a more environmentally friendly energy delivery system. The smart grid will enable the large-scale use of renewable energy sources that depend on the natural phenomenon to generate power and which are intermittent, such as wind and solar. Providing clean energy is an engineering challenge that must necessarily include active feedback control systems, sensors, and actuators. In the second example presented here, a rotating disk speed control illustrates the concept of open-loop and closed-loop feedback control. The third example is an insulin delivery control system in which we determine the design goals, the variables to control, and a preliminary closed-loop system configuration.

\section{EXAMPLE 1.12 Smart grid control systems}

A smart grid is as much a concept as it is a physical system. In essence, the concept is to deliver power more reliably and efficiently while remaining environmentally friendly, economical, and safe $[89,90]$. A smart grid can be viewed as a system comprised of hardware and software that routes power more reliably and efficiently to homes, businesses, schools, and other users of power. One view of the smart grid is illustrated schematically in Figure 1.23. Smart grids can be national or local in scope. One can even consider home smart grids (or microgrids). In fact, smart grids encompass a wide and rich field of investigation. As we will find, control systems play a key role in smart grids at all levels.

One interesting aspect of the smart grid is real-time demand side management requiring a two-way flow of information between the user and the power generation system [91]. For example, smart meters are used to measure electricity use in the home and office. These sensors transmit data to utilities and allow the utility to transmit control signals back to a home or building. These smart meters can control and turn on or off home and office appliances and devices. Smart home-energy devices enable the homeowners to control their usage and respond to price changes at peak-use times.

The five key technologies required to implement a successful modern smart grid include (i) integrated communications, (ii) sensing and measurements, (iii) advanced components, (iv) advanced control methods, and (v) improved interfaces and decision support [87]. Two of the five key technologies fall under the general category of control systems, namely (ii) sensing and measurements and (iii) advanced control methods. It is evident that control systems will play a key role in realizing the modern smart grid. The potential impact of the smart grid on delivery of power is very high. Currently, the total U.S. grid includes 9,200 units generating over 1 million MW of capacity over 300,000 miles of transmission lines. A smart grid will use sensors, 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0059.jpg?height=981&width=1478&top_left_y=154&top_left_x=143)

FIGURE 1.23 Smart grids are distribution networks that measure and control usage.

controllers, the Internet, and communication systems to improve the reliability and efficiency of the grid. It is estimated that deployment of smart grids could reduce emissions of $\mathrm{CO}_{2}$ by 12 percent by 2030 [91].

One of the elements of the smart grid are the distribution networks that measure and control usage. In a smart grid, the power generation depends on the market situation (supply/demand and cost) and the power source available (wind, coal, nuclear, geothermal, biomass, etc.). In fact, smart grid customers with solar panels or wind turbines can sell their excess energy to the grid and get paid as microgenerators [92]. In the subsequent chapters, we discuss various control problems associated with pointing solar panels to the sun and with prescribing the pitch of the wind turbine blades to manage the rotor speed thereby controlling the power output.

Transmission of power is called power flow and the improved control of power will increase its security and efficiency. Transmission lines have inductive, capacitive, and resistive effects that result in dynamic impacts or disturbances. The smart grid must anticipate and respond to system disturbances rapidly. This is referred to as self-healing. In other words, a smart grid should be capable of managing significant disturbances occurring on very short time scales. To accomplish this, the self-healing process is constructed around the idea of a feedback control system where self-assessments are used to detect and analyze disturbances so that corrective action can be applied to restore the grid. This requires sensing and measurements to provide information to the control systems. One of the benefits of using smart grids is that renewable energy sources that depend on intermittent natural phenomena (such as wind and sunshine) can potentially be utilized more efficiently by allowing for load shedding when the wind dies out or clouds block the sunshine.

Feedback control systems will play an increasingly important role in the development of smart grids as we move to the target date. It may be interesting to recall the various topics discussed in this section in the context of control systems as each chapter in this textbook unfolds new methods of control system design and analysis.

\section{EXAMPLE 1.13 Rotating disk speed control}

Many modern devices employ a rotating disk held at a constant speed. For example, spinning disk conformal microscopes enable line-cell imaging in biomedical applications. Our goal is to design a system for rotating disk speed control that will ensure that the actual speed of rotation is within a specified percentage of the desired speed [40, 43]. We will consider a system without feedback and a system with feedback.

To obtain disk rotation, we will select a DC motor as the actuator because it provides a speed proportional to the applied motor voltage. For the input voltage to the motor, we will select an amplifier that can provide the required power.

The open-loop system (without feedback) is shown in Figure 1.24(a). This system uses a battery source to provide a voltage that is proportional to the desired speed. This voltage is amplified and applied to the motor. The block diagram of the openloop system identifying the controller, actuator, and process is shown in Figure 1.24(b).

To obtain a feedback system, we need to select a sensor. One useful sensor is a tachometer that provides an output voltage proportional to the speed of its shaft. Thus the closed-loop feedback system takes the form shown in Figure 1.25(a). The block diagram model of the feedback system is shown in Figure 1.25(b). The error voltage is generated by the difference between the input voltage and the tachometer voltage.

We expect the feedback system of Figure 1.25 to be superior to the open-loop system of Figure 1.24 because the feedback system will respond to errors and act to

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0060.jpg?height=271&width=774&top_left_y=1525&top_left_x=714)

(a)

FIGURE 1.24

(a) Open-loop (without feedback) control of the speed of a rotating disk. (b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0060.jpg?height=169&width=1190&top_left_y=1898&top_left_x=503)

(b) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0061.jpg?height=322&width=941&top_left_y=159&top_left_x=508)

(a)

FIGURE 1.25

(a) Closed-loop control of the speed of a rotating disk. (b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0061.jpg?height=289&width=1298&top_left_y=582&top_left_x=320)

(b)

reduce them. With precision components, we could expect to reduce the error of the feedback system to one-hundredth of the error of the open-loop system.

\section{EXAMPLE 1.14 Insulin delivery control system}

Control systems have been utilized in the biomedical field to create implanted automatic drug-delivery systems to patients [29-31]. Automatic systems can be used to regulate blood pressure, blood sugar level, and heart rate. A common application of control engineering is in the field of drug delivery in which mathematical models of the dose-effect relationship of the drugs are used. A drug-delivery system implanted in the body uses a closed-loop system since miniaturized glucose sensors are now available. The best solutions rely on individually programmable, pocket-sized insulin pumps that can deliver insulin.

The blood glucose and insulin concentrations for a healthy person are shown in Figure 1.26. The system must provide the insulin from a reservoir implanted within the diabetic person. Therefore, the control goal is:

\section{Control Goal}

Design a system to regulate the blood sugar concentration of a diabetic by controlled dispensing of insulin.

Referring to Figure 1.26, the next step in the design process is to define the variable to be controlled. Associated with the control goal we can define the variable to be controlled to be:

\section{Variable to Be Controlled \\ Blood glucose concentration}

In subsequent chapters, we will have the tools to quantitatively describe the control design specifications using a variety of steady-state performance FIGURE 1.26

The blood glucose and insulin levels for a healthy person.
FIGURE 1.27

(a) Open-loop (without feedback) control and (b) closed-loop control of blood glucose.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0062.jpg?height=598&width=832&top_left_y=155&top_left_x=520)

specifications and transient response specifications, both in the time-domain and in the frequency domain. At this point, the control design specifications will be qualitative and imprecise. In that regard, for the problem at hand, we can state the design specification as:

\section{Control Design Specifications}

Provide a blood glucose level for the diabetic that closely approximates (tracks) the glucose level of a healthy person.

Given the design goals, variables to be controlled, and control design specifications, we can now propose a preliminary system configuration. A closed-loop system uses a fully implantable glucose sensor and miniature motor pump to regulate the insulin delivery rate as shown in Figure 1.27. The feedback control system uses a sensor to measure the actual glucose level and compare that level with the desired level, thus turning the motor pump on when it is required.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0062.jpg?height=176&width=763&top_left_y=1422&top_left_x=743)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0062.jpg?height=329&width=1136&top_left_y=1698&top_left_x=594)

Desired glucose level

(b) 

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

We will use the design process of Figure 1.17 in each chapter to identify the steps that we are accomplishing. For example, in Chapter 1 we (1) identify the control goal, (2) identify the variables to control, (3) write the initial specifications for the variables, and (4) establish the preliminary system configuration.

Information can be readily and efficiently stored on magnetic disks. Hard disk drives (HDD) are used in notebook computers and larger computers of all sizes and are essentially all standardized as defined by ANSI standards. Even with the advent of advanced storage technologies, such as cloud storage, flash memory, and solid-state drives (SSDs), the HDD remains an important storage media. The role of the HDD is changing from fast and primary storage to slow storage with enormous capacity [50]. The installation of SSD units are surpassing HDD units for the first time. The SSD units are known to have much better performance than HDD, however, the difference in cost per gigabyte ratio is about $6: 1$, and that is expected to remain that way until 2030. Among the many reasons to keep our interest in HDD units is that it is anticipated that about $90 \%$ of the required capacity for cloud computing applications will be realized with HHDs moving into the foreseeable future $[51,62]$. In the past, disk drive designers have concentrated on increasing data density and data access times. Designers are now considering employing disk drives to perform tasks historically delegated to central processing units (CPUs), thereby leading to improvements in the computing environment [63]. Three areas of "intelligence" under investigation include off-line error recovery, disk drive failure warnings, and storing data across multiple disk drives. Consider the basic diagram of a disk drive shown in Figure 1.28. The goal of the disk drive reader device is to position the reader head to read the data stored on a track on the disk. The variable to accurately control is the position of the reader head (mounted on a slider device). The disk rotates at a speed between 1800 and 10,000 rpm, and the head "flies" above the disk at a distance of less than $100 \mathrm{~nm}$. The initial specification for the position accuracy is $1 \mu \mathrm{m}$. Furthermore, we plan to be able to move the head from track a to track b within $50 \mathrm{~ms}$, if possible. Thus, we establish an initial system configuration

FIGURE 1.28

(a) A disk drive (Ragnarock/ Shutterstock.) (b) Diagram of a disk drive.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0063.jpg?height=410&width=518&top_left_y=1637&top_left_x=369)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0063.jpg?height=414&width=607&top_left_y=1637&top_left_x=901)

(b) FIGURE 1.29

Closed-loop control system for disk drive.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0064.jpg?height=238&width=1169&top_left_y=154&top_left_x=507)

as shown in Figure 1.29. This proposed closed-loop system uses a motor to actuate (move) the arm to the desired location on the disk. We will consider the design of the disk drive further in Chapter 2.

\subsection{SUMMARY}

In this chapter, we discussed open- and closed-loop feedback control systems. Examples of control systems through the course of history were presented to motivate and connect the subject to the past. In terms of contemporary issues, key areas of application were discussed, including humanoid robots, unmanned aerial vehicles, wind energy, hybrid automobiles, and embedded control. The central role of controls in mechatronics was discussed. Mechatronics is the synergistic integration of mechanical, electrical, and computer systems. Finally, the design process was presented in a structured form and included the following steps: the establishment of goals and variables to be controlled, definition of specifications, system definition, modeling, and analysis. The iterative nature of design allows us to handle the design gap effectively while accomplishing necessary trade-offs in complexity, performance, and cost.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. In the following True or False and Multiple Choice problems, circle the correct answer.

1. The flyball governor is generally agreed to be the first automatic feedback controller used in an industrial process.

True or False

2. A closed-loop control system uses a measurement of the output and feedback of the signal to compare it with the desired input.

True or False

3. Engineering synthesis and engineering analysis are the same.

True or False

4. The block diagram in Figure 1.30 is an example of a closed-loop feedback system.

True or False

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0064.jpg?height=96&width=679&top_left_y=1876&top_left_x=733)

FIGURE 1.30 System with control device, actuator, and process. 5. A multivariable system is a system with more than one input and/or more than one output.

6. Early applications of feedback control include which of the following?
a. Water clock of Ktesibios
b. Watt's flyball governor
c. Drebbel's temperature regulator
d. All of the above

7. Important modern applications of control systems include which of the following?
a. Safe automobiles
b. Autonomous robots
c. Automated manufacturing
d. All of the above

8. Complete the following sentence:

Control of an industrial process by automatic rather than manual means is often called
a. negative feedback
b. automation
c. a design gap
d. a specification

9. Complete the following sentence: are intrinsic in the progression from an initial concept to the final product.
a. Closed-loop feedback systems
b. Flyball governors
c. Design gaps
d. Open-loop control systems

10. Complete the following sentence:

Control engineers are concerned with understanding and controlling segments of their environments, often called
a. systems
b. design synthesis
c. trade-offs
d. risk

11. Early pioneers in the development of systems and control theory include:
a. H. Nyquist
b. H. W. Bode
c. H. S. Black
d. All of the above

12. Complete the following sentence:

An open-loop control system utilizes an actuating device to control a process
a. without using feedback
b. using feedback
c. in engineering design
d. in engineering synthesis 13. A system with more than one input variable or more than one output variable is known by what name?
a. Closed-loop feedback system
b. Open-loop feedback system
c. Multivariable control system
d. Robust control system

14. Control engineering is applicable to which fields of engineering?
a. Mechanical and aerospace
b. Electrical and biomedical
c. Chemical and environmental
d. All of the above

15. Closed-loop control systems should have which of the following properties:
a. Good regulation against disturbances
b. Desirable responses to commands
c. Low sensitivity to changes in the plant parameters
d. All of the above

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Optimization

b. Risk

c. Complexity of design

d. System

e. Design

f. Closed-loop feedback control system

g. Flyball governor

h. Specifications

i. Synthesis

j. Open-loop control system

k. Feedback signal

I. Robot

m. Multivariable control system
The output signal is fed back so that it subtracts from the input signal.

A system that uses a measurement of the output and compares it with the desired output. A set of prescribed performance criteria.

A measure of the output of the system used for feedback to control the system.

A system with more than one input variable or more than one output variable.

The result of making a judgment about how much compromise must be made between conflicting criteria.

An interconnection of elements and devices for a desired purpose.

A reprogrammable, multifunctional manipulator used for a variety of tasks.

A gap between the complex physical system and the design model intrinsic to the progression from the initial concept to the final product.

The intricate pattern of interwoven parts and knowledge required.

The ratio of physical output to physical input of an industrial process.

The process of designing a technical system.

A system that utilizes a device to control the process without using feedback. 
n. Design gap
o. Positive feedback
p. Negative feedback
q. Trade-off
r. Productivity
s. Engineering design
t. Process
u. Control system
v. Automation

Uncertainties embodied in the unintended consequences of a design.

The process of conceiving or inventing the forms, parts, and details of a system to achieve a specified purpose.

The device, plant, or system under control.

The output signal is fed back so that it adds to the input signal.

An interconnection of components forming a system configuration that will provide a desired response.

The control of a process by automatic means.

The adjustment of the parameters to achieve the most favorable or advantageous design.

The process by which new physical configurations are created.

A mechanical device for controlling the speed of a steam engine.

\section{EXERCISES}

Exercises are straightforward applications of the concepts of the chapter.

The following systems can be described by a block diagram showing the cause-effect relationship and the feedback (if present). Identify the function of each block and the desired input variable, output variable, and measured variable. Use Figure 1.3 as a model where appropriate.

E1.1 Describe typical sensors that can measure each of the following [93]:

a. Linear position
b. Velocity (or speed)
c. Nongravitational acceleration
d. Rotational position (or angle)
e. Rotational velocity
f. Temperature
g. Pressure
h. Liquid (or gas) flow rate
i. Torque
j. Force
k. Earth's magnetic field
p. Heart rate

$i(t)$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0067.jpg?height=225&width=1042&top_left_y=1802&top_left_x=330)

FIGURE E1.3 Partial block diagram of an optical source. E1.2 Describe typical actuators that can convert the following [93]:
a. Mechanical energy to fluidic energy
b. Mechanical energy to electrical energy
c. Electrical energy to mechanical energy
d. Kinetic energy to electrical energy
e. Electrical energy to heat

E1.3 A CD player laser beam focusing system has an array of photodiodes that is used to determine if the laser beam is in focus. The laser beam focus is controlled by an input current to a lens focusing motor. A microprocessor controls the input current to the motor by comparing the output from the array of photodiodes. Complete the block diagram representing this closed-loop control system shown in Figure E1.3, identifying the output, input, and measured variables, and the control device.

E1.4 A surgeon uses a control system, that is a robot surgical system, to perform surgery remotely. Sketch a block diagram to illustrate this feedback system.

E1.5 Fly-fishing is a sport that challenges the person to cast a small feathery fly using a light rod and line. The goal is to place the fly accurately and lightly on the distant surface of the stream [59]. Describe the fly-casting process and a model of this process.

E1.6 An autofocus camera will adjust the distance of the lens from the film by using a beam of infrared or ultrasound to determine the distance to the subject [42]. Sketch a block diagram of this control system, and briefly explain its operation.

E1.7 Because a sailboat cannot sail directly into the wind, and traveling straight downwind is usually slow, the shortest sailing distance is rarely a straight line. Thus sailboats tack upwind-the familiar zigzag courseand jibe downwind. A tactician's decision of when to tack and where to go can determine the outcome of a race.

Describe the process of tacking a sailboat as the wind shifts direction. Sketch a block diagram depicting this process.

E1.8 An autonomous self-driving vehicle can sense its environment and navigate without human input. Describe a simplified feedback control system for a guidance system that ensures the vehicle navigates its surroundings safely.

E1.9 Describe the block diagram of the control system of a skateboard with a human rider.

E1.10 Describe the process of human biofeedback used to regulate factors such as pain or body temperature. Biofeedback is a technique whereby a human can, with some success, consciously regulate pulse, reaction to pain, and body temperature.

E1.11 Future advanced commercial aircraft will be E-enabled. This will allow the aircraft to take advantage of continuing improvements in computer power and network growth. Aircraft can continuously communicate their location, speed, and critical health parameters to ground controllers, and gather and transmit local meteorological data. Sketch a block diagram showing how the meteorological data from multiple aircraft can be transmitted to the ground, combined using ground-based powerful networked computers to create an accurate weather situational awareness, and then transmitted back to the aircraft for optimal routing.

E1.12 Unmanned aerial vehicles (UAVs) are being developed to operate in the air autonomously for long periods of time. By autonomous, we mean that there is no interaction with human ground controllers. Sketch a block diagram of an autonomous UAV that is tasked for crop monitoring using aerial photography. The UAV must photograph and transmit the entire land area by flying a pre-specified trajectory as accurately as possible.

E1.13 Consider the inverted pendulum shown in Figure E1.13. Sketch the block diagram of a feedback control system. Identify the process, sensor, actuator, and controller. The objective is keep the pendulum in the upright position, that is to keep $\theta=0$, in the presence of disturbances.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0068.jpg?height=501&width=731&top_left_y=1260&top_left_x=1008)

FIGURE E1.13 Inverted pendulum control.

E1.14 Sketch a block diagram of a person playing a video game. Suppose that the input device is a joystick and the game is being played on a desktop computer. E1.15 For people with diabetes, keeping track of and maintaining blood glucose at safe levels is very important. Continuous blood glucose monitors and readers are available that enable a measurement of blood glucose with a painless scan rather than a fingerprick, as illustrated in Figure E1.15. Sketch a block diagram with a continuous blood glucose monitor and a reader and their possible control actions they might implement as they manage a high blood glucose reading.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0069.jpg?height=320&width=758&top_left_y=148&top_left_x=858)

FIGURE E1.15 A continuous blood glucose monitoring system

\section{PROBLEMS}

Problems require extending the concepts of this chapter to new situations.

The following systems may be described by a block diagram showing the cause-effect relationship and the feedback (if present). Each block should describe its function. Use Figure 1.3 as a model where appropriate.

P1.1 Automobiles have variable windshield wiper speed settings for different rain intensity. Sketch a block diagram of a wiper system where the driver sets the wiper speed. Identify the function of each element of the variable speed control of the wiper system.

P1.2 Control systems can use a human operator as part of a closed-loop control system. Sketch the block diagram of the valve control system shown in Figure P1.2.

P1.3 In a chemical process control system, it is valuable to control the chemical composition of the product. To do so, a measurement of the composition can be obtained by using an infrared stream analyzer, as shown in Figure P1.3. The valve on the additive stream may be controlled. Complete the control feedback loop, and sketch a block diagram describing the operation of the control loop.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0069.jpg?height=417&width=703&top_left_y=751&top_left_x=900)

FIGURE P1.2 Fluid-flow control.

P1.4 The accurate control of a nuclear reactor is important for power system generators. Assuming the number of neutrons present is proportional to the power level, an ionization chamber is used to measure the power level. The current $i_{\mathrm{O}}$ is proportional to the power level. The position of the graphite control rods moderates the power level. Complete the control system of the nuclear reactor shown in Figure P1.4 and sketch the block diagram describing the operation of the feedback control loop.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0069.jpg?height=317&width=1256&top_left_y=1775&top_left_x=275)

FIGURE P1.3 Chemical composition control. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0070.jpg?height=275&width=567&top_left_y=154&top_left_x=333)

FIGURE P1.4 Nuclear reactor control.

P1.5 A light-seeking control system, used to track the sun, is shown in Figure P1.5. The output shaft, driven by the motor through a worm reduction gear, has a bracket attached on which are mounted two photocells. Complete the closed-loop system so that the system follows the light source.

P1.6 Feedback systems do not always involve negative feedback. Economic inflation, which is evidenced by continually rising prices, is a positive feedback system. A positive feedback control system, as shown in Figure P1.6, adds the feedback signal to the input signal, and the resulting signal is used as the input to the process. A simple model of the price-wage inflationary spiral is shown in Figure P1.6. Add additional feedback loops, such as legislative control or control of the tax rate, to stabilize the system. It is assumed that an increase in workers' salaries, after some time delay, results in an increase in prices. Under what conditions could prices be stabilized by falsifying or delaying the availability of cost-of-living data? How would a national wage and price economic guideline program affect the feedback system?

P1.7 The story is told about the sergeant who stopped at the jewelry store every morning at nine o'clock and compared and reset his watch with the chronometer in the window. Finally, one day the sergeant went into the store and complimented the owner on the accuracy of the chronometer.

"Is it set according to time signals from Arlington?" asked the sergeant.

"No," said the owner, "I set it by the five o'clock cannon fired from the fort each afternoon. Tell me,

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0070.jpg?height=405&width=731&top_left_y=155&top_left_x=1008)

FIGURE P1.6 Positive feedback.

Sergeant, why do you stop every day and check your watch?" fort!"

The sergeant replied, "I'm the gunner at the

Is the feedback prevalent in this case positive or negative? The jeweler's chronometer loses two minutes each 24-hour period and the sergeant's watch loses three minutes during each eight hours. What is the net time error of the cannon at the fort after 12 days?

P1.8 In a public address system, when the microphone is placed too close to the loudspeaker, a positive feedback system is inadvertently created. The audio input from the microphone is amplified, which comes out through the loudspeaker. This audio output is received by the microphone again, which gets amplified further, and comes out through the loudspeaker again. This positive loop gain is known as audio feedback or the Larsen effect, and causes the system to overload, resulting in a high-pitched sound. Construct the corresponding feedback model, and identify each block of the model.

P1.9 Models of physiological control systems are valuable aids to the medical profession. A model of the heart-rate control system is shown in Figure P1.9 [23, 48]. This model includes the processing of the nerve signals by the brain. The heart-rate control system is, in fact, a multivariable system, and the variables $x, y, w, v, z$, and $u$ are vector

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0070.jpg?height=308&width=921&top_left_y=1730&top_left_x=506)

FIGURE P1.5 A photocell is mounted in each tube. The light reaching each cell is the same in both only when the light source is exactly in the middle as shown. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0071.jpg?height=372&width=1269&top_left_y=153&top_left_x=198)

FIGURE P1.9 Heart-rate control.

variables. In other words, the variable $x$ represents many heart variables $x_{1}, x_{2}, \ldots, x_{n}$. Examine the model of the heart-rate control system and add or delete blocks, if necessary. Determine a control system model of one of the following physiological control systems:

1. Respiratory control system

2. Adrenaline control system

3. Human arm control system

4. Eye control system

5. Pancreas and the blood-sugar-level control system

6. Circulatory system

P1.10 The role of air traffic control systems is increasing as airplane traffic increases at busy airports. Engineers are developing air traffic control systems and collision avoidance systems using the Global Positioning System (GPS) navigation satellites [34, 55]. GPS allows each aircraft to know its position in the airspace landing corridor very precisely. Sketch a block diagram depicting how an air traffic controller might use GPS for aircraft collision avoidance.

P1.11 Automatic control of water level using a float level was used in the Middle East for a water clock $[1,11]$. The water clock (Figure P1.11) was used from sometime before Christ until the 17th century. Discuss the operation of the water clock, and establish how the float provides a feedback control that maintains the accuracy of the clock. Sketch a block diagram of the feedback system.

P1.12 An automatic turning gear for windmills was invented by Meikle in about $1750[1,11]$. The fantail gear shown in Figure P1.12 automatically turns the windmill into the wind. The fantail windmill at right angle to the mainsail is used to turn the turret. The gear ratio is of the order of 3000 to 1 . Discuss the operation of the windmill, and establish the feedback operation that maintains the main sails into the wind.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0071.jpg?height=643&width=527&top_left_y=657&top_left_x=978)

FIGURE P1.11 Water clock. (From Newton, Gould, and Kaiser, Analytical Design of Linear Feedback Controls. Wiley, New York, 1957, with permission.)

P1.13 A common example of a two-input control system is an automobile power transmission system, with a gear shifter and an accelerator pedal. The objective is to obtain (1) a desired speed and (2) a desired torque. Sketch a block diagram of the closed-loop control system.

P1.14 Adam Smith (1723-1790) discussed the issue of free competition between the participants of an economy in his book Wealth of Nations. It may be said that Smith employed social feedback mechanisms to explain his theories [41]. Smith suggests that (1) the available workers as a whole compare the various possible employments and enter that one offering the greatest rewards, and (2) in any employment the 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0072.jpg?height=543&width=755&top_left_y=152&top_left_x=220)

FIGURE P1.12 Automatic turning gear for windmills. (From Newton, Gould, and Kaiser, Analytical Design of Linear Feedback Controls. Wiley, New York, 1957, with permission.)

rewards diminish as the number of competing workers rises. Let $r=$ total of rewards averaged over all trades, $c=$ total of rewards in a particular trade, and $q=$ influx of workers into the specific trade. Sketch a feedback system to represent this system.

P1.15 Small computers are used as part of a start-stop system in automobiles to control emissions and obtain improved gas mileage. A computer-controlled start-stop system that automatically stops and restarts an engine to reduce the time the engine idles could improve gas mileage and reduce unwanted polluting emissions significantly. Sketch a block diagram for such a system for an automobile.

P1.16 All humans have experienced a fever associated with an illness. A fever is related to the changing of the control input in the body's thermostat. This thermostat, within the brain, normally regulates temperature near $98^{\circ} \mathrm{F}$ in spite of external temperatures ranging from $0^{\circ} \mathrm{F}$ to $100^{\circ} \mathrm{F}$ or more. For a fever, the input, or desired, temperature is increased. Even to many scientists, it often comes as a surprise to learn that fever does not indicate something wrong with body temperature control but rather well-contrived regulation at an elevated level of desired input. Sketch a block diagram of the temperature control system and explain how aspirin will lower a fever.

P1.17 Baseball players use feedback to judge a fly ball and to hit a pitch [35]. Describe a method used by a

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0072.jpg?height=624&width=644&top_left_y=163&top_left_x=1108)

FIGURE P1.18 Pressure regulator.

batter to judge the location of a pitch so that he can have the bat in the proper position to hit the ball.

P1.18 A cutaway view of a commonly used pressure regulator is shown in Figure P1.18. The desired pressure is set by turning a calibrated screw. This compresses the spring and sets up a force that opposes the upward motion of the diaphragm. The bottom side of the diaphragm is exposed to the water pressure that is to be controlled. Thus the motion of the diaphragm is an indication of the pressure difference between the desired and the actual pressures. It acts like a comparator. The valve is connected to the diaphragm and moves according to the pressure difference until it reaches a position in which the difference is zero. Sketch a block diagram showing the control system with the output pressure as the regulated variable.

P1.19 Ichiro Masaki of General Motors has patented a system that automatically adjusts a car's speed to keep a safe distance from vehicles in front. Using a video camera, the system detects and stores a reference image of the car in front. It then compares this image with a stream of incoming live images as the two cars move down the highway and calculates the distance. Masaki suggests that the system could control steering as well as speed, allowing drivers to lock on to the car ahead and get a "computerized tow." Sketch a block diagram for the control system. P1.20 A high-performance race car with an adjustable wing (airfoil) is shown in Figure P1.20. Develop a block diagram describing the ability of the airfoil to keep a constant road adhesion between the car's tires and the race track surface. Why is it important to maintain good road adhesion?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0073.jpg?height=595&width=758&top_left_y=399&top_left_x=89)

FIGURE P1.20 A high-performance race car with an adjustable wing.

P1.21 The potential of employing two or more helicopters for transporting payloads that are too heavy for a single helicopter is a well-addressed issue in the civil and military rotorcraft design arenas [37]. Overall requirements can be satisfied more efficiently with a smaller aircraft by using multilift for infrequent peak demands. Hence the principal motivation for using multilift can be attributed to the promise of obtaining increased productivity without having to manufacture larger and more expensive helicopters. A specific case of a multilift arrangement where two helicopters jointly transport payloads has been named twin lift. Figure P1.21 shows a typical "two-point pendant" twin lift configuration in the lateral/vertical plane.

Develop the block diagram describing the pilots' action, the position of each helicopter, and the position of the load.

P1.22 Engineers want to design a control system that will allow a building or other structure to react to the force of an earthquake much as a human would. The structure would yield to the force, but only so much, before developing strength to push back [47]. Develop a block diagram of a control system to reduce the effect of an earthquake force.

P1.23 Engineers at the Science University of Tokyo are developing a robot with a humanlike face [52]. The

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0073.jpg?height=543&width=778&top_left_y=152&top_left_x=839)

FIGURE P1.21 Two helicopters used to lift and move a large load.

robot can display facial expressions, so that it can work cooperatively with human workers. Sketch a block diagram for a facial expression control system of your own design.

P1.24 An innovation for an intermittent automobile windshield wiper is the concept of adjusting its wiping cycle according to the intensity of the rain [54]. Sketch a block diagram of the wiper control system.

P1.25 In the past 50 years, over 20,000 metric tons of hardware have been placed in Earth's orbit. During the same time span, over 15,000 metric tons of hardware returned to Earth. The objects remaining in Earth's orbit range in size from large operational spacecraft to tiny flecks of paint. There are over 500,000 objects in Earth's orbit $1 \mathrm{~cm}$ or larger in size. About 20,000 of the space objects are currently tracked from groundstations on the Earth. Space traffic control [61] is becoming an important issue, especially for commercial satellite companies that plan to "fly" their satellites through orbit altitudes where other satellites are operating, and through areas where high concentrations of space debris may exist. Sketch a block diagram of a space traffic control system that commercial companies might use to keep their satellites safe from collisions while operating in space.

P1.26 NASA is developing a compact rover designed to transmit data from the surface of an asteroid back to Earth, as illustrated in Figure P1.26. The rover will use a camera to take panoramic shots of the asteroid surface. The rover can position itself so that the camera can be pointed straight down 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0074.jpg?height=576&width=738&top_left_y=154&top_left_x=226)

FIGURE P1.26 Microrover designed to explore an asteroid. (Photo courtesy of NASA.) at the surface or straight up at the sky. Sketch a block diagram illustrating how the microrover can be positioned to point the camera in the desired direction. Assume that the pointing commands are relayed from the Earth to the microrover and that the position of the camera is measured and relayed back to Earth.

P1.27 A direct methanol fuel cell is an electrochemical device that converts a methanol water solution to electricity [75]. Like rechargeable batteries, fuel cells directly convert chemicals to energy; they are very often compared to batteries, specifically rechargeable batteries. However, one significant difference between rechargeable batteries and direct methanol fuel cells is that, by adding more methanol water solution, the fuel cells recharge instantly. Sketch a block diagram of the direct methanol fuel cell recharging system that uses feedback to continuously monitor and recharge the fuel cell.

\section{ADVANCED PROBLEMS}

Advanced problems represent problems of increasing complexity.

AP1.1 The development of robotic microsurgery devices will have major implications on delicate eye and brain surgical procedures. One such device is shown in Figure AP1.1. Haptic (force and tactile) feedback can greatly help a surgeon by mimicking the physical interaction that takes place between the microsurgery robotic manipulator and human tissue. Sketch a block diagram for a haptic and tactile subsystem with a microsurgical device in the loop being operated by a surgeon. Assume that the force of the end-effector on the microsurgical device can be measured and is available for feedback.

AP1.2 Advanced wind energy systems are being installed in many locations throughout the world as a way for nations to deal with rising fuel prices and energy shortages, and to reduce the negative effects of fossil fuel utilization on the quality of the air. The modern windmill can be viewed as a mechatronic system. Think about how an advanced wind energy system would be designed as a mechatronic system. List the various components of the wind energy system and associate each component with one of the five elements of a mechatronic system: physical system modeling, signals and systems, computers and logic systems, software and data acquisition, and sensors and actuators.

AP1.3 Many modern luxury automobiles have an advanced driver-assistance systems (ADAS) option. The collision avoidance feature of an ADAS system uses radars to detect nearby obstacles to notify drivers of potential collisions. Figure AP1.3 illustrates the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0074.jpg?height=717&width=746&top_left_y=996&top_left_x=1005)

FIGURE AP1.1 Microsurgery robotic manipulator. (Photo courtesy of NASA.)

collision avoidance feature of an ADAS system. Sketch a block diagram of this ADAS feedback control system. In your own words, describe the control problem and the challenges facing the designers of the control system.

AP1.4 Adaptive optics has applications to a wide variety of key control problems, including imaging of the human retina and large-scale, ground-based astronomical 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0075.jpg?height=642&width=1421&top_left_y=154&top_left_x=143)

FIGURE AP1.3 A collision avoidance feature of an ADAS system.

observations [98]. In both cases, the approach is to use a wavefront sensor to measure distortions in the incoming light and to actively control and compensate to the errors induced by the distortions. Consider the case of an extremely large ground-based optical telescope, possibly an optical telescope up to 100 meters in diameter. The telescope components include deformable mirrors actuated by micro-electro-mechanical (MEMS) devices and sensors to measure the distortion of the incoming light as it passes through the turbulent and uncertain atmosphere of Earth.

There is at least one major technological barrier to constructing a $100-\mathrm{m}$ optical telescope. The numerical computations associated with the control and compensation of the extremely large optical telescope can be on the order of $10^{10}$ calculations each
$1.5 \mathrm{~ms}$. If we assume that the computational capability is available, then one can consider the design of a feedback control system that uses the available computational power. We can consider many control issues associated with the large-scale optical telescope. Some of the controls problems that might be considered include controlling the pointing of the main dish, controlling the individual deformable mirrors, and attenuating the deformation of the dish due to changes in outside temperature.

Describe a closed-loop feedback control system to control one of the deformable mirrors to compensate for the distortions in the incoming light. Figure AP1.4 shows a diagram of the telescope with a single deformable mirror. Suppose that the mirror has an associated MEMS actuator that can be used to

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0075.jpg?height=661&width=981&top_left_y=1457&top_left_x=375)

FIGURE AP1.4 Extremely large optical telescope with deformable mirrors for atmosphere compensation. vary the orientation. Also, assume that the wavefront sensor and associated algorithms provide the desired configuration of the deformable mirror to the feedback control system.

AP1.5 The Burj Dubai is the tallest building in the world [94]. The building, shown in Figure AP1.5, stands at over $800 \mathrm{~m}$ with more than 160 stories. There are 57 elevators servicing this tallest free-standing structure in the world. Traveling at up to $10 \mathrm{~m} / \mathrm{s}$, the elevators have the world's longest travel distance from lowest to highest stop. Describe a closed-loop feedback control system that guides an elevator of a highrise building to a desired floor while maintaining a reasonable transit time [95]. Remember that high accelerations will make the passengers uncomfortable.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0076.jpg?height=600&width=402&top_left_y=704&top_left_x=394)

FIGURE AP1.5 The world's tallest building in Dubai. (Photo courtesy of Obstando Images/Alamy.)

AP1.6 The robotic vacuum cleaner depicted in Figure AP1.6 is an example of a mechatronic system that aids humans in maintaining their homes. A dirt detection control system would enable the robotic vacuum cleaner to vacuum the same area more than once if the dirt level is unsatisfactory, since a single pass may not be enough to adequately remove a high level of dirt. If the robotic vacuum cleaner detects more dirt than usual, it should vacuum the same area until the sensors detect lesser dirt in that area. Describe a closed-loop feedback control system to

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0076.jpg?height=559&width=647&top_left_y=172&top_left_x=1031)

FIGURE AP1.6 A robotic vacuum cleaner communicates with the base station as it maneuvers around the room. (Photo courtesy of Hugh Threlfall/Alamy.)

detect an acceptable level of dirt, so that the robotic vacuum cleaner will vacuum the same area again.

AP1.7 Space $\mathrm{X}$ has developed a very important system to allow for recovery of the first stage of their Falcon rocket at sea, as depicted in Figure AP1.7. The landing ship is an autonomous drone ship. Sketch a block diagram describing a control system that would control the pitch and roll of the landing ship on the sea.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0076.jpg?height=447&width=755&top_left_y=1230&top_left_x=996)

FIGURE AP1.7 Space $X$ return landing on sea- based drone ship.

\section{DESIGN PROBLEMS}

Design problems emphasize the design task. Continuous design problems (CDP) build upon a design problem from chapter to chapter.

CDP1.1 Increasingly stringent requirements of modern, high-precision machinery are placing increasing demands on slide systems [53]. The typical goal is to accurately control the desired path of the table shown in Figure CDP1.1. Sketch a block diagram model of a feedback system to achieve the desired goal. The table can move in the $x$ direction as shown. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0077.jpg?height=580&width=456&top_left_y=171&top_left_x=240)

FIGURE CDP1.1 Machine tool with table.

DP1.1 Background noise affects the audio output quality of a headphone. Noise-cancelling headphones use active noise control to reduce this unwanted ambient noise. Sketch a block diagram of an "active noise control" feedback system that will reduce the effect of unwanted noise. Indicate the device within each block.

DP1.2 Aircraft are fitted with autopilot control that, at the press of a button, automatically controls the flight path of an aircraft, without manual control by a pilot. In this way, the pilot can focus on monitoring the flight path, weather, and onboard systems. Design a feedback control in block diagram form for an autopilot system.

DP1.3 Describe a feedback control system in which a user utilizes a smart phone to remotely monitor and control a washing machine as illustrated in Figure DP1.3. The control system should be able to start and stop the wash cycle, control the amount of detergent and the water temperature, and provide notifications on the status of the cycle.

DP1.4 As part of the automation of a dairy farm, the automation of cow milking is under study [36]. Design a milking machine that can milk cows four or five times a day at the cow's demand. Sketch a block diagram and indicate the devices in each block.

DP1.5 A large, braced robot arm for welding large structures is shown in Figure DP1.5. Sketch the block diagram of a closed-loop feedback control system for accurately controlling the location of the weld tip.

DP1.6 Vehicle traction control, which includes antiskid braking and antispin acceleration, can enhance vehicle performance and handling. The objective of this control is to maximize tire traction by preventing locked brakes as well as tire spinning during acceleration. Wheel slip, the difference between the vehicle speed and the wheel speed, is chosen as the controlled

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0077.jpg?height=468&width=642&top_left_y=152&top_left_x=921)

FIGURE DP1.3 Using a smart phone to remotely monitor and control a washing machine. (Photo courtesy of Mikkel William/E+/Getty Images.)

variable because of its strong influence on the tractive force between the tire and the road [19]. The adhesion coefficient between the wheel and the road reaches a maximum at a low slip. Develop a block diagram model of one wheel of a traction control system.

DP1.7 The Hubble space telescope was repaired and modified in space on several occasions [44, 46, 49]. One

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0077.jpg?height=854&width=722&top_left_y=1224&top_left_x=895)

FIGURE DP1.5 Robot welder. challenging problem with controlling the Hubble is damping the jitter that vibrates the spacecraft each time it passes into or out of the Earth's shadow. The worst vibration has a period of about 20 seconds, or a frequency of 0.05 hertz. Design a feedback system that will reduce the vibrations of the Hubble space telescope.

DP1.8 A challenging application of control design is the use of nanorobots in medicine. Nanorobots will require onboard computing capability, and very tiny sensors and actuators. Fortunately, advances in biomolecular computing, bio-sensors, and actuators are promising to enable medical nanorobots to emerge within the next decade [99]. Many interesting medical applications will benefit from nanorobotics. For example, one use might be to use the robotic devices to precisely deliver anti-HIV drugs or to combat cancer by targeted delivering of chemotherapy as illustrated in Figure DP1.8.

At the present time, we cannot construct practical nanorobots, but we can consider the control design process that would enable the eventual development and installation of these tiny devices in the medical field. Consider the problem of designing a nanorobot to deliver a cancer drug to a specific location within the human body. The target site might be the location of a tumor, for example. Suggest one or more control goals that might guide the design process. Recommend the variables that should be controlled and provide a list of reasonable specifications for those variables.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0078.jpg?height=471&width=607&top_left_y=1230&top_left_x=313)

FIGURE DP1.8 An artist illustration of a nanorobot interacting with human blood cells.

DP1.9 Consider the human transportation vehicle (HTV) depicted in Figure DP1.9. The self-balancing HTV is actively controlled to allow safe and easy transportation of a single person [97]. Describe a closed-loop feedback control system to assist the rider of the HTV in balancing and maneuvering the vehicle.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0078.jpg?height=590&width=325&top_left_y=340&top_left_x=1218)

FIGURE DP1.9 Personal transportation vehicle. (Photo courtesy of Sergiy Kuzmin/Shutterstock.)

DP1.10 In addition to maintaining automobile speed, many vehicles can also maintain a prescribed distance to an automobile in front, as illustrated in Figure DP1.10. Design a feedback control sysytem that can maintain cruise speed at a prescribed distance to the vehicle in front. What happens if the leading vehicle slows down below the desired cruise speed?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0078.jpg?height=541&width=666&top_left_y=1315&top_left_x=1031)

FIGURE DP1.10 Maintaining cruise speed at a prescribed distance. 

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) False; (5) True

Multiple Choice: (6) d; (7) d; (8) b; (9) c; (10) a; (11) d; (12) a; (13) c; (14) d; (15) d
Word Match (in order, top to bottom): p, f, h, k, m, q, d, l, n, c, r, s, j, b, e, t, o, u, v, a, i, g

\section{TERMS AND CONCEPTS}

Actuator A device employed by the control system to alter or adjust the environment.

Analysis The process of examining a system in order to gain a better understanding, provide insight, and find directions for improvement.

Automation The control of a process by automatic means.

Closed-loop feedback control system A system that uses a measurement of the output and compares it with the desired output to control the process.

Complexity of design The intricate pattern of interwoven parts and knowledge required.

Control system An interconnection of components forming a system configuration that will provide a desired response.

Control system engineering An engineering discipline that focuses on the modeling of a wide assortment of physical systems and using those models to design controllers that will cause the closed-loop systems to possess desired performance characteristics.

Design The process of conceiving or inventing the forms, parts, and details of a system to achieve a specified purpose.

Design gap A gap between the complex physical system and the design model intrinsic to the progression from the initial concept to the final product.

Disturbance An unwanted input signal that affects the output signal.

Embedded control Feedback control system that employs on-board special-purpose digital computers as integral components of the feedback loop.

Engineering design The process of designing a technical system.

Feedback signal A measure of the output of the system used for feedback to control the system.

Flyball governor A mechanical device for controlling the speed of a steam engine.

Hybrid fuel automobile An automobile that uses a conventional internal combustion engine in combination with an energy storage device to provide a propulsion system.

Internet of Things (IoT) Network of physical objects embedded with electronics, software, sensors, and connectivity.

Measurement noise An unwanted input signal that affects the measured output signal.
Mechatronics The synergistic integration of mechanical, electrical, and computer systems.

Multiloop feedback control system A feedback control system with more than one feedback control loop.

Multivariable control system A system with more than one input variable or more than one output variable.

Negative feedback An output signal fed back so that it subtracts from the input signal.

Open-loop control system A system that uses a device to control the process without using feedback. Thus the output has no effect upon the signal to the process.

Optimization The adjustment of the parameters to achieve the most favorable or advantageous design.

Plant See Process.

Positive feedback An output signal fed back so that it adds to the input signal.

Process The device, plant, or system under control.

Productivity The ratio of physical output to physical input of an industrial process.

Risk Uncertainties embodied in the unintended consequences of a design.

Robot Programmable computers integrated with a manipulator. A reprogrammable, multifunctional manipulator used for a variety of tasks.

Sensor A device that provides a measurement of a desired external signal.

Specifications Statements that explicitly state what the device or product is to be and to do. A set of prescribed performance criteria.

Synthesis The process by which new physical configurations are created. The combining of separate elements or devices to form a coherent whole.

System An interconnection of elements and devices for a desired purpose.

Trade-off The result of making a judgment about how to compromise between conflicting criteria.

Ubiquitous computing A concept in which computing is made available everywhere at any time and can occur on any device.

Ubiquitous positioning A concept in which positioning systems identify the location and position of people, vehicles and objects in time at any location indoors and outdoors. 

\section{CHAPTER}

\section{Mathematical Models}

of Systems

2.1 Introduction 80

2.2 Differential Equations of Physical Systems 80

2.3 Linear Approximations of Physical Systems 85

2.4 The Laplace Transform 88

2.5 The Transfer Function of Linear Systems 95

2.6 Block Diagram Models 107

2.7 Signal-Flow Graph Models 112

2.8 Design Examples 119

2.9 The Simulation of Systems Using Control Design Software 136

2.10 Sequential Design Example: Disk Drive Read System 150

2.11 Summary 153

\section{PREVIEW}

Mathematical models of physical systems are key elements in the design and analysis of control systems. The dynamic behavior is generally described by ordinary differential equations. We will consider a wide range of systems. Since most physical systems are nonlinear, we will discuss linearization approximations which allow us to use Laplace transform methods. We will then proceed to obtain the input-output relationship in the form of transfer functions. The transfer functions can be organized into block diagrams or signal-flow graphs to graphically depict the interconnections. Block diagrams and signal-flow graphs are very convenient and natural tools for designing and analyzing complicated control systems. We conclude the chapter by developing transfer function models for the various components of the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 2, students should be able to:

$\square$ Recognize that differential equations can describe the dynamic behavior of physical systems.

- Utilize linearization approximations through Taylor series.

- Understand the application of Laplace transforms and their role in obtaining transfer functions.

$\square \quad$ Interpret block diagrams and signal-flow graphs and explain their role in analyzing control systems.

$\square$ Describe the important role of modeling in the control system design process. 

\subsection{INTRODUCTION}

To understand and control complex systems, one must obtain quantitative mathematical models of these systems. It is necessary therefore to analyze the relationships between the system variables and to obtain a mathematical model. Because the systems under consideration are dynamic in nature, the descriptive equations are usually differential equations. Furthermore, if these equations can be linearized, then the Laplace transform can be used to simplify the method of solution. In practice, the complexity of systems and our ignorance of all the relevant factors necessitate the introduction of assumptions concerning the system operation. Therefore we will often find it useful to consider the physical system, express any necessary assumptions, and linearize the system. Then, by using the physical laws describing the linear equivalent system, we can obtain a set of time-invariant, ordinary linear differential equations. Finally, using mathematical tools, such as the Laplace transform, we obtain a solution describing the operation of the system. In summary, the approach to dynamic system modeling can be listed as follows:

1. Define the system and its components.

2. Formulate the mathematical model and fundamental necessary assumptions based on basic principles.

3. Obtain the differential equations representing the mathematical model.

4. Solve the equations for the desired output variables.

5. Examine the solutions and the assumptions.

6. If necessary, reanalyze or redesign the system.

\subsection{DIFFERENTIAL EQUATIONS OF PHYSICAL SYSTEMS}

The differential equations describing the dynamic performance of a physical system are obtained by utilizing the physical laws of the process [1-4]. Consider the torsional spring-mass system in Figure 2.1 with applied torque $T_{a}(t)$. Assume the torsional spring element is massless. Suppose we want to measure the torque $T_{S}(t)$ transmitted to the mass $m$. Since the spring is massless, the sum of the torques acting on the spring itself must be zero, or

$$
T_{a}(t)-T_{s}(t)=0
$$

which implies that $T_{s}(t)=T_{a}(t)$. We see immediately that the external torque $T_{a}(t)$ applied at the end of the spring is transmitted through the torsional spring. Because of this, we refer to the torque as a through-variable. In a similar manner, the angular rate difference associated with the torsional spring element is

$$
\omega(t)=\omega_{s}(t)-\omega_{a}(t)
$$

FIGURE 2.1

(a) Torsional spring-mass system. (b) Spring element.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0082.jpg?height=482&width=303&top_left_y=152&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0082.jpg?height=410&width=141&top_left_y=225&top_left_x=936)

(b)
Thus, the angular rate difference is measured across the torsional spring element and is referred to as an across-variable. These same types of arguments can be made for most common physical variables (such as force, current, volume, flow rate, etc.). A more complete discussion on through- and across-variables can be found in $[26,27]$. A summary of the through- and across-variables of dynamic systems is given in Table 2.1 [5]. Information concerning the International System (SI) of units associated with the various variables discussed in this section can be found online, as well in many handy references, such as the MCS website. ${ }^{\dagger}$ For example, variables that measure temperature are degrees Kelvin in SI units, and variables that measure length are meters. A summary of the describing equations for lumped, linear, dynamic elements is given in Table 2.2 [5]. The equations in
$$
\begin{array}{lclll}
\text { Table 2.2 } & \text { Summary of Governing Differential Equations for Ideal Elements } \\
\text { Type of } & \text { Physical } & \text { Governing } & \text { Energy } E \text { or } & \\
\text { Element } & \text { Element } & \text { Equation } & \text { Power } \mathscr{P} & \text { Symbol } \\
\hline
\end{array}
$$
$$
\text { Inductive storage }\left\{\begin{array}{lll}
\text { Electrical inductance } & v_{21}=L \frac{d i}{d t} & E=\frac{1}{2} L i^2 \\
\text { Translational spring } & v_{21}=\frac{1}{k} \frac{d F}{d t} & E=\frac{1}{2} \frac{F^2}{k} \\
\text { Rotational spring } & \omega_{21}=\frac{1}{k} \frac{d T}{d t} & E=\frac{1}{2} \frac{T^2}{k} \\
\text { Fluid inertia } & P_{21}=I \frac{d Q}{d t} & E=\frac{1}{2} I Q^2
\end{array}\right.
$$

|1|2|






${ }^{\dagger}$ The companion website is available at www.pearsonglobaleditions.com. Table 2.2 are idealized descriptions and only approximate the actual conditions (for example, when a linear, lumped approximation is used for a distributed element).

\section{Table 2.2 Summary of Governing Differential Equations for Ideal Elements}

\section{Type of \\ Element}

Capacitive storage

Energy dissipators

Inductive storage

\section{Physical}

Element

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=172&width=306&top_left_y=1530&top_left_x=89)

Electrical inductance

Equation

$v_{21}=L \frac{d i}{d t}$

Energy $E$ or

Power $\mathscr{P}$

$E=\frac{1}{2} L i^{2}$

$v_{21}=\frac{1}{k} \frac{d F}{d t}$

$E=\frac{1}{2} \frac{F^{2}}{k}$

$\omega_{21}=\frac{1}{k} \frac{d T}{d t}$

$E=\frac{1}{2} \frac{T^{2}}{k}$

$P_{21}=I \frac{d Q}{d t}$

$E=\frac{1}{2} I Q^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=89&width=286&top_left_y=840&top_left_x=1240)

Fluid inertia

Electrical capacitance

$i=C \frac{d v_{21}}{d t}$

$E=\frac{1}{2} C v_{21}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=85&width=268&top_left_y=962&top_left_x=1242)

Translational mass

$F=M \frac{d v_{2}}{d t} \quad E=\frac{1}{2} M v_{2}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=87&width=280&top_left_y=1076&top_left_x=1243)

$T=J \frac{d \omega_{2}}{d t}$

$E=\frac{1}{2} J \omega_{2}^{2}$

$T \rightarrow \underset{\omega_{2}}{\longrightarrow} \underset{\begin{array}{c}\omega_{1} \\ \text { constant }\end{array}}{\stackrel{\circ}{\longrightarrow}}=$

Fluid capacitance

$Q=C_{f} \frac{d P_{21}}{d t} \quad E=\frac{1}{2} C_{f} P_{21}^{2}$

$Q \rightarrow \underset{P_{2}}{\circ} \longrightarrow P_{f}$

Thermal capacitance

$q=C_{t} \frac{d \mathscr{T}_{2}}{d t} \quad E=C_{t} \mathscr{T}_{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=103&width=268&top_left_y=1395&top_left_x=1240)

Electrical resistance

$i=\frac{1}{R} v_{21}$

$\mathscr{P}=\frac{1}{R} v_{21}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=80&width=283&top_left_y=1529&top_left_x=1239)

Translational damper

$F=b v_{21}$

$\mathscr{P}=b v_{21}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=77&width=271&top_left_y=1636&top_left_x=1243)

Rotational damper

$T=b \omega_{21}$

$\mathscr{P}=b \omega_{21}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=73&width=271&top_left_y=1732&top_left_x=1243)

Fluid resistance

$Q=\frac{1}{R_{f}} P_{21}$

$\mathscr{P}=\frac{1}{R_{f}} P_{21}^{2}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0083.jpg?height=82&width=268&top_left_y=1845&top_left_x=1254)

Thermal resistance
$q=\frac{1}{R_{t}} \mathscr{T}_{21} \quad \mathscr{P}=\frac{1}{R_{t}} \mathscr{T}_{21}$ 

\section{Nomenclature}

$\square \quad$ Through-variable: $F=$ force, $T=$ torque, $i=$ current, $Q=$ fluid volumetric flow rate, $q=$ heat flow rate.

$\square$ Across-variable: $v=$ translational velocity, $\omega=$ angular velocity, $v=$ voltage, $P=$ pressure, $\mathscr{T}=$ temperature.

$\square \quad$ Inductive storage: $L=$ inductance, $1 / k=$ reciprocal translational or rotational stiffness, $I=$ fluid inertance.

$\square \quad$ Capacitive storage: $C=$ capacitance, $M=$ mass, $J=$ moment of inertia, $C_{f}=$ fluid capacitance, $C_{t}=$ thermal capacitance.

$\square$ Energy dissipators: $R=$ resistance, $b=$ viscous friction, $R_{f}=$ fluid resistance, $R_{t}=$ thermal resistance.

The symbol $v$ is used for both voltage in electrical circuits and velocity in translational mechanical systems and is distinguished within the context of each differential equation. For mechanical systems, one uses Newton's laws; for electrical systems, Kirchhoff's voltage laws. For example, the simple spring-mass-damper mechanical system shown in Figure 2.2(a) is described by Newton's second law of motion. The free-body diagram of the mass $M$ is shown in Figure 2.2(b). In this spring-mass-damper example, we model the wall friction as a viscous damper, that is, the friction force is linearly proportional to the velocity of the mass. In reality the friction force may behave in a more complicated fashion. For example, the wall friction may behave as a Coulomb damper. Coulomb friction, also known as dry friction, is a nonlinear function of the mass velocity and possesses a discontinuity around zero velocity. For a well-lubricated, sliding surface, the viscous friction is appropriate and will be used here and in subsequent spring-mass-damper examples. Summing the forces acting on $M$ and utilizing Newton's second law yields

$$
M \frac{d^{2} y(t)}{d t^{2}}+b \frac{d y(t)}{d t}+k y(t)=r(t)
$$

where $k$ is the spring constant of the ideal spring and $b$ is the friction constant. Equation (2.1) is a second-order linear constant-coefficient (time-invariant) differential equation.

FIGURE 2.2

(a) Spring-massdamper system. (b) Free-body diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0084.jpg?height=433&width=435&top_left_y=1618&top_left_x=502)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0084.jpg?height=379&width=285&top_left_y=1673&top_left_x=1029)

(b) FIGURE 2.3

RLC circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0085.jpg?height=186&width=515&top_left_y=152&top_left_x=389)

Alternatively, one may describe the electrical $R L C$ circuit of Figure 2.3 by utilizing Kirchhoff's current law. Then we obtain the following integrodifferential equation:

$$
\frac{v(t)}{R}+C \frac{d v(t)}{d t}+\frac{1}{L} \int_{0}^{t} v(t) d t=r(t) .
$$

The solution of the differential equation describing the process may be obtained by classical methods such as the use of integrating factors and the method of undetermined coefficients [1]. For example, when the mass is initially displaced a distance $y(0)=y_{0}$ and released, the dynamic response of the system can be represented by an equation of the form

$$
y(t)=K_{1} e^{-\alpha_{1} t} \sin \left(\beta_{1} t+\theta_{1}\right) .
$$

A similar solution is obtained for the voltage of the $R L C$ circuit when the circuit is subjected to a constant current $r(t)=I$. Then the voltage is

$$
v(t)=K_{2} e^{-\alpha_{2} t} \cos \left(\beta_{2} t+\theta_{2}\right) .
$$

A voltage curve typical of an $R L C$ circuit is shown in Figure 2.4.

To reveal further the close similarity between the differential equations for the mechanical and electrical systems, we shall rewrite Equation (2.1) in terms of velocity:

$$
v(t)=\frac{d y(t)}{d t} \text {. }
$$

Then we have

$$
M \frac{d v(t)}{d t}+b v(t)+k \int_{0}^{t} v(t) d t=r(t)
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0085.jpg?height=593&width=1070&top_left_y=1517&top_left_x=375)

FIGURE 2.4

Typical voltage response for an $R L C$ circuit. One immediately notes the equivalence of Equations (2.5) and (2.2) where velocity $v(t)$ and voltage $v(t)$ are equivalent variables, usually called analogous variables, and the systems are analogous systems. Therefore the solution for velocity is similar to Equation (2.4), and the response for an underdamped system is shown in Figure 2.4. The concept of analogous systems is a very useful and powerful technique for system modeling. The voltage-velocity analogy, often called the force-current analogy, is a natural one because it relates the analogous through- and across-variables of the electrical and mechanical systems. Another analogy that relates the velocity and current variables is often used and is called the force-voltage analogy [21, 23].

Analogous systems with similar solutions exist for electrical, mechanical, thermal, and fluid systems. The existence of analogous systems and solutions provides the analyst with the ability to extend the solution of one system to all analogous systems with the same describing differential equations. Therefore what one learns about the analysis and design of electrical systems is immediately extended to an understanding of fluid, thermal, and mechanical systems.

\subsection{LINEAR APPROXIMATIONS OF PHYSICAL SYSTEMS}

A great majority of physical systems are linear within some range of the variables. In general, systems ultimately become nonlinear as the variables are increased without limit. For example, the spring-mass-damper system of Figure 2.2 is linear and described by Equation (2.1) as long as the mass is subjected to small deflections $y(t)$. However, if $y(t)$ were continually increased, eventually the spring would be overextended and break. Therefore the question of linearity and the range of applicability must be considered for each system.

A system is defined as linear in terms of the system excitation and response. In the case of the electrical network, the excitation is the input current $r(t)$ and the response is the voltage $v(t)$. In general, a necessary condition for a linear system can be determined in terms of an excitation $x(t)$ and a response $y(t)$. When the system at rest is subjected to an excitation $x_{1}(t)$, it provides a response $y_{1}(t)$. Furthermore, when the system is subjected to an excitation $x_{2}(t)$, it provides a corresponding response $y_{2}(t)$. For a linear system, it is necessary that the excitation $x_{1}(t)+x_{2}(t)$ result in a response $y_{1}(t)+y_{2}(t)$. This is the principle of superposition.

Furthermore, the magnitude scale factor must be preserved in a linear system. Again, consider a system with an input $x(t)$ that results in an output $y(t)$. Then the response of a linear system to a constant multiple $\beta$ of an input $x$ must be equal to the response to the input multiplied by the same constant so that the output is equal to $\beta y(t)$. This is the property of homogeneity.

\section{A linear system satisfies the properties of superposition and homogeneity.}

A system characterized by the relation $y(t)=x^{2}(t)$ is not linear, because the superposition property is not satisfied. A system represented by the relation $y(t)=m x(t)+b$ is not linear, because it does not satisfy the homogeneity property. However, this second system may be considered linear about an operating point $x_{0}, y_{0}$ for small changes $\Delta x$ and $\Delta y$. When $x(t)=x_{0}+\Delta x(t)$ and $y(t)=y_{0}+\Delta y(t)$, we have

$$
y(t)=m x(t)+b
$$

or

$$
y_{0}+\Delta y(t)=m x_{0}+m \Delta x(t)+b .
$$

Therefore, $\Delta y(t)=m \Delta x(t)$, which satisfies the necessary conditions.

The linearity of many mechanical and electrical elements can be assumed over a reasonably large range of the variables [7]. This is not usually the case for thermal and fluid elements, which are more frequently nonlinear in character. Fortunately, however, one can often linearize nonlinear elements assuming small-signal conditions. This is the normal approach used to obtain a linear equivalent circuit for electronic circuits and transistors. Consider a general element with an excitation (through-) variable $x(t)$ and a response (across-) variable $y(t)$. Several examples of dynamic system variables are given in Table 2.1. The relationship of the two variables is written as

$$
y(t)=g(x(t)),
$$

where $g(x(t))$ indicates $y(t)$ is a function of $x(t)$. The normal operating point is designated by $x_{0}$. Because the curve (function) is continuous over the range of interest, a Taylor series expansion about the operating point may be utilized [7]. Then we have

$$
y(t)=g(x(t))=g\left(x_{0}\right)+\left.\frac{d g}{d x}\right|_{x(t)=x_{0}} \frac{\left(x(t)-x_{0}\right)}{1 !}+\left.\frac{d^{2} g}{d x^{2}}\right|_{x(t)=x_{0}} \frac{\left(x(t)-x_{0}\right)^{2}}{2 !}+\cdots .
$$

The slope at the operating point,

$$
m=\left.\frac{d g}{d x}\right|_{x(t)=x_{0}}
$$

is a good approximation to the curve over a small range of $x(t)-x_{0}$, the deviation from the operating point. Then, as a reasonable approximation, Equation (2.7) becomes

$$
y(t)=g\left(x_{0}\right)+\left.\frac{d g}{d x}\right|_{x(t)=x_{0}}\left(x(t)-x_{0}\right)=y_{0}+m\left(x(t)-x_{0}\right) .
$$

Finally, Equation (2.8) can be rewritten as the linear equation

$$
y(t)-y_{0}=m\left(x(t)-x_{0}\right)
$$

or

$$
\Delta y(t)=m \Delta x(t)
$$

Consider the case of a mass, $M$, sitting on a nonlinear spring, as shown in Figure 2.5(a). The normal operating point is the equilibrium position that occurs when the spring force balances the gravitational force $M g$, where $g$ is the gravitational constant. Thus, we obtain $f_{0}=M g$, as shown. For the nonlinear spring with $f(t)=y^{2}(t)$, the equilibrium position is $y_{0}=(M g)^{1 / 2}$. The linear model for small deviation is

$$
\Delta f(t)=m \Delta y(t),
$$

FIGURE 2.5

(a) A mass sitting on a nonlinear spring.

(b) The spring force versus $y(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0088.jpg?height=407&width=381&top_left_y=189&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0088.jpg?height=480&width=573&top_left_y=155&top_left_x=993)

(b)

where

$$
m=\left.\frac{d f}{d y}\right|_{y(t)=y_{0}},
$$

as shown in Figure 2.5(b). Thus, $m=2 y_{0}$. A linear approximation is as accurate as the assumption of small signals is applicable to the specific problem.

If the dependent variable $y(t)$ depends upon several excitation variables, $x_{1}(t), x_{2}(t), \ldots, x_{n}(t)$, then the functional relationship is written as

$$
y(t)=g\left(x_{1}(t), x_{2}(t), \ldots, x_{n}(t)\right) .
$$

The Taylor series expansion about the operating point $x_{1_{0}}, x_{2_{0}}, \ldots, x_{n_{0}}$ is useful for a linear approximation to the nonlinear function. When the higher-order terms are neglected, the linear approximation is written as

$$
\begin{aligned}
y(t)= & g\left(x_{1_{0}}, x_{2_{0}}, \ldots, x_{n_{0}}\right)+\left.\frac{\partial g}{\partial x_{1}}\right|_{x(t)=x_{0}}\left(x_{1}(t)-x_{1_{0}}\right)+\left.\frac{\partial g}{\partial x_{2}}\right|_{x(t)=x_{0}}\left(x_{2}(t)-x_{2_{0}}\right) \\
& +\cdots+\left.\frac{\partial g}{\partial x_{n}}\right|_{x(t)=x_{0}}\left(x_{n}(t)-x_{n_{0}}\right),
\end{aligned}
$$

where $x_{0}$ is the operating point. Example 2.1 will clearly illustrate the utility of this method.

\section{EXAMPLE 2.1 Pendulum oscillator model}

Consider the pendulum oscillator shown in Figure 2.6(a). The torque on the mass is

$$
T(t)=M g L \sin \theta(t)
$$

where $g$ is the gravity constant. The equilibrium condition for the mass is $\theta_{0}=0^{\circ}$. The nonlinear relation between $T(t)$ and $\theta(t)$ is shown graphically in Figure 2.6(b). The first derivative evaluated at equilibrium provides the linear approximation, which is

$$
T(t)-\left.T_{0} \cong M g L \frac{\partial \sin \theta}{\partial \theta}\right|_{\theta(t)=\theta_{0}}\left(\theta(t)-\theta_{0}\right),
$$

FIGURE 2.6

Pendulum oscillator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0089.jpg?height=331&width=322&top_left_y=192&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0089.jpg?height=372&width=423&top_left_y=155&top_left_x=767)

(b)

where $T_{0}=0$. Then, we have

$$
T(t)=\operatorname{Mg} L \theta(t) .
$$

This approximation is reasonably accurate for $-\pi / 4 \leq \theta \leq \pi / 4$. For example, the response of the linear model for the swing through $\pm 30^{\circ}$ is within $5 \%$ of the actual nonlinear pendulum response.

\subsection{THE LAPLACE TRANSFORM}

The ability to obtain linear time-invariant approximations of physical systems allows the analyst to consider the use of the Laplace transformation. The Laplace transform method substitutes relatively easily solved algebraic equations for the more difficult differential equations $[1,3]$. The time-response solution is obtained by the following operations:

1. Obtain the linearized differential equations.

2. Obtain the Laplace transformation of the differential equations.

3. Solve the resulting algebraic equation for the transform of the variable of interest.

The Laplace transform exists for linear differential equations for which the transformation integral converges. Therefore, for $f(t)$ to be transformable, it is sufficient that

$$
\int_{0^{-}}^{\infty} f(t) \mid e^{-\sigma_{1} t} d t<\infty,
$$

for some real, positive $\sigma_{1}$ [1]. The $0^{-}$indicates that the integral should include any discontinuity, such as a delta function at $t=0$. If the magnitude of $f(t)$ is $|f(t)|<M e^{\alpha t}$ for all positive $t$, the integral will converge for $\sigma_{1}>\alpha$. The region of convergence is therefore given by $\infty>\sigma_{1}>\alpha$, and $\sigma_{1}$ is known as the abscissa of absolute convergence. Signals that are physically realizable always have a Laplace transform. The Laplace transformation for a function of time, $f(t)$, is

$$
F(s)=\int_{0^{-}}^{\infty} f(t) e^{-s t} d t=\mathscr{L}\{f(t)\} .
$$

The inverse Laplace transform is written as

$$
f(t)=\frac{1}{2 \pi j} \int_{\sigma-j \infty}^{\sigma+j \infty} F(s) e^{+s t} d s .
$$

The transformation integrals have been employed to derive tables of Laplace transforms that are used for the great majority of problems. A table of important Laplace transform pairs is given in Table 2.3. A more complete list of Laplace transform pairs can be found in many references, including at the MCS website.

\section{Table 2.3 Important Laplace Transform Pairs}

$$
\begin{aligned}
& \frac{\boldsymbol{f}(\boldsymbol{t})}{\text { Step function, } u(t)} \\
& e^{-a t} \\
& \sin \omega t \\
& \cos \omega t \\
& t^{n} \\
& f^{(k)}(t)=\frac{d^{k} f(t)}{d t^{k}} \\
& \int_{-\infty}^{t} f(t) d t
\end{aligned}
$$

Impulse function $\delta(t)$

$$
e^{-a t} \sin \omega t
$$$$
e^{-a t} \cos \omega t
$$$$
\frac{1}{\omega}\left[(\alpha-a)^{2}+\omega^{2}\right]^{1 / 2} e^{-a t} \sin (\omega t+\phi),
$$

$$
\phi=\tan ^{-1} \frac{\omega}{\alpha-a}
$$$$
\frac{\omega_{n}}{\sqrt{1-\zeta^{2}}} e^{-\zeta \omega_{n} t} \sin \omega_{n} \sqrt{1-\zeta^{2}} t, \zeta<1
$$$$
\frac{1}{a^{2}+\omega^{2}}+\frac{1}{\omega \sqrt{a^{2}+\omega^{2}}} e^{-a t} \sin (\omega t-\phi),
$$$$
\phi=\tan ^{-1} \frac{\omega}{-a}
$$$$
1-\frac{1}{\sqrt{1-\zeta^{2}}} e^{-\zeta \omega_{n} t} \sin \left(\omega_{n} \sqrt{1-\zeta^{2}} t+\phi\right),
$$$$
\phi=\cos ^{-1} \zeta, \zeta<1
$$$$
\frac{\alpha}{a^{2}+\omega^{2}}+\frac{1}{\omega}\left[\frac{(\alpha-a)^{2}+\omega^{2}}{a^{2}+\omega^{2}}\right]^{1 / 2} e^{-a t} \sin (\omega t+\phi) \text {. }
$$$$
\phi=\tan ^{-1} \frac{\omega}{\alpha-a}-\tan ^{-1} \frac{\omega}{-a}
$$

\section{$F(s)$}

$\frac{1}{s}$

$\frac{1}{s+a}$

$$
\frac{\omega}{s^{2}+\omega^{2}}
$$

$$
\frac{s}{s^{2}+\omega^{2}}
$$

$\frac{n !}{s^{n+1}}$

$$
\begin{aligned}
& s^{k} F(s)-s^{k-1} f\left(0^{-}\right)-s^{k-2} f^{\prime}\left(0^{-}\right) \\
& -\ldots-f^{(k-1)}\left(0^{-}\right) \\
& \frac{F(s)}{s}+\frac{1}{s} \int_{-\infty}^{0} f(t) d t
\end{aligned}
$$

1

$$
\begin{gathered}
\frac{\omega}{(s+a)^{2}+\omega^{2}} \\
\frac{s+a}{(s+a)^{2}+\omega^{2}} \\
\frac{s+\alpha}{(s+a)^{2}+\omega^{2}}
\end{gathered}
$$

$$
\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}}
$$$$
\frac{1}{s\left[(s+a)^{2}+\omega^{2}\right]}
$$

$\frac{\omega_{n}^{2}}{s\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)}$

$$
\frac{s+\alpha}{s\left[(s+a)^{2}+\omega^{2}\right]}
$$

Alternatively, the Laplace variable $s$ can be considered to be the differential operator so that

$$
s \equiv \frac{d}{d t}
$$

Then we also have the integral operator

$$
\frac{1}{s} \equiv \int_{0^{-}}^{t} d t .
$$

The inverse Laplace transformation is usually obtained by using the Heaviside partial fraction expansion. This approach is particularly useful for systems analysis and design because the effect of each characteristic root or eigenvalue can be clearly observed.

To illustrate the usefulness of the Laplace transformation and the steps involved in the system analysis, reconsider the spring-mass-damper system described by Equation (2.1), which is

$$
M \frac{d^{2} y(t)}{d t^{2}}+b \frac{d y(t)}{d t}+k y(t)=r(t) .
$$

We wish to obtain the response, $y(t)$, as a function of time. The Laplace transform of Equation (2.18) is

$$
M\left(s^{2} Y(s)-s y\left(0^{-}\right)-\frac{d y}{d t}\left(0^{-}\right)\right)+b\left(s Y(s)-y\left(0^{-}\right)\right)+k Y(s)=R(s) .
$$

When

$$
r(t)=0, \quad \text { and } \quad y\left(0^{-}\right)=y_{0}, \quad \text { and }\left.\quad \frac{d y}{d t}\right|_{t=0^{-}}=0
$$

we have

$$
M s^{2} Y(s)-M s y_{0}+b s Y(s)-b y_{0}+k Y(s)=0 .
$$

Solving for $Y(s)$, we obtain

$$
Y(s)=\frac{(M s+b) y_{0}}{M s^{2}+b s+k}=\frac{p(s)}{q(s)} .
$$

The denominator polynomial $q(s)$, when set equal to zero, is called the characteristic equation because the roots of this equation determine the character of the time response. The roots of this characteristic equation are also called the poles of the system. The roots of the numerator polynomial $p(s)$ are called the zeros of the system; for example, $s=-b / M$ is a zero of Equation (2.21). Poles and zeros are critical frequencies. At the poles, the function $Y(s)$ becomes infinite, whereas at the zeros, the function becomes zero. The complex frequency $s$-plane plot of the poles and zeros graphically portrays the character of the natural transient response of the system.

For a specific case, consider the system when $k / M=2$ and $b / M=3$. Then Equation (2.21) becomes

$$
Y(s)=\frac{(s+3) y_{0}}{(s+1)(s+2)} .
$$

FIGURE 2.7

An s-plane pole and zero plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0092.jpg?height=342&width=633&top_left_y=163&top_left_x=521)

The poles and zeros of $Y(s)$ are shown on the $s$-plane in Figure 2.7.

Expanding Equation (2.22) in a partial fraction expansion, we obtain

$$
Y(s)=\frac{k_{1}}{s+1}+\frac{k_{2}}{s+2},
$$

where $k_{1}$ and $k_{2}$ are the coefficients of the expansion. The coefficients $k_{i}$ are called residues and are evaluated by multiplying through by the denominator factor of Equation (2.22) corresponding to $k_{i}$ and setting $s$ equal to the root. Evaluating $k_{1}$ when $y_{0}=1$, we have

$$
\begin{aligned}
k_{1} & =\left.\frac{\left(s-s_{1}\right) p(s)}{q(s)}\right|_{s=s_{1}} \\
& =\left.\frac{(s+1)(s+3)}{(s+1)(s+2)}\right|_{s_{1}=-1}=2
\end{aligned}
$$

and $k_{2}=-1$. Alternatively, the residues of $Y(s)$ at the respective poles may be evaluated graphically on the $s$-plane plot, since Equation (2.24) may be written as

$$
\begin{aligned}
k_{1} & =\left.\frac{s+3}{s+2}\right|_{s=s_{1}=-1} \\
& =\left.\frac{s_{1}+3}{s_{1}+2}\right|_{s_{1}=-1}=2 .
\end{aligned}
$$

The graphical representation of Equation (2.25) is shown in Figure 2.8. The graphical method of evaluating the residues is particularly valuable when the order of the characteristic equation is high and several poles are complex conjugate pairs.

FIGURE 2.8

Graphical evaluation of the residues. The inverse Laplace transform of Equation (2.22) is then

$$
y(t)=\mathscr{L}^{-1}\left\{\frac{2}{s+1}\right\}+\mathscr{L}^{-1}\left\{\frac{-1}{s+2}\right\} .
$$

Using Table 2.3, we find that

$$
y(t)=2 e^{-t}-1 e^{-2 t}
$$

Finally, it is usually desired to determine the steady-state or final value of the response of $y(t)$. For example, the final or steady-state rest position of the springmass-damper system may be calculated. The final value theorem states that

$$
\lim _{t \rightarrow \infty} y(t)=\lim _{s \rightarrow 0} s Y(s)
$$

where a simple pole of $Y(s)$ at the origin is permitted, but poles on the imaginary axis and in the right half-plane and repeated poles at the origin are excluded. Therefore, for the specific case of the spring-mass-damper, we find that

$$
\lim _{t \rightarrow \infty} y(t)=\lim _{s \rightarrow 0} s Y(s)=0 .
$$

Hence the final position for the mass is the normal equilibrium position $y=0$.

Reconsider the spring-mass-damper system. The equation for $Y(s)$ may be written as

$$
Y(s)=\frac{(s+b / M) y_{0}}{s^{2}+(b / M) s+k / M}=\frac{\left(s+2 \zeta \omega_{n}\right) y_{0}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}},
$$

where $\zeta$ is the dimensionless damping ratio, and $\omega_{n}$ is the natural frequency of the system. The roots of the characteristic equation are

$$
s_{1}, s_{2}=-\zeta \omega_{n} \pm \omega_{n} \sqrt{\zeta^{2}-1}
$$

where, in this case, $\omega_{n}=\sqrt{k / M}$ and $\zeta=b /(2 \sqrt{k M})$. When $\zeta>1$, the roots are real and the system is overdamped; when $\zeta<1$, the roots are complex and the system is underdamped. When $\zeta=1$, the roots are repeated and real, and the condition is called critical damping.

When $\zeta<1$, the response is underdamped, and

$$
s_{1,2}=-\zeta \omega_{n} \pm j \omega_{n} \sqrt{1-\zeta^{2}} .
$$

The $s$-plane plot of the poles and zeros of $Y(s)$ is shown in Figure 2.9, where $\theta=\cos ^{-1} \zeta$. As $\zeta$ varies with $\omega_{n}$ constant, the complex conjugate roots follow a

FIGURE 2.9

An s-plane plot of the poles and zeros of $Y(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0093.jpg?height=442&width=647&top_left_y=1675&top_left_x=368)

FIGURE 2.10

The locus of roots as $\zeta$ varies with $\omega_{n}$ constant.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0094.jpg?height=430&width=612&top_left_y=166&top_left_x=517)

circular locus, as shown in Figure 2.10. The transient response is increasingly oscillatory as the roots approach the imaginary axis when $\zeta$ approaches zero.

The inverse Laplace transform can be evaluated using the graphical residue evaluation. The partial fraction expansion of Equation (2.30) is

$$
Y(s)=\frac{k_{1}}{s-s_{1}}+\frac{k_{2}}{s-s_{2}} .
$$

Since $s_{2}$ is the complex conjugate of $s_{1}$, the residue $k_{2}$ is the complex conjugate of $k_{1}$ so that we obtain

$$
Y(s)=\frac{k_{1}}{s-s_{1}}+\frac{\hat{k}_{1}}{s-\hat{s}_{1}}
$$

where the hat indicates the conjugate relation. The residue $k_{1}$ is evaluated from Figure 2.11 as

$$
k_{1}=\frac{y_{0}\left(s_{1}+2 \zeta \omega_{n}\right)}{s_{1}-\hat{s}_{1}}=\frac{y_{0} M_{1} e^{j \theta}}{M_{2} e^{j \pi / 2}},
$$

where $M_{1}$ is the magnitude of $s_{1}+2 \zeta \omega_{n}$, and $M_{2}$ is the magnitude of $s_{1}-\hat{s}_{1}$. A review of complex numbers can be found in many online references, as well as on the MCS website. In this case, we obtain

$$
k_{1}=\frac{y_{0}\left(\omega_{n} e^{j \theta}\right)}{2 \omega_{n} \sqrt{1-\zeta^{2}} e^{j \pi / 2}}=\frac{y_{0}}{2 \sqrt{1-\zeta^{2}} e^{j(\pi / 2-\theta)}},
$$

FIGURE 2.11

Evaluation of the residue $k_{1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0094.jpg?height=436&width=635&top_left_y=1673&top_left_x=515)

FIGURE 2.12

Response of the spring-massdamper system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0095.jpg?height=612&width=999&top_left_y=155&top_left_x=373)

where $\theta=\cos ^{-1} \zeta$. Therefore,

$$
k_{2}=\frac{y_{0}}{2 \sqrt{1-\zeta^{2}}} e^{j(\pi / 2-\theta)} .
$$

Finally, letting $\beta=\sqrt{1-\zeta^{2}}$, we find that

$$
\begin{aligned}
y(t) & =k_{1} e^{S_{1} t}+k_{2} e^{S_{2} t} \\
& =\frac{y_{0}}{2 \sqrt{1-\zeta^{2}}}\left(e^{j(\theta-\pi / 2)} e^{-\zeta \omega_{n} t} e^{j \omega_{n} \beta t}+e^{j(\pi / 2-\theta)} e^{-\zeta \omega_{n} t} e^{-j \omega_{n} \beta t}\right) \\
& =\frac{y_{0}}{\sqrt{1-\zeta^{2}}} e^{-\zeta \omega_{n} t} \sin \left(\omega_{n} \sqrt{1-\zeta^{2}} t+\theta\right) .
\end{aligned}
$$

The solution, Equation (2.37), can also be obtained using item 11 of Table 2.3. The transient responses of the overdamped $(\zeta>1)$ and underdamped $(\zeta<1)$ cases are shown in Figure 2.12. The transient response that occurs when $\zeta<1$ exhibits an oscillation in which the amplitude decreases with time, and it is called a damped oscillation.

The relationship between the $s$-plane location of the poles and zeros and the form of the transient response can be interpreted from the $s$-plane pole-zero plots. For example, as seen in Equation (2.37), adjusting the value of $\zeta \omega_{n}$ varies the $e^{-\zeta \omega_{n} t}$ envelope, hence the response $y(t)$ shown in Figure 2.12. The larger the value of $\zeta \omega_{n}$, the faster the damping of the response, $y(t)$. In Figure 2.9, we see that the location of the complex pole $s_{1}$ is given by $s_{1}=-\zeta \omega_{n}+j \omega_{n} \sqrt{1-\zeta^{2}}$. So, making $\zeta \omega_{n}$ larger moves the pole further to the left in the $s$-plane. Thus, the connection between the location of the pole in the $s$-plane and the step response is apparent-moving the pole $s_{1}$ farther in the left half-plane leads to a faster damping of the transient step response. Of course, most control systems will have more than one complex pair of poles, so the transient response will be the result of the contributions of all the poles. In fact, the magnitude of the response of each pole, represented by the residue, can be visualized by examining the graphical residues on the $s$-plane. We will discuss the connection between the pole and zero locations and the transient and steady-state response more in subsequent chapters. We will find that the Laplace transformation and the $s$-plane approach are very useful techniques for system analysis and design where emphasis is placed on the transient and steady-state performance. In fact, because the study of control systems is concerned primarily with the transient and steady-state performance of dynamic systems, we have real cause to appreciate the value of the Laplace transform techniques.

\subsection{THE TRANSFER FUNCTION OF LINEAR SYSTEMS}

The transfer function of a linear system is defined as the ratio of the Laplace transform of the output variable to the Laplace transform of the input variable, with all initial conditions assumed to be zero. The transfer function of a system (or element) represents the relationship describing the dynamics of the system under consideration.

A transfer function may be defined only for a linear, stationary (constant parameter) system. A nonstationary system, often called a time-varying system, has one or more time-varying parameters, and the Laplace transformation may not be utilized. Furthermore, a transfer function is an input-output description of the behavior of a system. Thus, the transfer function description does not include any information concerning the internal structure of the system and its behavior.

The transfer function of the spring-mass-damper system is obtained from the original Equation (2.19), rewritten with zero initial conditions as follows:

$$
M s^{2} Y(s)+b s Y(s)+k Y(s)=R(s) .
$$

Then the transfer function is the ratio of the output to the input, or

$$
G(s)=\frac{Y(s)}{R(s)}=\frac{1}{M s^{2}+b s+k} .
$$

The transfer function of the $R C$ network shown in Figure 2.13 is obtained by writing the Kirchhoff voltage equation, yielding

$$
V_{1}(s)=\left(R+\frac{1}{C s}\right) I(s),
$$

expressed in terms of transform variables. We shall frequently refer to variables and their transforms interchangeably. The transform variable will be distinguishable by the use of an uppercase letter or the argument $(s)$.

The output voltage is

$$
V_{2}(s)=I(s)\left(\frac{1}{C s}\right)
$$

FIGURE 2.13 An $R C$ network.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0096.jpg?height=196&width=602&top_left_y=1920&top_left_x=508)

Therefore, solving Equation (2.40) for $I(s)$ and substituting in Equation (2.41), we have

$$
V_{2}(s)=\frac{(1 / C s) V_{1}(s)}{R+1 / C s} .
$$

Then the transfer function is obtained as the ratio $V_{2}(s) / V_{1}(s)$,

$$
G(s)=\frac{V_{2}(s)}{V_{1}(s)}=\frac{1}{R C s+1}=\frac{1}{\tau s+1}=\frac{1 / \tau}{s+1 / \tau},
$$

where $\tau=R C$, the time constant of the network. The single pole of $G(s)$ is $s=-1 / \tau$. Equation (2.42) could be immediately obtained if one observes that the circuit is a voltage divider, where

$$
\frac{V_{2}(s)}{V_{1}(s)}=\frac{Z_{2}(s)}{Z_{1}(s)+Z_{2}(s)}
$$

and $Z_{1}(s)=R, Z_{2}=1 / C s$.

A multiloop electrical circuit or an analogous multiple-mass mechanical system results in a set of simultaneous equations in the Laplace variable. It is usually more convenient to solve the simultaneous equations by using matrices and determinants $[1,3,15]$. An introduction to matrices and determinants can be found in many references online, as well as on the MCS website.

Let us consider the long-term behavior of a system and determine the response to certain inputs that remain after the transients fade away. Consider the dynamic system represented by the differential equation

$$
\begin{aligned}
\frac{d^{n} y(t)}{d t^{n}} & +q_{n-1} \frac{d^{n-1} y(t)}{d t^{n-1}}+\ldots+q_{0} y(t) \\
= & p_{n-1} \frac{d^{n-1} r(t)}{d t^{n-1}}+p_{n-2} \frac{d^{n-2} r(t)}{d t^{n-2}}+\cdots+p_{0} r(t),
\end{aligned}
$$

where $y(t)$ is the response, and $r(t)$ is the input or forcing function. If the initial conditions are all zero, then the transfer function is the coefficient of $R(s)$ in

$$
Y(s)=G(s) R(s)=\frac{p(s)}{q(s)} R(s)=\frac{p_{n-1} s^{n-1}+p_{n-2} s^{n-2}+\cdots+p_{0}}{s^{n}+q_{n-1} s^{n-1}+\cdots+q_{0}} R(s) .
$$

The output response consists of a natural response (determined by the initial conditions) plus a forced response determined by the input. We now have

$$
Y(s)=\frac{m(s)}{q(s)}+\frac{p(s)}{q(s)} R(s)
$$

where $q(s)=0$ is the characteristic equation. If the input has the rational form

$$
R(s)=\frac{n(s)}{d(s)}
$$

then

$$
Y(s)=\frac{m(s)}{q(s)}+\frac{p(s)}{q(s)} \frac{n(s)}{d(s)}=Y_{1}(s)+Y_{2}(s)+Y_{3}(s),
$$

where $Y_{1}(s)$ is the partial fraction expansion of the natural response, $Y_{2}(s)$ is the partial fraction expansion of the terms involving factors of $q(s)$, and $Y_{3}(s)$ is the partial fraction expansion of terms involving factors of $d(s)$.

Taking the inverse Laplace transform yields

$$
y(t)=y_{1}(t)+y_{2}(t)+y_{3}(t) .
$$

The transient response consists of $y_{1}(t)+y_{2}(t)$, and the steady-state response is $y_{3}(t)$.

\section{EXAMPLE 2.2 Solution of a differential equation}

Consider a system represented by the differential equation

$$
\frac{d^{2} y(t)}{d t^{2}}+4 \frac{d y(t)}{d t}+3 y(t)=2 r(t)
$$

where the initial conditions are $y(0)=1, \frac{d y}{d t}(0)=0$, and $r(t)=1, t \geq 0$.
The Laplace transform yields

$$
\left[s^{2} Y(s)-s y(0)\right]+4[s Y(s)-y(0)]+3 Y(s)=2 R(s) .
$$

Since $R(s)=1 / s$ and $y(0)=1$, we obtain

$$
Y(s)=\frac{s+4}{s^{2}+4 s+3}+\frac{2}{s\left(s^{2}+4 s+3\right)},
$$

where $q(s)=s^{2}+4 s+3=(s+1)(s+3)=0$ is the characteristic equation, and $d(s)=s$. Then the partial fraction expansion yields

$$
Y(s)=\left[\frac{3 / 2}{s+1}+\frac{-1 / 2}{s+3}\right]+\left[\frac{-1}{s+1}+\frac{1 / 3}{s+3}\right]+\frac{2 / 3}{s}=Y_{1}(s)+Y_{2}(s)+Y_{3}(s) .
$$

Hence, the response is

$$
y(t)=\left[\frac{3}{2} e^{-t}-\frac{1}{2} e^{-3 t}\right]+\left[-1 e^{-t}+\frac{1}{3} e^{-3 t}\right]+\frac{2}{3},
$$

and the steady-state response is

$$
\lim _{t \rightarrow \infty} y(t)=\frac{2}{3}
$$

\section{EXAMPLE 2.3 Transfer function of an op-amp circuit}

The operational amplifier (op-amp) belongs to an important class of analog integrated circuits commonly used as building blocks in the implementation of control systems and in many other important applications. Op-amps are active elements (that is, they have external power sources) with a high gain when operating in their linear regions. A model of an ideal op-amp is shown in Figure 2.14. FIGURE 2.14

The ideal op-amp.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0099.jpg?height=263&width=868&top_left_y=165&top_left_x=375)

The operating conditions for the ideal op-amp are (1) $i_{1}=0$ and $i_{2}=0$, thus implying that the input impedance is infinite, and (2) $v_{2}-v_{1}=0$ (or $v_{1}=v_{2}$ ). The input-output relationship for an ideal op-amp is

$$
v_{0}=K\left(v_{2}-v_{1}\right)=-K\left(v_{1}-v_{2}\right),
$$

where the gain $K$ approaches infinity. In our analysis, we will assume that the linear op-amps are operating with high gain and under idealized conditions.

Consider the inverting amplifier shown in Figure 2.15. Under ideal conditions, we have $i_{1}=0$, so that writing the node equation at $v_{1}$ yields

$$
\frac{v_{1}-v_{\text {in }}}{R_{1}}+\frac{v_{1}-v_{0}}{R_{2}}=0 .
$$

Since $v_{2}=v_{1}$ (under ideal conditions) and $v_{2}=0$ (see Figure 2.15 and compare it with Figure 2.14), it follows that $v_{1}=0$. Therefore,

$$
-\frac{v_{\text {in }}}{R_{1}}-\frac{v_{0}}{R_{2}}=0,
$$

and rearranging terms, we obtain

$$
\frac{v_{0}}{v_{\text {in }}}=-\frac{R_{2}}{R_{1}} .
$$

We see that when $R_{2}=R_{1}$, the ideal op-amp circuit inverts the sign of the input, that is, $v_{0}=-v_{\text {in }}$ when $R_{2}=R_{1}$.

\section{EXAMPLE 2.4 Transfer function of a system}

Consider the mechanical system shown in Figure 2.16 and its electrical circuit ana$\log$ shown in Figure 2.17. The electrical circuit analog is a force-current analog as outlined in Table 2.1. The velocities $v_{1}(t)$ and $v_{2}(t)$ of the mechanical system are

FIGURE 2.15

An Inverting amplifier operating with ideal conditions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0099.jpg?height=332&width=610&top_left_y=1786&top_left_x=370)

FIGURE 2.16

Two-mass

mechanical system.

FIGURE 2.17

Two-node electric circuit analog $C_{1}=M_{1}, C_{2}=M_{2}$, $L=1 / k, R_{1}=1 / b_{1}$ $R_{2}=1 / b_{2}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0100.jpg?height=836&width=642&top_left_y=153&top_left_x=509)

directly analogous to the node voltages $v_{1}(t)$ and $v_{2}(t)$ of the electrical circuit. The simultaneous equations, assuming that the initial conditions are zero, are

$$
M_{1} s V_{1}(s)+\left(b_{1}+b_{2}\right) V_{1}(s)-b_{1} V_{2}(s)=R(s),
$$

and

$$
M_{2} s V_{2}(s)+b_{1} V_{2}\left((s)-V_{1}(s)\right)+k \frac{V_{2}(s)}{s}=0 .
$$

These equations are obtained using the force equations for the mechanical system of Figure 2.16. Rearranging Equations (2.47) and (2.48), we obtain

$$
\begin{gathered}
\left(M_{1} s+\left(b_{1}+b_{2}\right)\right) V_{1}(s)+\left(-b_{1}\right) V_{2}(s)=R(s), \\
\left(-b_{1}\right) V_{1}(s)+\left(M_{2} s+b_{1}+\frac{k}{s}\right) V_{2}(s)=0,
\end{gathered}
$$

or, in matrix form,

$$
\left[\begin{array}{cc}
M_{1} s+b_{1}+b_{2} & -b_{1} \\
-b_{1} & M_{2} s+b_{1}+\frac{k}{s}
\end{array}\right]\left[\begin{array}{c}
V_{1}(s) \\
V_{2}(s)
\end{array}\right]=\left[\begin{array}{c}
R(s) \\
0
\end{array}\right] .
$$

Assuming that the velocity of $M_{1}$ is the output variable, we solve for $V_{1}(s)$ by matrix inversion or Cramer's rule to obtain $[1,3]$

$$
V_{1}(s)=\frac{\left(M_{2} s+b_{1}+k / s\right) R(s)}{\left(M_{1} s+b_{1}+b_{2}\right)\left(M_{2} s+b_{1}+k / s\right)-b_{1}^{2}} .
$$

Then the transfer function of the mechanical (or electrical) system is

$$
\begin{aligned}
G(s)= & \frac{V_{1}(s)}{R(s)}=\frac{\left(M_{2} s+b_{1}+k / s\right)}{\left(M_{1} s+b_{1}+b_{2}\right)\left(M_{2} s+b_{1}+k / s\right)-b_{1}^{2}} \\
& =\frac{\left(M_{2} s^{2}+b_{1} s+k\right)}{\left(M_{1} s+b_{1}+b_{2}\right)\left(M_{2} s^{2}+b_{1} s+k\right)-b_{1}^{2} s} .
\end{aligned}
$$

If the transfer function in terms of the position $x_{1}(t)$ is desired, then we have

$$
\frac{X_{1}(s)}{R(s)}=\frac{V_{1}(s)}{s R(s)}=\frac{G(s)}{s} .
$$

As an example, let us obtain the transfer function of an important electrical control component, the DC motor [8]. A DC motor is used to move loads and is called an actuator.

\section{An actuator is a device that provides the motive power to the process.}

\section{EXAMPLE 2.5 Transfer function of the DC motor}

The DC motor is a power actuator device that delivers energy to a load, as shown in Figure 2.18(a); a sketch of a DC motor is shown in Figure 2.18(b). The DC motor converts direct current (DC) electrical energy into rotational mechanical energy. A major fraction of the torque generated in the rotor (armature) of the motor is available to drive an external load. Because of features such as high torque, speed controllability over a wide range, portability, well-behaved speed-torque characteristics, and adaptability to various types of control methods, DC motors are widely used in numerous control applications, including robotic manipulators, tape transport mechanisms, disk drives, machine tools, and servovalve actuators.

The transfer function of the DC motor will be developed for a linear approximation to an actual motor, and second-order effects, such as hysteresis and the voltage drop across the brushes, will be neglected. The input voltage may be applied to the field or armature terminals. The air-gap flux $\phi(t)$ of the motor is proportional to the field current, provided the field is unsaturated, so that

$$
\phi(t)=K_{f} i_{f}(t) .
$$

The torque developed by the motor is assumed to be related linearly to $\phi(t)$ and the armature current as follows:

$$
T_{m}(t)=K_{1} \phi(t) i_{a}(t)=K_{1} K_{f} i_{f}(t) i_{a}(t)
$$

FIGURE 2.18

A DC motor

(a) electrical diagram and

(b) sketch.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0102.jpg?height=632&width=530&top_left_y=152&top_left_x=483)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0102.jpg?height=595&width=703&top_left_y=192&top_left_x=1050)

(b)

It is clear from Equation (2.54) that, to have a linear system, one current must be maintained constant while the other current becomes the input current. First, we shall consider the field current controlled motor, which provides a substantial power amplification. Then we have, in Laplace transform notation,

$$
T_{m}(s)=\left(K_{1} K_{f} I_{a}\right) I_{f}(s)=K_{m} I_{f}(s),
$$

where $i_{a}=I_{a}$ is a constant armature current, and $K_{m}$ is defined as the motor constant. The field current is related to the field voltage as

$$
V_{f}(s)=\left(R_{f}+L_{f} s\right) I_{f}(s) .
$$

The motor torque $T_{m}(s)$ is equal to the torque delivered to the load. This relation may be expressed as

$$
T_{m}(s)=T_{L}(s)+T_{d}(s)
$$

where $T_{L}(s)$ is the load torque and $T_{d}(s)$ is the disturbance torque, which is often negligible. However, the disturbance torque often must be considered in systems subjected to external forces such as antenna wind-gust forces. The load torque for rotating inertia, as shown in Figure 2.18, is written as

$$
T_{L}(s)=J s^{2} \theta(s)+b s \theta(s) .
$$

Rearranging Equations (2.55)-(2.57), we have

$$
\begin{aligned}
T_{L}(s) & =T_{m}(s)-T_{d}(s), \\
T_{m}(s) & =K_{m} I_{f}(s), \\
I_{f}(s) & =\frac{V_{f}(s)}{R_{f}+L_{f} s} .
\end{aligned}
$$

FIGURE 2.19

Block diagram model of fieldcontrolled DC motor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0103.jpg?height=212&width=1263&top_left_y=167&top_left_x=373)

Therefore, the transfer function of the motor-load combination, with $T_{d}(s)=0$, is

$$
\frac{\theta(s)}{V_{f}(s)}=\frac{K_{m}}{s(J s+b)\left(L_{f} s+R_{f}\right)}=\frac{K_{m} /\left(J L_{f}\right)}{s(s+b / J)\left(s+R_{f} / L_{f}\right)} .
$$

The block diagram model of the field-controlled DC motor is shown in Figure 2.19. Alternatively, the transfer function may be written in terms of the time constants of the motor as

$$
\frac{\theta(s)}{V_{f}(s)}=G(s)=\frac{K_{m} /\left(b R_{f}\right)}{s\left(\tau_{f} s+1\right)\left(\tau_{L} s+1\right)},
$$

where $\tau_{f}=L_{f} / R_{f}$ and $\tau_{L}=J / b$. Typically, one finds that $\tau_{L}>\tau_{f}$ and often the field time constant may be neglected.

The armature-controlled DC motor uses the armature current $i_{a}$ as the control variable. The stator field can be established by a field coil and current or a permanent magnet. When a constant field current is established in a field coil, the motor torque is

$$
T_{m}(s)=\left(K_{1} K_{f} I_{f}\right) I_{a}(s)=K_{m} I_{a}(s) .
$$

When a permanent magnet is used, we have

$$
T_{m}(s)=K_{m} I_{a}(s),
$$

where $K_{m}$ is a function of the permeability of the magnetic material.

The armature current is related to the input voltage applied to the armature by

$$
V_{a}(s)=\left(R_{a}+L_{a} s\right) I_{a}(s)+V_{b}(s),
$$

where $V_{b}(s)$ is the back electromotive-force voltage proportional to the motor speed. Therefore, we have

$$
V_{b}(s)=K_{b} \omega(s),
$$

where $\omega(s)=s \theta(s)$ is the transform of the angular speed and the armature current is

$$
I_{a}(s)=\frac{V_{a}(s)-K_{b} \omega(s)}{R_{a}+L_{a} s} .
$$

Equations (2.58) and (2.59) represent the load torque, so that

$$
T_{L}(s)=J s^{2} \theta(s)+b s \theta(s)=T_{m}(s)-T_{d}(s) .
$$

FIGURE 2.20

Armature-controlled DC motor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0104.jpg?height=371&width=1144&top_left_y=151&top_left_x=517)

The relations for the armature-controlled DC motor are shown schematically in Figure 2.20. Using Equations (2.64), (2.67), and (2.68) or the block diagram, and letting $T_{d}(s)=0$, we solve to obtain the transfer function

$$
\begin{aligned}
G(s)=\frac{\theta(s)}{V_{a}(s)} & =\frac{K_{m}}{s\left[\left(R_{a}+L_{a} s\right)(J s+b)+K_{b} K_{m}\right]} \\
& =\frac{K_{m}}{s\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)} .
\end{aligned}
$$

However, for many DC motors, the time constant of the armature, $\tau_{a}=L_{a} / R_{a}$, is negligible; therefore,

$$
G(s)=\frac{\theta(s)}{V_{a}(s)}=\frac{K_{m}}{s\left[R_{a}(J s+b)+K_{b} K_{m}\right]}=\frac{K_{m} /\left(R_{a} b+K_{b} K_{m}\right)}{s\left(\tau_{1} s+1\right)},
$$

where the equivalent time constant $\tau_{1}=R_{a} J /\left(R_{a} b+K_{b} K_{m}\right)$.

Note that $K_{m}$ is equal to $K_{b}$. This equality may be shown by considering the steady-state motor operation and the power balance when the rotor resistance is neglected. The power input to the rotor is $K_{b} \omega(t) i_{a}(t)$, and the power delivered to the shaft is $T(t) \omega(t)$. In the steady-state condition, the power input is equal to the power delivered to the shaft so that $K_{b} \omega(t) i_{a}(t)=T(t) \omega(t)$; since $T(t)=K_{m} i_{a}(t)$ (Equation 2.64), we find that $K_{b}=K_{m}$.

The transfer function concept and approach is very important because it provides the analyst and designer with a useful mathematical model of the system elements. We shall find the transfer function to be a continually valuable aid in the attempt to model dynamic systems. The approach is particularly useful because the $s$-plane poles and zeros of the transfer function represent the transient response of the system. The transfer functions of several dynamic elements are given in Table 2.4.

In many situations in engineering, the transmission of rotary motion from one shaft to another is a fundamental requirement. For example, the output power of an automobile engine is transferred to the driving wheels by means of the gearbox and differential. The gearbox allows the driver to select different gear ratios depending on the traffic situation, whereas the differential has a fixed ratio. The speed of the engine in this case is not constant, since it is under the control of the driver. Another example is a set of gears that transfer the power at the shaft of an electric motor to the shaft of a rotating antenna. Examples of mechanical converters are gears, chain drives, and belt drives. A commonly used electric converter is the electric transformer. An example of a device that converts rotational motion to linear motion is the rack-and-pinion gear shown in Table 2.4, item 17. 

\section{Table 2.4 Transfer Functions of Dynamic Elements and Networks}

\section{Element or System} $G(s)$

1. Integrating circuit, filter

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0105.jpg?height=344&width=517&top_left_y=348&top_left_x=87)

$$
\frac{V_{2}(s)}{V_{1}(s)}=-\frac{1}{R C s}
$$

2. Differentiating circuit

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0105.jpg?height=317&width=520&top_left_y=820&top_left_x=88)

$$
\frac{V_{2}(s)}{V_{1}(s)}=-R C s
$$

3. Differentiating circuit

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0105.jpg?height=327&width=513&top_left_y=1267&top_left_x=87)

$$
\frac{V_{2}(s)}{V_{1}(s)}=-\frac{R_{2}\left(R_{1} C s+1\right)}{R_{1}}
$$

4. Integrating filter

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0105.jpg?height=341&width=513&top_left_y=1730&top_left_x=87)$$
\frac{V_{2}(s)}{V_{1}(s)}=-\frac{\left(R_{1} C_{1} s+1\right)\left(R_{2} C_{2} s+1\right)}{R_{1} C_{2} s}
$$ 

\section{Table 2.4 (continued)}

\section{Element or System}

5. DC motor, field-controlled, rotational actuator
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0106.jpg?height=212&width=436&top_left_y=352&top_left_x=227)

6. DC motor, armature-controlled, rotational actuator

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0106.jpg?height=232&width=438&top_left_y=632&top_left_x=223)

7. AC motor, two-phase control field, rotational actuator

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0106.jpg?height=247&width=430&top_left_y=940&top_left_x=227)

8. Rotary Amplifier (Amplidyne)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0106.jpg?height=390&width=548&top_left_y=1242&top_left_x=220)

9. Hydraulic actuator $[9,10]$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0106.jpg?height=371&width=487&top_left_y=1703&top_left_x=227)

$$
\frac{\theta(s)}{V_{f}(s)}=\frac{K_{m}}{s(J s+b)\left(L_{f} s+R_{f}\right)}
$$

$$
\frac{\theta(s)}{V_{a}(s)}=\frac{K_{m}}{s\left[\left(R_{a}+L_{a} s\right)\left(J_{s}+b\right)+K_{b} K_{m}\right]}
$$

$$
\begin{aligned}
\frac{\theta(s)}{V_{c}(s)} & =\frac{K_{m}}{s(\tau s+1)} \\
\tau & =J /(b-m) \\
m & =\begin{array}{l}
\text { slope of linearized torque-speed } \\
\text { curve (normally negative) }
\end{array}
\end{aligned}
$$

$$
\begin{aligned}
\frac{V_{\mathrm{o}}(s)}{V_{c}(s)} & =\frac{K /\left(R_{c} R_{q}\right)}{\left(s \tau_{c}+1\right)\left(s \tau_{q}+1\right)} \\
\tau_{c} & =L_{c} / R_{c}, \quad \tau_{q}=L_{q} / R_{q}
\end{aligned}
$$

for the unloaded case, $i_{d} \approx 0, \tau_{c} \approx \tau_{q}$,

$0.05 \mathrm{~s}<\tau_{c}<0.5 \mathrm{~s}$

$$
V_{q}, \quad V_{34}=V_{d}
$$

$$
\begin{aligned}
\frac{Y(s)}{X(s)} & =\frac{K}{s(M s+B)} \\
K & =\frac{A k_{x}}{k_{p}}, \quad \mathrm{~B}=\left(b+\frac{A^{2}}{k_{p}}\right) \\
k_{x} & =\left.\frac{\partial g}{\partial x}\right|_{x_{0}, P_{0}}, \quad k_{p}=\left.\frac{\partial g}{\partial P}\right|_{x_{0}, P_{0}}, \\
g & =g(x, P)=\text { flow } \\
A & =\text { area of piston } \\
M & =\text { load mass } \\
b & =\text { load friction }
\end{aligned}
$$

(continued) Table 2.4 (continued)

\section{Element or System}

$G(s)$

10. Gear train, rotational transformer

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0107.jpg?height=351&width=445&top_left_y=356&top_left_x=88)

$$
\begin{aligned}
\text { Gear ratio } & =n=\frac{N_{1}}{N_{2}} \\
N_{2} \theta_{L}(t) & =N_{1} \theta_{m}(t), \quad \theta_{L}(t)=n \theta_{m}(t) \\
\omega_{L}(t) & =n \omega_{m}(t)
\end{aligned}
$$

11. Potentiometer, voltage control
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0107.jpg?height=302&width=492&top_left_y=808&top_left_x=88)

$$
\begin{aligned}
\frac{V_{2}(s)}{V_{1}(s)} & =\frac{R_{2}}{R}=\frac{R_{2}}{R_{1}+R_{2}} \\
\frac{R_{2}}{R} & =\frac{\theta}{\theta_{\max }}
\end{aligned}
$$

12. Potentiometer, error detector bridge

$$
\begin{aligned}
V_{2}(s) & =k_{s}\left(\theta_{1}(s)-\theta_{2}(s)\right) \\
V_{2}(s) & =k_{s} \theta_{\text {error }}(s) \\
k_{s} & =\frac{V_{\text {Battery }}}{\theta_{\max }}
\end{aligned}
$$

13. Tachometer, velocity sensor

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0107.jpg?height=183&width=388&top_left_y=1522&top_left_x=88)

$$
\begin{aligned}
V_{2}(s) & =K_{t} \omega(s)=K_{t} s \theta(s) \\
K_{t} & =\text { constant }
\end{aligned}
$$

14. DC amplifier

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0107.jpg?height=151&width=426&top_left_y=1804&top_left_x=88)

$$
\begin{aligned}
\frac{V_{2}(s)}{V_{1}(s)}= & \frac{k_{a}}{s \tau+1} \\
R_{\mathrm{O}}= & \text { output resistance } \\
C_{\mathrm{O}}= & \text { output capacitance } \\
\tau= & R_{\mathrm{O}} C_{\mathrm{O}}, \tau=1 \mathrm{~s} \\
& \begin{array}{l}
\text { and is often negligible for } \\
\end{array}
\end{aligned}
$$

Table 2.4 (continued)

\section{Element or System}

15. Accelerometer, acceleration sensor

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0108.jpg?height=280&width=421&top_left_y=356&top_left_x=222)

16. Thermal heating system

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0108.jpg?height=327&width=480&top_left_y=754&top_left_x=221)

17. Rack and pinion

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0108.jpg?height=419&width=440&top_left_y=1232&top_left_x=222)

\section{$G(s)$}

$x_{\mathrm{o}}(t)=y(t)-x_{\text {in }}(t)$,

$\frac{X_{\mathrm{o}}(s)}{X_{\text {in }}(s)}=\frac{-s^{2}}{s^{2}+(b / M) s+k / M}$

For low-frequency oscillations, where

$\omega<\omega_{n}$,

$\frac{X_{\mathrm{o}}(j \omega)}{X_{\text {in }}(j \omega)} \simeq \frac{\omega^{2}}{k / M}$

$\frac{T(s)}{q(s)}=\frac{1}{C_{t} s+\left(Q S+1 / R_{t}\right)}$, where

$T=T_{\mathrm{o}}-T_{e}=$ temperature difference due to thermal process

$C_{t}=$ thermal capacitance

$Q=$ fluid flow rate $=$ constant

$S=$ specific heat of water

$R_{t}=$ thermal resistance of insulation

$q(s)=$ transform of rate of heat flow of heating element

$$
x(t)=r \theta(t)
$$

converts radial motion

to linear motion

\subsection{BLOCK DIAGRAM MODELS}

The dynamic systems that comprise feedback control systems are typically represented mathematically by a set of simultaneous differential equations. As we have noted in the previous sections, the Laplace transformation reduces the problem to the solution of a set of linear algebraic equations. Since control systems are concerned with the control of specific variables, the controlled variables must relate to the controlling variables. This relationship is typically represented by the transfer function of the subsystem relating the input and output variables. Therefore, one can correctly assume that the transfer function is an important relation for control engineering. FIGURE 2.21

Block diagram of a DC motor.

FIGURE 2.22 General block representation of two-input, twooutput system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0109.jpg?height=400&width=662&top_left_y=152&top_left_x=374)

The importance of this cause-and-effect relationship is evidenced by the facility to represent the relationship of system variables graphically using block diagrams. Block diagrams consist of unidirectional, operational blocks that represent the transfer function of the systems of interest. A block diagram of a field-controlled DC motor and load is shown in Figure 2.21. The relationship between the displacement $\theta(s)$ and the input voltage $V_{f}(s)$ is represented in the block diagram.

To represent a system with several variables under control, an interconnection of blocks is utilized. For example, the system shown in Figure 2.22 has two input variables and two output variables [6]. Using transfer function relations, we can write the simultaneous equations for the output variables as

$$
Y_{1}(s)=G_{11}(s) R_{1}(s)+G_{12}(s) R_{2}(s),
$$

and

$$
Y_{2}(s)=G_{21}(s) R_{1}(s)+G_{22}(s) R_{2}(s),
$$

where $G_{i j}(s)$ is the transfer function relating the $i$ th output variable to the $j$ th input variable. The block diagram representing this set of equations is shown in Figure 2.23. In general, for $J$ inputs and $I$ outputs, we write the simultaneous equation in matrix form as

$$
\left[\begin{array}{c}
Y_{1}(s) \\
Y_{2}(s) \\
\vdots \\
Y_{I}(s)
\end{array}\right]=\left[\begin{array}{ccc}
G_{11}(s) & \ldots & G_{1 J}(s) \\
G_{21}(s) & \ldots & G_{2 J}(s) \\
\vdots & & \vdots \\
G_{I 1}(s) & \ldots & G_{I J}(s)
\end{array}\right]\left[\begin{array}{c}
R_{1}(s) \\
R_{2}(s) \\
\vdots \\
R_{J}(s)
\end{array}\right]
$$

or

$$
\mathbf{Y}(s)=\mathbf{G}(s) \mathbf{R}(s) .
$$

FIGURE 2.23

Block diagram of a two-input, twooutput interconnected system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0109.jpg?height=398&width=806&top_left_y=1711&top_left_x=359)

Here the $\mathbf{Y}(s)$ and $\mathbf{R}(s)$ matrices are column matrices containing the $I$ output and the $J$ input variables, respectively, and $\mathbf{G}(s)$ is an $I$ by $J$ transfer function matrix. The matrix representation of the interrelationship of many variables is particularly valuable for complex multi-variable control systems. Background information on matrix algebra can be found on-line and in many references, for example in [21].

The block diagram representation of a given system often can be reduced to a simplified block diagram with fewer blocks than the original diagram. Since the transfer functions represent linear systems, the multiplication is commutative. Thus, in Table 2.5, item 1, we have

$$
X_{3}(s)=G_{2}(s) X_{2}(s)=G_{2}(s) G_{1}(s) X_{1}(s) .
$$

\section{Table 2.5 Block Diagram Transformations}

\section{Transformation}

1. Combining blocks in cascade

Original Diagram
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=400&width=490&top_left_y=823&top_left_x=695)

3. Moving a pickoff point ahead of a block

2. Moving a summing point behind a block

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=162&width=303&top_left_y=1276&top_left_x=693)

4. Moving a pickoff point behind a block

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=163&width=306&top_left_y=1485&top_left_x=694)

5. Moving a summing point ahead of a block

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=181&width=360&top_left_y=1697&top_left_x=695)

6. Eliminating a feedback loop

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=174&width=402&top_left_y=1905&top_left_x=693)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=194&width=456&top_left_y=1476&top_left_x=1216)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=184&width=379&top_left_y=1693&top_left_x=1222)

Equivalent Diagram
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=1166&width=446&top_left_y=826&top_left_x=1216)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0110.jpg?height=131&width=303&top_left_y=920&top_left_x=1222)

FIGURE 2.24

Negative feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0111.jpg?height=379&width=1227&top_left_y=149&top_left_x=372)

When two blocks are connected in cascade, as in Table 2.5, item 1, we assume that

$$
X_{3}(s)=G_{2}(s) G_{1}(s) X_{1}(s)
$$

holds true. This assumes that when the first block is connected to the second block, the effect of loading of the first block is negligible. Loading and interaction between interconnected components or systems may occur. If the loading of interconnected devices does occur, the engineer must account for this change in the transfer function and use the corrected transfer function in subsequent calculations.

Block diagram transformations and reduction techniques are derived by considering the algebra of the diagram variables. For example, consider the block diagram shown in Figure 2.24. This negative feedback control system is described by the equation for the actuating signal, which is

$$
E_{a}(s)=R(s)-B(s)=R(s)-H(s) Y(s) .
$$

Because the output is related to the actuating signal by $G(s)$, we have

$$
Y(s)=G(s) U(s)=G(s) G_{a}(s) Z(s)=G(s) G_{a}(s) G_{c}(s) E_{a}(s) ;
$$

thus,

$$
Y(s)=G(s) G_{a}(s) G_{c}(s)[R(s)-H(s) Y(s)] .
$$

Combining the $Y(s)$ terms, we obtain

$$
Y(s)\left[1+G(s) G_{a}(s) G_{c}(s) H(s)\right]=G(s) G_{a}(s) G_{c}(s) R(s) .
$$

Therefore, the closed-loop transfer function relating the output $Y(s)$ to the input $R(s)$ is

$$
\frac{Y(s)}{R(s)}=\frac{G(s) G_{a}(s) G_{c}(s)}{1+G(s) G_{a}(s) G_{c}(s) H(s)} .
$$

The reduction of the block diagram shown in Figure 2.24 to a single block representation is one example of several useful techniques. These diagram transformations are given in Table 2.5. All the transformations in Table 2.5 can be derived by algebraic manipulation of the equations representing the blocks. System analysis by the method of block diagram reduction affords a better understanding of the contribution of each component element than possible by the manipulation of equations. The utility of the block diagram transformations will be illustrated by an example using block diagram reduction. FIGURE 2.25

Multiple-loop feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0112.jpg?height=428&width=1269&top_left_y=165&top_left_x=506)

EXAMPLE 2.6 Block diagram reduction

The block diagram of a multiple-loop feedback control system is shown in Figure 2.25. It is interesting to note that the feedback signal $H_{1}(s) Y(s)$ is a positive feedback signal, and the loop $G_{3}(s) G_{4}(s) H_{1}(s)$ is a positive feedback loop. The block diagram reduction procedure is based on the use of Table 2.5, transformation 6 , which eliminates feedback loops. Therefore the other transformations are used to transform the diagram to a form ready for eliminating feedback loops. First, to eliminate the loop $G_{3}(s) G_{4}(s) H_{1}(s)$, we move $H_{2}(s)$ behind block $G_{4}(s)$ by using transformation 4, and obtain Figure 2.26(a). Eliminating the loop $G_{3}(s) G_{4}(s) H_{1}(s)$ by using transformation 6 , we obtain Figure 2.26(b). Then, eliminating the inner loop containing $\mathrm{H}_{2}(s) / G_{4}(s)$, we obtain Figure 2.26(c). Finally, by reducing the loop containing $\mathrm{H}_{3}(s)$, we obtain the closed-loop system transfer function as shown in Figure 2.26(d). It is worthwhile to examine the form of the numerator and denominator of this closed-loop transfer function. We note that the numerator is composed of the cascade transfer function of the feedforward elements connecting the input $R(s)$ and the output $Y(s)$. The denominator is composed of 1 minus the sum of each loop transfer function. The loop $G_{3}(s) G_{4}(s) H_{1}(s)$ has a plus sign in the sum to be subtracted because it is a positive feedback loop, whereas the loops $G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) H_{3}(s)$ and $G_{2}(s) G_{3}(s) H_{2}(s)$ are negative feedback loops. To illustrate this point, the denominator can be rewritten as

$q(s)=1-\left(+G_{3}(s) G_{4}(s) H_{1}(s)-G_{2}(s) G_{3}(s) H_{2}(s)-G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) H_{3}(s)\right)$.

This form of the numerator and denominator is quite close to the general form for multiple-loop feedback systems, as we shall find in the following section.

The block diagram representation of feedback control systems is a valuable and widely used approach. The block diagram provides the analyst with a graphical representation of the system interrelationships. Furthermore, the designer can readily visualize the possibilities for adding blocks to the existing system block diagram to alter and improve the system performance. The transition from the block diagram method to a method utilizing a line path representation instead of a block representation is readily accomplished and is presented in the following section. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0113.jpg?height=317&width=1112&top_left_y=159&top_left_x=258)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0113.jpg?height=264&width=1112&top_left_y=564&top_left_x=258)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0113.jpg?height=171&width=1553&top_left_y=914&top_left_x=87)

(c)

(d)

FIGURE 2.26 Block diagram reduction of the system of Figure 2.25.

\subsection{SIGNAL-FLOW GRAPH MODELS}

Block diagrams are adequate for the representation of the interrelationships of controlled and input variables. An alternative method for determining the relationship between system variables has been developed by Mason and is based on a representation of the system by line segments $[4,25]$. The advantage of the line path method, called the signal-flow graph method, is the availability of a flow graph gain formula, which provides the relation between system variables without requiring any reduction procedure or manipulation of the flow graph.

The transition from a block diagram representation to a directed line segment representation is easy to accomplish by reconsidering the systems of the previous section. A signal-flow graph is a diagram consisting of nodes that are connected by several directed branches and is a graphical representation of a set of linear relations. Signal-flow graphs are particularly useful for feedback control systems because feedback theory is primarily concerned with the flow and processing of signals in systems. The basic element of a signal-flow graph is a unidirectional path segment called a branch, which relates the dependency of an input and an output variable in a manner equivalent to a block of a block diagram. Therefore, the branch relating the output $\theta(s)$ of a DC motor to the field voltage $V_{f}(s)$ is similar to the block diagram FIGURE 2.27

Signal-flow graph of the DC motor.

FIGURE 2.28 Signal-flow graph of a two-input, two-output interconnected system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0114.jpg?height=380&width=538&top_left_y=166&top_left_x=502)

of Figure 2.21 and is shown in Figure 2.27. The input and output points or junctions are called nodes. Similarly, the signal-flow graph representing Equations (2.71) and (2.72), as well as Figure 2.23, is shown in Figure 2.28. The relation between each variable is written next to the directional arrow. All branches leaving a node will pass the nodal signal to the output node of each branch (unidirectionally). The summation of all signals entering a node is equal to the node variable. A path is a branch or a continuous sequence of branches that can be traversed from one signal (node) to another signal (node). A loop is a closed path that originates and terminates on the same node, with no node being met twice along the path. Two loops are said to be nontouching if they do not have a common node. Two touching loops share one or more common nodes. Therefore, considering Figure 2.28 again, we obtain

$$
Y_{1}(s)=G_{11}(s) R_{1}(s)+G_{12}(s) R_{2}(s),
$$

and

$$
Y_{2}(s)=G_{21}(s) R_{1}(s)+G_{22}(s) R_{2}(s) .
$$

The flow graph is a graphical method of writing a system of algebraic equations that indicates the interdependencies of the variables. As another example, consider the following set of simultaneous algebraic equations:

$$
\begin{aligned}
& a_{11} x_{1}+a_{12} x_{2}+r_{1}=x_{1} \\
& a_{21} x_{1}+a_{22} x_{2}+r_{2}=x_{2} .
\end{aligned}
$$

The two input variables are $r_{1}$ and $r_{2}$, and the output variables are $x_{1}$ and $x_{2}$. A signal-flow graph representing Equations (2.83) and (2.84) is shown in Figure 2.29. Equations (2.83) and (2.84) may be rewritten as

$$
x_{1}\left(1-a_{11}\right)+x_{2}\left(-a_{12}\right)=r_{1},
$$

and

$$
x_{1}\left(-a_{21}\right)+x_{2}\left(1-a_{22}\right)=r_{2}
$$

The simultaneous solution of Equations (2.85) and (2.86) using Cramer's rule results in the solutions

$$
x_{1}=\frac{\left(1-a_{22}\right) r_{1}+a_{12} r_{2}}{\left(1-a_{11}\right)\left(1-a_{22}\right)-a_{12} a_{21}}=\frac{1-a_{22}}{\Delta} r_{1}+\frac{a_{12}}{\Delta} r_{2},
$$

FIGURE 2.29

Signal-flow graph of two algebraic equations.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0115.jpg?height=404&width=436&top_left_y=153&top_left_x=370)

and

$$
x_{2}=\frac{\left(1-a_{11}\right) r_{2}+a_{21} r_{1}}{\left(1-a_{11}\right)\left(1-a_{22}\right)-a_{12} a_{21}}=\frac{1-a_{11}}{\Delta} r_{2}+\frac{a_{21}}{\Delta} r_{1} .
$$

The denominator of the solution is the determinant $\Delta$ of the set of equations and is rewritten as

$$
\Delta=\left(1-a_{11}\right)\left(1-a_{22}\right)-a_{12} a_{21}=1-a_{11}-a_{22}+a_{11} a_{22}-a_{12} a_{21} .
$$

In this case, the denominator is equal to 1 minus each self-loop $a_{11}, a_{22}$, and $a_{12} a_{21}$, plus the product of the two nontouching loops $a_{11}$ and $a_{22}$. The loops $a_{22}$ and $a_{21} a_{12}$ are touching, as are $a_{11}$ and $a_{21} a_{12}$.

The numerator for $x_{1}$ with the input $r_{1}$ is 1 times $1-a_{22}$, which is the value of $\Delta$ excluding terms that touch the path 1 from $r_{1}$ to $x_{1}$. Therefore the numerator from $r_{2}$ to $x_{1}$ is simply $a_{12}$ because the path through $a_{12}$ touches all the loops. The numerator for $x_{2}$ is symmetrical to that of $x_{1}$.

In general, the linear dependence $T_{i j}(s)$ between the independent variable $x_{i}$ (often called the input variable) and a dependent variable $x_{j}$ is given by Mason's signal-flow gain formula $[11,12]$,

$$
T_{i j}(s)=\frac{\sum_{k} P_{i j k}(s) \Delta_{i j k}(s)}{\Delta(s)},
$$

$$
\begin{aligned}
P_{i j k}(s) & =\text { gain of kth path from variable } x_{i} \text { to variable } x_{j}, \\
\Delta(s) & =\text { determinant of the graph, } \\
\Delta_{i j k}(s) & =\text { cofactor of the path } P_{i j k}(s),
\end{aligned}
$$

and the summation is taken over all possible $k$ paths from $x_{i}$ to $x_{j}$. The path gain or transmittance $P_{i j k}(s)$ is defined as the product of the gains of the branches of the path, traversed in the direction of the arrows with no node encountered more than once. The cofactor $\Delta_{i j k}(s)$ is the determinant with the loops touching the $k$ th path removed. The determinant $\Delta(s)$ is

$$
\Delta(s)=1-\sum_{n=1}^{N} L_{n}(s)+\sum_{\substack{n, m \\ \text { nontouching }}} L_{n}(s) L_{m}(s)-\sum_{\substack{n, m, \\ \text { pnontouching }}} L_{n}(s) L_{m}(s) L_{p}(s)+\cdots,
$$

where $L_{q}(s)$ equals the value of the $q$ th loop transmittance. Therefore the rule for evaluating $\Delta(s)$ in terms of loops $L_{1}(s), L_{2}(s), L_{3}(s), \ldots, L_{N}(s)$ is $\Delta=1-$ (sum of all different loop gains)

+ (sum of the gain products of all combinations of two nontouching loops)

- (sum of the gain products of all combinations of three nontouching loops)

$+\ldots$

The gain formula is often used to relate the output variable $Y(s)$ to the input variable $R(s)$ and is given in somewhat simplified form as

$$
T(s)=\frac{\Sigma_{k} P_{k}(s) \Delta_{k}(s)}{\Delta(s)},
$$

where $T(s)=Y(s) / R(s)$.

Several examples will illustrate the utility and ease of this method. Although the gain Equation (2.90) appears to be formidable, one must remember that it represents a summation process, not a complicated solution process.

\section{EXAMPLE 2.7 Transfer function of an interacting system}

A two-path signal-flow graph is shown in Figure 2.30(a) and the corresponding block diagram is shown in Figure 2.30(b). An example of a control system with multiple signal paths is a multilegged robot. The paths connecting the input $R(s)$ and output $Y(s)$ are

FIGURE 2.30

Two-path interacting system. (a) Signal-flow graph. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0116.jpg?height=646&width=734&top_left_y=968&top_left_x=769)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0116.jpg?height=412&width=1246&top_left_y=1713&top_left_x=506)

(b) There are four self-loops:

$$
\begin{aligned}
& L_{1}(s)=G_{2}(s) H_{2}(s), \quad L_{2}(s)=H_{3}(s) G_{3}(s), \\
& L_{3}(s)=G_{6}(s) H_{6}(s), \quad \text { and } \quad L_{4}(s)=G_{7}(s) H_{7}(s) \text {. }
\end{aligned}
$$

Loops $L_{1}$ and $L_{2}$ do not touch $L_{3}$ and $L_{4}$. Therefore, the determinant is

$$
\begin{aligned}
\Delta(s)= & 1-\left(L_{1}(s)+L_{2}(s)+L_{3}(s)+L_{4}(s)\right)+ \\
& \left(L_{1}(s) L_{3}(s)+L_{1}(s) L_{4}(s)+L_{2}(s) L_{3}(s)+L_{2}(s) L_{4}(s)\right) .
\end{aligned}
$$

The cofactor of the determinant along path 1 is evaluated by removing the loops that touch path 1 from $\Delta(s)$. Hence, we have

$$
L_{1}(s)=L_{2}(s)=0 \quad \text { and } \quad \Delta_{1}(s)=1-\left(L_{3}(s)+L_{4}(s)\right) .
$$

Similarly, the cofactor for path 2 is

$$
\Delta_{2}(s)=1-\left(L_{1}(s)+L_{2}(s)\right) .
$$

Therefore, the transfer function of the system is

$$
\begin{aligned}
\frac{Y(s)}{R(s)}= & T(s)=\frac{P_{1}(s) \Delta_{1}(s)+P_{2}(s) \Delta_{2}(s)}{\Delta(s)} \\
= & \frac{G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s)\left(1-L_{3}(s)-L_{4}(s)\right)}{\Delta(s)} \\
& +\frac{G_{5}(s) G_{6}(s) G_{7}(s) G_{8}(s)\left(1-L_{1}(s)-L_{2}(s)\right)}{\Delta(s)}
\end{aligned}
$$

where $\Delta(s)$ in given in Equation (2.93).

A similar analysis can be accomplished using block diagram reduction techniques. The block diagram shown in Figure 2.30(b) has four inner feedback loops within the overall block diagram. The block diagram reduction is simplified by first reducing the four inner feedback loops and then placing the resulting systems in series. Along the top path, the transfer function is

$$
\begin{aligned}
Y_{1}(s) & =G_{1}(s)\left[\frac{G_{2}(s)}{1-G_{2}(s) H_{2}(s)}\right]\left[\frac{G_{3}(s)}{1-G_{3}(s) H_{3}(s)}\right] G_{4}(s) R(s) \\
& =\left[\frac{G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s)}{\left(1-G_{2}(s) H_{2}(s)\right)\left(1-G_{3}(s) H_{3}(s)\right)}\right] R(s) .
\end{aligned}
$$

Similarly across the bottom path, the transfer function is

$$
\begin{aligned}
Y_{2}(s) & =G_{5}(s)\left[\frac{G_{6}(s)}{1-G_{6}(s) H_{6}(s)}\right]\left[\frac{G_{7}(s)}{1-G_{7}(s) H_{7}(s)}\right] G_{8}(s) R(s) \\
& =\left[\frac{G_{5}(s) G_{6}(s) G_{7}(s) G_{8}(s)}{\left(1-G_{6}(s) H_{6}(s)\right)\left(1-G_{7}(s) H_{7}(s)\right)}\right] R(s) .
\end{aligned}
$$

The total transfer function is then given by

$$
\begin{aligned}
Y(s)= & Y_{1}(s)+Y_{2}(s)=\left[\frac{G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s)}{\left(1-G_{2}(s) H_{2}(s)\right)\left(1-G_{3}(s) H_{3}(s)\right)}\right. \\
& \left.+\frac{G_{5}(s) G_{6}(s) G_{7}(s) G_{8}(s)}{\left(1-G_{6}(s) H_{6}(s)\right)\left(1-G_{7}(s) H_{7}(s)\right)}\right] R(s) .
\end{aligned}
$$

\section{EXAMPLE 2.8 Armature-controlled motor}

The block diagram of the armature-controlled DC motor is shown in Figure 2.20. This diagram was obtained from Equations (2.64)-(2.68). The signal-flow diagram is shown in Figure 2.31. Using Mason's signal-flow gain formula, let us obtain the transfer function for $\theta(s) / V_{a}(s)$ with $T_{d}(s)=0$. The forward path is $P_{1}(s)$, which touches the one loop, $L_{1}(s)$, where

$$
P_{1}(s)=\frac{1}{s} G_{1}(s) G_{2}(s) \text { and } L_{1}(s)=-K_{b} G_{1}(s) G_{2}(s) .
$$

Therefore, the transfer function is

$$
T(s)=\frac{P_{1}(s)}{1-L_{1}(s)}=\frac{(1 / s) G_{1}(s) G_{2}(s)}{1+K_{b} G_{1}(s) G_{2}(s)}=\frac{K_{m}}{s\left[\left(R_{a}+L_{a} s\right)(J s+b)+K_{b} K_{m}\right]} .
$$

The signal-flow graph gain formula provides a reasonably straightforward approach for the evaluation of complicated systems. To compare the method with block diagram reduction, let us reconsider the complex system of Example 2.6.

\section{EXAMPLE 2.9 Transfer function of a multiple-loop system}

A multiple-loop feedback system is shown in Figure 2.25 in block diagram form. There is no need to redraw the diagram in signal-flow graph form, and we shall proceed using Mason's signal-flow gain formula. There is one forward path $P_{1}(s)=G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s)$. The feedback loops are

$$
\begin{aligned}
L_{1}(s) & =-G_{2}(s) G_{3}(s) H_{2}(s), \quad L_{2}(s)=G_{3}(s) G_{4}(s) H_{1}(s), \\
\text { and } \quad & L_{3}(s)=-G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) H_{3}(s) .
\end{aligned}
$$

FIGURE 2.31

The signal-flow graph of the armature-controlled DC motor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0118.jpg?height=360&width=1277&top_left_y=1753&top_left_x=509)

All the loops have common nodes and therefore are all touching. Furthermore, the path $P_{1}(s)$ touches all the loops, so $\Delta_{1}(s)=1$. Thus, the closed-loop transfer function is

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{P_{1}(s) \Delta_{1}(s)}{1-L_{1}(s)-L_{2}(s)-L_{3}(s)}=\frac{G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s)}{\Delta(s)}
$$

where

$\Delta(s)=1+G_{2}(s) G_{3}(s) H_{2}(s)-G_{3}(s) G_{4}(s) H_{1}(s)+G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) H_{3}(s)$.

\section{EXAMPLE 2.10 Transfer function of a complex system}

Consider the system with several feedback loops and feedforward paths shown in Figure 2.32. The forward paths are

$P_{1}(s)=G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) G_{5}(s) G_{6}(s), \quad P_{2}(s)=G_{1}(s) G_{2}(s) G_{7}(s) G_{6}(s)$, and $P_{3}(s)=G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) G_{8}(s)$.

The feedback loops are

$$
\begin{aligned}
& L_{1}(s)=-G_{2}(s) G_{3}(s) G_{4}(s) G_{5}(s) H_{3}(s) . \quad L_{2}(s)=-G_{5}(s) G_{6}(s) H_{1}(s), \\
& L_{3}(s)=-G_{8}(s) H_{1}(s), L_{4}(s)=-G_{7}(s) H_{2}(s) G_{2}(s), \\
& L_{5}(s)=-G_{4}(s) H_{4}(s), \quad L_{6}(s)=-G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) G_{5}(s) G_{6}(s) H_{3}(s), \\
& L_{7}(s)=-G_{1}(s) G_{2}(s) G_{7}(s) G_{6}(s) H_{3}(s), \text { and } \\
& L_{8}(s)=-G_{1}(s) G_{2}(s) G_{3}(s) G_{4}(s) G_{8}(s) H_{3}(s) .
\end{aligned}
$$

Loop $L_{5}$ does not touch loop $L_{4}$ or loop $L_{7}$, and loop $L_{3}$ does not touch loop $L_{4}$; but all other loops touch. Therefore, the determinant is

$$
\begin{aligned}
\Delta(s)= & 1-\left(L_{1}(s)+L_{2}(s)+L_{3}(s)+L_{4}(s)+L_{5}(s)+L_{6}(s)+L_{7}(s)+L_{8}(s)\right) \\
& +\left(L_{5}(s) L_{7}(s)+L_{5}(s) L_{4}(s)+L_{3}(s) L_{4}(s)\right) .
\end{aligned}
$$

The cofactors are

$$
\Delta_{1}(s)=\Delta_{3}(s)=1 \quad \text { and } \quad \Delta_{2}(s)=1-L_{5}(s)=1+G_{4}(s) H_{4}(s) .
$$

FIGURE 2.32

Signal-flow graph of a multiple-loop system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0119.jpg?height=442&width=1268&top_left_y=1710&top_left_x=349)

Finally, the transfer function is

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{P_{1}(s)+P_{2}(s) \Delta_{2}(s)+P_{3}(s)}{\Delta(s)} .
$$

\subsection{DESIGN EXAMPLES}

In this section, we present four illustrative design examples. The first example describes modeling of a photovoltaic generator in a manner amenable to feedback control to achieve maximum power delivery as the sunlight varies over time. Using feedback control to improve the efficiency of producing electricity using solar energy in areas of abundant sunlight is a valuable contribution to green engineering. In the second example, we present a detailed look at modeling of the fluid level in a reservoir. The modeling is presented in a very detailed manner to emphasize the effort required to obtain a linear model in the form of a transfer function. The remaining two examples include an electric traction motor model development and the design of a low-pass filter.

\section{EXAMPLE 2.11 Photovoltaic generators}

Photovoltaic cells were developed at Bell Laboratories in 1954. Solar cells are one example of photovoltaic cells and convert solar light to electricity. Other types of photovoltaic cells can detect radiation and measure light intensity. The use of solar cells to produce energy supports the principles of green engineering by minimizing pollution. Solar panels minimize the depletion of natural resources and are effective in areas where sunlight is abundant. Photovoltaic generators are systems that provide electricity using an assortment of photovoltaic modules comprised of interconnected solar cells. Photovoltaic generators can be used to recharge batteries, they can be directly connected to an electrical grid, or they can drive electric motors without a battery [34-42].

The power output of a solar cell varies with available solar light, temperature, and external loads. To increase the overall efficiency of the photovoltaic generator, feedback control strategies can be employed to seek to maximize the power output. This is known as maximum power point tracking (MPPT) [34-36]. There are certain values of current and voltage associated with the solar cells corresponding to the maximum power output. The MPPT uses closed-loop feedback control to seek the optimal point to allow the power converter circuit to extract the maximum power from the photovoltaic generator system. We will discuss the control design in later chapters, but here we focus on the modeling of the system.

The solar cell can be modeled as an equivalent circuit shown in Figure 2.33 composed of a current generator, $I_{P H}$, a light sensitive diode, a resistance series, $R_{S}$, and a shunt resistance, $R_{P}[34,36-38]$.

FIGURE 2.33

Equivalent circuit of the photovoltaic generator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0120.jpg?height=243&width=476&top_left_y=1899&top_left_x=503)

FIGURE 2.34

Voltage versus current and power versus current for an example photovoltaic generator at a specific insolation level.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0121.jpg?height=785&width=1040&top_left_y=165&top_left_x=374)

The output voltage, $V_{P V}$, is given by

$$
V_{P V}=\frac{N}{\lambda} \ln \left(\frac{I_{P H}-I_{P V}+M I_{0}}{M I_{0}}\right)-\frac{N}{M} R_{S} I_{P V},
$$

where the photovoltaic generator is comprised of $M$ parallel strings with $N$ series cells per string, $I_{0}$ is the reverse saturation current of the diode, $I_{P H}$ represents the insolation level, and $\lambda$ is a known constant that depends on the cell material [34-36]. The insolation level is a measure of the amount of incident solar radiation on the solar cells.

Suppose that we have a single silicon solar panel $(M=1)$ with 10 series cells $(N=10)$ and the parameters given by $1 / \lambda=0.05 \mathrm{~V}, R_{S}=0.025 \Omega, I_{P H}=3 \mathrm{~A}$, and $I_{0}=0.001 \mathrm{~A}$. The voltage versus current relationship in Equation (2.99) and the power versus voltage are shown in Figure 2.34 for one particular insolation level where $I_{P H}=3 \mathrm{~A}$. In Figure 2.34, we see that when $d P / d I_{P V}=0$ we are at the maximum power level with an associated $V_{P V}=V_{m p}$ and $I_{P V}=I_{m p}$, the values of voltage and current at the maximum power, respectively. As the sunlight varies, the insolation level, $I_{P H}$, varies resulting in different power curves.

The goal of the power point tracking is to seek the voltage and current condition that maximizes the power output as conditions vary. This is accomplished by varying the reference voltage as a function of the insolation level. The reference voltage is the voltage at the maximum power point as shown in Figure 2.35. The feedback control system should track the reference voltage in a rapid and accurate fashion.

Figure 2.36 illustrates a simplified block diagram of the controlled system. The main components are a power circuit (e.g., a phase control IC and a thyristor bridge), photovoltaic generator, and current transducer. The plant including the 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0122.jpg?height=868&width=1079&top_left_y=154&top_left_x=505)

FIGURE 2.35 Maximum power point for varying values of $I_{P H}$ specifies $V_{\text {ref }}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0122.jpg?height=294&width=1263&top_left_y=1123&top_left_x=502)

FIGURE 2.36 Block diagram of feedback control system for maximum power transfer.

power circuit, photovoltaic generator, and current transducer is modeled as a second-order transfer function given by

$$
G(s)=\frac{K}{s(s+p)},
$$

where $K$ and $p$ depend on the photovoltaic generator and associated electronics [35]. The controller, $G_{c}(s)$, in Figure 2.36 is designed such that as the insolation levels varies (that is, as $I_{P H}$ varies), the voltage output will approach the reference input voltage, $V_{\text {ref }}(s)$, which has been set to the voltage associated with the maximum power point resulting in maximum power transfer. If, for example, the controller is the proportional plus integral controller

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s},
$$

the closed-loop transfer function is

$$
T(s)=\frac{K\left(K_{P} s+K_{I}\right)}{s^{3}+p s^{2}+K K_{P} s+K K_{I}} .
$$

We can select the controller gains in Equation (2.101) to place the poles of $T(s)$ in the desired locations to meet the desired performance specifications.

\section{EXAMPLE 2.12 Fluid flow modeling}

A fluid flow system is shown in Figure 2.37. The reservoir (or tank) contains water that evacuates through an output port. Water is fed to the reservoir through a pipe controlled by an input valve. The variables of interest are the fluid velocity $V(\mathrm{~m} / \mathrm{s})$, fluid height in the reservoir $H(\mathrm{~m})$, and $p$ ressure $p\left(\mathrm{~N} / \mathrm{m}^{2}\right)$. The pressure is defined as the force per unit area exerted by the fluid on a surface immersed (and at rest with respect to) the fluid. Fluid pressure acts normal to the surface. For further reading on fluid flow modeling, see [28-30].

The elements of the control system design process emphasized in this example are shown in Figure 2.38. The strategy is to establish the system configuration and then obtain the appropriate mathematical models describing the fluid flow reservoir from an input-output perspective.

The general equations of motion and energy describing fluid flow are quite complicated. The governing equations are coupled nonlinear partial differential equations. We must make some selective assumptions that reduce the complexity of the mathematical model. Although the control engineer is not required to be a fluid dynamicist, and a deep understanding of fluid dynamics is not necessarily acquired during the control system design process, it makes good engineering sense to gain at least a rudimentary understanding of the important simplifying assumptions. For a more complete discussion of fluid motion, see [31-33].

To obtain a realistic, yet tractable, mathematical model for the fluid flow reservoir, we first make several key assumptions. We assume that the water in the tank is incompressible and that the flow is inviscid, irrotational and steady. An incompressible fluid has a constant density $\rho\left(\mathrm{kg} / \mathrm{m}^{3}\right)$. In fact, all fluids are compressible to some extent. The compressibility factor, $k$, is a measure of the compressibility of

FIGURE 2.37

The fluid flow reservoir configuration.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0123.jpg?height=523&width=663&top_left_y=1599&top_left_x=372)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0124.jpg?height=1021&width=1361&top_left_y=235&top_left_x=392)

FIGURE 2.38 Elements of the control system design process emphasized in the fluid flow reservoir example.

a fluid. A smaller value of $k$ indicates less compressibility. Air (which is a compressible fluid) has a compressibility factor of $k_{\text {air }}=0.98 \mathrm{~m}^{2} / \mathrm{N}$, while water has a compressibility factor of $k_{\mathrm{H}_{2} \mathrm{O}}=4.9 \times 10^{-10} \mathrm{~m}^{2} / \mathrm{N}=50 \times 10^{-6} \mathrm{~atm}^{-1}$. In other words, a given volume of water decreases by 50 one-millionths of the original volume for each atmosphere (atm) increase in pressure. Thus the assumption that the water is incompressible is valid for our application.

Consider a fluid in motion. Suppose that initially the flow velocities are different for adjacent layers of fluid. Then an exchange of molecules between the two layers tends to equalize the velocities in the layers. This is internal friction, and the exchange of momentum is known as viscosity. Solids are more viscous than fluids, and fluids are more viscous than gases. A measure of viscosity is the coefficient of viscosity $\mu\left(\mathrm{N} \mathrm{s} / \mathrm{m}^{2}\right)$. A larger coefficient of viscosity implies higher viscosity. The coefficient of viscosity (under standard conditions, $20^{\circ} \mathrm{C}$ ) for air is $\mu_{\text {air }}=0.178 \times 10^{-4} \mathrm{~N} \mathrm{~s} / \mathrm{m}^{2}$, and for water we have $\mu \mathrm{H}_{2} \mathrm{O}=1.054 \times 10^{-3} \mathrm{~N} \mathrm{~s} / \mathrm{m}^{2}$.

Therefore water is about 60 times more viscous than air. Viscosity depends primarily on temperature, not pressure. For comparison, water at $0^{\circ} \mathrm{C}$ is about 2 times more viscous than water at $20^{\circ} \mathrm{C}$. With fluids of low viscosity, such as air and water, the effects of friction are important only in the boundary layer, a thin layer adjacent to the wall of the reservoir and output pipe. We can neglect viscosity in our model development. We say our fluid is inviscid.

If each fluid element at each point in the flow has no net angular velocity about that point, the flow is termed irrotational. Imagine a small paddle wheel immersed in the fluid (say in the output port). If the paddle wheel translates without rotating, the flow is irrotational. We will assume the water in the tank is irrotational. For an inviscid fluid, an initially irrotational flow remains irrotational.

The water flow in the tank and output port can be either steady or unsteady. The flow is steady if the velocity at each point is constant in time. This does not necessarily imply that the velocity is the same at every point but rather that an an given point the velocity does not change with time. Steady-state conditions can be achieved at low fluid speeds. We will assume steady flow conditions. If the output port area is too large, then the flow through the reservoir may not be slow enough to establish the steady-state condition that we are assuming exists and our model will not accurately predict the fluid flow motion.

To obtain a mathematical model of the flow within the reservoir, we employ basic principles of science and engineering, such as the principle of conservation of mass. The mass of water in the tank at any given time is

$$
m(t)=\rho A_{1} H(t)
$$

where $A_{1}$ is the area of the tank, $\rho$ is the water density, and $H(t)$ is the height of the water in the reservoir. The constants for the reservoir system are given in Table 2.6.

In the following formulas, a subscript 1 denotes quantities at the input, and a subscript 2 refers to quantities at the output. Taking the time derivative of $m(t)$ in Equation (2.102) yields

$$
\dot{m}(t)=\rho A_{1} \dot{H}(t),
$$

where we have used the fact that our fluid is incompressible (that is, $\dot{\rho}=0$ ) and that the area of the tank, $A_{1}$, does not change with time. The change in mass in the reservoir is equal to the mass that enters the tank minus the mass that leaves the tank, or

$$
\dot{m}(t)=\rho A_{1} \dot{H}(t)=Q_{1}(t)-\rho A_{2} v_{2}(t),
$$

where $Q_{1}(t)$ is the input mass flow rate, $v_{2}(t)$ is the exit velocity, and $A_{2}$ is the output port area. The exit velocity, $v_{2}(t)$, is a function of the water height. From Bernoulli's equation [39] we have

$$
\frac{1}{2} \rho v_{1}^{2}(t)+P_{1}+\rho g H(t)=\frac{1}{2} \rho v_{2}^{2}(t)+P_{2},
$$

Table 2.6 Water Tank Physical Constants

\begin{tabular}{cccccc}
$\begin{array}{c}\rho \\
\left(\mathrm{kg} / \mathrm{m}^{3}\right)\end{array}$ & $\begin{array}{c}g \\
\left(\mathrm{~m} / \mathrm{s}^{2}\right)\end{array}$ & $\begin{array}{c}A_{1} \\
\left(\mathrm{~m}^{2}\right)\end{array}$ & $\begin{array}{c}A_{2} \\
\left(\mathrm{~m}^{2}\right)\end{array}$ & $\begin{array}{c}H^{*} \\
(\mathrm{~m})\end{array}$ & $\begin{array}{c}Q^{*} \\
(\mathrm{~kg} / \mathrm{s})\end{array}$ \\
\hline 1000 & 9.8 & $\pi / 4$ & $\pi / 400$ & 1 & 34.77 \\
\hline
\end{tabular}

where $v_{1}$ is the water velocity at the mouth of the reservoir, and $P_{1}$ and $P_{2}$ are the atmospheric pressures at the input and output, respectively. But $P_{1}$ and $P_{2}$ are equal, and $A_{2}$ is sufficiently small $\left(A_{2}=A_{1} / 100\right)$, so the water flows out slowly and the velocity $v_{1}(t)$ is negligible. Thus Bernoulli's equation reduces to

$$
v_{2}(t)=\sqrt{2 g H(t)} .
$$

Substituting Equation (2.104) into Equation (2.103) and solving for $\dot{H}(t)$ yields

$$
\dot{H}(t)=-\left[\frac{A_{2}}{A_{1}} \sqrt{2 g}\right] \sqrt{H(t)}+\frac{1}{\rho A_{1}} Q_{1}(t) .
$$

Using Equation (2.104), we obtain the exit mass flow rate

$$
Q_{2}(t)=\rho A_{2} v_{2}(t)=\left(\rho \sqrt{2 g} A_{2}\right) \sqrt{H(t)} .
$$

To keep the equations manageable, define

$$
k_{1}:=-\frac{A_{2} \sqrt{2 g}}{A_{1}}, \quad k_{2}:=\frac{1}{\rho A_{1}}, \quad \text { and } \quad k_{3}:=\rho \sqrt{2 g} A_{2} .
$$

Then, it follows that

$$
\begin{aligned}
\dot{H}(t) & =k_{1} \sqrt{H(t)}+k_{2} Q_{1}(t), \\
Q_{2}(t) & =k_{3} \sqrt{H(t)} .
\end{aligned}
$$

Equation (2.107) represents our model of the water tank system, where the input is $Q_{1}(t)$ and the output is $Q_{2}(t)$. Equation (2.107) is a nonlinear, first-order, ordinary differential equation model. The model in Equation (2.107) has the functional form

$$
\begin{aligned}
\dot{H}(t) & =f\left(H(t), Q_{1}(t)\right), \\
Q_{2}(t) & =h\left(H(t), Q_{1}(t)\right),
\end{aligned}
$$

where

$$
f\left(H(t), Q_{1}(t)\right)=k_{1} \sqrt{H(t)}+k_{2} Q_{1}(t) \text { and } h\left(H(t), Q_{1}(t)\right)=k_{3} \sqrt{H(t)} .
$$

A set of linearized equations describing the height of the water in the reservoir is obtained using Taylor series expansions about an equilibrium flow condition. When the tank system is in equilibrium, we have $\dot{H}(t)=0$. We can define $Q^{*}$ and $H^{*}$ as the equilibrium input mass flow rate and water level, respectively. The relationship between $Q^{*}$ and $H^{*}$ is given by

$$
Q^{*}=-\frac{k_{1}}{k_{2}} \sqrt{H^{*}}=\rho \sqrt{2 g} A_{2} \sqrt{H^{*}} .
$$

This condition occurs when just enough water enters the tank in $A_{1}$ to make up for the amount leaving through $A_{2}$. We can write the water level and input mass flow rate as

$$
\begin{array}{r}
H(t)=H^{*}+\Delta H(t), \\
Q_{1}(t)=Q^{*}+\Delta Q_{1}(t),
\end{array}
$$

where $\Delta H(t)$ and $\Delta Q_{1}(t)$ are small deviations from the equilibrium (steady-state) values. The Taylor series expansion about the equilibrium conditions is given by

$$
\begin{gathered}
\dot{H}(t)=f\left(H(t), Q_{1}(t)\right)=f\left(H^{*}, Q^{*}\right)+\left.\frac{\partial f}{\partial H}\right|_{\substack{H=H^{*} \\
Q 1=Q^{*}}}\left(H(t)-H^{*}\right) \\
+\left.\frac{\partial f}{\partial Q_{1}}\right|_{\substack{H=H^{*} \\
Q 1=Q^{*}}}\left(Q_{1}(t)-Q^{*}\right)+\ldots,
\end{gathered}
$$

where

$$
\left.\frac{\partial f}{\partial H}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=\left.\frac{\partial\left(k_{1} \sqrt{H}+k_{2} Q_{1}\right)}{\partial H}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=\frac{1}{2} \frac{k_{1}}{\sqrt{H^{*}}},
$$

and

$$
\left.\frac{\partial f}{\partial Q_{1}}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=\left.\frac{\partial\left(k_{1} \sqrt{H}+k_{2} Q_{1}\right)}{\partial Q_{1}}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=k_{2} .
$$

Using Equation (2.108), we have

$$
\sqrt{H^{*}}=\frac{Q^{*}}{\rho \sqrt{2 g} A_{2}},
$$

so that

$$
\left.\frac{\partial f}{\partial H}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=-\frac{A_{2}^{2}}{A_{1}} \frac{g \rho}{Q^{*}} .
$$

It follows from Equation (2.109) that

$$
\dot{H}(t)=\Delta \dot{H}(t),
$$

since $H^{*}$ is constant. Also, the term $f\left(H^{*}, Q^{*}\right)$ is identically zero, by definition of the equilibrium condition. Neglecting the higher order terms in the Taylor series expansion yields

$$
\Delta \dot{H}(t)=-\frac{A_{2}^{2}}{A_{1}} \frac{g \rho}{Q^{*}} \Delta H(t)+\frac{1}{\rho A_{1}} \Delta Q_{1}(t) .
$$

Equation (2.111) is a linear model describing the deviation in water level $\Delta H(t)$ from the steady state due to a deviation from the nominal input mass flow rate $\Delta Q_{1}(t)$.

Similarly, for the output variable $Q_{2}(t)$ we have

$$
\begin{aligned}
Q_{2}(t) & =Q_{2}^{*}+\Delta Q_{2}(t)=h\left(H(t), Q_{1}(t)\right) \\
\approx & h\left(H^{*}, Q^{*}\right)+\left.\frac{\partial h}{\partial H}\right|_{\substack{H=H^{*} \\
Q 1=Q^{*}}} \Delta H(t)+\left.\frac{\partial h}{\partial Q_{1}}\right|_{\substack{H=H^{*} \\
Q 1=Q^{*}}} \Delta Q_{1}(t),
\end{aligned}
$$

where $\Delta Q_{2}(t)$ is a small deviation in the output mass flow rate and

$$
\left.\frac{\partial h}{\partial H}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=\frac{g \rho^{2} A_{2}^{2}}{Q^{*}},
$$

and

$$
\left.\frac{\partial h}{\partial Q_{1}}\right|_{\substack{H=H^{*} \\ Q 1=Q^{*}}}=0 .
$$

Therefore, the linearized equation for the output variable $Q_{2}(t)$ is

$$
\Delta Q_{2}(t)=\frac{g \rho^{2} A_{2}^{2}}{Q^{*}} \Delta H(t) .
$$

For control system design and analysis, it is convenient to obtain the input-output relationship in the form of a transfer function. The tool to accomplish this is the Laplace transform. Taking the time-derivative of Equation (2.113) and substituting into Equation (2.111) yields the input-output relationship

$$
\Delta \dot{Q}_{2}(t)+\frac{A_{2}^{2}}{A_{1}} \frac{g \rho}{Q^{*}} \Delta Q_{2}(t)=\frac{A_{2}^{2} g \rho}{A_{1} Q^{*}} \Delta Q_{1}(t) .
$$

If we define

$$
\Omega:=\frac{A_{2}^{2}}{A_{1}} \frac{g \rho}{Q^{*}}
$$

then we have

$$
\Delta \dot{Q}_{2}(t)+\Omega \Delta Q_{2}(t)=\Omega \Delta Q_{1}(t)
$$

Taking the Laplace transform (with zero initial conditions) yields the transfer function

$$
\Delta Q_{2}(s) / \Delta Q_{1}(s)=\frac{\Omega}{s+\Omega} .
$$

Equation (2.116) describes the relationship between the change in the output mass flow rate $\Delta Q_{2}(s)$ due to a change in the input mass flow rate $\Delta Q_{1}(s)$. We can also obtain a transfer function relationship between the change in the input mass flow rate and the change in the water level in the tank, $\Delta H(s)$. Taking the Laplace transform (with zero initial conditions) of Eq. (2.111) yields

$$
\Delta H(s) / \Delta Q_{1}(s)=\frac{k_{2}}{s+\Omega} .
$$

Given the linear time-invariant model of the water tank system in Equation (2.115), we can obtain solutions for step and sinusoidal inputs. Remember that our input $\Delta Q_{1}(s)$ is actually a change in the input mass flow rate from the steady-state value $Q^{*}$.

Consider the step input

$$
\Delta Q_{1}(s)=q_{o} / s
$$

where $q_{o}$ is the magnitude of the step input, and the initial condition is $\Delta Q_{2}(0)=0$. Then we can use the transfer function form given in Eq. (2.116) to obtain

$$
\Delta Q_{2}(s)=\frac{q_{o} \Omega}{s(s+\Omega)} .
$$

The partial fraction expansion yields

$$
\Delta Q_{2}(s)=\frac{-q_{o}}{s+\Omega}+\frac{q_{o}}{s} .
$$

Taking the inverse Laplace transform yields

$$
\Delta Q_{2}(t)=-q_{o} e^{-\Omega t}+q_{o} .
$$

Note that $\Omega>0$ (see Equation (2.114)), so the term $e^{-\Omega t}$ approaches zero as $t$ approaches $\infty$. Therefore, the steady-state output due to the step input of magnitude $q_{o}$ is

$$
\Delta Q_{2_{\mathrm{ss}}}=q_{o} .
$$

We see that in the steady state, the deviation of the output mass flow rate from the equilibrium value is equal to the deviation of the input mass flow rate from the equilibrium value. By examining the variable $\Omega$ in Equation (2.114), we find that the larger the output port opening $A_{2}$, the faster the system reaches steady state. In other words, as $\Omega$ gets larger, the exponential term $e^{-\Omega t}$ vanishes more quickly, and steady state is reached faster.

Similarly for the water level we have

$$
\Delta H(s)=\frac{-q_{o} k_{2}}{\Omega}\left(\frac{1}{s+\Omega}-\frac{1}{s}\right) .
$$

Taking the inverse Laplace transform yields

$$
\Delta H(t)=\frac{-q_{o} k_{2}}{\Omega}\left(e^{-\Omega t}-1\right) .
$$

The steady-state change in water level due to the step input of magnitude $q_{o}$ is

$$
\Delta H_{\mathrm{ss}}=\frac{q_{o} k_{2}}{\Omega} .
$$

Consider the sinusoidal input

$$
\Delta Q_{1}(t)=q_{o} \sin \omega t
$$

which has Laplace transform

$$
\Delta Q_{1}(s)=\frac{q_{o} \omega}{s^{2}+\omega^{2}} .
$$

Suppose the system has zero initial conditions, that is, $\Delta Q_{2}(0)=0$. Then from Equation (2.116) we have

$$
\Delta Q_{2}(s)=\frac{q_{o} \omega \Omega}{(s+\Omega)\left(s^{2}+\omega^{2}\right)} .
$$

Expanding in a partial fraction expansion and taking the inverse Laplace transform yields

$$
\Delta Q_{2}(t)=q_{o} \Omega \omega\left(\frac{e^{-\Omega t}}{\Omega^{2}+\omega^{2}}+\frac{\sin (\omega t-\phi)}{\omega\left(\Omega^{2}+\omega^{2}\right)^{1 / 2}}\right),
$$

where $\phi=\tan ^{-1}(\omega / \Omega)$. So, as $t \rightarrow \infty$, we have

$$
\Delta Q_{2}(t) \rightarrow \frac{q_{o} \Omega}{\sqrt{\Omega^{2}+\omega^{2}}} \sin (\omega t-\phi) .
$$

The maximum change in output flow rate is

$$
\left|\Delta Q_{2}(t)\right|_{\max }=\frac{q_{o} \Omega}{\sqrt{\Omega^{2}+\omega^{2}}} .
$$

The above analytic analysis of the linear system model to step and sinusoidal inputs is a valuable way to gain insight into the system response to test signals. Analytic analysis is limited, however, in the sense that a more complete representation can be obtained with carefully constructed numerical investigations using computer simulations of both the linear and nonlinear mathematical models. A computer simulation uses a model and the actual conditions of the system being modeled, as well as actual input commands to which the system will be subjected.

Various levels of simulation fidelity (that is, accuracy) are available to the control engineer. In the early stages of the design process, highly interactive design software packages are effective. At this stage, computer speed is not as important as the time it takes to obtain an initial valid solution and to iterate and fine tune that solution. Good graphics output capability is crucial. The analysis simulations are generally low fidelity in the sense that many of the simplifications (such as linearization) made in the design process are retained in the simulation.

As the design matures usually it is necessary to conduct numerical experiments in a more realistic simulation environment. At this point in the design process, the computer processing speed becomes more important, since long simulation times necessarily reduce the number of computer experiments that can be obtained and correspondingly raise costs. Usually these high-fidelity simulations are programmed in FORTRAN, C, C++, MATLAB, LabVIEW or similar languages.

Assuming that a model and the simulation are reliably accurate, computer simulation has the following advantages [13]:

1. System performance can be observed under all conceivable conditions.

2. Results of field-system performance can be extrapolated with a simulation model for prediction purposes.

3. Decisions concerning future systems presently in a conceptual stage can be examined.

4. Trials of systems under test can be accomplished in a much-reduced period of time.

5. Simulation results can be obtained at lower cost than real experimentation.

6. Study of hypothetical situations can be achieved even when the hypothetical situation would be unrealizable at present.

7. Computer modeling and simulation is often the only feasible or safe technique to analyze and evaluate a system.

The nonlinear model describing the water level flow rate is as follows (using the constants given in Table 2.6):

$$
\begin{aligned}
\dot{H}(t) & =-0.0443 \sqrt{H(t)}+1.2732 \times 10^{-3} Q_{1}(t), \\
Q_{2}(t) & =34.77 \sqrt{H(t)} .
\end{aligned}
$$

FIGURE 2.39

The tank water level time history obtained by integrating the nonlinear equations of motion in Equation (2.119) with $H(0)=0.5 \mathrm{~m}$ and $Q_{1}(t)=Q^{*}=34.77 \mathrm{~kg} / \mathrm{s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0131.jpg?height=819&width=1061&top_left_y=155&top_left_x=373)

With $H(0)=0.5 \mathrm{~m}$ and $Q_{1}(t)=34.77 \mathrm{~kg} / \mathrm{s}$, we can numerically integrate the nonlinear model given by Equation (2.119) to obtain the time history of $H(t)$. and $Q_{2}(t)$. The response of the system is shown in Figure 2.39. As expected from Equation (2.108), the system steady-state water level is $H^{*}=1 \mathrm{~m}$ when $Q^{*}=34.77 \mathrm{~kg} / \mathrm{m}^{3}$.

It takes about 250 seconds to reach steady-state. Suppose that the system is at steady state and we want to evaluate the response to a step change in the input mass flow rate. Consider

$$
\Delta Q_{1}(t)=1 \mathrm{~kg} / \mathrm{s} .
$$

Then we can use the transfer function model to obtain the unit step response. The step response is shown in Figure 2.40 for both the linear and nonlinear models. Using the linear model, we find that the steady-state change in water level is $\Delta H=5.75 \mathrm{~cm}$. Using the nonlinear model, we find that the steady-state change in water level is $\Delta H=5.84 \mathrm{~cm}$. So we see a small difference in the results obtained from the linear model and the more accurate nonlinear model.

As the final step, we consider the system response to a sinusoidal change in the input flow rate. Let

$$
\Delta Q_{1}(s)=\frac{q_{o} \omega}{s^{2}+\omega^{2}},
$$

where $\omega=0.05 \mathrm{rad} / \mathrm{s}$ and $q_{o}=1$. The total water input flow rate is

$$
Q_{1}(t)=Q^{*}+\Delta Q_{1}(t),
$$

where $Q^{*}=34.77 \mathrm{~kg} / \mathrm{s}$. The output flow rate is shown in Figure 2.41 . FIGURE 2.40

The response showing the linear versus nonlinear response to a step input.

FIGURE 2.41

The output flow rate response to a sinusoidal variation in the input flow.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0132.jpg?height=1676&width=1066&top_left_y=154&top_left_x=518)

The response of the water level is shown in Figure 2.42. The water level is sinusoidal, with an average value of $H_{\mathrm{av}}=H^{*}=1 \mathrm{~m}$. As shown in Equation (2.118), the output flow rate is sinusoidal in the steady state, with

$$
\left|\Delta Q_{2}(t)\right|_{\max }=\frac{q_{o} \Omega}{\sqrt{\Omega^{2}+\omega^{2}}}=0.4 \mathrm{~kg} / \mathrm{s} .
$$

FIGURE 2.42 The water level response to a sinusoidal variation in the input flow.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0133.jpg?height=821&width=1073&top_left_y=154&top_left_x=374)

Thus in the steady state (see Figure 2.41) we expect that the output flow rate will oscillate at a frequency of $\omega=0.05 \mathrm{rad} / \mathrm{s}$, with a maximum value of

$$
Q_{2_{\max }}=Q^{*}+\left|\Delta Q_{2}(t)\right|_{\max }=35.18 \mathrm{~kg} / \mathrm{s}
$$

\section{EXAMPLE 2.13 Electric traction motor control}

The electric motor drive is shown in block diagram form in Figure 2.43(a), incorporating the necessary control. The goal of the design is to obtain a system model and the closed-loop transfer function of the system, $\omega(s) / \omega_{d}(s)$, select appropriate resistors $R_{1}, R_{2}, R_{3}$, and $R_{4}$, and then predict the system response.

The first step is to describe the transfer function of each block. We propose the use of a tachometer to generate a voltage proportional to velocity and to connect that voltage, $v_{t}$, to one input of a difference amplifier, as shown in Figure 2.43(b). The power amplifier is nonlinear and can be approximately represented by $v_{2}(t)=2 e^{3} v_{1}(t)=g\left(v_{1}\right)$, an exponential function with a normal operating point, $v_{10}=1.5 \mathrm{~V}$. We then obtain a linear model

$$
\Delta v_{2}(t)=\left.\frac{d g\left(v_{1}\right)}{d v_{1}}\right|_{v_{10}} \Delta v_{1}(t)=6 e^{3 v_{10}} \Delta v_{1}(t)=540 \Delta v_{1}(t) .
$$

Taking the Laplace transform, yields

$$
\Delta V_{2}(s)=540 \Delta V_{1}(s) .
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0134.jpg?height=238&width=1188&top_left_y=163&top_left_x=523)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0134.jpg?height=396&width=1245&top_left_y=505&top_left_x=490)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0134.jpg?height=289&width=1246&top_left_y=1003&top_left_x=506)

(c)

FIGURE 2.43

Speed control of an electric traction motor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0134.jpg?height=200&width=1245&top_left_y=1398&top_left_x=502)

(d)

Also, for the differential amplifier, we have

$$
v_{1}=\frac{1+R_{2} / R_{1}}{1+R_{3} / R_{4}} v_{\text {in }}-\frac{R_{2}}{R_{1}} v_{t} .
$$

We wish to obtain an input control that sets $\omega_{d}(t)=v_{\text {in }}$, where the units of $\omega_{d}$ are $\mathrm{rad} / \mathrm{s}$ and the units of $v_{\text {in }}$ are volts. Then, when $v_{\text {in }}=10 \mathrm{~V}$, the steady-state speed is $\omega=10 \mathrm{rad} / \mathrm{s}$. We note that $v_{t}=K_{t} \omega_{d}$ in steady state, and we expect, in balance, the steady-state output to be

$$
v_{1}=\frac{1+R_{2} / R_{1}}{1+R_{3} / R_{4}} v_{\text {in }}-\frac{R_{2}}{R_{1}} K_{t} v_{\text {in }} .
$$



\section{Table 2.7 Parameters of a Large DC Motor}
$K_{m}=10$
$J=2$
$R_{a}=1$
$b=0.5$
$L_{a}=1$
$K_{b}=0.1$

When the system is in balance, $v_{1}=0$, and when $K_{t}=0.1$, we have

$$
\frac{1+R_{2} / R_{1}}{1+R_{3} / R_{4}}=\frac{R_{2}}{R_{1}} K_{t} .
$$

This relation can be achieved when

$$
R_{2} / R_{1}=10 \text { and } R_{3} / R_{4}=10 .
$$

The parameters of the motor and load are given in Table 2.7. The overall system is shown in Figure 2.43(b). Reducing the block diagram in Figure 2.43(c) or the signal-flow graph in Figure 2.43(d) yields the transfer function

$$
\begin{aligned}
\frac{\omega(s)}{\omega_{d}(s)} & =\frac{540 G_{1}(s) G_{2}(s)}{1+0.1 G_{1}(s) G_{2}(s)+540 G_{1}(s) G_{2}(s)}=\frac{540 G_{1}(s) G_{2}(s)}{1+540.1 G_{1}(s) G_{2}(s)} \\
& =\frac{5400}{(s+1)(2 s+0.5)+5401}=\frac{5400}{2 s^{2}+2.5 s+5401.5} \\
& =\frac{2700}{s^{2}+1.25 s+2700.75} .
\end{aligned}
$$

Since the characteristic equation is second order, we note that $\omega_{n}=52$ and $\zeta=0.012$, and we expect the response of the system to be highly oscillatory (underdamped).

\section{EXAMPLE 2.14 Design of a low-pass filter}

Our goal is to design a first-order low-pass filter that passes signals at a frequency below $106.1 \mathrm{~Hz}$ and attenuates signals with a frequency above $106.1 \mathrm{~Hz}$. In addition, the DC gain should be $1 / 2$.

A ladder network with one energy storage element, as shown in Figure 2.44(a), will act as a first-order low-pass network. Note that the DC gain will be equal to $1 / 2$ (open-circuit the capacitor). The current and voltage equations are

$$
\begin{aligned}
& I_{1}=\left(V_{1}-V_{2}\right) G, \\
& I_{2}=\left(V_{2}-V_{3}\right) G, \\
& V_{2}=\left(I_{1}-I_{2}\right) R, \\
& V_{3}=I_{2} Z,
\end{aligned}
$$

where $G=1 / R$ and $Z(s)=1 / C s$. The signal-flow graph constructed for the four equations is shown in Figure 2.44(b), and the corresponding block diagram is shown in Figure 2.44(c). The three loops are $L_{1}(s)=-G R=-1, L_{2}(s)=-G R=-1$, and 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0136.jpg?height=207&width=546&top_left_y=162&top_left_x=844)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0136.jpg?height=336&width=1282&top_left_y=467&top_left_x=469)

(b)

FIGURE 2.44

(a) Ladder network, (b) its signal-flow graph, and (c) its block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0136.jpg?height=266&width=1171&top_left_y=902&top_left_x=527)

(c)

$L_{3}(s)=-G Z(s)$. All loops touch the forward path. Loops $L_{1}(s)$ and $L_{3}(s)$ are nontouching. Therefore, the transfer function is

$$
\begin{aligned}
T(s)=\frac{V_{3}(s)}{V_{1}(s)} & =\frac{P_{1}(s)}{1-\left(L_{1}(s)+L_{2}(s)+L_{3}(s)\right)+L_{1}(s) L_{3}(s)}=\frac{G Z(s)}{3+2 G Z(s)} \\
& =\frac{1}{3 R C s+2}=\frac{1 /(3 R C)}{s+2 /(3 R C)} .
\end{aligned}
$$

If one prefers to utilize block diagram reduction techniques, one can start at the output with

$$
V_{3}(s)=Z(s) I_{2}(s) .
$$

But the block diagram shows that

$$
I_{2}(s)=G\left(V_{2}(s)-V_{3}(s)\right) .
$$

Therefore,

$$
V_{3}(s)=Z(s) G V_{2}(s)-Z(s) G V_{3}(s)
$$

SO

$$
V_{2}(s)=\frac{1+Z(s) G}{Z(s) G} V_{3}(s) .
$$

We will use this relationship between $V_{3}(s)$ and $V_{2}(s)$ in the subsequent development. Continuing with the block diagram reduction, we have

$$
V_{3}(s)=-Z(s) G V_{3}(s)+Z(s) G R\left(I_{1}(s)-I_{2}(s)\right),
$$

but from the block diagram, we see that

Therefore,

$$
I_{1}(s)=G\left(V_{1}(s)-V_{2}(s)\right), \quad I_{2}(s)=\frac{V_{3}(s)}{Z(s)} .
$$

$$
V_{3}(s)=-Z(s) G V_{3}(s)+Z(s) G^{2} R\left(V_{1}(s)-V_{2}(s)\right)-G R V_{3}(s)
$$

Substituting for $V_{2}(s)$ yields

$$
V_{3}(s)=\frac{(G R)(G Z(s))}{1+2 G R+G Z(s)+(G R)(G Z(s))} V_{1}(s) .
$$

But we know that $G R=1$; hence, we obtain

$$
V_{3}(s)=\frac{G Z(s)}{3+2 G Z(s)} V_{1}(s)=\frac{1 /(3 R C)}{s+2 /(3 R C)} .
$$

Note that the DC gain is $1 / 2$ as expected. The pole is desired at $p=2 \pi(106.1)=666.7=2000 / 3$. Therefore, we require $R C=0.001$. Select $R=1 \mathrm{k} \Omega$ and $C=1 \mu \mathrm{F}$. Hence, we achieve the filter

$$
T(s)=\frac{333.3}{s+666.7}
$$

\subsection{THE SIMULATION OF SYSTEMS USING CONTROL DESIGN SOFTWARE}

Application of the many classical and modern control system design and analysis tools is based on mathematical models. Most popular control design software packages can be used with systems given in the form of transfer function descriptions. In this book, we will focus on m-file scripts containing commands and functions to analyze and design control systems. Various commercial control system packages are available for student use. The m-files described here are compatible with the MATLAB ${ }^{\dagger}$ Control System Toolbox and the LabVIEW MathScript RT Module.

${ }^{\dagger}$ See Appendix A for an introduction to MATLAB.

${ }^{\ddagger}$ See Appendix B for an introduction to LabVIEW MathScipt RT Module. We begin this section by analyzing a typical spring-mass-damper mathematical model of a mechanical system. Using an m-file script, we will develop an interactive analysis capability to analyze the effects of natural frequency and damping on the unforced response of the mass displacement. This analysis will use the fact that we have an analytic solution that describes the unforced time response of the mass displacement.

Later, we will discuss transfer functions and block diagrams. In particular, we are interested in manipulating polynomials, computing poles and zeros of transfer functions, computing closed-loop transfer functions, computing block diagram reductions, and computing the response of a system to a unit step input. The section concludes with the electric traction motor control design of Example 2.13.

The functions covered in this section are roots, poly, conv, polyval, tf, pzmap, pole, zero, series, parallel, feedback, minreal, and step.

A spring-mass-damper mechanical system is shown in Figure 2.2. The motion of the mass, denoted by $y(t)$, is described by the differential equation

$$
M \dot{y}(t)+b \dot{y}(t)+k y(t)=r(t) .
$$

The unforced dynamic response $y(t)$ of the spring-mass-damper mechanical system is

$$
y(t)=\frac{y(0)}{\sqrt{1-\zeta^{2}}} e^{-\zeta \omega_{n} t} \sin \left(\omega_{n} \sqrt{1-\zeta^{2}} t+\theta\right)
$$

where $\omega_{n}=\sqrt{k / M}, \zeta=b /(2 \sqrt{k M})$, and $\theta=\cos ^{-1} \zeta$. The initial displacement is $y(0)$. The transient system response is underdamped when $\zeta<1$, overdamped when $\zeta>1$, and critically damped when $\zeta=1$. We can visualize the unforced time response of the mass displacement following an initial displacement of $y(0)$. Consider the underdamped case:

$$
\square y(0)=0.15 \mathrm{~m}, \quad \omega_{n}=\sqrt{2} \frac{\mathrm{rad}}{\mathrm{s}}, \quad \zeta=\frac{1}{2 \sqrt{2}} \quad\left(\frac{k}{M}=2, \frac{b}{M}=1\right) .
$$

The commands to generate the plot of the unforced response are shown in Figure 2.45. In the setup, the variables $y(0), \omega_{n}, t$, and $\zeta$ are input at the command level. Then the script unforced.m is executed to generate the desired plots. This creates an interactive analysis capability to analyze the effects of natural frequency and damping on the unforced response of the mass displacement. One can investigate the effects of the natural frequency and the damping on the time response by simply entering new values of $\omega_{n}$ and $\zeta$ at the command prompt and running the script unforced.m again. The time-response plot is shown in Figure 2.46. Notice that the script automatically labels the plot with the values of the damping coefficient and natural frequency. This avoids confusion when making many interactive simulations. Using scripts is an important aspect of developing an effective interactive design and analysis capability.

For the spring-mass-damper problem, the unforced solution to the differential equation was readily available. In general, when simulating closed-loop feedback FIGURE 2.45

Script to analyze the spring-massdamper.
FIGURE 2.46

Spring-massdamper unforced response.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0139.jpg?height=1540&width=1234&top_left_y=166&top_left_x=370)

control systems subject to a variety of inputs and initial conditions, it is difficult to obtain the solution analytically. In these cases, we can compute the solutions numerically and to display the solution graphically.

Most systems considered in this book can be described by transfer functions. Since the transfer function is a ratio of polynomials, we begin by investigating how to manipulate polynomials, remembering that working with transfer functions means that both a numerator polynomial and a denominator polynomial must be specified. FIGURE 2.47

Entering the polynomial $p(s)=s^{3}+3 s^{2}+4$ and calculating its roots.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0140.jpg?height=522&width=931&top_left_y=153&top_left_x=520)

Polynomials are represented by row vectors containing the polynomial coefficients in order of descending degree. For example, the polynomial

$$
p(s)=s^{3}+3 s^{2}+4
$$

is entered as shown in Figure 2.47. Notice that even though the coefficient of the $s$ term is zero, it is included in the input definition of $p(s)$.

If $\mathbf{p}$ is a row vector containing the coefficients of $p(s)$ in descending degree, then $\operatorname{roots}(\mathbf{p})$ is a column vector containing the roots of the polynomial. Conversely, if $\mathbf{r}$ is a column vector containing the roots of the polynomial, then $\operatorname{poly}(\mathbf{r})$ is a row vector with the polynomial coefficients in descending degree. We can compute the roots of the polynomial $p(s)=s^{3}+3 s^{2}+4$ with the roots function as shown in Figure 2.47. In this figure, we show how to reassemble the polynomial with the poly function.

Multiplication of polynomials is accomplished with the conv function. Suppose we want to expand the polynomial

$$
n(s)=\left(3 s^{2}+2 s+1\right)(s+4) .
$$

The associated commands using the conv function are shown in Figure 2.48. Thus, the expanded polynomial is

$$
n(s)=3 s^{3}+14 s^{2}+9 s+4
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0140.jpg?height=326&width=860&top_left_y=1769&top_left_x=536)

FIGURE 2.48

Using conv and polyval to multiply and evaluate the polynomials $\left(3 s^{2}+2 s+1\right)$ $(s+4)$. FIGURE 2.49

(a) The tf function.

(b) Using the tf function to create transfer function objects and adding them using the $t f$ operator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0141.jpg?height=776&width=473&top_left_y=165&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0141.jpg?height=769&width=585&top_left_y=166&top_left_x=860)

(b)

The function polyval is used to evaluate the value of a polynomial at the given value of the variable. The polynomial $n(s)$ has the value $n(-5)=-66$, as shown in Figure 2.48 .

Linear, time-invariant system models can be treated as objects, allowing one to manipulate the system models as single entities. In the case of transfer functions, one creates the system models using the tf function; for state variable models one employs the ss function. The use of tf is illustrated in Figure 2.49(a). For example, consider the two system models

$$
G_{1}(s)=\frac{10}{s^{2}+2 s+5} \text { and } G_{2}(s)=\frac{1}{s+1} .
$$

The systems $G_{1}(s)$ and $G_{2}(s)$ can be added using the "+" operator yielding

$$
G(s)=G_{1}(s)+G_{2}(s)=\frac{s^{2}+12 s+15}{s^{3}+3 s^{2}+7 s+5} .
$$

The corresponding commands are shown in Figure 2.49(b) where sys 1 represents $G_{1}(s)$ and sys2 represents $G_{2}(s)$. Computing the poles and zeros associated with a transfer function is accomplished by operating on the system model object with the pole and zero functions, respectively, as illustrated in Figure 2.50.

In the next example, we obtain a plot of the pole-zero locations in the complex plane. This will be accomplished using the pzmap function, shown in Figure 2.51. On the pole-zero map, zeros are denoted by an "o" and poles are denoted by an " $\times$ " If the pzmap function is invoked without left-hand arguments, the plot is generated automatically. FIGURE 2.50

(a) The pole and zero functions.

(b) Using the pole and zero functions to compute the pole and zero locations of a linear system.

FIGURE 2.51

The pzmap function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0142.jpg?height=790&width=456&top_left_y=165&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0142.jpg?height=772&width=529&top_left_y=169&top_left_x=1010)

(b)

\section{EXAMPLE 2.15 Transfer functions}

Consider the transfer functions

$$
G(s)=\frac{6 s^{2}+1}{s^{3}+3 s^{2}+3 s+1} \quad \text { and } \quad H(s)=\frac{(s+1)(s+2)}{(s+2 i)(s-2 i)(s+3)} .
$$

Using an m-file script, we can compute the poles and zeros of $G(s)$, the characteristic equation of $H(s)$, and divide $G(s)$ by $H(s)$. We can also obtain a plot of the pole-zero map of $G(s) / H(s)$ in the complex plane.

The pole-zero map of the transfer function $G(s) / H(s)$ is shown in Figure 2.52, and the associated commands are shown in Figure 2.53. The pole-zero map shows clearly the five zero locations, but it appears that there are only two poles. FIGURE 2.52

Pole-zero map for $G(s) / H(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0143.jpg?height=611&width=927&top_left_y=153&top_left_x=374)

$>>$ numg=[ $\left.\begin{array}{lll}6 & 0 & 1\end{array}\right]$; deng=[ $\left.\begin{array}{llll}1 & 3 & 3 & 1\end{array}\right] ;$ sysg=tf(numg,deng); >>z=zero(sysg)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0143.jpg?height=929&width=891&top_left_y=928&top_left_x=387)

This cannot be the case, since we know that for physical systems the number of poles must be greater than or equal to the number of zeros. Using the roots function, we can ascertain that there are in fact four poles at $s=-1$. Hence, multiple poles or multiple zeros at the same location cannot be discerned on the pole-zero map. FIGURE 2.54

Open-loop control system (without feedback).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0144.jpg?height=165&width=666&top_left_y=153&top_left_x=523)

Suppose we have developed mathematical models in the form of transfer functions for a process, represented by $G(s)$, and a controller, represented by $G_{c}(s)$, and possibly many other system components such as sensors and actuators. Our objective is to interconnect these components to form a control system.

A simple open-loop control system can be obtained by interconnecting a process and a controller in series as illustrated in Figure 2.54. We can compute the transfer function from $R(s)$ to $Y(s)$, as follows.

\section{EXAMPLE 2.16 Series connection}

Let the process represented by the transfer function $G(s)$ be

$$
G(s)=\frac{1}{500 s^{2}},
$$

and let the controller represented by the transfer function $G_{c}(s)$ be

$$
G_{c}(s)=\frac{s+1}{s+2}
$$

We can use the series function to cascade two transfer functions $G_{1}(s)$ and $G_{2}(s)$, as shown in Figure 2.55.

The transfer function $G_{c}(s) G(s)$ is computed using the series function as shown in Figure 2.56. The resulting transfer function is

$$
G_{c}(s) G(s)=\frac{s+1}{500 s^{3}+1000 s^{2}}=\text { sys, }
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0144.jpg?height=151&width=809&top_left_y=1479&top_left_x=583)

FIGURE 2.55

(a) Block diagram.

(b) The series function. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0144.jpg?height=343&width=929&top_left_y=1729&top_left_x=523)

(b) FIGURE 2.56

Application of the series function.

FIGURE 2.57

(a) Block diagram. (b) The parallel function.

FIGURE 2.58

A basic control system with unity feedback.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0145.jpg?height=94&width=774&top_left_y=153&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0145.jpg?height=203&width=638&top_left_y=365&top_left_x=442)

Transfer function:

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0145.jpg?height=250&width=799&top_left_y=750&top_left_x=426)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0145.jpg?height=275&width=877&top_left_y=1114&top_left_x=387)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0145.jpg?height=237&width=887&top_left_y=1476&top_left_x=375)

where sys is the transfer function name in the m-file script.

Block diagrams quite often have transfer functions in parallel. In such cases, the function parallel can be quite useful. The parallel function is described in Figure 2.57.

We can introduce a feedback signal into the control system by closing the loop with unity feedback, as shown in Figure 2.58. The signal $E_{a}(s)$ is an error signal; the signal $R(s)$ is a reference input. In this control system, the controller is in the forward path, and the closed-loop transfer function is

$$
T(s)=\frac{G_{c}(s) G(s)}{1 \mp G_{c}(s) G(s)} .
$$

FIGURE 2.59

(a) Block diagram.

(b) The feedback function with unity feedback.
FIGURE 2.60

(a) Block diagram.

(b) The feedback function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0146.jpg?height=132&width=626&top_left_y=167&top_left_x=731)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0146.jpg?height=308&width=1056&top_left_y=401&top_left_x=521)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0146.jpg?height=238&width=659&top_left_y=869&top_left_x=731)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0146.jpg?height=323&width=1070&top_left_y=1212&top_left_x=526)

(b)

We can utilize the feedback function to aid in the block diagram reduction process to compute closed-loop transfer functions for single- and multiple-loop control systems.

It is often the case that the closed-loop control system has unity feedback, as illustrated in Figure 2.58. We can use the feedback function to compute the closedloop transfer function by setting $H(s)=1$. The use of the feedback function for unity feedback is depicted in Figure 2.59.

The feedback function is shown in Figure 2.60 with the associated system configuration, which includes $H(s)$ in the feedback path. If the input "sign" is omitted, then negative feedback is assumed. FIGURE 2.61

(a) Block diagram. (b) Application of the feedback function.

FIGURE 2.62

A basic control system with the controller in the feedback loop.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0147.jpg?height=160&width=908&top_left_y=155&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0147.jpg?height=311&width=809&top_left_y=432&top_left_x=421)

Transfer function:

$$
\frac{\mathrm{s}+1}{500 \mathrm{~s}^{\wedge} 3+1000 \mathrm{~s}^{\wedge} 2+\mathrm{s}+1} \longleftarrow \frac{Y(s)}{R(s)}=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}
$$

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0147.jpg?height=238&width=680&top_left_y=944&top_left_x=375)

\section{EXAMPLE 2.17 The feedback function with unity feedback}

Let the process, $G(s)$, and the controller, $G_{c}(s)$, be as in Figure 2.61(a). To apply the feedback function, we first use the series function to compute $G_{c}(s) G(s)$, followed by the feedback function to close the loop. The command sequence is shown in Figure 2.61(b). The closed-loop transfer function, as shown in Figure 2.61(b), is

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}=\frac{s+1}{500 s^{3}+1000 s^{2}+s+1}=\text { sys. }
$$

Another basic feedback control configuration is shown in Figure 2.62. In this case, the controller is located in the feedback path. The closed-loop transfer function is

$$
T(s)=\frac{G(s)}{1 \mp G(s) H(s)} .
$$

\section{EXAMPLE 2.18 The feedback function}

Let the process, $G(s)$, and the controller, $H(s)$, be as in Figure 2.63(a). To compute the closed-loop transfer function with the controller in the feedback loop, we use FIGURE 2.63

Application of the feedback function:

(a) block diagram,

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0148.jpg?height=228&width=796&top_left_y=161&top_left_x=522)

(a)

$>>$ numg=[1]; deng=[500 0 0]; sys $1=$ tf(numg,deng);

$>>$ numh=[1 1]; denh=[1 2]; sys2=tf(numh,denh);

$>>$ sys=feedback(sys 1 ,sys2);

>>sys

Transfer function:

$$
\frac{s+2}{500 s^{\wedge} 3+1000 s^{\wedge} 2+s+1} \longleftarrow \frac{Y(s)}{R(s)}=\frac{G(s)}{1+G(s) H(s)}
$$

(b)

the feedback function. The command sequence is shown in Figure 2.63(b). The closed-loop transfer function is

$$
T(s)=\frac{s+2}{500 s^{3}+1000 s^{2}+s+1}=\text { sys. }
$$

The functions series, parallel, and feedback can be used as aids in block diagram manipulations for multiple-loop block diagrams.

\section{EXAMPLE 2.19 Multiloop reduction}

A multiloop feedback system is shown in Figure 2.26. Our objective is to compute the closed-loop transfer function, $T(s)$, with

$$
\begin{aligned}
& G_{1}(s)=\frac{1}{s+10}, \quad G_{2}(s)=\frac{1}{s+1}, \\
& G_{3}(s)=\frac{s^{2}+1}{s^{2}+4 s+4}, \quad G_{4}(s)=\frac{s+1}{s+6}, \\
& H_{1}(s)=\frac{s+1}{s+2}, \quad H_{2}(s)=2, \quad \text { and } \quad H_{3}(s)=1 .
\end{aligned}
$$

For this example, a five-step procedure is followed:

$\square \quad$ Step 1. Input the system transfer functions.

$\square \quad$ Step 2. Move $H_{2}(s)$ behind $G_{4}(s)$.

$\square \quad$ Step 3. Eliminate the $G_{3}(s) G_{4}(s) H_{1}(s)$ loop.

$\square \quad$ Step 4. Eliminate the loop containing $\mathrm{H}_{2}(s)$.

$\square \quad$ Step 5. Eliminate the remaining loop and calculate $T(s)$. FIGURE 2.64 Multiple-loop block reduction.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0149.jpg?height=629&width=876&top_left_y=184&top_left_x=389)

The five steps are utilized in Figure 2.64, and the corresponding block diagram reduction is shown in Figure 2.27. The result of executing the commands is

$$
\text { sys }=\frac{s^{5}+4 s^{4}+6 s^{3}+6 s^{2}+5 s+2}{12 s^{6}+205 s^{5}+1066 s^{4}+2517 s^{3}+3128 s^{2}+2196 s+712} .
$$

We must be careful in calling this the closed-loop transfer function. The transfer function is defined as the input-output relationship after pole-zero cancellations. If we compute the poles and zeros of $T(s)$, we find that the numerator and denominator polynomials have $(s+1)$ as a common factor. This must be canceled before we can claim we have the closed-loop transfer function. To assist us in the polezero cancellation, we will use the minreal function. The minreal function, shown in Figure 2.65, removes common pole-zero factors of a transfer function. The final step in the block reduction process is to cancel out the common factors, as shown in Figure 2.66. After the application of the minreal function, we find that the order of the denominator polynomial has been reduced from six to five, implying one polezero cancellation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0149.jpg?height=310&width=774&top_left_y=1797&top_left_x=373)

FIGURE 2.65 function. FIGURE 2.66 Application of the minreal function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0150.jpg?height=250&width=777&top_left_y=184&top_left_x=538)

$>>$ num1=[10]; den1=[1 1]; sys1=tf(num1, den1);

$>>$ num2=[1]; den2=[2 0.5]; sys2=tf(num2,den2);

$>>$ num3=[540]; den3=[1]; sys3=tf(num3,den3);

$>$ num4=[0.1]; den4=[1]; sys4=tf(num4,den4);

$>$ sys5=series(sys 1 ,sys2);

>>sys6=feedback(sys5,sys4);

Eliminate

inner loop

>>sys7=series(sys3,sys6);

FIGURE 2.67

Electric traction motor block reduction. >>sys=feedback(sys7,[1])

Compute closed-loop transfer function

Transfer function:
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0150.jpg?height=294&width=776&top_left_y=848&top_left_x=549)

\section{EXAMPLE 2.20 Electric traction motor control}

Finally, let us reconsider the electric traction motor system from Example 2.13. The block diagram is shown in Figure 2.43(c). The objective is to compute the closedloop transfer function and investigate the response of $\omega(s)$ to a commanded $\omega_{d}(s)$. The first step, as shown in Figure 2.67, is to compute the closed-loop transfer function $\omega(s) / \omega_{d}(s)=T(s)$. The closed-loop characteristic equation is second order with $\omega_{n}=52$ and $\zeta=0.012$. Since the damping is low, we expect the response to be highly oscillatory. We can investigate the response $\omega(t)$ to a reference input, $\omega_{d}(t)$, by utilizing the step function. The step function, shown in Figure 2.68, calculates the unit step response of a linear system. The step function is very important, since control system performance specifications are often given in terms of the unit step response.

If the only objective is to plot the output, $y(t)$, we can use the step function without left-hand arguments and obtain the plot automatically with axis labels. If we need $y(t)$ for any purpose other than plotting, we must use the step function with left-hand arguments, followed by the plot function to plot $y(t)$. We define $t$ as a row vector containing the times at which we wish the value of the output variable $y(t)$. We can also select $t=t_{\text {final }}$, which results in a step response from $t=0$ to $t=t_{\text {final }}$ and the number of intermediate points are selected automatically. 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0151.jpg?height=138&width=958&top_left_y=160&top_left_x=412)

(a)

FIGURE 2.68

The step function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0151.jpg?height=374&width=1016&top_left_y=410&top_left_x=376)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0151.jpg?height=436&width=588&top_left_y=991&top_left_x=334)

(a)
$\%$ This script computes the step

$\%$ response of the traction motor

$\%$ wheel velocity

$\%$

num=[5400]; den=[2 2.5 5402]; sys=tf(num,den); $\mathrm{t}=[0: 0.005: 3]$

$[y, t]=\operatorname{step}($ sys,$t)$;

plot(t,y),grid

xlabel('Time (s)')

ylabel('Wheel velocity')

FIGURE 2.69 (a) Traction motor wheel velocity step response. (b) m-file script.

The step response of the electric traction motor is shown in Figure 2.69. As expected, the wheel velocity response, given by $y(t)$, is highly oscillatory. Note that the output is $y(t) \equiv \omega(t)$.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

Our goal for the disk drive system is to position the reader head accurately at the desired track and to move from one track to another. We need to identify the plant, the sensor, and the controller. The disk drive reader uses a permanent magnet FIGURE 2.70

Head mount for reader, showing flexure.
FIGURE 2.71

Block diagram model of disk drive read system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0152.jpg?height=874&width=1266&top_left_y=154&top_left_x=489)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0152.jpg?height=263&width=1177&top_left_y=1127&top_left_x=538)

(b)

DC motor to rotate the reader arm. The DC motor is called a voice coil motor. The read head is mounted on a slider device, which is connected to the arm as shown in Figure 2.70. A flexure (spring metal) is used to enable the head to float above the disk at a gap of less than $100 \mathrm{~nm}$. The thin-film head reads the magnetic flux and provides a signal to an amplifier. The error signal of Figure 2.71(a) is provided by reading the error from a prerecorded index track. Assuming an accurate read head, the sensor has a transfer function $H(s)=1$, as shown in Figure 2.71(b). The model of the permanent magnet DC motor and a linear amplifier is shown in Figure 2.71(b). As a good approximation, we use the model of the armature-controlled DC motor as shown earlier in Figure 2.20 with $K_{b}=0$. The model shown in Figure 2.71(b) assumes that the flexure is entirely rigid and does not significantly flex. In future control designs, we should consider the model when the flexure cannot be assumed to be completely rigid. Table 2.8 Typical Parameters for Disk Drive Reader

\begin{tabular}{lll} 
Parameter & Symbol & Typical Value \\
\hline Inertia of arm and read head & $J$ & $1 \mathrm{~N} \mathrm{~m} \mathrm{~s}^{2} / \mathrm{rad}$ \\
Friction & $b$ & $20 \mathrm{~N} \mathrm{~m} \mathrm{~s} / \mathrm{rad}$ \\
Amplifier & $K_{a}$ & $10-1000$ \\
Armature resistance & $R$ & $1 \Omega$ \\
Motor constant & $K_{m}$ & $5 \mathrm{~N} \mathrm{~m} / \mathrm{A}$ \\
Armature inductance & $L$ & $1 \mathrm{mH}$ \\
\hline
\end{tabular}

Typical parameters for the disk drive system are given in Table 2.8. Thus, we have

$$
G(s)=\frac{K_{m}}{s(J s+b)(L s+R)}=\frac{5000}{s(s+20)(s+1000)} .
$$

We can also write

$$
G(s)=\frac{K_{m} /(b R)}{s\left(\tau_{L} s+1\right)(\tau s+1)},
$$

where $\tau_{L}=J / b=50 \mathrm{~ms}$ and $\tau=L / R=1 \mathrm{~ms}$. Since $\tau \ll \tau_{L}$, we often neglect $\tau$. Then, we would have

$$
G(s) \approx \frac{K_{m} /(b R)}{s\left(\tau_{L} s+1\right)}=\frac{0.25}{s(0.05 s+1)}=\frac{5}{s(s+20)}
$$

The block diagram of the closed-loop system is shown in Figure 2.72. Using the block diagram transformation of Table 2.5, we have

$$
\frac{Y(s)}{R(s)}=\frac{K_{a} G(s)}{1+K_{a} G(s)} .
$$

Using the approximate second-order model for $G(s)$, we obtain

FIGURE 2.72

Block diagram of closed-loop system.

$$
\frac{Y(s)}{R(s)}=\frac{5 K_{a}}{s^{2}+20 s+5 K_{a}} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0153.jpg?height=243&width=1024&top_left_y=1880&top_left_x=372)

FIGURE 2.73

The system response of the system shown in Figure 2.72 for

$R(s)=\frac{0.1}{s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0154.jpg?height=611&width=779&top_left_y=153&top_left_x=523)

When $K_{a}=40$, we have

$$
Y(s)=\frac{200}{s^{2}+20 s+200} R(s)
$$

We obtain the step response for $R(s)=\frac{0.1}{s}$ rad, as shown in Figure 2.73.

\subsection{SUMMARY}

In this chapter, we have been concerned with quantitative mathematical models of control components and systems. The differential equations describing the dynamic performance of physical systems were utilized to construct a mathematical model. The physical systems under consideration can include a wide-range of mechanical, electrical, biomedical, environmental, aerospace, industrial, and chemical engineering systems. A linear approximation using a Taylor series expansion about the operating point was utilized to obtain a small-signal linear approximation for nonlinear control components. Then, with the approximation of a linear system, one may utilize the Laplace transformation and its related input-output relationship given by the transfer function. The transfer function approach to linear systems allows the analyst to determine the response of the system to various input signals in terms of the location of the poles and zeros of the transfer function. Using transfer function notations, block diagram models of systems of interconnected components were developed. The block relationships were obtained. Additionally, an alternative use of transfer function models in signal-flow graph form was investigated. Mason's signal-flow gain formula was presented and found to be useful for obtaining the relationship between system variables in a complex feedback system. The advantage of the signal-flow graph method was the availability of Mason's signal-flow gain formula, which provides the relationship between system variables without requiring any reduction or manipulation of the flow graph. Thus, we have obtained a useful mathematical model for feedback control systems by developing the concept of a transfer function of a linear system and the relationship among system variables using block diagram and signal-flow graph models. We considered the utility of the computer simulation of linear and nonlinear systems to determine the response of a system for several conditions of the system parameters and the environment. Finally, we continued the development of the Disk Drive Read System by obtaining a model in transfer function form of the motor and arm.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 2.74 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0155.jpg?height=400&width=1169&top_left_y=774&top_left_x=373)

FIGURE 2.74 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. Very few physical systems are linear within some range of the variables.

True or False

2. The $s$-plane plot of the poles and zeros graphically portrays the character of the natural response of a system.

True or False

3. The roots of the characteristic equation are the zeros of the closed-loop system.

True or False

4. A linear system satisfies the properties of superposition and homogeneity. True or False

5. The transfer function is the ratio of the Laplace transform of the output variable to the Laplace transform of the input variable, with all initial conditions equal to zero.

True or False

6. Consider the system in Figure 2.74 where

$$
G_{c}(s)=10, \quad H(s)=1, \quad \text { and } \quad G(s)=\frac{s+50}{s^{2}+60 s+500} .
$$

If the input $R(s)$ is a unit step input, $T_{d}(s)=0$, and $N(s)=0$, the final value of the output $y(t)$ is:
a. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=100$
b. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=1$
c. $y_{s s}=\lim y(t)=50$
d. None of the above 7. Consider the system in Figure 2.74 with

$$
G_{c}(s)=20, \quad H(s)=1, \quad \text { and } \quad G(s)=\frac{s+4}{s^{2}-12 s-65} .
$$

When all initial conditions are zero, the input $R(s)$ is an impulse, the disturbance $T_{d}(s)=0$, and the noise $N(s)=0$, the output $y(t)$ is
a. $y(t)=10 e^{-5 t}+10 e^{-3 t}$
b. $y(t)=e^{-8 t}+10 e^{-t}$
c. $y(t)=10 e^{-3 t}-10 e^{-5 t}$
d. $y(t)=20 e^{-8 t}+5 e^{-15 t}$

8. Consider a system represented by the block diagram in Figure 2.75 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0156.jpg?height=360&width=741&top_left_y=653&top_left_x=693)

FIGURE 2.75 Block diagram with an internal loop.

The closed-loop transfer function $T(s)=Y(s) / R(s)$ is
a. $T(s)=\frac{50}{s^{2}+55 s+50}$
b. $T(s)=\frac{10}{s^{2}+55 s+10}$
c. $T(s)=\frac{10}{s^{2}+50 s+55}$
d. None of the above

Consider the block diagram in Figure 2.74 for Problems 9 through 11 where

$$
\begin{gathered}
G_{c}(s)=4, \quad H(s)=1, \text { and } G(s)=\frac{5}{s^{2}+10 s+5} . \\
T_{d}(s)=0, \text { and } N(s)=0 .
\end{gathered}
$$

9. The closed-loop transfer function $T(s)=Y(s) / R(s)$ is:
a. $T(s)=\frac{50}{s^{2}+5 s+50}$
b. $T(s)=\frac{20}{s^{2}+10 s+25}$
c. $T(s)=\frac{50}{s^{2}+5 s+56}$
d. $T(s)=\frac{20}{s^{2}+10 s-15}$ 10. The closed-loop unit step response is:
a. $y(t)=\frac{20}{25}+\frac{20}{25} e^{-5 t}-t^{2} e^{-5 t}$
b. $y(t)=1+20 t e^{-5 t}$
c. $y(t)=\frac{20}{25}-\frac{20}{25} e^{-5 t}-4 t e^{-5 t}$
d. $y(t)=1-2 e^{-5 t}-4 t e^{-5 t}$

11. The final value of the unit step response $y(t)$ is:
a. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=0.8$
b. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=1.0$
c. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=2.0$
d. $y_{s s}=\lim _{t \rightarrow \infty} y(t)=1.25$

12. Consider the differential equation

$$
\ddot{y}(t)+2 \dot{y}(t)+y(t)=u(t)
$$

where $y(0)=\dot{y}(0)=0$. The poles of this system are:
a. $s_{1}=-1, s_{2}=-1$
b. $s_{1}=1 j, s_{2}=-1 j$
c. $s_{1}=-1, s_{2}=-2$
d. None of the above

13. A cart of mass $m=1000 \mathrm{~kg}$ is attached to a truck using a spring of stiffness $k=20,000 \mathrm{~N} / \mathrm{m}$ and a damper of constant $b=200 \mathrm{Ns} / \mathrm{m}$, as shown in Figure 2.76. The truck moves at a constant acceleration of $a=0.7 \mathrm{~m} / \mathrm{s}^{2}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0157.jpg?height=278&width=1059&top_left_y=1298&top_left_x=449)

FIGURE 2.76 Truck pulling a cart of mass $m$.

The transfer function between the speed of the truck and the speed of the cart is:
a. $T(s)=\frac{50}{5 s^{2}+s+100}$
b. $T(s)=\frac{20+s}{s^{2}+10 s+25}$
c. $T(s)=\frac{100+s}{5 s^{2}+s+100}$
d. None of the above 14. Consider the closed-loop system in Figure 2.74 with

$$
\begin{gathered}
G_{c}(s)=15, \quad H(s)=1, \text { and } G(s)=\frac{1000}{s^{3}+50 s^{2}+4500 s+1000} . \\
T_{d}(s)=0, \text { and } N(s)=0 .
\end{gathered}
$$

Compute the closed-loop transfer function and the closed-loop poles.
a. $T(s)=\frac{15000}{s^{3}+50 s^{2}+4500 s+16000}, s_{1}=-3.70, s_{2,3}=-23.15 \pm 61.59 j$
b. $T(s)=\frac{15000}{50 s^{2}+4500 s+16000}, s_{1}=-3.70, s_{2}=-86.29$
c. $T(s)=\frac{1}{s^{3}+50 s^{2}+4500 s+16000}, s_{1}=-3.70, s_{2,3}=-23.2 \pm 63.2 j$
d. $T(s)=\frac{15000}{s^{3}+50 s^{2}+4500 s+16000}, s_{1}=-3.70, s_{2}=-23.2, s_{3}=-63.2$

15. Consider the feedback system in Figure 2.74 with

$$
G_{c}(s)=\frac{K(s+0.3)}{s}, \quad H(s)=2 s, \quad \text { and } \quad G(s)=\frac{1}{(s-2)\left(s^{2}+10 s+45\right)} .
$$

Assuming $R(s)=0$ and $\mathrm{N}(s)=0$, the closed-loop transfer function from the disturbance $T_{d}(s)$ to the output $Y(s)$ is:
a. $\frac{Y(s)}{T_{d}(s)}=\frac{1}{s^{3}+8 s^{2}+(2 K+25) s+(0.6 K-90)}$
b. $\frac{Y(s)}{T_{d}(s)}=\frac{100}{s^{3}+8 s^{2}+(2 K+25) s+(0.6 K-90)}$
c. $\frac{Y(s)}{T_{d}(s)}=\frac{1}{8 s^{2}+(2 K+25) s+(0.6 K-90)}$
d. $\frac{Y(s)}{T_{d}(s)}=\frac{K(s+0.3)}{s^{4}+8 s^{3}+(2 K+25) s^{2}+(0.6 K-90) s}$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.
a. Actuator
b. Block diagrams
c. Characteristic equation
d. Critical damping

e. Damped oscillation

f. Damping ratio

g. DC motor
An oscillation in which the amplitude decreases with time.

A system that satisfies the properties of superposition and homogeneity.

The case where damping is on the boundary between underdamped and overdamped.

A transformation of a function $f(t)$ from the time domain into the complex frequency domain yielding $F(s)$.

The device that provides the motive power to the process.

A measure of damping. A dimensionless number for the second-order characteristic equation.

The relation formed by equating to zero the denominator of a transfer function. h. Laplace transform

i. Linear approximation

j. Linear system

k. Mason loop rule

I. Mathematical models

m. Signal-flow graph

n. Simulation

o. Transfer function
Unidirectional, operational blocks that represent the transfer functions of the elements of the system.

A rule that enables the user to obtain a transfer function by tracing paths and loops within a system.

An electric actuator that uses an input voltage as a control variable.

The ratio of the Laplace transform of the output variable to the Laplace transform of the input variable.

Descriptions of the behavior of a system using mathematics.

A model of a system that is used to investigate the behavior of a system by utilizing actual input signals.

A diagram that consists of nodes connected by several directed branches and that is a graphical representation of a set of linear relations.

An approximate model that results in a linear relationship between the output and the input of the device.

\section{EXERCISES}

Exercises are straightforward applications of the concepts of the chapter.

E2.1 A unity, negative feedback system has a nonlinear function $y=f(e)=e^{2}$, as shown in Figure E2.1. For an input $r$ in the range of 0 to 4 , calculate and plot the open-loop and closed-loop output versus input and show that the feedback system results in a more linear relationship.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0159.jpg?height=181&width=437&top_left_y=1354&top_left_x=245)

FIGURE E2.1 Open and closed loop.

E2.2 A thermistor has a response to temperature represented by

$$
R=R_{\mathrm{o}} e^{-0.3 t},
$$

where $R_{\mathrm{O}}=5,000 \Omega, R=$ resistance, and $T=$ temperature in degrees Celsius. Find the linear model for the thermistor operating at $T=20^{\circ} \mathrm{C}$ and for a small range of variation of temperature.

Answer: $\Delta R=-3.7 \Delta T$

E2.3 The force versus displacement for a spring is shown in Figure E2.3 for the spring-mass-damper system of Figure 2.1. Graphically find the spring constant for the equilibrium point of $y=1.0 \mathrm{~cm}$ and a range of operation of $\pm 2.0 \mathrm{~cm}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0159.jpg?height=341&width=527&top_left_y=1053&top_left_x=1035)

FIGURE E2.3 Spring behavior.

E2.4 A laser printer uses a laser beam to print copy rapidly for a computer. The laser is positioned by a control input $r(t)$, so that we have

$$
Y(s)=\frac{4(s+50)}{s^{2}+30 s+200} R(s) .
$$

The input $r(t)$ represents the desired position of the laser beam.

(a) If $r(t)$ is a unit step input, find the output $y(t)$.

(b) What is the final value of $y(t)$ ?

Answer: (a) $y(t)=1+0.6 e^{-20 t}-1.6 e^{-10 t}$, (b) $y_{s s}=1$

E2.5 A summing amplifier uses an op-amp as shown in Figure E2.5. Assume an ideal op-amp model, and determine $v_{\mathrm{o}}$.

Answer: $v_{0}=-\frac{R_{2}}{R_{1}}\left(v_{1}+v_{2}+v_{3}\right)$ 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0160.jpg?height=320&width=607&top_left_y=167&top_left_x=280)

FIGURE E2.5 A summing amplifier using an op-amp.

E2.6 A nonlinear device is represented by the function

$$
y=f(x)=A e^{x},
$$

where the operating point for the input $x$ is $x_{\mathrm{o}}=0$, where $A$ is a constant. Determine a linear approximation valid near the operating point.

Answer: $y=A+A x=A(1+x)$.

E2.7 A lamp's intensity stays constant when monitored by an optotransistor-controlled feedback loop. When the voltage drops, the lamp's output also drops, and optotransistor $Q_{1}$ draws less current. As a result, a power transistor conducts more heavily and charges a capacitor more rapidly [24]. The capacitor voltage controls the lamp voltage directly. A block diagram of the system is shown in Figure E2.7. Find the closedloop transfer function, $I(s) / R(s)$ where $I(s)$ is the lamp intensity, and $R(s)$ is the command or desired level of light.

E2.8 A control engineer, N. Minorsky, designed an innovative ship steering system in the 1930s for the U.S. Navy. The system is represented by the block diagram shown in Figure E2.8, where $Y(s)$ is the ship's course, $R(s)$ is the desired course, and $A(s)$ is the rudder angle [16]. Find the transfer function $Y(s) / R(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0160.jpg?height=261&width=644&top_left_y=152&top_left_x=1068)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0160.jpg?height=234&width=574&top_left_y=522&top_left_x=1104)

(b)

FIGURE E2.7 Lamp controller.

Answer: $\frac{Y(s)}{R(s)}=$

$\frac{K G_{1}(s) G_{2}(s) / s}{1+G_{1}(s) H_{3}(s)+G_{1}(s) G_{2}(s)\left[H_{1}(s)+H_{2}(s)\right]+K G_{1}(s) G_{2}(s) / s}$

E2.9 A four-wheel antilock automobile braking system uses electronic feedback to control automatically the brake force on each wheel [15]. A block diagram model of a brake control system is shown in Figure E2.9, where $F_{f}(s)$ and $F_{R}(s)$ are the braking force of the front and rear wheels, respectively, and $R(s)$ is the desired automobile response on an icy road. Find $F_{f}(s) / R(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0160.jpg?height=546&width=1169&top_left_y=1526&top_left_x=356)

FIGURE E2.8 Ship steering system. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0161.jpg?height=346&width=724&top_left_y=163&top_left_x=106)

FIGURE E2.9 Brake control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0161.jpg?height=564&width=751&top_left_y=619&top_left_x=76)

FIGURE E2.10 Shock absorber.

E2.10 One of the beneficial applications of an automotive control system is the active control of the suspension system. One feedback control system uses a shock absorber consisting of a cylinder filled with a compressible fluid that provides both spring and damping forces [17]. The cylinder has a plunger

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0161.jpg?height=418&width=621&top_left_y=165&top_left_x=938)

FIGURE E2.11 Spring characteristic.

activated by a gear motor, a displacement-measuring sensor, and a piston. Spring force is generated by piston displacement, which compresses the fluid. During piston displacement, the pressure imbalance across the piston is used to control damping. The plunger varies the internal volume of the cylinder. This system is shown in Figure E2.10. Develop a block diagram model.

E2.11 A spring exhibits a force-versus-displacement characteristic as shown in Figure E2.11. For small deviations from the operating point $x_{\mathrm{o}}$, find the spring constant when $x_{\mathrm{o}}$ is (a) -1.1 , (b) 0 , and (c) 2.8.

E2.12 Off-road vehicles experience many disturbance inputs as they traverse over rough roads. An active suspension system can be controlled by a sensor that looks "ahead" at the road conditions. An example of a simple suspension system that can accommodate the bumps is shown in Figure E2.12. Find the appropriate gain $K_{1}$ so that the vehicle does not bounce when the desired deflection is $R(s)=0$ and the disturbance is $T_{d}(s)$.

Answer: $K_{1} K_{2}=1$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0161.jpg?height=475&width=1060&top_left_y=1592&top_left_x=406)

FIGURE E2.12 Active suspension system. E2.13 Consider the feedback system in Figure E2.13. Compute the transfer functions $Y(s) / T_{d}(s)$ and $Y(s) / N(s)$.

E2.14 Find the transfer function

$$
\frac{Y_{1}(s)}{R_{2}(s)}
$$

for the multivariable system in Figure E2.14.

E2.15 Obtain the differential equations of the circuit in Figure E2.15 in terms of $i_{1}(t)$ and $i_{2}(t)$.

E2.16 The position control system for a spacecraft platform is governed by the following equations:

$$
\begin{aligned}
\frac{d^{2} p(t)}{d t^{2}}+2 \frac{d p(t)}{d t}+4 p(t) & =\theta \\
v_{1}(t) & =r(t)-p(t)
\end{aligned}
$$

$$
\begin{gathered}
\frac{d \theta(t)}{d t}=0.5 v_{2}(t) \\
v_{2}(t)=8 v_{1}(t) .
\end{gathered}
$$

The variables involved are as follows:

$$
\begin{aligned}
r(t) & =\text { desired platform position } \\
p(t) & =\text { actual platform position } \\
v_{1}(t) & =\text { amplifier input voltage } \\
v_{2}(t) & =\text { amplifier output voltage } \\
\theta(t) & =\text { motor shaft position }
\end{aligned}
$$

Sketch a signal-flow diagram or a block diagram of the system, identifying the component parts, and determine the system transfer function $P(s) / R(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0162.jpg?height=362&width=1142&top_left_y=847&top_left_x=424)

FIGURE E2.13 Feedback system with measurement noise, $N(s)$, and plant disturbances, $T_{d}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0162.jpg?height=632&width=1190&top_left_y=1434&top_left_x=339)

FIGURE E2.14 Multivariable system. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0163.jpg?height=341&width=668&top_left_y=168&top_left_x=125)

FIGURE E2.15 Electric circuit.

E2.17 A logarithmic amplifier has a diode whose voltage is represented by the relation

$$
V=C \operatorname{In} I,
$$

where $C$ is a constant and $I$ is the current across the diode. Determine a linear model for the diode when $I_{\mathrm{o}}=1$.

E2.18 The output $y$ and input $x$ of a device are related by

$$
y=x+1.9 x^{3} .
$$

(a) Find the values of the output for steady-state operation at the two operating points $x_{\mathrm{o}}=1.2$ and $x_{\mathrm{o}}=2.5$.

(b) Obtain a linearized model for both operating points and compare them.

E2.19 The transfer function of a system is

$$
\frac{Y(s)}{R(s)}=\frac{15(s+1)}{s^{2}+9 s+14} .
$$

Determine $y(t)$ when $r(t)$ is a unit step input.

Answer: $y(t)=1.07+1.5 e^{-2 t}-2.57 e^{-7 t}, t \geq 0$

E2.20 Determine the transfer function $V_{0}(s) / V(s)$ of the operational amplifier circuit shown in Figure E2.20. Assume an ideal operational amplifier. Determine the transfer function when $R_{1}=R_{2}=170 \mathrm{k} \Omega, C_{1}=$ $15 \mu \mathrm{F}$, and $C_{2}=25 \mu \mathrm{F}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0163.jpg?height=435&width=666&top_left_y=1542&top_left_x=147)

FIGURE E2.20 Op-amp circuit.
E2.21 A high-precision positioning slide is shown in Figure E2.21. Determine the transfer function $X_{p}(s) / X_{\text {in }}(s)$ when the drive shaft friction is $b_{d}=0.7$, the drive shaft spring constant is $k_{d}=2, m_{c}=1$, and the sliding friction is $b_{s}=0.8$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0163.jpg?height=372&width=706&top_left_y=461&top_left_x=898)

FIGURE E2.21 Precision slide.

E2.22 The rotational velocity $\omega$ of the satellite shown in Figure E2.22 is adjusted by changing the length of the beam $L$. The transfer function between $\omega(s)$ and the incremental change in beam length $\Delta L(s)$ is

$$
\frac{\omega(s)}{\Delta L(s)}=\frac{8(s+3)}{(s+2)(s+3)^{2}} .
$$

The beam length change is $\Delta L(s)=2 / s$. Determine the response of the rotation $\omega(t)$.

Answer: $\omega(t)=2.67-8 e^{-2 t}+5.33 e^{-3 t}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0163.jpg?height=446&width=546&top_left_y=1541&top_left_x=957)

FIGURE E2.22 Satellite with adjustable rotational velocity. E2.23 Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$ for the system of Figure E2.23.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0164.jpg?height=254&width=779&top_left_y=268&top_left_x=222)

FIGURE E2.23 Control system with three feedback loops.

E2.24 An amplifier may have a region of deadband as shown in Figure E2.24. Use an approximation that uses a cubic equation $y=a x^{3}$ in the approximately linear region. Select $a$ and determine a linear approximation for the amplifier when the operating point is $x=0.6$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0164.jpg?height=552&width=670&top_left_y=900&top_left_x=272)

FIGURE E2.24 An amplifier with a deadband region.

E2.25 The block diagram of a system is shown in Figure E2.25. Determine the transfer function $T(s)=Y(s) / R(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0164.jpg?height=343&width=741&top_left_y=1722&top_left_x=236)

FIGURE E2.25 Multiloop feedback system.
E2.26 Determine the transfer function $X_{2}(s) / F(s)$ for the system shown in Figure E2.26. Both masses slide on a frictionless surface and $k=1 \mathrm{~N} / \mathrm{m}$.

$$
\text { Answer: } \frac{X_{2}(s)}{F(s)}=\frac{1}{s^{2}\left(s^{2}+2\right)}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0164.jpg?height=261&width=748&top_left_y=462&top_left_x=1025)

FIGURE E2.26 Two connected masses on a frictionless surface.

E2.27 Find the transfer function $Y(s) / T_{d}(s)$ for the system shown in Figure E2.27.

Answer: $\frac{Y(s)}{T_{d}(s)}=\frac{G_{2}(s)}{1+G_{1}(s) G_{2}(s) H(s)}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0164.jpg?height=344&width=687&top_left_y=1225&top_left_x=1049)

FIGURE E2.27 System with disturbance.

E2.28 Determine the transfer function $V_{\mathrm{o}}(s) / V(s)$ for the op-amp circuit shown in Figure E2.28 [1]. Let $R_{1}=167 \mathrm{k} \Omega, R_{2}=240 \mathrm{k} \Omega, R_{3}=1 \mathrm{k} \Omega, R_{4}=100 \mathrm{k} \Omega$, and $C=1 \mu \mathrm{F}$. Assume an ideal op-amp.

E2.29 A system is shown in Fig. E2.29(a).

(a) Determine $G(s)$ and $H(s)$ of the block diagram shown in Figure E2.29(b) that are equivalent to those of the block diagram of Figure E2.29(a).

(b) Determine $Y(s) / R(s)$ for Figure E2.29(b). FIGURE E2.28 Op-amp circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0165.jpg?height=190&width=751&top_left_y=620&top_left_x=76)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0165.jpg?height=202&width=569&top_left_y=906&top_left_x=167)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0165.jpg?height=362&width=854&top_left_y=151&top_left_x=387)

FIGURE E2.29 Block diagram equivalence.

E2.30 A system is shown in Figure E2.30.

(a) Find the closed-loop transfer function $Y(s) / R(s)$

when $G(s)=\frac{10}{s^{2}+2 s+10}$.

(b) Determine $Y(s)$ when the input $R(s)$ is a unit step.

(c) Compute $y(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0165.jpg?height=172&width=682&top_left_y=622&top_left_x=901)

FIGURE E2.30 Unity feedback control system.

E2.31 Determine the partial fraction expansion for $V(s)$, and compute the inverse Laplace transform. The transfer function $V(s)$ is given by

$$
V(s)=\frac{400}{s^{2}+8 s+400} .
$$

\section{PROBLEMS}

Problems require an extension of the concepts of the chapter to new situations.

P2.1 An electric circuit is shown in Figure P2.1. Obtain a set of simultaneous integrodifferential equations representing the network.

P2.2 A dynamic vibration absorber is shown in Figure $\mathrm{P} 2.2$. This system is representative of many situations involving the vibration of machines containing unbalanced components. The parameters $M_{2}$ and $k_{12}$ may be chosen so that the main mass $M_{1}$ does not vibrate in the steady state when $F(t)=a \sin \left(\omega_{0} t\right)$. Obtain the differential equations describing the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0165.jpg?height=374&width=555&top_left_y=1676&top_left_x=863)

FIGURE P2.1 Electric circuit. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0166.jpg?height=419&width=533&top_left_y=167&top_left_x=338)

FIGURE P2.2 Vibration absorber.

P2.3 A coupled spring-mass system is shown in Figure P2.3. The masses and springs are assumed to be equal. Obtain the differential equations describing the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0166.jpg?height=292&width=698&top_left_y=842&top_left_x=258)

FIGURE P2.3 Two-mass system.

P2.4 A nonlinear amplifier can be described by the following characteristic:

$$
v_{0}(t)=\left\{\begin{array}{ll}
2 v_{\text {in }}^{2} & v_{\text {in }} \geq 0 \\
-22_{\text {in }}^{2} & v_{\text {in }}<0
\end{array} .\right.
$$

The amplifier will be operated over a range of $\pm 0.5 \mathrm{~V}$ around the operating point for $v_{\text {in }}$. Describe the amplifier by a linear approximation (a) when the operating point is $v_{\text {in }}=0$ and (b) when the operating point is $v_{\text {in }}=1 V$. Obtain a sketch of the nonlinear function and the approximation for each case.

P2.5 Fluid flowing through an orifice can be represented by the nonlinear equation

$$
Q=K\left(P_{1}-P_{2}\right)^{1 / 2},
$$

where the variables are shown in Figure P2.5 and $K$ is a constant [2]. (a) Determine a linear approximation

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0166.jpg?height=188&width=444&top_left_y=1882&top_left_x=385)

FIGURE P2.5 Flow through an orifice. for the fluid-flow equation. (b) What happens to the approximation obtained in part (a) if the operating point is $P_{1}-P_{2}=0$ ?

P2.6 Using the Laplace transformation, obtain the current $I_{2}(s)$ of Problem P2.1. Assume that all the initial currents are zero, the initial voltage across capacitor $C_{1}$ is $5 v(t)$, and the initial voltage across $C_{2}$ is 10 volts.

P2.7 Obtain the transfer function of the integrating amplifier circuit shown in Figure P2.7, which is an implementation of a first-order low pass filter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0166.jpg?height=338&width=599&top_left_y=579&top_left_x=1074)

FIGURE P2.7 An integrating amplifier circuit.

P2.8 A bridged-T network is often used in AC control systems as a filter network [8]. The circuit of one bridged-T network is shown in Figure P2.8. Show that the transfer function of the network is

$$
\frac{V_{\mathrm{o}}(s)}{V_{\mathrm{in}}(s)}=\frac{1+2 R_{1} C s+R_{1} R_{2} C^{2} s^{2}}{1+\left(2 R_{1}+R_{2}\right) C s+R_{1} R_{2} C^{2} s^{2}} .
$$

Sketch the pole-zero diagram when $R_{1}=0.5, R_{2}=1$, and $C=0.5$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0166.jpg?height=311&width=377&top_left_y=1390&top_left_x=1185)

FIGURE P2.8 Bridged-T network.

P2.9 Determine the transfer function $X_{1}(s) / F(s)$ for the coupled spring-mass system of Problem P2.3. Sketch the $s$-plane pole-zero diagram for low damping when $M=1, b / k=1$, and

$$
\zeta=\frac{1}{2} \frac{b}{\sqrt{k M}}=0.1 .
$$

P2.10 Determine the transfer function $Y_{1}(s) / F(s)$ for the vibration absorber system of Problem P2.2. Determine 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0167.jpg?height=520&width=1093&top_left_y=159&top_left_x=352)

FIGURE P2.11 Amplidyne and armature-controlled motor.

the necessary parameters $M_{2}$ and $k_{12}$ so that the mass $M_{1}$ does not vibrate in the steady state when $F(t)=a \sin \left(\omega_{0} t\right)$.

P2.11 For electromechanical systems that require large power amplification, rotary amplifiers are often used $[8,19]$. An amplidyne is a power amplifying rotary amplifier. An amplidyne and a servomotor are shown in Figure P2.11. Obtain the transfer function $\theta(s) / V_{c}(s)$, and draw the block diagram of the system. Assume $v_{d}=k_{2} i_{q}$ and $v_{q}=k_{1} i_{c}$.

P2.12 For the open-loop control system described by the block diagram shown in Figure P2.12, determine the value of $K$ such that $y(t) \rightarrow 1$ as $t \rightarrow \infty$ when $r(t)$ is a unit step input. Assume zero initial conditions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0167.jpg?height=167&width=666&top_left_y=1410&top_left_x=128)

FIGURE P2.12 Open-loop control system.
P2.13 An electromechanical open-loop control system is shown in Figure P2.13. The generator, driven at a constant speed, provides the field voltage for the motor. The motor has an inertia $J_{m}$ and bearing friction $b_{m}$. Obtain the transfer function $\theta_{L}(s) / V_{f}(s)$ and draw a block diagram of the system. The generator voltage $v_{g}$ can be assumed to be proportional to the field current $i_{f}$.

P2.14 A rotating load is connected to a field-controlled DC electric motor through a gear system. The motor is assumed to be linear. A test results in the output load reaching a speed of $1 \mathrm{rad} / \mathrm{s}$ within $0.5 \mathrm{~s}$ when a constant $80 \mathrm{~V}$ is applied to the motor terminals. The output steady-state speed is $2.4 \mathrm{rad} / \mathrm{s}$. Determine the transfer function $\theta(s) / V_{f}(s)$ of the motor, in $\mathrm{rad} / \mathrm{V}$. The inductance of the field may be assumed to be negligible. Also, note that the application of $80 \mathrm{~V}$ to the motor terminals is a step input of $80 \mathrm{~V}$ in magnitude.

P2.15 Consider the spring-mass system depicted in Figure $\mathrm{P} 2.15$. Determine a differential equation to describe the motion of the mass $m$. Obtain the system response $x(t)$ subjected to an impulse input with zero initial conditions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0167.jpg?height=369&width=1190&top_left_y=1697&top_left_x=299)

FIGURE P2.13 Motor and generator. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0168.jpg?height=398&width=346&top_left_y=168&top_left_x=429)

FIGURE P2.15 Suspended spring-mass-damper system.

P2.16 A mechanical system is shown in Figure P2.16, which is subjected to a known displacement $x_{3}(t)$ with respect to the reference. (a) Determine the two independent equations of motion. (b) Obtain the equations of motion in terms of the Laplace transform, assuming that the initial conditions are zero. (c) Sketch a signal-flow graph representing the system of equations. (d) Obtain the relationship $T_{13}(s)$ between $X_{1}(s)$ and $X_{3}(s)$ by using Mason's signal-flow gain formula. Compare the work necessary to obtain $T_{13}(s)$ by matrix methods to that using Mason's signal-flow gain formula.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0168.jpg?height=644&width=661&top_left_y=1181&top_left_x=276)

FIGURE P2.16 Mechanical system.

P2.17 Obtain a signal-flow graph to represent the following set of algebraic equations where $x_{1}$ and $x_{2}$ are to be considered the dependent variables and 6 and 11 are the inputs:

$$
x_{1}+3 x_{2}=9, \quad 3 x_{1}+6 x_{2}=22 .
$$

Determine the value of each dependent variable by using the gain formula. After solving for $x_{1}$ by Mason's signal-flow gain formula, verify the solution by using Cramer's rule.

P2.18 An $L C$ ladder network is shown in Figure P2.18. One may write the equations describing the network as follows:

$$
\begin{array}{ll}
I_{1}=\left(V_{1}-V_{a}\right) Y_{1}, & V_{a}=\left(I_{1}-I_{a}\right) Z_{2}, \\
I_{a}=\left(V_{a}-V_{2}\right) Y_{3}, & V_{2}=I_{a} Z_{4} .
\end{array}
$$

Construct a flow graph from the equations and determine the transfer function $V_{2}(s) / V_{1}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0168.jpg?height=268&width=698&top_left_y=680&top_left_x=1034)

FIGURE P2.18 LC ladder network.

P2.19 The source follower amplifier provides lower output impedance and essentially unity gain. The circuit diagram is shown in Figure P2.19(a), and the small-signal model is shown in Figure P2.19(b). This circuit uses an FET and provides a gain of approximately unity. Assume that $R_{2} \gg R_{1}$ for biasing purposes and that $R_{g} \gg R_{2}$. (a) Solve for the amplifier gain. (b) Solve for the gain when $g_{m}=1000 \mu \Omega$ and $R_{s}=25 \mathrm{k} \Omega$ where $R_{s}=R_{1}+R_{2}$. (c) Sketch a block diagram that represents the circuit equations.

P2.20 A hydraulic servomechanism with mechanical feedback is shown in Figure P2.20 [18]. The power piston has an area equal to $A$. When the valve is moved a small amount $\Delta z$, the oil will flow through to the cylinder at a rate $p \cdot \Delta z$, where $p$ is the port coefficient. The input oil pressure is assumed to be constant. From the geometry, we find that $\Delta z=k \frac{l_{1}-l_{2}}{l_{1}}(x-y)-\frac{l_{2}}{l_{1}} y$. (a) Determine the closed-loop signal-flow graph or block diagram for this mechanical system. (b) Obtain the closed-loop transfer function $Y(s) / X(s)$.

P2.21 Figure P2.21 shows two pendulums suspended from frictionless pivots and connected at their midpoints by a spring [1]. Assume that each pendulum can be represented by a mass $M$ at the end of a massless bar of length $L$. Also assume that the displacement is small and linear approximations can be used for $\sin \theta$ and $\cos \theta$. The spring located in the middle of the bars is unstretched when $\theta_{1}=\theta_{2}$. The input force is represented by $f(t)$, which influences the left-hand bar 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=520&width=534&top_left_y=154&top_left_x=203)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=381&width=557&top_left_y=771&top_left_x=199)

(b)

FIGURE P2.19 The source follower or common drain amplifier using an FET.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=724&width=588&top_left_y=1327&top_left_x=169)

FIGURE P2.20 Hydraulic servomechanism.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=407&width=567&top_left_y=152&top_left_x=958)

FIGURE P2.21 The bars are each of length $L$ and the spring is located at $L / 2$.

only. (a) Obtain the equations of motion, and sketch a block diagram for them. (b) Determine the transfer function $T(s)=\theta_{1}(s) / F(s)$. (c) Sketch the location of the poles and zeros of $T(s)$ on the $s$-plane.

P2.22 A particular form of an operational amplifier is when the feedback loop is short-circuited. This amplifier is known as a voltage follower (buffer amplifier) as shown in Figure P2.22. Show that $T=V_{o}(s) / V_{\text {in }}(s)=1$. Assume an ideal op-amp. Discuss a practical use of this amplifier.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=273&width=388&top_left_y=1054&top_left_x=1048)

FIGURE P2.22 A buffer amplifier.

P2.23 The small-signal circuit equivalent to a commonemitter transistor amplifier is shown in Figure P2.23. The transistor amplifier includes a feedback resistor $R_{f}$. Determine the input-output ratio $V_{c e}(s) / V_{\text {in }}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0169.jpg?height=310&width=831&top_left_y=1595&top_left_x=824)

FIGURE P2.23 CE amplifier.

P2.24 A two-transistor series voltage feedback amplifier is shown in Figure P2.24(a). This AC equivalent circuit neglects the bias resistors and the shunt capacitors. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0170.jpg?height=430&width=609&top_left_y=152&top_left_x=222)

(a)

FIGURE P2.24 Feedback amplifier.

FIGURE P2.25

Black's amplifier.
H. S.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0170.jpg?height=369&width=417&top_left_y=766&top_left_x=563)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0170.jpg?height=336&width=773&top_left_y=185&top_left_x=846)

(b)
A block diagram representing the circuit is shown in Figure P2.24(b). This block diagram neglects the effect of $h_{r e}$, which is usually an accurate approximation, and assumes that $R_{2}+R_{L} \gg R_{1}$. (a) Determine the voltage gain $V_{o}(s) / V_{\text {in }}(s)$. (b) Determine the current gain $i_{c 2} / i_{b 1}$. (c) Determine the input impedance $V_{\text {in }}(s) / I_{b 1}(s)$.

P2.25 H. S. Black is noted for developing a negative feedback amplifier in 1927. Often overlooked is the fact that three years earlier he had invented a circuit design technique known as feedforward correction [19]. Recent experiments have shown that this technique offers the potential for yielding excellent amplifier stabilization. Black's amplifier is shown in Figure P2.25(a) in the form recorded in 1924. The block diagram is shown in Figure P2.25(b). Determine the transfer function between the output $Y(s)$ and the input $R(s)$ and between the output and the disturbance $T_{d}(s) . G(s)$ is used to denote the amplifier represented by $\mu$ in Figure P2.25(a).

P2.26 A robot includes significant flexibility in the arm members with a heavy load in the gripper [6, 20]. A two-mass model of the robot is shown in Figure P2.26. Find the transfer function $Y(s) / F(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0170.jpg?height=402&width=719&top_left_y=735&top_left_x=1033)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0170.jpg?height=252&width=705&top_left_y=1257&top_left_x=1047)

FIGURE P2.26 The spring-mass-damper model of a robot arm.

P2.27 Magnetic levitation trains provide a high-speed, very low friction alternative to steel wheels on steel rails. The train floats on an air gap as shown in Figure P2.27 [25]. The levitation force $F_{L}$ is controlled by the coil current $i$ in the levitation coils and may be approximated by

$$
F_{L}=k \frac{i^{2}}{z^{2}},
$$

where $z$ is the air gap. This force is opposed by the downward force $F=m g$. Determine the linearized relationship between the air gap $z$ and the controlling current near the equilibrium condition.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0171.jpg?height=522&width=572&top_left_y=259&top_left_x=161)

FIGURE P2.27 Cutaway view of train.

P2.28 A multiple-loop model of an urban ecological system might include the following variables: number of people in the city $(P)$, modernization $(M)$, migration into the city $(C)$, sanitation facilities $(S)$, number of diseases $(D)$, bacteria/area $(B)$, and amount of garbage/area $(G)$, where the symbol for the variable is given in parentheses. The following causal loops are hypothesized:

1. $P \rightarrow G \rightarrow B \rightarrow D \rightarrow P$

2. $P \rightarrow M \rightarrow C \rightarrow P$

3. $P \rightarrow M \rightarrow S \rightarrow D \rightarrow P$

4. $P \rightarrow M \rightarrow S \rightarrow B \rightarrow D \rightarrow P$

Sketch a signal-flow graph for these causal relationships, using appropriate gain symbols. Indicate whether you believe each gain transmission is positive or negative. For example, the causal link $S$ to $B$ is negative because improved sanitation facilities lead to reduced bacteria/area. Which of the four loops are positive feedback loops and which are negative feedback loops?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0171.jpg?height=370&width=758&top_left_y=1706&top_left_x=75)

FIGURE P2.29 Tilting beam and ball.
P2.29 We desire to balance a rolling ball on a tilting beam as shown in Figure P2.29. We will assume the motor input current $i$ controls the torque with negligible friction. Assume the beam may be balanced near the horizontal $(\phi=0)$; therefore, we have a small deviation of $\phi(t)$. Find the transfer function $X(s) / I(s)$, and draw a block diagram illustrating the transfer function showing $\phi(s), X(s)$, and $I(s)$.

P2.30 The measurement or sensor element in a feedback system is important to the accuracy of the system [6]. The dynamic response of the sensor is important. Many sensor elements possess a transfer function

$$
H(s)=\frac{k}{\tau s+1} .
$$

Suppose that a position-sensing photo detector has $\tau=10 \mu \mathrm{s}$. Obtain the step response of the system. Show that the step response is independent of $k$. Compute the time to reach $98 \%$ of the final value.

P2.31 An interacting control system with two inputs and two outputs is shown in Figure P2.31. Solve for $Y_{1}(s) / R_{1}(s)$ and $Y_{2}(s) / R_{1}(s)$ when $R_{2}=0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0171.jpg?height=515&width=755&top_left_y=970&top_left_x=864)

FIGURE P2.31 Interacting system.

P2.32 A system consists of two electric motors that are coupled by a continuous flexible belt. The belt also passes over a swinging arm that is instrumented to allow measurement of the belt speed and tension. The basic control problem is to regulate the belt speed and tension by varying the motor torques.

An example of a practical system similar to that shown occurs in textile fiber manufacturing processes when yarn is wound from one spool to another at high speed. Between the two spools, the yarn is processed in a way that may require the yarn speed and tension to be controlled within defined limits. A model of the system is shown in Figure P2.32. Find $Y_{2}(s) / R_{1}(s)$. Determine a relationship for the system that will make $Y_{2}$ independent of $R_{1}$. FIGURE P2.32

A model of the coupled motor drives.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0172.jpg?height=1250&width=1344&top_left_y=152&top_left_x=406)

FIGURE P2.33 Idle speed control system.
P2.33 Find the transfer function for $Y(s) / R(s)$ for the idle-speed control system for a fuel-injected engine as shown in Figure P2.33.

P2.34 The suspension system for one wheel of an oldfashioned pickup truck is illustrated in Figure P2.34. The mass of the vehicle is $m_{1}$ and the mass of the wheel is $m_{2}$. The suspension spring has a spring constant $k_{1}$ and the tire has a spring constant $k_{2}$. The damping constant of the shock absorber is $b$. Obtain the transfer function $Y_{1}(s) / X(s)$, which represents the vehicle response to bumps in the road.

P2.35 A feedback control system has the structure shown in Figure P2.35. Determine the closed-loop transfer function $Y(s) / R(s)$ (a) by block diagram manipulation and (b) by using a signal-flow graph and Mason's signal-flow gain formula. (c) Select the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0172.jpg?height=396&width=747&top_left_y=1526&top_left_x=1002)

FIGURE P2.34 Pickup truck suspension.

gains $K_{1}$ and $K_{2}$ so that the closed-loop response to a step input is critically damped with two equal roots at $s=-10$. (d) Plot the critically damped response 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0173.jpg?height=351&width=663&top_left_y=154&top_left_x=132)

FIGURE P2.35 Multiloop feedback system.

for a unit step input. What is the time required for the step response to reach $90 \%$ of its final value?

P2.36 A system is represented by Figure P2.36. (a) Determine the partial fraction expansion and $y(t)$ for a ramp input, $r(t)=t$, and $t \geq 0$. (b) Obtain a plot of $y(t)$ for part (a), and find $y(t)$ for $t=1.0 \mathrm{~s}$. (c) Determine the impulse response of the system $y(t)$ for $t \geq 0$. (d) Obtain a plot of $y(t)$ for part (c), and find $y(t)$ for $t=1.0 \mathrm{~s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0173.jpg?height=148&width=678&top_left_y=975&top_left_x=129)

FIGURE P2.36 A third-order system.

P2.37 A two-mass system is shown in Figure P2.37 with an input force $u(t)$. When $m_{1}=m_{2}=1$ and $K_{1}=K_{2}=1$, (a) find the set of differential equations describing the system, and (b) compute the transfer function from $U(s)$ to $Y(s)$.

P2.38 A winding oscillator consists of two steel spheres on each end of a long slender rod, as shown in Figure P2.38. The rod is hung on a thin wire that can be twisted many revolutions without breaking. The device will be wound up 4000 degrees. How long will it take until the motion decays to a swing of only 10 degrees? Assume that the thin wire has a rotational spring constant of $2 \times 10^{-4} \mathrm{~N} \mathrm{~m} / \mathrm{rad}$ and that the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0173.jpg?height=508&width=308&top_left_y=167&top_left_x=1069)

FIGURE P2.37 Two-mass system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0173.jpg?height=365&width=699&top_left_y=775&top_left_x=883)

FIGURE P2.38 Winding oscillator.

viscous friction coefficient for the sphere in air is $2 \times 10^{-4} \mathrm{~N} \mathrm{~ms} / \mathrm{rad}$. The sphere has a mass of $1 \mathrm{~kg}$.

P2.39 For the circuit of Figure P2.39, determine the transform of the output voltage $V_{0}(s)$. Assume that the circuit is in steady state when $t<0$. Assume that the switch moves instantaneously from contact 1 to contact 2 at $t=0$.

P2.40 A damping device is used to reduce the undesired vibrations of machines. A viscous fluid, such as a heavy oil, is placed between the wheels, as shown in
FIGURE P2.39

Model of an electronic circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0173.jpg?height=391&width=967&top_left_y=1719&top_left_x=462)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0174.jpg?height=369&width=680&top_left_y=154&top_left_x=262)

FIGURE P2.40 Cutaway view of damping device.

Figure P2.40. When vibration becomes excessive, the relative motion of the two wheels creates damping. When the device is rotating without vibration, there is no relative motion and no damping occurs. Find $\theta_{1}(s)$ and $\theta_{2}(s)$. Assume that the shaft has a spring constant $K$ and that $b$ is the damping constant of the fluid. The load torque is $T$.

P2.41 The lateral control of a rocket with a gimbaled engine is shown in Figure P2.41. The lateral deviation from the desired trajectory is $h$ and the forward rocket speed is $V$. The control torque of the engine is $T_{c}(s)$ and the disturbance torque is $T_{d}(s)$. Derive the describing equations of a linear model of the system, and draw the block diagram with the appropriate transfer functions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0174.jpg?height=762&width=395&top_left_y=1160&top_left_x=412)

FIGURE P2.41 Rocket with gimbaled engine.

P2.42 In many applications, such as reading product codes in supermarkets and in printing and manufacturing, an optical scanner is utilized to read codes, as shown in Figure P2.42. As the mirror rotates, a friction force is developed that is proportional to its angular speed. The friction constant is equal to $0.06 \mathrm{~N} \mathrm{~s} / \mathrm{rad}$, and the moment of inertia is equal to $0.1 \mathrm{~kg} \mathrm{~m}^{2}$. The output variable is the velocity $\omega(t)$. (a) Obtain the differential equation for the motor. (b) Find the response of the system when the input motor torque is a unit step and the initial velocity at $t=0$ is equal to 0.7 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0174.jpg?height=458&width=642&top_left_y=472&top_left_x=1053)

FIGURE P2.42 Optical scanner.

P2.43 An ideal set of gears is shown in Table 2.4, item 10. Neglect the inertia and friction of the gears and assume that the work done by one gear is equal to that of the other. Derive the relationships given in item 10 of Table 2.4. Also, determine the relationship between the torques $T_{m}$ and $T_{L}$.

P2.44 An ideal set of gears is connected to a solid cylinder load as shown in Figure P2.44. The inertia of the motor shaft and gear $G_{2}$ is $J_{m}$. Determine (a) the inertia of the load $J_{L}$ and (b) the torque $T$ at the motor shaft. Assume the friction at the load is $b_{L}$ and the friction at the motor shaft is $b_{m}$. Also assume the density of the load disk is $\rho$ and the gear ratio is $n$. Hint: The torque at the motorshaft is given by $T=T_{1}+T_{m}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0174.jpg?height=334&width=665&top_left_y=1576&top_left_x=1088)

FIGURE P2.44 Motor, gears, and load.

P2.45 To exploit the strength advantage of robot manipulators and the intellectual advantage of humans, a class of manipulators called extenders has been examined [22]. The extender is defined as an active manipulator worn by a human to augment the human's strength. The human provides an input $U(s)$, as shown in Figure $\mathrm{P} 2.45$. The endpoint of the extender is $P(s)$. Determine the output $P(s)$ for both $U(s)$ and $F(s)$ in the form

$$
P(s)=T_{1}(s) U(s)+T_{2}(s) F(s) .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0175.jpg?height=548&width=743&top_left_y=441&top_left_x=87)

FIGURE P2.45 Model of extender.

P2.46 A load added to a truck results in a force $F(s)$ on the support spring, and the tire flexes as shown in Figure P2.46(a). The model for the tire movement is shown in Figure P2.46(b). Determine the transfer function $X_{1}(s) / F(s)$.
P2.47 The water level $h(t)$ in a tank is controlled by an open-loop system, as shown in Figure P2.47. A DC motor controlled by an armature current $i_{a}$ turns a shaft, opening a valve. The inductance of the DC motor is negligible, that is, $L_{a}=0$. Also, the rotational friction of the motor shaft and valve is negligible, that is, $b=0$. The height of the water in the tank is

$$
h(t)=\int[1.6 \theta(t)-h(t)] d t,
$$

the motor constant is $K_{m}=10$, and the inertia of the motor shaft and valve is $J=6 \times 10^{-3} \mathrm{~kg} \mathrm{~m}^{2}$. Determine (a) the differential equation for $h(t)$ and $v(t)$ and (b) the transfer function $H(s) / V(t)$.

P2.48 The circuit shown in Figure P2.48 is called a lead-lag filter.

(a) Find the transfer function $V_{2}(s) / V_{1}(s)$. Assume an ideal op-amp.

(b) Determine $V_{2}(s) / V_{1}(s)$ when $R_{1}=250 \mathrm{k} \Omega$, $R_{2}=250 k \Omega, C_{1}=2 \mu F$, and $C_{2}=0.3 \mu F$.

(c) Determine the partial fraction expansion for $V_{2}(s) / V_{1}(s)$.

P2.49 A closed-loop control system is shown in Figure P2.49.

(a) Determine the transfer function

$$
T(s)=Y(s) / R(s) .
$$

(b) Determine the poles and zeros of $T(s)$.

(c) Use a unit step input, $R(s)=1 / s$, and obtain the partial fraction expansion for $Y(s)$ and the value of the residues.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0175.jpg?height=687&width=537&top_left_y=1369&top_left_x=957)

(b)
FIGURE P2.46

Truck support model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0175.jpg?height=570&width=384&top_left_y=1465&top_left_x=542)

(a) FIGURE P2.47

Open-loop control system for the water level of a tank.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0176.jpg?height=322&width=569&top_left_y=954&top_left_x=320)

FIGURE P2.48 Lead-lag filter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0176.jpg?height=169&width=720&top_left_y=1374&top_left_x=242)

FIGURE P2.49 Unity feedback control system.

(d) Plot $y(t)$ and discuss the effect of the real and complex poles of $T(s)$. Do the complex poles or the real poles dominate the response?

P2.50 A closed-loop control system is shown in Figure P2.50.

(a) Determine the transferfunction $T(s)=Y(s) / R(s)$.

(b) Determine the poles and zeros of $T(s)$.

(c) Use a unit step input, $R(s)=1 / s$, and obtain the partial fraction expansion for $Y(s)$ and the value of the residues.

(d) Plot $y(t)$ and discuss the effect of the real and complex poles of $T(s)$. Do the complex poles or the real poles dominate the response?
$10 \Omega$

$\underset{i_{a}(t)}{\longrightarrow}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0176.jpg?height=214&width=278&top_left_y=318&top_left_x=997)

(e) Predict the final value of $y(t)$ for the unit step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0176.jpg?height=175&width=734&top_left_y=1065&top_left_x=1016)

FIGURE P2.50 Third-order feedback system.

P2.51 Consider the two-mass system in Figure P2.51. Find the set of differential equations describing the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0176.jpg?height=551&width=341&top_left_y=1498&top_left_x=1217)

FIGURE P2.51 Two-mass system with two springs and one damper. 

\section{ADVANCED PROBLEMS}

AP2.1 A first-order RL circuit consisting of a resistor and an inductor in series driven by a voltage source is one of the simplest analog infinite impulse response electronic filters. For an input voltage of $5 \mathrm{~V}$, the current at $t=1 \mathrm{~s}$ is $2 \mathrm{~A}$, and the steady state current is $5 \mathrm{~A}$ when $t \rightarrow \infty$. Determine the transfer function $I(s) / V(s)$.

AP2.2 A system has a block diagram as shown in Figure AP2.2. Determine the transfer function

$$
T(s)=\frac{Y_{2}(s)}{R_{1}(s)} .
$$

It is desired to decouple $Y_{2}(s)$ from $R_{1}(s)$ by obtaining $T(s)=0$. Select $G_{5}(s)$ in terms of the other $G_{i}(s)$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0177.jpg?height=635&width=785&top_left_y=757&top_left_x=85)

FIGURE AP2.2 Interacting control system.

to achieve decoupling.

AP2.3 Consider the feedback control system in Figure AP2.3. Define the tracking error as

$$
E(s)=R(s)-Y(s) .
$$

(a) Determine a suitable $H(s)$ such that the tracking error is zero for any input $R(s)$ in the absence of a disturbance input (that is, when $T_{d}(s)=0$ ). (b) Using $H(s)$ determined in part (a), determine the response $Y(s)$ for a disturbance $T_{d}(s)$ when the input $R(s)=0$. (c) Is it possible to obtain $Y(s)=0$ for an arbitrary disturbance $T_{d}(s)$ when $G_{d}(s) \neq 0$ ? Explain your answer.

AP2.4 Consider a DC amplifier given by

$$
\frac{V_{2}(s)}{V_{1}(s)}=\frac{k_{a}}{R_{o} C_{o} s+1},
$$

where $V_{2}(s)$ is the output voltage and $V_{1}(s)$ is the input voltage. The system parameters are $R_{O}$ and

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0177.jpg?height=400&width=728&top_left_y=261&top_left_x=859)

FIGURE AP2.3 Feedback system with a disturbance input.

$C_{o}$, the output resistance and capacitance, respectively. The DC amplifier is illustrated in Table 2.4. (a) Determine the response of the system to a unit step $V_{1}(s)=1 / s$. (b) As $t \rightarrow \infty$, what value does the step response determined in part (a) approach? This is known as the steady-state response. (c) Describe how you would select the system parameters $R_{o}$ and $C_{o}$ to increase the speed of response of the system to a step input.

AP2.5 For the three-cart system (Figure AP2.5), obtain the equations of motion. The system has three inputs $u_{1}(t), u_{2}(t)$, and $u_{3}(t)$ and three outputs $x_{1}(t), x_{2}(t)$, and $x_{3}(t)$. Obtain three second-order ordinary differential equations with constant coefficients. If possible, write the equations of motion in matrix form.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0177.jpg?height=296&width=792&top_left_y=1395&top_left_x=860)

FIGURE AP2.5 Three-cart system with three inputs and three outputs.

AP2.6 Consider the hanging crane structure in Figure AP2.6. Write the equations of motion describing the motion of the cart and the payload. The mass of the cart is $M$, the mass of the payload is $m$, the massless rigid connector has length $L$, and the friction is modeled as $F_{b}(t)=-b \dot{x}(t)$ where $x(t)$ is the distance traveled by the cart.

AP2.7 Consider the unity feedback system described in the block diagram in Figure AP2.7. Compute analytically FIGURE AP2.6

(a) Hanging crane supporting the Space Shuttle Atlantis (photo courtesy of: NASA Jack Pfaller) and (b) schematic representation of the hanging crane structure.

FIGURE AP2.7 Unity feedback control system with controller $G_{c}(s)=K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0178.jpg?height=645&width=421&top_left_y=155&top_left_x=505)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0178.jpg?height=303&width=470&top_left_y=488&top_left_x=1014)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0178.jpg?height=305&width=1360&top_left_y=873&top_left_x=226)

the response of the system to an impulse disturbance. Determine a relationship between the gain $K$ and the minimum time it takes the impulse disturbance response of the system to reach $y(t)<0.5$. Assume that $K>0$. For what value of $K$ does the disturbance response first reach at $y(t)=0.5$ at $t=0.01$ ?

AP2.8 Consider the cable reel control system given in Figure AP2.8. Find the value of $K_{t}$ and $K_{a}$ such that the percent overshoot is P.O. $\leq 15 \%$ and a zero steady state error to a unit step is achieved. Compute the closed-loop response $y(t)$ analytically and confirm that the steady-state response and P.O. meet the specifications.
AP2.9 Consider the inverting operational amplifier in Figure AP2.9. Find the transfer function $V_{o}(s) / V_{i}(s)$. Show that the transfer function can be expressed as

$$
G(s)=\frac{V_{o}(s)}{V_{i}(s)}=K_{P}+K_{D} s,
$$

where the gains $K_{P}$ and $K_{D}$ are functions of $C, R_{1}$, and $R_{2}$. This circuit is a proportional-derivative (PD) controller.
FIGURE AP2.8

Cable reel control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0178.jpg?height=430&width=1225&top_left_y=1690&top_left_x=488)

FIGURE AP2.9 An inverting operational amplifier circuit representing a PD controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0179.jpg?height=424&width=903&top_left_y=162&top_left_x=508)

\section{DESIGN PROBLEMS}

CDP2.1 We want to accurately position a table for a machine as shown in Figure CDP2.1. A traction-drive motor with a capstan roller possesses several desirable characteristics compared to the more popular ball screw. The traction drive exhibits low friction and no backlash. However, it is susceptible to disturbances. Develop a model of the traction drive shown in Figure CDP2.1(a) for the parameters given in Table CDP2.1. The drive uses a DC armature-controlled motor with a capstan roller attached to the shaft. The drive bar moves the linear slide-table. The slide uses an air bearing, so its friction is negligible. We are considering the open-loop model, Figure CDP2.1(b), and its transfer function in this problem. Feedback will be introduced later.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0179.jpg?height=335&width=748&top_left_y=1227&top_left_x=87)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0179.jpg?height=116&width=555&top_left_y=1659&top_left_x=181)

(b)

FIGURE CDP2.1 (a) Traction drive, capstan roller, and linear slide. (b) The block diagram model.

DP2.1 A control system is shown in Figure DP2.1. With

and

$$
G_{1}(s)=\frac{10}{s+10}
$$

$$
G_{2}(s)=\frac{1}{s},
$$

\section{Table CDP2.1 Typical Parameters for the Armature-Controlled DC Motor and the Capstan and Slide}

\begin{tabular}{lll}
$M_{s}$ & Mass of slide & $5.693 \mathrm{~kg}$ \\
$M_{b}$ & Mass of drive bar & $6.96 \mathrm{~kg}$ \\
$J_{m}$ & $\begin{array}{l}\text { Inertia of } \\
\text { roller, shaft, motor } \\
\text { and tachometer }\end{array}$ & $10.91 \cdot 10^{-3} \mathrm{~kg} \mathrm{~m}^{2}$ \\
& $\begin{array}{l}\text { Roller radius } \\
r\end{array}$ & $31.75 \cdot 10^{-3} \mathrm{~m}$ \\
$b_{m}$ & Motor damping & $0.268 \mathrm{~N} \mathrm{~ms} / \mathrm{rad}$ \\
$K_{m}$ & Torque constant & $0.8379 \mathrm{~N} \mathrm{~m} / \mathrm{amp}$ \\
$K_{b}$ & Back emf constant & $0.838 \mathrm{~V} \mathrm{~s} / \mathrm{rad}$ \\
$R_{m}$ & Motor resistance & $1.36 \Omega$ \\
$L_{m}$ & Motor inductance & $3.6 \mathrm{mH}$ \\
\hline
\end{tabular}

determine the gains $K_{1}$ and $K_{2}$ such that the final value $y(t)$ as $t \rightarrow \infty$ reaches $y \rightarrow 1$ and the closed-loop poles are located at $s_{1}=-20$ and $s_{2}=-0.5$.

DP2.2 The television beam circuit of a television is represented by the model in Figure DP2.2. Select the unknown conductance $G$ so that the voltage $v$ is $24 \mathrm{~V}$. Each conductance is given in siemens ( $\mathrm{S}$ ).

DP2.3 An input $r(t)=t, t \geq 0$, is applied to a black box with a transfer function $G(s)$. The resulting output response, when the initial conditions are zero, is

$$
y(t)=\frac{1}{4} e^{-t}-\frac{1}{100} e^{-5 t}-\frac{6}{25}+\frac{1}{5} t, t \geq 0 .
$$

Determine $G(s)$ for this system.

DP2.4 An operational amplifier circuit that can serve as an active low-pass filter circuit is shown in Figure DP2.4. Determine the transfer function of the circuit, assuming an ideal op-amp. Find $v_{0}(t)$ when the input is $v_{1}(t)=\delta(t), t \geq 0$. FIGURE DP2.1

Selection of transfer functions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0180.jpg?height=400&width=896&top_left_y=153&top_left_x=521)

FIGURE DP2.2 Television beam circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0180.jpg?height=268&width=741&top_left_y=607&top_left_x=801)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0180.jpg?height=358&width=675&top_left_y=997&top_left_x=227)

FIGURE DP2.4 Operational amplifier circuit.

FIGURE DP2.5

(a) Typical clock (photo courtesy of Science and Society/ SuperStock) and (b) schematic representation of the pendulum.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0180.jpg?height=475&width=400&top_left_y=1581&top_left_x=527)

(a)
DP2.5 Consider the clock shown in Figure DP2.5. The pendulum rod of length $L$ supports a pendulum disk. Assume that the pendulum rod is a massless rigid thin rod and the pendulum disc has mass $m$. Design the length of the pendulum, $L$, so that the period of motion is 2 seconds. Note that with a period of 2 seconds each "tick" and each "tock" of the clock represents 1 second, as desired. Assume small angles, $\varphi(t)$, in the analysis so that $\sin \varphi(t) \approx \varphi(t)$. Can you explain why most grandfather clocks are about $1.5 \mathrm{~m}$ or taller?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0180.jpg?height=471&width=609&top_left_y=1578&top_left_x=1013)

(b) 

\section{COMPUTER PROBLEMS}

CP2.1 Consider the two polynomials

$$
p(s)=s^{2}+7 s+10
$$

and

$$
q(s)=s+2 .
$$

Compute the following
(a) $p(s) q(s)$
(b) poles and zeros of $G(s)=\frac{q(s)}{p(s)}$

CP2.2 Consider the feedback system depicted in Figure CP2.2.

(a) Compute the closed-loop transfer function using the series and feedback functions.

(b) Obtain the closed-loop system unit step response with the step function, and verify that final value of the output is 0.571 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0181.jpg?height=309&width=722&top_left_y=951&top_left_x=86)

FIGURE CP2.2 A negative feedback control system.

CP2.3 Consider the differential equation

$$
\ddot{y}+4 \dot{y}(t)+3 y=u,
$$

where $y(0)=\dot{y}(0)=0$ and $u(t)$ is a unit step. Determine the solution $y(t)$ analytically, and verify by co-plotting the analytic solution and the step response obtained with the step function.

CP2.4 Consider the mechanical system depicted in Figure CP2.4. The input is given by $f(t)$, and the output is $y(t)$. Determine the transfer function from $f(t)$ to $y(t)$ and, using an $\mathrm{m}$-file, plot the system response

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0181.jpg?height=504&width=454&top_left_y=263&top_left_x=1010)

FIGURE CP2.4 A mechanical spring-mass-damper system.

to a unit step input. Let $m=10, k=1$, and $b=0.5$. Show that the peak amplitude of the output is about 1.8.

CP2.5 A satellite single-axis attitude control system can be represented by the block diagram in Figure CP2.5. The variables $k, a$, and $b$ are controller parameters, and $J$ is the spacecraft moment of inertia. Suppose the nominal moment of inertia is $J=10.8 \mathrm{E} 8\left(\operatorname{slug} \mathrm{ft}^{2}\right)$, and the controller parameters are $k=10.8 \mathrm{E} 8, a=1$, and $b=8$.

(a) Develop an m-file script to compute the closedloop transfer function $T(s)=\theta(s) / \theta_{d}(s)$.

(b) Compute and plot the step response to a $10^{\circ}$ step input.

(c) The exact moment of inertia is generally unknown and may change slowly with time. Compare the step response performance of the spacecraft when $J$ is reduced by $20 \%$ and $50 \%$. Use the controller parameters $k=10.8 \mathrm{E} 8, a=1$, and $b=8$ and a $10^{\circ}$ step input. Discuss your results.

CP2.6 Consider the block diagram in Figure CP2.6.

(a) Use an m-file to reduce the block diagram in Figure CP2.6, and compute the closed-loop transfer function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0181.jpg?height=238&width=934&top_left_y=1838&top_left_x=389)

FIGURE CP2.5 A spacecraft single-axis attitude control block diagram. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0182.jpg?height=397&width=1263&top_left_y=145&top_left_x=375)

FIGURE CP2.6 A multiple-loop feedback control system block diagram.

(b) Generate a pole-zero map of the closed-loop transfer function in graphical form using the pzmap function.

(c) Determine explicitly the poles and zeros of the closed-loop transfer function using the pole and zero functions and correlate the results with the pole-zero map in part (b).

CP2.7 For the simple pendulum shown in Figure CP2.7, the nonlinear equation of motion is given by

$$
\ddot{\theta}(t)+\frac{g}{L} \sin \theta(t)=0,
$$

where $L=0.5 \mathrm{~m}, m=1 \mathrm{~kg}$, and $g=9.8 \mathrm{~m} / \mathrm{s}^{2}$. When the nonlinear equation is linearized about the equilibrium point $\theta_{0}=0$, we obtain the linear time-invariant model,

$$
\ddot{\theta}(t)+\frac{g}{L} \theta(t)=0 .
$$

Create an m-file to plot both the nonlinear and the linear response of the simple pendulum when the initial angle of the pendulum is $\theta(0)=30^{\circ}$ and explain any differences.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0182.jpg?height=517&width=701&top_left_y=1555&top_left_x=221)

FIGURE CP2.7 Simple pendulum.
CP2.8 A system has a transfer function

$$
\frac{X(s)}{R(s)}=\frac{(20 / z)(s+z)}{s^{2}+3 s+20} .
$$

Plot the response of the system when $R(s)$ is a unit step for the parameter $z=5,10$, and 15 .

CP2.9 Consider the feedback control system in Figure CP2.9, where

$$
G(s)=\frac{s+1}{s+2} \quad \text { and } \quad H(s)=\frac{1}{s+1} .
$$

(a) Using an m-file, determine the closed-loop transfer function.

(b) Obtain the pole-zero map using the pzmap function. Where are the closed-loop system poles and zeros?

(c) Are there any pole-zero cancellations? If so, use the minreal function to cancel common poles and zeros in the closed-loop transfer function.

(d) Why is it important to cancel common poles and zeros in the transfer function?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0182.jpg?height=191&width=527&top_left_y=1499&top_left_x=1148)

FIGURE CP2.9 Control system with nonunity feedback.

CP2.10 Consider the block diagram in Figure CP2.10. Create an $\mathrm{m}$-file to complete the following tasks:

(a) Compute the step response of the closed-loop system (that is, $R(s)=1 / s$ and $T_{d}(s)=0$ ) and plot the steady-state value of the output $Y(s)$ as a function of the controller gain $0<K \leq 10$.

(b) Compute the disturbance step response of the closed-loop system (i.e., $R(s)=0$ and $\left.T_{d}(s)=1 / s\right)$ and co-plot the steady-state value of the output $Y(s)$ as a function of the controller gain $0<K \leq 10$ on the same plot as in (a) above. (c) Determine the value of $K$ such that the steadystate value of the output is equal for both the input response and the disturbance response.
FIGURE CP2.10 Block diagram of a unity feedback system with a reference input $R(s)$ and a disturbance input $T_{d}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0183.jpg?height=301&width=1093&top_left_y=355&top_left_x=526)

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) False; (2) True; (3) False; (4) True; (5) True

Multiple Choice: (6) d; (7) a; (8) b; (9) b; (10) c; (11) a; (12) a; (13) c; (14) a; (15) a
Word Match (in order, top to bottom): e, j, d, h, a, f, c, $\mathrm{b}, \mathrm{k}, \mathrm{g}, \mathrm{o}, \mathrm{l}, \mathrm{n}, \mathrm{m}, \mathrm{i}$

\section{TERMS AND CONCEPTS}

Across-Variable A variable determined by measuring the difference of the values at the two ends of an element.

Actuator The device that causes the process to provide the output. The device that provides the motive power to the process.

Analogous variables Variables associated with electrical, mechanical, thermal, and fluid systems possessing similar solutions providing the analyst with the ability to extend the solution of one system to all analogous systems with the same describing differential equations.

Assumptions Statements that reflect situations and conditions that are taken for granted and without proof. In control systems, assumptions are often employed to simplify the physical dynamical models of systems under consideration to make the control design problem more tractable.

Block diagrams Unidirectional, operational blocks that represent the transfer functions of the elements of the system.

Branch A unidirectional path segment in a signal-flow graph that relates the dependency of an input and an output variable.

Characteristic equation The relation formed by equating to zero the denominator of a transfer function.

Closed-loop transfer function A ratio of the output signal to the input signal for an interconnection of systems when all the feedback or feedfoward loops have been closed or otherwise accounted for. Generally obtained by block diagram or signal-flow graph reduction.

Coulomb damper A type of mechanical damper where the model of the friction force is a nonlinear function of the mass velocity and possesses a discontinuity around zero velocity. Also know as dry friction.

Critical damping The case where damping is on the boundary between underdamped and overdamped.

Damped oscillation An oscillation in which the amplitude decreases with time.

Damping ratio A measure of damping. A dimensionless number for the second-order characteristic equation.

DC motor An electric actuator that uses an input voltage as a control variable.

Differential equation An equation including differentials of a function.

Error signal The difference between the desired output $R(s)$ and the actual output $Y(s)$; therefore $E(s)=R(s)-Y(s)$.

Final value The value that the output achieves after all the transient constituents of the response have faded. Also referred to as the steady-state value.

Final value theorem The theorem that states that $\lim _{t \rightarrow \infty} y(t)=\lim _{s \rightarrow 0} s Y(s)$, where $Y(s)$ is the Laplace transform of $y(t)$. Homogeneity The property of a linear system in which the system response, $y(t)$, to an input $u(t)$ leads to the response $\beta y(t)$ when the input is $\beta u(t)$.

Inverse Laplace transform A transformation of a function $F(s)$ from the complex frequency domain into the time domain yielding $f(t)$.

Laplace transform A transformation of a function $f(t)$ from the time domain into the complex frequency domain yielding $F(s)$.

Linear approximation An approximate model that results in a linear relationship between the output and the input of the device.

Linear system A system that satisfies the properties of superposition and homogeneity.

Linearized Made linear or placed in a linear form. Taylor series approximations are commonly employed to obtain linear models of physical systems.

Loop A closed path that originates and terminates on the same node of a signal-flow graph with no node being met twice along the path.

Mason loop rule A rule that enables the user to obtain a transfer function by tracing paths and loops within a system.

Mathematical models Descriptions of the behavior of a system using mathematics.

Natural frequency The frequency of natural oscillation that would occur for two complex poles if the damping were equal to zero.

Necessary condition A condition or statement that must be satisfied to achieve a desired effect or result. For example, for a linear system it is necessary that the input $u_{1}(t)+u_{2}(t)$ results in the response $y_{1}(t)+y_{2}(t)$, where the input $u_{1}(t)$ results in the response $y_{1}(t)$ and the input $u_{2}(t)$ results in the response $y_{2}(t)$.

Node The input and output points or junctions in a signalflow graph.

Nontouching Two loops in a signal-flow graph that do not have a common node.

Overdamped The case where the damping ratio is $\zeta>1$.

Path A branch or a continuous sequence of branches that can be traversed from one signal (node) to another signal (node) in a signal-flow graph.

Poles The roots of the denominator polynomial (i.e., the roots of the characteristic equation) of the transfer function.

Positive feedback loop Feedback loop wherein the output signal is fed back so that it adds to the input signal.
Principle of superposition The law that states that if two inputs are scaled and summed and routed through a linear, time-invariant system, then the output will be identical to the sum of outputs due to the individual scaled inputs when routed through the same system.

Reference input The input to a control system often representing the desired output, denoted by $R(s)$.

Residues The constants $k_{\mathrm{i}}$ associated with the partial fraction expansion of the output $Y(s)$, when the output is written in a residue-pole format.

Signal-flow graph A diagram that consists of nodes connected by several directed branches and that is a graphical representation of a set of linear relations.

Simulation A model of a system that is used to investigate the behavior of a system by utilizing actual input signals.

Steady state The value that the output achieves after all the transient constituents of the response have faded. Also referred to as the final value.

$s$-plane The complex plane where, given the complex number $s=s+j w$, the $x$-axis (or horizontal axis) is the $s$-axis, and the $y$-axis (or vertical axis) is the $j w$-axis.

Taylor series A power series defined by $g(x)=$ $\sum_{m=0}^{\infty} \frac{g^{(m)}\left(x_{0}\right)}{m !}\left(x-x_{0}\right)^{m}$. For $m<\infty$, the series is an approximation which is used to linearize functions and system models.

Through-variable A variable that has the same value at both ends of an element.

Time constant The time interval necessary for a system to change from one state to another by a specified percentage. For a first order system, the time constant is the time it takes the output to manifest a $63.2 \%$ change due to a step input.

Transfer function The ratio of the Laplace transform of the output variable to the Laplace transform of the input variable.

Underdamped The case where the damping ratio is $\zeta<1$.

Unity feedback A feedback control system wherein the gain of the feedback loop is one.

Viscous damper A type of mechanical damper where the model of the friction force is linearly proportional to the velocity of the mass.

Zeros The roots of the numerator polynomial of the transfer function. 

\title{
CHAPTER
}

\section{State Variable Models}

\author{
3.1 Introduction 185 \\ 3.2 The State Variables of a Dynamic System 185 \\ 3.3 The State Differential Equation 188 \\ 3.4 Signal-Flow Graph and Block Diagram Models 194 \\ 3.5 Alternative Signal-Flow Graph and Block Diagram Models 205 \\ 3.6 The Transfer Function from the State Equation 209 \\ 3.7 The Time Response and the State Transition Matrix 210 \\ 3.8 Design Examples 214 \\ 3.9 Analysis of State Variable Models Using Control Design Software 228 \\ 3.10 Sequential Design Example: Disk Drive Read System 232 \\ 3.11 Summary 235
}

\section{PREVIEW}

In this chapter, we consider system modeling using time-domain methods. We consider physical systems described by an $n$ th-order ordinary differential equation. Utilizing a (nonunique) set of variables, known as state variables, we can obtain a set of first-order differential equations. We group these first-order equations using a compact matrix notation in a model known as the state variable model. The relationship between signal-flow graph models and state variable models will be investigated. Several interesting physical systems, including a space station and a printer belt drive, are presented and analyzed. The chapter concludes with the development of a state variable model for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 3, students should be able to:

$\square \quad$ Define state variables, state differential equations, and output equations.

$\square$ Recognize that state variable models can describe the dynamic behavior of physical systems and can be represented by block diagrams and signal flow graphs.

$\square$ Obtain the transfer function model from a state variable model, and vice versa.

$\square \quad$ Identify solution methods for state variable models and describe the role of the state transition matrix in obtaining the time responses.

$\square$ Explain the important role of state variable modeling in control system design. 

\subsection{INTRODUCTION}

In the preceding chapter, we developed and studied several useful approaches to the analysis and design of feedback systems. The Laplace transform was used to transform the differential equations representing the system to an algebraic equation expressed in terms of the complex variable $s$. Using this algebraic equation, we were able to obtain a transfer function representation of the input-output relationship.

In this chapter, we represent system models utilizing a set of ordinary differential equations in a convenient matrix-vector form. The time domain is the mathematical domain that incorporates the description of the system, including the inputs, outputs, and response, in terms of time, $t$. Linear time-invariant single-input, single-output models, can be represented via state variable models. Powerful mathematical concepts from linear algebra and matrix-vector analysis, as well as effective computational tools, can be utilized in the design and analysis of control systems in the time domain. Also, these time domain design and analysis methods are readily extended to nonlinear, time-varying, and multiple input-output systems. As we shall see, mathematical models of linear time-invariant physical systems can be represented in either the frequency domain or the time domain. The time domain design techniques are another tool in the designer's toolbox.

\section{A time-varying control system is a system in which one or more of the parameters of the system may vary as a function of time.}

For example, the mass of an airplane varies as a function of time as the fuel is expended during flight. A multivariable system is a system with several input and output signals.

The time-domain representation of control systems is an essential basis for modern control theory and system optimization. In later chapters, we will have an opportunity to design optimum control systems by utilizing time-domain methods. In this chapter, we develop the time-domain representation of control systems and illustrate several methods for the solution of the system time response.

\subsection{THE STATE VARIABLES OF A DYNAMIC SYSTEM}

The time-domain analysis and design of control systems uses the concept of the state of a system $[1-3,5]$.

The state of a system is a set of variables whose values, together with the input signals and the equations describing the dynamics, will provide the future state and output of the system.

For a dynamic system, the state of a system is described in terms of a set of state variables $\mathbf{x}(t)=\left(x_{1}(t), x_{2}(t), \ldots, x_{n}(t)\right)$. The state variables are those variables that determine the future behavior of a system when the present state of the FIGURE 3.1

Dynamic system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0187.jpg?height=205&width=793&top_left_y=147&top_left_x=356)

system and the inputs are known. Consider the system shown in Figure 3.1, where $y(t)$ is the output signal and $u(t)$ is the input signal. A set of state variables $x(t)=\left(x_{1}(t), x_{2}(t), \ldots, x_{n}(t)\right)$ forthesystemshownin the figureisasetsuch that knowledge of the initial values of the state variables $x\left(t_{0}\right)=\left(x_{1}\left(t_{0}\right), x_{2}\left(t_{0}\right), \ldots, x_{n}\left(t_{0}\right)\right)$ at the initial time $t_{0}$, and of the input signal $u(t)$ for $t \geq t_{0}$, suffices to determine the future values of the outputs and state variables [2].

The concept of a set of state variables that represent a dynamic system can be illustrated in terms of the spring-mass-damper system shown in Figure 3.2. The number of state variables chosen to represent this system should be as small as possible in order to avoid redundant state variables. A set of state variables sufficient to describe this system includes the position and the velocity of the mass. Therefore, we will define a set of state variables as $x(t)=\left(x_{1}(t), x_{2}(t)\right)$, where

$$
x_{1}(t)=y(t) \text { and } \quad x_{2}(t)=\frac{d y(t)}{d t} .
$$

The differential equation describes the behavior of the system and can be written as

$$
M \frac{d^{2} y(t)}{d t^{2}}+b \frac{d y(t)}{d t}+k y(t)=u(t) .
$$

To write Equation (3.1) in terms of the state variables, we substitute the state variables as already defined and obtain

$$
M \frac{d x_{2}(t)}{d t}+b x_{2}(t)+k x_{1}(t)=u(t) .
$$

Therefore, we can write the equations that describe the behavior of the springmass-damper system as the set of two first-order differential equations

$$
\frac{d x_{1}(t)}{d t}=x_{2}(t)
$$

and

$$
\frac{d x_{2}(t)}{d t}=\frac{-b}{M} x_{2}(t)-\frac{k}{M} x_{1}(t)+\frac{1}{M} u(t)
$$

This set of differential equations describes the behavior of the state of the system in terms of the rate of change of each state variable.

As another example of the state variable characterization of a system, consider the $R L C$ circuit shown in Figure 3.3. The state of this system can be described by a set of state variables $\mathbf{x}(t)=\left(x_{1}(t), x_{2}(t)\right)$, where $x_{1}(t)$ is the capacitor voltage FIGURE 3.3

An $R L C$ circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0188.jpg?height=219&width=600&top_left_y=154&top_left_x=514)

$v_{c}(t)$ and $x_{2}(t)$ is the inductor current $i_{L}(t)$. This choice of state variables is intuitively satisfactory because the stored energy of the network can be described in terms of these variables as

$$
\mathscr{E}=\frac{1}{2} L i_{L}^{2}(t)+\frac{1}{2} C v_{c}^{2}(t)
$$

Therefore $x_{1}\left(t_{0}\right)$ and $x_{2}\left(t_{0}\right)$ provide the total initial energy of the network and the state of the system at $t=t_{0}$. For a passive $R L C$ network, the number of state variables required is equal to the number of independent energy-storage elements. Utilizing Kirchhoff's current law at the junction, we obtain a first-order differential equation by describing the rate of change of capacitor voltage as

$$
i_{c}(t)=C \frac{d v_{c}(t)}{d t}=+u(t)-i_{L}(t)
$$

Kirchhoff's voltage law for the right-hand loop provides the equation describing the rate of change of inductor current as

$$
L \frac{d i_{L}(t)}{d t}=-R i_{L}(t)+v_{c}(t)
$$

The output of this system is represented by the linear algebraic equation

$$
v_{\mathrm{o}}(t)=R i_{L}(t) .
$$

We can rewrite Equations (3.6) and (3.7) as a set of two first-order differential equations in terms of the state variables $x_{1}(t)$ and $x_{2}(t)$ as

$$
\frac{d x_{1}(t)}{d t}=-\frac{1}{C} x_{2}(t)+\frac{1}{C} u(t)
$$

and

$$
\frac{d x_{2}(t)}{d t}=+\frac{1}{L} x_{1}(t)-\frac{R}{L} x_{2}(t)
$$

The output signal is then

$$
y_{1}(t)=v_{\mathrm{o}}(t)=R x_{2}(t) .
$$

Utilizing Equations (3.8) and (3.9) and the initial conditions of the network represented by $\mathbf{x}\left(t_{0}\right)=\left(x_{1}\left(t_{0}\right), x_{2}\left(t_{0}\right)\right)$, we can determine the future behavior. The state variables that describe a system are not a unique set, and several alternative sets of state variables can be chosen. For example, for a second-order system, such as the spring-mass-damper or $R L C$ circuit, the state variables may be any two independent linear combinations of $x_{1}(t)$ and $x_{2}(t)$. For the $R L C$ circuit, we might choose the set of state variables as the two voltages, $v_{c}(t)$ and $v_{L}(t)$, where $v_{L}(t)$ is the voltage drop across the inductor. Then the new state variables, $x_{1}^{*}(t)$ and $x_{2}^{*}(t)$, are related to the old state variables, $x_{1}(t)$ and $x_{2}(t)$, as

$$
x_{1}^{*}(t)=v_{c}(t)=x_{1}(t),
$$

and

$$
x_{2}^{*}(t)=v_{L}(t)=v_{c}(t)-R i_{L}(t)=x_{1}(t)-R x_{2}(t) .
$$

Equation (3.12) represents the relation between the inductor voltage and the former state variables $v_{c}(t)$ and $i_{L}(t)$. In a typical system, there are several choices of a set of state variables that specify the energy stored in a system and therefore adequately describe the dynamics of the system. It is usual to choose a set of state variables that can be readily measured.

An alternative approach to developing a model of a device is the use of the bond graph. Bond graphs can be used for electrical, mechanical, hydraulic, and thermal devices or systems as well as for combinations of various types of elements. Bond graphs produce a set of equations in the state variable form [7].

The state variables of a system characterize the dynamic behavior of a system. The engineer's interest is primarily in physical systems, where the variables typically are voltages, currents, velocities, positions, pressures, temperatures, and similar physical variables. However, the concept of system state is also useful in analyzing biological, social, and economic systems. For these systems, the concept of state is extended beyond the concept of the current configuration of a physical system to the broader viewpoint of variables that will be capable of describing the future behavior of the system.

\subsection{THE STATE DIFFERENTIAL EQUATION}

The response of a system is described by the set of first-order differential equations written in terms of the state variables $\left(x_{1}(t), x_{2}(t), \ldots, x_{n}(t)\right)$ and the inputs $\left(u_{1}(t), u_{2}(t), \ldots, u_{m}(t)\right)$. A set of linear first-order differential equations can be written in general form as

$$
\begin{aligned}
& \dot{x}_{1}(t)=a_{11} x_{1}(t)+a_{12} x_{2}(t)+\cdots+a_{1 n} x_{n}(t)+b_{11} u_{1}(t)+\cdots+b_{1 m} u_{m}(t), \\
& \dot{x}_{2}(t)=a_{21} x_{1}(t)+a_{22} x_{2}(t)+\cdots+a_{2 n} x_{n}(t)+b_{21} u_{1}(t)+\cdots+b_{2 m} u_{m}(t), \\
& \quad \vdots \\
& \dot{x}_{n}(t)=a_{n 1} x_{1}(t)+a_{n 2} x_{2}(t)+\cdots+a_{n n} x_{n}(t)+b_{n 1} u_{1}(t)+\cdots+b_{n m} u_{m}(t),
\end{aligned}
$$

where $\dot{x}(t)=d x(t) / d t$. Thus, this set of simultaneous differential equations can be written in matrix form as follows $[2,5]$ :

$$
\frac{d}{d t}\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right)=\left[\begin{array}{ccc}
a_{11} & a_{12} \cdots & a_{1 n} \\
a_{21} & a_{22} \cdots & a_{2 n} \\
\vdots & \cdots & \vdots \\
a_{n 1} & a_{n 2} \cdots & a_{n n}
\end{array}\right]\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right)+\left[\begin{array}{ccc}
b_{11} & \cdots & b_{1 n} \\
\vdots & & \vdots \\
b_{n 1} & \cdots & b_{n m}
\end{array}\right]\left(\begin{array}{c}
u_{1}(t) \\
\vdots \\
u_{m}(t)
\end{array}\right) .
$$

The column matrix consisting of the state variables is called the state vector and is written as

$$
\mathbf{x}(t)=\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right)
$$

where the boldface indicates a vector. The vector of input signals is defined as $\mathbf{u}(t)$. Then the system can be represented by the compact notation of the state differential equation as

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B u}(t)
$$

Equation (3.16) is also commonly called the state equation.

The matrix $\mathbf{A}$ is an $n \times n$ square matrix, and $\mathbf{B}$ is an $n \times m$ matrix. ${ }^{\dagger}$ The state differential equation relates the rate of change of the state of the system to the state of the system and the input signals. In general, the outputs of a linear system can be related to the state variables and the input signals by the output equation

$$
\mathbf{y}(t)=\mathbf{C x}(t)+\mathbf{D u}(t)
$$

where $y(t)$ is the set of output signals expressed in column vector form. The statespace representation (or state-variable representation) comprises the state differential equation and the output equation.

We use Equations (3.8) and (3.9) to obtain the state variable differential equation for the $R L C$ of Figure 3.3 as

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & \frac{-1}{C} \\
\frac{1}{L} & \frac{-R}{L}
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
\frac{1}{C} \\
0
\end{array}\right] u(t)
$$

†oldfaced lowercase letters denote vector quantities and boldfaced uppercase letters denote matrices. For an introduction to matrices and elementary matrix operations, refer to the MCS website and references [1] and [2]. and the output as

$$
y(t)=\left[\begin{array}{ll}
0 & R
\end{array}\right] \mathbf{x}(t) .
$$

When $R=3, L=1$, and $C=1 / 2$, we have

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & -2 \\
1 & -3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
2 \\
0
\end{array}\right] u(t)
$$

and

$$
y(t)=\left[\begin{array}{ll}
0 & 3
\end{array}\right] \mathbf{x}(t) .
$$

The solution of the state differential equation can be obtained in a manner similar to the method for solving a first-order differential equation. Consider the first-order differential equation

$$
\dot{x}(t)=a x(t)+b u(t),
$$

where $x(t)$ and $u(t)$ are scalar functions of time. We expect an exponential solution of the form $e^{a t}$. Taking the Laplace transform of Equation (3.20), we have

$$
s X(s)-x(0)=a X(s)+b U(s)
$$

therefore,

$$
X(s)=\frac{x(0)}{s-a}+\frac{b}{s-a} U(s)
$$

The inverse Laplace transform of Equation (3.21) is

$$
x(t)=e^{a t} x(0)+\int_{0}^{t} e^{+a(t-\tau)} b u(\tau) d \tau .
$$

We expect the solution of the general state differential equation to be similar to Equation (3.22) and to be of exponential form. The matrix exponential function is defined as

$$
e^{\mathbf{A} t}=\exp (\mathbf{A} t)=\mathbf{I}+\mathbf{A} t+\frac{\mathbf{A}^{2} t^{2}}{2 !}+\cdots+\frac{\mathbf{A}^{k} t^{k}}{k !}+\cdots
$$

which converges for all finite $t$ and any $\mathbf{A}[2]$. Then the solution of the state differential equation is found to be

$$
\mathbf{x}(t)=\exp (\mathbf{A} t) \mathbf{x}(0)+\int_{0}^{t} \exp [\mathbf{A}(t-\tau)] \mathbf{B} \mathbf{u}(\tau) d \tau .
$$

Equation (3.24) may be verified by taking the Laplace transform of Equation (3.16) and rearranging to obtain

$$
\mathbf{X}(s)=[s \mathbf{I}-\mathbf{A}]^{-1} \mathbf{x}(0)+[s \mathbf{I}-\mathbf{A}]^{-1} \mathbf{B} \mathbf{U}(s),
$$

where we note that $[s \mathbf{I}-\mathbf{A}]^{-1}=\mathbf{\Phi}(s)$ is the Laplace transform of $\boldsymbol{\Phi}(t)=\exp (\mathbf{A} t)$. Taking the inverse Laplace transform of Equation (3.25) and noting that the second term on the right-hand side involves the product $\boldsymbol{\Phi}(s) \mathbf{B U}(s)$, we obtain Equation (3.24). The matrix exponential function describes the unforced response of the system and is called the fundamental or state transition matrix $\boldsymbol{\Phi}(t)$. Thus, Equation (3.24) can be written as

$$
\mathbf{x}(t)=\boldsymbol{\Phi}(t) \mathbf{x}(0)+\int_{0}^{t} \boldsymbol{\Phi}(t-\tau) \mathbf{B u}(\tau) d \tau
$$

The solution to the unforced system (that is, when $\mathbf{u}(t)=0$ ) is

$$
\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t)
\end{array}\right)=\left[\begin{array}{ccc}
\phi_{11} & \cdots & \phi_{1 n}(t) \\
\phi_{21} & \cdots & \phi_{2 n}(t) \\
\vdots & & \vdots \\
\phi_{n 1} & \cdots & \phi_{n n}(t)
\end{array}\right]\left(\begin{array}{c}
x_{1}(0) \\
x_{2}(0) \\
\vdots \\
x_{n}(0)
\end{array}\right) .
$$

We note that to determine the state transition matrix, all initial conditions are set to 0 except for one state variable, and the output of each state variable is evaluated. That is, the term $\phi_{i j}(t)$ is the response of the $i$ th state variable due to an initial condition on the $j$ th state variable when there are zero initial conditions on all the other variables. We shall use this relationship between the initial conditions and the state variables to evaluate the coefficients of the transition matrix in a later section. However, first we shall develop several suitable signal-flow state models of systems and investigate the stability of the systems by utilizing these flow graphs.

\section{EXAMPLE 3.1 Two rolling carts}

Consider the system shown in Figure 3.4. The variables of interest are noted on the figure and defined as: $M_{1}, M_{2}=$ mass of carts, $p(t), q(t)=$ position of carts, $u(t)=$ external force acting on system, $k_{1}, k_{2}=$ spring constants, and

FIGURE 3.4

Two rolling carts attached with springs and dampers.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0192.jpg?height=334&width=983&top_left_y=1788&top_left_x=506)

$b_{1}, b_{2}=$ damping coefficients. The free-body diagram of mass $M_{1}$ is shown in Figure 3.5(b), where $\dot{p}(t), \dot{q}(t)=$ velocity of $M_{1}$ and $M_{2}$, respectively. We assume that the carts have negligible rolling friction. We consider any existing rolling friction to be lumped into the damping coefficients, $b_{1}$ and $b_{2}$.

Now, given the free-body diagram with forces and directions appropriately applied, we use Newton's second law (sum of the forces equals mass of the object multiplied by its acceleration) to obtain the equations of motion-one equation for each mass. For mass $M_{1}$ we have

$$
M_{1} \ddot{p}(t)+b_{1} \dot{p}(t)+k_{1} p(t)=u(t)+k_{1} q(t)+b_{1} \dot{q}(t)
$$

where

$$
\ddot{p}(t), \ddot{q}(t)=\text { acceleration of } M_{1} \text { and } M_{2} \text {, respectively. }
$$

Similarly, for mass $M_{2}$ in Figure 3.5(a), we have

$$
M_{2} \ddot{q}(t)+\left(k_{1}+k_{2}\right) q(t)+\left(b_{1}+b_{2}\right) \dot{q}(t)=k_{1} p(t)+b_{1} \dot{p}(t) .
$$

We now have a model given by the two second-order ordinary differential equations in Equations (3.28) and (3.29). We can start developing a state-space model by defining

$$
\begin{aligned}
& x_{1}(t)=p(t), \\
& x_{2}(t)=q(t) .
\end{aligned}
$$

We could have alternatively defined $x_{1}(t)=q(t)$ and $x_{2}(t)=p(t)$. The state-space model is not unique. Denoting the derivatives of $x_{1}(t)$ and $x_{2}(t)$ as $x_{3}(t)$ and $x_{4}(t)$, respectively, it follows that

$$
\begin{aligned}
& x_{3}(t)=\dot{x}_{1}(t)=\dot{p}(t), \\
& x_{4}(t)=\dot{x}_{2}(t)=\dot{q}(t) .
\end{aligned}
$$

Taking the derivative of $x_{3}(t)$ and $x_{4}(t)$ yields, respectively,

$$
\begin{gathered}
\dot{x}_{3}(t)=\ddot{p}(t)=-\frac{b_{1}}{M_{1}} \dot{p}(t)-\frac{k_{1}}{M_{1}} p(t)+\frac{1}{M_{1}} u(t)+\frac{k_{1}}{M_{1}} q(t)+\frac{b_{1}}{M_{1}} \dot{q}(t), \\
\dot{x}_{4}(t)=\ddot{q}(t)=-\frac{k_{1}+k_{2}}{M_{2}} q(t)-\frac{b_{1}+b_{2}}{M_{2}} \dot{q}(t)+\frac{k_{1}}{M_{2}} p(t)+\frac{b_{1}}{M_{2}} \dot{p}(t),
\end{gathered}
$$

where we use the relationship for $\ddot{p}(t)$ given in Equation (3.28) and the relationship for $\ddot{q}(t)$ given in Equation (3.29). But $\dot{p}(t)=x_{3}(t)$ and $\dot{q}(t)=x_{4}(t)$, so Equation (3.32) can be written as

$$
\dot{x}_{3}(t)=-\frac{k_{1}}{M_{1}} x_{1}(t)+\frac{k_{1}}{M_{1}} x_{2}(t)-\frac{b_{1}}{M_{1}} x_{3}(t)+\frac{b_{1}}{M_{1}} x_{4}(t)+\frac{1}{M_{1}} u(t)
$$

and Equation (3.33) as

$$
\dot{x}_{4}(t)=\frac{k_{1}}{M_{2}} x_{1}(t)-\frac{k_{1}+k_{2}}{M_{2}} x_{2}(t)+\frac{b_{1}}{M_{2}} x_{3}(t)-\frac{b_{1}+b_{2}}{M_{2}} x_{4}(t) .
$$

In matrix form, Equations (3.30), (3.31), (3.34), and (3.35) can be written as

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

where

$$
\begin{gathered}
\mathbf{x}(t)=\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
x_{3}(t) \\
x_{4}(t)
\end{array}\right)=\left(\begin{array}{c}
p(t) \\
q(t) \\
\dot{p}(t) \\
\dot{q}(t)
\end{array}\right), \\
\mathbf{A}=\left[\begin{array}{cccc}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-\frac{k_{1}}{M_{1}} & \frac{k_{1}}{M_{1}} & -\frac{b_{1}}{M_{1}} & \frac{b_{1}}{M_{1}} \\
\frac{k_{1}}{M_{2}} & -\frac{k_{1}+k_{2}}{M_{2}} & \frac{b_{1}}{M_{2}} & -\frac{b_{1}+b_{2}}{M_{2}}
\end{array}\right], \text { and } \mathbf{B}=\left[\begin{array}{c}
0 \\
0 \\
\frac{1}{M_{1}} \\
0
\end{array}\right],
\end{gathered}
$$

and $u(t)$ is the external force acting on the system. If we choose $p(t)$ as the output, then

$$
y(t)=\left[\begin{array}{llll}
1 & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)=\mathbf{C x}(t)
$$

Suppose that the two rolling carts have the following parameter values: $k_{1}=150 \mathrm{~N} / \mathrm{m} ; \quad k_{2}=700 \mathrm{~N} / \mathrm{m} ; b_{1}=15 \mathrm{~N} \mathrm{~s} / \mathrm{m} ; b_{2}=30 \mathrm{~N} \mathrm{~s} / \mathrm{m} ; M_{1}=5 \mathrm{~kg} ; \quad$ and $M_{2}=20 \mathrm{~kg}$. The response of the two rolling cart system is shown in Figure 3.6 when the initial conditions are $p(0)=10 \mathrm{~cm}, q(0)=0$, and $\dot{p}(0)=\dot{q}(0)=0$ and there is no input driving force, that is, $u(t)=0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0194.jpg?height=270&width=776&top_left_y=1690&top_left_x=221)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0194.jpg?height=270&width=743&top_left_y=1690&top_left_x=1028)

(b)

FIGURE 3.5 Free-body diagrams of the two rolling carts. (a) Cart 2; (b) Cart 1. FIGURE 3.6

Initial condition response of the two cart system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0195.jpg?height=806&width=1002&top_left_y=166&top_left_x=426)

\subsection{SIGNAL-FLOW GRAPH AND BLOCK DIAGRAM MODELS}

The state of a system describes the dynamic behavior where the dynamics of the system are represented by a set of first-order differential equations. Alternatively, the dynamics of the system can be represented by a state differential equation as in Equation (3.16). In either case, it is useful to develop a graphical model of the system and use this model to relate the state variable concept to the familiar transfer function representation. The graphical model can be represented via signal-flow graphs or block diagrams.

As we have learned in previous chapters, a system can be meaningfully described by an input-output relationship, the transfer function $G(s)$. For example, if we are interested in the relation between the output voltage and the input voltage of the network of Figure 3.3, we can obtain the transfer function

$$
G(s)=\frac{V_{0}(s)}{U(s)} .
$$

The transfer function for the $R L C$ network of Figure 3.3 is of the form

$$
G(s)=\frac{V_{0}(s)}{U(s)}=\frac{\alpha}{s^{2}+\beta s+\gamma},
$$

where $\alpha, \beta$, and $\gamma$ are functions of the circuit parameters $R, L$, and $C$, respectively. The values of $\alpha, \beta$, and $\gamma$ can be determined from the differential equations that describe the circuit. For the $R L C$ circuit (see Equations 3.8 and 3.9), we have

$$
\begin{aligned}
& \dot{x}_{1}(t)=-\frac{1}{C} x_{2}(t)+\frac{1}{C} u(t), \\
& \dot{x}_{2}(t)=\frac{1}{L} x_{1}(t)-\frac{R}{L} x_{2}(t),
\end{aligned}
$$

and

$$
v_{o}(t)=R x_{2}(t) .
$$

The flow graph representing these simultaneous equations is shown in Figure 3.7(a), where $1 / s$ indicates an integration. The corresponding block diagram model is shown in Figure 3.7(b). The transfer function is found to be

$$
\frac{V_{\mathrm{o}}(s)}{U(s)}=\frac{R /\left(L C s^{2}\right)}{1+R /(L s)+1 /\left(L C s^{2}\right)}=\frac{R /(L C)}{s^{2}+(R / L) s+1 /(L C)} .
$$

Many electric circuits, electromechanical systems, and other control systems are not as simple as the $R L C$ circuit of Figure 3.3, and it is often a difficult task to determine a set of first-order differential equations describing the system. Therefore, it is often simpler to derive the transfer function of the system and then derive the state model from the transfer function.

The signal-flow graph state model and the block diagram model can be readily derived from the transfer function of a system. However, as we noted in Section 3.3,

FIGURE 3.7

$R L C$ network. (a) Signal-flow graph. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0196.jpg?height=294&width=1094&top_left_y=1243&top_left_x=544)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0196.jpg?height=372&width=1164&top_left_y=1632&top_left_x=509)

(b) there is more than one alternative set of state variables, and therefore there is more than one possible form for the signal-flow graph and block diagram models. There are several key canonical forms of the state-variable representation, such as the phase variable canonical form, that we will investigate in this chapter. In general, we can represent a transfer function as

$$
G(s)=\frac{Y(s)}{U(s)}=\frac{b_{m} s^{m}+b_{m-1} s^{m-1}+\cdots+b_{1} s+b_{0}}{s^{n}+a_{n-1} s^{n-1}+\cdots+a_{1} s+a_{0}}
$$

where $n \geq m$, and all the $a$ and $b$ coefficients are real numbers. If we multiply the numerator and denominator by $s^{-n}$, we obtain

$$
G(s)=\frac{b_{m} s^{-(n-m)}+b_{m-1} s^{-(n-m+1)}+\cdots+b_{1} s^{-(n-1)}+b_{0} s^{-n}}{1+a_{n-1} s^{-1}+\cdots+a_{1} s^{-(n-1)}+a_{0} s^{-n}} .
$$

Our familiarity with Mason's signal-flow gain formula allows us to recognize the familiar feedback factors in the denominator and the forward-path factors in the numerator. Mason's signal-flow gain formula was discussed in Section 2.7 and is written as

$$
G(s)=\frac{Y(s)}{U(s)}=\frac{\sum_{k} P_{k}(s) \Delta_{k}(s)}{\Delta(s)} .
$$

When all the feedback loops are touching and all the forward paths touch the feedback loops, Equation (3.43) reduces to

$$
G(s)=\frac{\sum_{k} P_{k}(s)}{1-\sum_{q-1}^{N} L_{q}(s)}=\frac{\text { Sum of the forward }- \text { path factors }}{1-\text { sum of the feedback loop factors }} .
$$

There are several flow graphs that could represent the transfer function. Two flow graph configurations based on Mason's signal-flow gain formula are of particular interest, and we will consider these in greater detail. In the next section, we will consider two additional configurations: the physical state variable model and the diagonal (or Jordan canonical) form model.

To illustrate the derivation of the signal-flow graph state model, let us initially consider the fourth-order transfer function

$$
\begin{aligned}
G(s) & =\frac{Y(s)}{U(s)}=\frac{b_{0}}{s^{4}+a_{3} s^{3}+a_{2} s^{2}+a_{1} s+a_{0}} \\
& =\frac{b_{0} s^{-4}}{1+a_{3} s^{-1}+a_{2} s^{-2}+a_{1} s^{-3}+a_{0} s^{-4}} .
\end{aligned}
$$

First we note that the system is fourth order, and hence we identify four state variables $\left(x_{1}(t), x_{2}(t), x_{3}(t), x_{4}(t)\right)$. Recalling Mason's signal-flow gain formula, we note that the denominator can be considered to be 1 minus the sum of the loop gains. Furthermore, the numerator of the transfer function is equal to the forward-path factor of the flow graph. The flow graph must include a minimum number of integrators equal to the order of the system. Therefore, we use four integrators to represent this system. The necessary flow graph nodes and the four integrators are shown in Figure 3.8. FIGURE 3.8

Flow graph nodes and integrators for fourth-order system.
FIGURE 3.9

Model for $G(s)$ of Equation (3.45). (a) Signal-flow graph. (b) Block diagram.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0198.jpg?height=440&width=1130&top_left_y=166&top_left_x=490)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0198.jpg?height=456&width=1160&top_left_y=708&top_left_x=521)

(b)

Considering the simplest series interconnection of integrators, we can represent the transfer function by the flow graph of Figure 3.9. Examining this figure, we note that all the loops are touching and that the transfer function of this flow graph is indeed Equation (3.45). The reader can readily verify this by noting that the forward-path factor of the flow graph is $b_{0} / s^{4}$ and the denominator is equal to 1 minus the sum of the loop gains.

We can also consider the block diagram model of Equation (3.45). Rearranging the terms in Equation (3.45) and taking the inverse Laplace transform yields the differential equation model

$$
\begin{aligned}
\frac{d^{4}\left(y(t) / b_{0}\right)}{d t^{4}} & +a_{3} \frac{d^{3}\left(y(t) / b_{0}\right)}{d t^{3}}+a_{2} \frac{d^{2}\left(y(t) / b_{0}\right)}{d t^{2}}+a_{1} \frac{d\left(y(t) / b_{0}\right)}{d t} \\
& +a_{0}\left(y(t) / b_{0}\right)=u(t) .
\end{aligned}
$$

Define the four state variables as follows:

$$
\begin{aligned}
& x_{1}(t)=y(t) / b_{0} \\
& x_{2}(t)=\dot{x}_{1}(t)=\dot{y}(t) / b_{0} \\
& x_{3}(t)=\dot{x}_{2}(t)=\ddot{y}(t) / b_{0} \\
& x_{4}(t)=\dot{x}_{3}(t)=\dddot{y}(t) / b_{0} .
\end{aligned}
$$

Then it follows that the fourth-order differential equation can be written equivalently as four first-order differential equations, namely,

$$
\begin{aligned}
& \dot{x}_{1}(t)=x_{2}(t), \\
& \dot{x}_{2}(t)=x_{3}(t), \\
& \dot{x}_{3}(t)=x_{4}(t),
\end{aligned}
$$

and

$$
\dot{x}_{4}(t)=-a_{0} x_{1}(t)-a_{1} x_{2}(t)-a_{2} x_{3}(t)-a_{3} x_{4}(t)+u(t) ;
$$

and the corresponding output equation is

$$
y(t)=b_{0} x_{1}(t) .
$$

The block diagram model can be readily obtained from the four first-order differential equations as illustrated in Figure 3.9(b).

Now consider the fourth-order transfer function when the numerator is a polynomial in $s$, so that we have

$$
\begin{aligned}
G(s) & =\frac{b_{3} s^{3}+b_{2} s^{2}+b_{1} s+b_{0}}{s^{4}+a_{3} s^{3}+a_{2} s^{2}+a_{1} s+a_{0}} \\
& =\frac{b_{3} s^{-1}+b_{2} s^{-2}+b_{1} s^{-3}+b_{0} s^{-4}}{1+a_{3} s^{-1}+a_{2} s^{-2}+a_{1} s^{-3}+a_{0} s^{-4}} .
\end{aligned}
$$

The numerator terms represent forward-path factors in Mason's signal-flow gain formula. The forward paths will touch all the loops, and a suitable signal-flow graph realization of Equation (3.46) is shown in Figure 3.10(a). The forward-path factors are $b_{3} / s, b_{2} / s^{2}, b_{1} / s^{3}$, and $b_{0} / s^{4}$ as required to provide the numerator of the transfer function. Recall that Mason's signal-flow gain formula indicates that the numerator of the transfer function is simply the sum of the forward-path factors. This general form of a signal-flow graph can represent the general transfer function of Equation (3.46) by utilizing $n$ feedback loops involving the $a_{n}$ coefficients and $m$ forward-path factors involving the $b_{m}$ coefficients. The general form of the flow graph state model and the block diagram model shown in Figure 3.10 is called the phase variable

\section{canonical form.}

The state variables are identified in Figure 3.10 as the output of each energy storage element, that is, the output of each integrator. To obtain the set of first-order differential equations representing the state model of Equation (3.46), we will introduce a new set of flow graph nodes immediately preceding each integrator of Figure 3.10(a) [5,6]. The nodes are placed before each integrator, and therefore they represent the derivative of the output of each integrator. The signal-flow graph, including the added nodes, is shown in Figure 3.11. Using the flow graph of this figure, we are able to obtain the following set of first-order differential equations describing the state of the model:

$$
\begin{aligned}
& \dot{x}_{1}(t)=x_{2}(t), \quad \dot{x}_{2}(t)=x_{3}(t), \quad \dot{x}_{3}(t)=x_{4}(t), \\
& \dot{x}_{4}(t)=-a_{0} x_{1}(t)-a_{1} x_{2}(t)-a_{2} x_{3}(t)-a_{3} x_{4}(t)+u(t) .
\end{aligned}
$$

In this equation, $x_{1}(t), x_{2}(t), \ldots x_{n}(t)$ are the $n$ phase variables. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0200.jpg?height=407&width=1040&top_left_y=159&top_left_x=564)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0200.jpg?height=701&width=1367&top_left_y=670&top_left_x=389)

(b)

FIGURE 3.10 Model for $G(s)$ of Equation (3.46) in the phase variable format. (a) Signal-flow graph. (b) Block diagram.

FIGURE 3.11

Flow graph of Figure 3.10 with nodes inserted.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0200.jpg?height=421&width=1249&top_left_y=1706&top_left_x=521)

The block diagram model can also be constructed directly from Equation (3.46). Define the intermediate variable $Z(s)$ and rewrite Equation (3.46) as

$$
G(s)=\frac{Y(s)}{U(s)}=\frac{b_{3} s^{3}+b_{2} s^{2}+b_{1} s+b_{0}}{s^{4}+a_{3} s^{3}+a_{2} s^{2}+a_{1} s+a_{0}} \frac{Z(s)}{Z(s)} .
$$

Notice that, by multiplying by $Z(s) / Z(s)$, we do not change the transfer function, $G(s)$. Equating the numerator and denominator polynomials yields

$$
Y(s)=\left[b_{3} s^{3}+b_{2} s^{2}+b_{1} s+b_{0}\right] Z(s)
$$

and

$$
U(s)=\left[s^{4}+a_{3} s^{3}+a_{2} s^{2}+a_{1} s+a_{0}\right] Z(s) .
$$

Taking the inverse Laplace transform of both equations yields the differential equations

$$
y(t)=b_{3} \frac{d^{3} z(t)}{d t^{3}}+b_{2} \frac{d^{2} z(t)}{d t^{2}}+b_{1} \frac{d z(t)}{d t}+b_{0} z(t)
$$

and

$$
u(t)=\frac{d^{4} z(t)}{d t^{4}}+a_{3} \frac{d^{3} z(t)}{d t^{3}}+a_{2} \frac{d^{2} z(t)}{d t^{2}}+a_{1} \frac{d z(t)}{d t}+a_{0} z(t) .
$$

Define the four state variables as follows:

$$
\begin{aligned}
& x_{1}(t)=z(t) \\
& x_{2}(t)=\dot{x}_{1}(t)=\dot{z}(t) \\
& x_{3}(t)=\dot{x}_{2}(t)=\ddot{z}(t) \\
& x_{4}(t)=\dot{x}_{3}(t)=\dddot{z}(t) .
\end{aligned}
$$

Then the differential equation can be written equivalently as

$$
\begin{aligned}
& \dot{x}_{1}(t)=x_{2}(t), \\
& \dot{x}_{2}(t)=x_{3}(t), \\
& \dot{x}_{3}(t)=x_{4}(t),
\end{aligned}
$$

and

$$
\dot{x}_{4}(t)=-a_{0} x_{1}(t)-a_{1} x_{2}(t)-a_{2} x_{3}(t)-a_{3} x_{4}(t)+u(t),
$$

and the corresponding output equation is

$$
y(t)=b_{0} x_{1}(t)+b_{1} x_{2}(t)+b_{2} x_{3}(t)+b_{3} x_{4}(t) .
$$

The block diagram model can be readily obtained from the four first-order differential equations and the output equation as illustrated in Figure 3.10(b). In matrix form, we can represent the system in Equation (3.46) as

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t),
$$

or

$$
\frac{d}{d t}\left(\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4}
\end{array}\right)=\left[\begin{array}{cccc}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-a_{0} & -a_{1} & -a_{2} & -a_{3}
\end{array}\right]\left(\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4}
\end{array}\right)+\left[\begin{array}{l}
0 \\
0 \\
0 \\
1
\end{array}\right] u(t) .
$$

The output is

$$
y(t)=\mathbf{C x}(t)=\left[\begin{array}{llll}
b_{0} & b_{1} & b_{2} & b_{3}
\end{array}\right]\left(\begin{array}{c}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4}
\end{array}\right) .
$$

The graphical structures of Figure 3.10 are not unique representations of Equation (3.46); another equally useful structure can be obtained. A flow graph that represents Equation (3.46) equally well is shown in Figure 3.12(a). In this case, the forward-path factors are obtained by feeding forward the signal $U(s)$. We will call this model the input feedforward canonical form.

Then the output signal $y(t)$ is equal to the first state variable $x_{1}(t)$. This flow graph structure has the forward-path factors $b_{0} / s^{4}, b_{1} / s^{3}, b_{2} / s^{2}, b_{3} / s$, and all the forward paths touch the feedback loops. Therefore, the resulting transfer function is indeed equal to Equation (3.46).

Associated with the input feedforward format, we have the set of first-order differential equations

$$
\begin{array}{ll}
\dot{x}_{1}(t)=-a_{3} x_{1}(t)+x_{2}(t)+b_{3} u(t), & \dot{x}_{2}(t)=-a_{2} x_{1}(t)+x_{3}(t)+b_{2} u(t), \\
\dot{x}_{3}(t)=-a_{1} x_{1}(t)+x_{4}(t)+b_{1} u(t), & \text { and } \quad \dot{x}_{4}(t)=-a_{0} x_{1}(t)+b_{0} u(t) .
\end{array}
$$

Thus, in matrix form, we have

$$
\frac{d \mathbf{x}(t)}{d t}=\left[\begin{array}{cccc}
-a_{3} & 1 & 0 & 0 \\
-a_{2} & 0 & 1 & 0 \\
-a_{1} & 0 & 0 & 1 \\
-a_{0} & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
b_{3} \\
b_{2} \\
b_{1} \\
b_{0}
\end{array}\right] u(t)
$$

and

$$
y(t)=\left[\begin{array}{llll}
1 & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
$$

Although the input feedforward canonical form of Figure 3.12 represents the same transfer function as the phase variable canonical form of Figure 3.10, the state variables of each graph are not equal. Furthermore we recognize that the initial conditions of the system can be represented by the initial conditions of the integrators, 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0203.jpg?height=398&width=1263&top_left_y=154&top_left_x=239)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0203.jpg?height=694&width=1566&top_left_y=655&top_left_x=87)

(b)

FIGURE 3.12 (a) Alternative flow graph state model for Equation (3.46). This model is called the input feedforward canonical form. (b) Block diagram of the input feedforward canonical form.

$x_{1}(0), x_{2}(0), \ldots, x_{n}(0)$. Let us consider a control system and determine the state differential equation by utilizing the two forms of flow graph state models.

\section{EXAMPLE 3.2 Two state variable models}

Consider a closed-loop transfer function

$$
T(s)=\frac{Y(s)}{U(s)}=\frac{2 s^{2}+8 s+6}{s^{3}+8 s^{2}+16 s+6} .
$$

Multiplying the numerator and denominator by $s^{-3}$, we have

$$
T(s)=\frac{Y(s)}{U(s)}=\frac{2 s^{-1}+8 s^{-2}+6 s^{-3}}{1+8 s^{-1}+16 s^{-2}+6 s^{-3}} .
$$

FIGURE 3.13

(a) Phase variable flow graph state model for $T(s)$.

(b) Block diagram for the phase variable canonical form.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0204.jpg?height=330&width=887&top_left_y=155&top_left_x=676)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0204.jpg?height=541&width=1209&top_left_y=581&top_left_x=508)

(b)

The first model is the phase variable state model using the feedforward of the state variables to provide the output signal. The signal-flow graph and block diagram are shown in Figures 3.13(a) and (b), respectively. The state differential equation is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-6 & -16 & -8
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t),
$$

and the output is

$$
y(t)=\left[\begin{array}{lll}
6 & 8 & 2
\end{array}\right] \mathbf{x}(t) .
$$

The second model uses the feedforward of the input variable, as shown in Figure 3.14. The vector differential equation for the input feedforward model is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
-8 & 1 & 0 \\
-16 & 0 & 1 \\
-6 & 0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
2 \\
8 \\
6
\end{array}\right] u(t)
$$

and the output is

$$
y(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
$$

FIGURE 3.14

(a) Alternative flow graph state model for $T(s)$ using the input feedforward canonical form.

(b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0205.jpg?height=327&width=1003&top_left_y=161&top_left_x=484)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0205.jpg?height=531&width=1209&top_left_y=586&top_left_x=376)

(b)

We note that it was not necessary to factor the numerator or denominator polynomial to obtain the state differential equations for the phase variable model or the input feedforward model. Avoiding the factoring of polynomials permits us to avoid the tedious effort involved. Both models require three integrators because the system is third order. However, it is important to emphasize that the state variables of the state model of Figure 3.13 are not identical to the state variables of the state model of Figure 3.14. Of course, one set of state variables is related to the other set of state variables by an appropriate linear transformation of variables. A linear matrix transformation is represented by $\mathbf{z}=\mathbf{M x}$, which transforms the $\mathbf{x}$-vector into the $\mathbf{z}$-vector by means of the $\mathbf{M}$ matrix. Finally, we note that the transfer function of Equation (3.41) represents a single-output linear constant coefficient system; thus, the transfer function can represent an $n$ th-order differential equation

$$
\begin{aligned}
\frac{d^{n} y(t)}{d t^{n}}+a_{n-1} \frac{d^{n-1} y(t)}{d t^{n-1}}+\cdots+a_{0} y(t)= & \frac{d^{m} u(t)}{d t^{m}}+b_{m-1} \frac{d^{m-1} u(t)}{d t^{m-1}} \\
& +\cdots+b_{0} u(t)
\end{aligned}
$$

Accordingly, we can obtain the $n$ first-order equations for the $n$ th-order differential equation by utilizing the phase variable model or the input feedforward model of this section. 

\subsection{ALTERNATIVE SIGNAL-FLOW GRAPH AND BLOCK DIAGRAM MODELS}

Often the control system designer studies an actual control system block diagram that represents physical devices and variables. An example of a model of a DC motor with shaft velocity as the output is shown in Figure 3.15 [9]. We wish to select the physical variables as the state variables. Thus, we select: $x_{1}(t)=y(t)$, the velocity output; $x_{2}(t)=i(t)$, the field current; and the third state variable, $x_{3}(t)$, is selected to be $x_{3}(t)=\frac{1}{4} r(t)-\frac{1}{20} u(t)$, where $u(t)$ is the field voltage. We may draw the models for these physical variables, as shown in Figure 3.16. Note that the state variables $x_{1}(t), x_{2}(t)$, and $x_{3}(t)$ are identified on the models. We will denote this format as the physical state variable model. This model is particularly useful when we can measure the physical state variables. Note that the model of each block is separately determined. For example, note that the transfer function for the controller is

$$
\frac{U(s)}{R(s)}=G_{c}(s)=\frac{5(s+1)}{s+5}=\frac{5+5 s^{-1}}{1+5 s^{-1}},
$$

and the flow graph between $R(s)$ and $U(s)$ represents $G_{c}(s)$.

FIGURE 3.15

A block diagram model of an openloop DC motor control with velocity as the output.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0206.jpg?height=536&width=1430&top_left_y=1055&top_left_x=334)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0206.jpg?height=294&width=1495&top_left_y=1683&top_left_x=238)

(b)

FIGURE 3.16 (a) The physical state variable signal-flow graph for the block diagram of Figure 3.15. (b) Physical state block diagram. The state variable differential equation is directly obtained from Figure 3.16 as

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
-3 & 6 & 0 \\
0 & -2 & -20 \\
0 & 0 & -5
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
5 \\
1
\end{array}\right] r(t)
$$

and

$$
y=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
$$

A second form of the model we need to consider is the decoupled response modes. The overall input-output transfer function of the block diagram system shown in Figure 3.15 is

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{30(s+1)}{(s+5)(s+2)(s+3)}=\frac{q(s)}{\left(s-s_{1}\right)\left(s-s_{2}\right)\left(s-s_{3}\right)},
$$

and the transient response has three modes dictated by $s_{1}, s_{2}$, and $s_{3}$. These modes are indicated by the partial fraction expansion as

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{k_{1}}{s+5}+\frac{k_{2}}{s+2}+\frac{k_{3}}{s+3},
$$

where we find that $k_{1}=-20, k_{2}=-10$, and $k_{3}=30$. The decoupled state variable model representing Equation (3.61) is shown in Figure 3.17. The state variable matrix differential equation is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
-5 & 0 & 0 \\
0 & -2 & 0 \\
0 & 0 & -3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
1 \\
1
\end{array}\right] r(t)
$$

and

$$
y(t)=\left[\begin{array}{lll}
-20 & -10 & 30
\end{array}\right] \mathbf{x}(t) .
$$

Note that we chose $x_{1}(t)$ as the state variable associated with $s_{1}=-5, x_{2}(t)$ associated with $s_{2}=-2$, and $x_{3}(t)$ associated with $s_{3}=-3$, as indicated in Figure 3.17. This choice of state variables is arbitrary; for example, $x_{1}(t)$ could be chosen as associated with the factor $s+2$.

The decoupled form of the state differential matrix equation displays the distinct model poles $-s_{1},-s_{2}, \ldots,-s_{n}$, and this format is often called the diagonal canonical form. A system can always be written in diagonal form if it possesses distinct poles; otherwise, it can only be written in a block diagonal form, known as the Jordan canonical form [24]. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0208.jpg?height=501&width=736&top_left_y=192&top_left_x=225)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0208.jpg?height=670&width=740&top_left_y=154&top_left_x=1013)

(b)

FIGURE 3.17 (a) The decoupled state variable flow graph model for the system shown in block diagram form in Figure 3.15. (b) The decoupled state variable block diagram model.

\section{EXAMPLE 3.3 Inverted pendulum control}

The problem of balancing a broomstick on a person's hand is illustrated in Figure 3.18. The only equilibrium condition is $\theta(t)=0$ and $d \theta(t) / d t=0$. The problem of balancing a broomstick on one's hand is not unlike the problem of controlling the attitude of a missile during the initial stages of launch. This problem is the classic and intriguing problem of the inverted pendulum mounted on a cart, as shown in Figure 3.19. The cart must be moved so that mass $m$ is always in an upright position. The state variables must be expressed in terms of the angular rotation $\theta(t)$ and the position of the cart $y(t)$. The differential equations describing the motion of the system can be obtained by writing the sum of the forces in the horizontal direction and the sum of the moments about the pivot point $[2,3,10,23]$. We will assume that $M \gg m$ and the angle of rotation $\theta(t)$, is small so that the equations are linear. The sum of the forces in the horizontal direction is

$$
M \ddot{y}(t)+m l \ddot{\theta}(t)-u(t)=0,
$$

where $u(s)$ equals the force on the cart, and $l$ is the distance from the mass $m$ to the pivot point. The sum of the torques about the pivot point is

$$
m l \ddot{y}(t)+m l^{2} \ddot{\theta}(t)-m \lg \theta(t)=0 .
$$

The state variables for the two second-order equations are chosen as $\left(x_{1}(t)\right.$, $\left.x_{2}(t), x_{3}(t), x_{4}(t)\right)=(y(t), \dot{y}(t), \theta(t), \dot{\theta}(t))$. Then Equations (3.63) and (3.64) are written in terms of the state variables as

$$
M \dot{x}_{2}(t)+m l \dot{x}_{4}(t)-u(t)=0
$$

and

$$
\dot{x}_{2}(t)+l \dot{x}_{4}(t)-g x_{3}(t)=0 .
$$

FIGURE 3.18

An inverted pendulum balanced on a person's hand by moving the hand to reduce $\theta(t)$.

Assume, for ease, that the pendulum rotates in the $x-y$ plane.

FIGURE 3.19

A cart and an inverted pendulum. The pendulum is constrained to pivot in the vertical plane.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0209.jpg?height=868&width=628&top_left_y=152&top_left_x=375)

To obtain the necessary first-order differential equations, we solve for $l \dot{x}_{4}(t)$ in Equation (3.66) and substitute into Equation (3.65) to obtain

$$
M \dot{x}_{2}(t)+\operatorname{mgx}_{3}(t)=u(t),
$$

since $M \gg m$. Substituting $\dot{x}_{2}(t)$ from Equation (3.65) into Equation (3.66), we have

$$
M l \dot{x}_{4}(t)-M g x_{3}(t)+u(t)=0 .
$$

Therefore, the four first-order differential equations can be written as

$$
\begin{aligned}
& \dot{x}_{1}(t)=x_{2}(t), \quad \dot{x}_{2}(t)=-\frac{m g}{M} x_{3}(t)+\frac{1}{M} u(t), \\
& \dot{x}_{3}(t)=x_{4}(t), \quad \text { and } \quad \dot{x}_{4}(t)=\frac{g}{l} x_{3}(t)-\frac{1}{M l} u(t) .
\end{aligned}
$$

Thus, the system matrices are

$$
\mathbf{A}=\left[\begin{array}{cccc}
0 & 1 & 0 & 0 \\
0 & 0 & -m g / M & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & g / l & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{c}
0 \\
1 / M \\
0 \\
-1 /(M l)
\end{array}\right]
$$



\subsection{THE TRANSFER FUNCTION FROM THE STATE EQUATION}

Given a transfer function $G(s)$, we can obtain the state variable equations using the signal-flow graph model. Now we turn to the matter of determining the transfer function $G(s)$ of a single-input, single-output (SISO) system. Recalling Equations (3.16) and (3.17), we have

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

and

$$
y(t)=\mathbf{C x}(t)+\mathbf{D} u(t)
$$

where $y(t)$ is the single output and $u(s)$ is the single input. The Laplace transforms of Equations (3.71) and (3.72) are

$$
s \mathbf{X}(s)=\mathbf{A} \mathbf{X}(s)+\mathbf{B} U(s)
$$

and

$$
Y(s)=\mathbf{C X}(s)+\mathbf{D} U(s)
$$

where $\mathbf{B}$ is an $n \times 1$ matrix, since $U(s)$ is a single input. Note that we do not include initial conditions, since we seek the transfer function. Rearranging Equation (3.73), we obtain

$$
(s \mathbf{I}-\mathbf{A}) \mathbf{X}(s)=\mathbf{B} U(s) .
$$

Since $[s \mathbf{I}-\mathbf{A}]^{-1}=\boldsymbol{\Phi}(s)$, we have

$$
\mathbf{X}(s)=\boldsymbol{\Phi}(s) \mathbf{B} U(s) .
$$

Substituting $\mathbf{X}(s)$ into Equation (3.74), we obtain

$$
Y(s)=[\mathbf{C \Phi}(s) \mathbf{B}+\mathbf{D}] U(s) .
$$

Therefore, the transfer function $G(s)=Y(s) / U(s)$ is

$$
G(s)=\mathbf{C} \boldsymbol{\Phi}(s) \mathbf{B}+\mathbf{D}
$$

\section{EXAMPLE 3.4 Transfer function of an $\boldsymbol{R} \boldsymbol{L} \boldsymbol{C}$ circuit}

Let us determine the transfer function $G(s)=Y(s) / U(s)$ for the $R L C$ circuit of Figure 3.3 as described by the differential equations (see Equations 3.18 and 3.19):

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & \frac{-1}{C} \\
\frac{1}{L} & \frac{-R}{L}
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
\frac{1}{C} \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & R] \mathbf{x}(t) .
\end{array}\right.
\end{aligned}
$$

Then we have

$$
[s \mathbf{I}-\mathbf{A}]=\left[\begin{array}{cc}
s & \frac{1}{C} \\
\frac{-1}{L} & s+\frac{R}{L}
\end{array}\right]
$$

Therefore, we obtain

$$
\Phi(s)=[s \mathbf{I}-\mathbf{A}]^{-1}=\frac{1}{\Delta(s)}\left[\begin{array}{cc}
\left(s+\frac{R}{L}\right) & \frac{-1}{C} \\
\frac{1}{L} & s
\end{array}\right],
$$

where

$$
\Delta(s)=s^{2}+\frac{R}{L} s+\frac{1}{L C}
$$

Then the transfer function is

$$
\begin{gathered}
G(s)=\left[\begin{array}{ll}
0 & R
\end{array}\right]\left[\begin{array}{cc}
\frac{s+\frac{R}{L}}{\Delta(s)} & \frac{-1}{C \Delta(s)} \\
\frac{1}{L \Delta(s)} & \frac{s}{\Delta(s)}
\end{array}\right]\left[\begin{array}{c}
1 \\
\frac{1}{C} \\
0
\end{array}\right] \\
=\frac{R /(L C)}{\Delta(s)}=\frac{R /(L C)}{s^{2}+\frac{R}{L} s+\frac{1}{L C}}
\end{gathered}
$$

which agrees with the result Equation (3.40) obtained from the flow graph model using Mason's signal-flow gain formula.

\subsection{THE TIME RESPONSE AND THE STATE TRANSITION MATRIX}

It is often desirable to obtain the time response of the state variables of a control system and thus examine the performance of the system. The transient response of a system can be readily obtained by evaluating the solution to the state vector differential equation. In Section 3.3, we found that the solution for the state differential Equation (3.26) was

$$
\mathbf{x}(t)=\boldsymbol{\Phi}(t) \mathbf{x}(0)+\int_{0}^{t} \boldsymbol{\Phi}(t-\tau) \mathbf{B u}(\tau) d \tau .
$$

If the initial conditions $\mathbf{x}(0)$, the input $\mathbf{u}(\tau)$, and the state transition matrix $\boldsymbol{\Phi}(t)$ are known, the time response of $\mathbf{x}(t)$ can be obtained. Thus the problem focuses on the evaluation of $\boldsymbol{\Phi}(t)$, the state transition matrix that represents the response of the system. Fortunately, the state transition matrix can be readily evaluated by using the signal-flow graph techniques.

Before proceeding to the evaluation of the state transition matrix using signal-flow graphs, we should note that several other methods exist for evaluating the transition matrix, such as the evaluation of the exponential series

$$
\boldsymbol{\Phi}(t)=\exp (\mathbf{A} t)=\sum_{k=0}^{\infty} \frac{\mathbf{A}^{k} t^{k}}{k !}
$$

in a truncated form $[2,8]$. Several efficient methods exist for the evaluation of $\Phi(t)$ by means of a computer algorithm [21].

In Equation (3.25), we found that $\boldsymbol{\Phi}(s)=[s \mathbf{I}-\mathbf{A}]^{-1}$. Therefore, if $\boldsymbol{\Phi}(s)$ is obtained by completing the matrix inversion, we can obtain $\boldsymbol{\Phi}(t)$ by noting that $\boldsymbol{\Phi}(t)=\mathscr{L}^{-1}\{\boldsymbol{\Phi}(s)\}$. The matrix inversion process is generally unwieldy for higher-order systems.

The usefulness of the signal-flow graph state model for obtaining the state transition matrix becomes clear upon consideration of the Laplace transformation version of Equation (3.80) when the input is zero. Taking the Laplace transformation of Equation (3.80) when $\mathbf{u}(\tau)=0$, we have

$$
\mathbf{X}(s)=\boldsymbol{\Phi}(s) \mathbf{x}(0) .
$$

Therefore, we can evaluate the Laplace transform of the transition matrix from the signal-flow graph by determining the relation between a state variable $X_{i}(s)$ and the state initial conditions $\left[x_{1}(0), x_{2}(0), \ldots, x_{n}(0)\right]$. Then the state transition matrix is the inverse transform of $\boldsymbol{\Phi}(s)$; that is,

$$
\boldsymbol{\Phi}(t)=\mathscr{L}^{-1}\{\boldsymbol{\Phi}(s)\}
$$

The relationship between a state variable $X_{i}(s)$ and the initial conditions $\mathbf{x}(0)$ is obtained by using Mason's signal-flow gain formula. Thus, for a second-order system, we would have

$$
\begin{aligned}
& X_{1}(s)=\phi_{11}(s) x_{1}(0)+\phi_{12}(s) x_{2}(0), \\
& X_{2}(s)=\phi_{21}(s) x_{1}(0)+\phi_{22}(s) x_{2}(0),
\end{aligned}
$$

and the relation between $X_{2}(s)$ as an output and $x_{1}(0)$ as an input can be evaluated by Mason's signal-flow gain formula. All the elements of the state transition matrix, $\phi_{i j}(s)$, can be obtained by evaluating the individual relationships between $X_{i}(s)$ and $x_{j}(0)$ from the state model flow graph. An example will illustrate this approach to determining the transition matrix.

\section{EXAMPLE 3.5 Evaluation of the state transition matrix}

We will consider the $R L C$ network of Figure 3.3. We seek to evaluate $\boldsymbol{\Phi}(s)$ by (1) determining the matrix inversion $\boldsymbol{\Phi}(s)=[s \mathbf{I}-\mathbf{A}]^{-1}$, and (2) using the signal-flow diagram and Mason's signal-flow gain formula. First, we determine $\boldsymbol{\Phi}(s)$ by evaluating $\boldsymbol{\Phi}(s)=[s \mathbf{I}-\mathbf{A}]^{-1}$. We note from Equation (3.18) that

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & -2 \\
1 & -3
\end{array}\right]
$$

Then

$$
[s \mathbf{I}-\mathbf{A}]=\left[\begin{array}{cc}
s & 2 \\
-1 & s+3
\end{array}\right]
$$

The inverse matrix is

$$
\boldsymbol{\Phi}(s)=[s \mathbf{I}-\mathbf{A}]^{-1}=\frac{1}{\Delta(s)}\left[\begin{array}{cc}
s+3 & -2 \\
1 & s
\end{array}\right],
$$

where $\Delta(s)=s(s+3)+2=s^{2}+3 s+2=(s+1)(s+2)$.

The signal-flow graph state model of the $R L C$ network of Figure 3.3, is shown in Figure 3.7. This $R L C$ network can be represented by the state variables $x_{1}(t)=v_{c}(t)$ and $x_{2}(t)=i_{L}(t)$. The initial conditions, $x_{1}(0)$ and $x_{2}(0)$, represent the initial capacitor voltage and inductor current, respectively. The flow graph, including the initial conditions of each state variable, is shown in Figure 3.20. The initial conditions appear as the initial value of the state variable at the output of each integrator.

To obtain $\Phi(s)$, we set $U(s)=0$. When $R=3, L=1$, and $C=1 / 2$, we obtain the signal-flow graph shown in Figure 3.21, where the output and input nodes are deleted because they are not involved in the evaluation of $\boldsymbol{\Phi}(s)$. Then, using Mason's signal-flow gain formula, we obtain $X_{1}(s)$ in terms of $x_{1}(0)$ as

$$
X_{1}(s)=\frac{1 \cdot \Delta_{1}(s) \cdot\left[x_{1}(0) / s\right]}{\Delta(s)},
$$

FIGURE 3.20

Flow graph of the $R L C$ network.

FIGURE 3.21

Flow graph of the $R L C$ network with $U(s)=0$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0213.jpg?height=654&width=774&top_left_y=1450&top_left_x=374)where $\Delta(s)$ is the graph determinant, and $\Delta_{1}(s)$ is the path cofactor. The graph determinant is

$$
\Delta(s)=1+3 s^{-1}+2 s^{-2} .
$$

The path cofactor is $\Delta_{1}=1+3 s^{-1}$ because the path between $x_{1}(0)$ and $X_{1}(s)$ does not touch the loop with the factor $-3 s^{-1}$. Therefore, the first element of the transition matrix is

$$
\phi_{11}(s)=\frac{\left(1+3 s^{-1}\right)(1 / s)}{1+3 s^{-1}+2 s^{-2}}=\frac{s+3}{s^{2}+3 s+2} .
$$

The element $\phi_{12}(s)$ is obtained by evaluating the relationship between $X_{1}(s)$ and $x_{2}(0)$ as

$$
X_{1}(s)=\frac{\left(-2 s^{-1}\right)\left(x_{2}(0) / s\right)}{1+3 s^{-1}+2 s^{-2}} .
$$

Therefore, we obtain

$$
\phi_{12}(s)=\frac{-2}{s^{2}+3 s+2}
$$

Similarly, for $\phi_{21}(s)$ we have

$$
\phi_{21}(s)=\frac{\left(s^{-1}\right)(1 / s)}{1+3 s^{-1}+2 s^{-2}}=\frac{1}{s^{2}+3 s+2} .
$$

Finally, for $\phi_{22}(s)$, we obtain

$$
\phi_{22}(s)=\frac{1(1 / s)}{1+3 s^{-1}+2 s^{-2}}=\frac{s}{s^{2}+3 s+2} .
$$

Therefore, the state transition matrix in Laplace transformation form is

$$
\boldsymbol{\Phi}(s)=\left[\begin{array}{cc}
(s+3) /\left(s^{2}+3 s+2\right) & -2 /\left(s^{2}+3 s+2\right) \\
1 /\left(s^{2}+3 s+2\right) & s /\left(s^{2}+3 s+2\right)
\end{array}\right] .
$$

The factors of the characteristic equation are $(s+1)$ and $(s+2)$, so that

$$
(s+1)(s+2)=s^{2}+3 s+2 .
$$

Then the state transition matrix is

$$
\boldsymbol{\Phi}(t)=\mathscr{L}^{-1}\{\boldsymbol{\Phi}(s)\}=\left[\begin{array}{cc}
\left(2 e^{-t}-e^{-2 t}\right) & \left(-2 e^{-t}+2 e^{-2 t}\right) \\
\left(e^{-t}-e^{-2 t}\right) & \left(-e^{-t}+2 e^{-2 t}\right)
\end{array}\right] .
$$

The evaluation of the time response of the $R L C$ network to various initial conditions and input signals can now be evaluated by using Equation (3.80). For example, when $x_{1}(0)=x_{2}(0)=1$ and $u(t)=0$, we have

$$
\left(\begin{array}{l}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)=\boldsymbol{\Phi}(t)\left(\begin{array}{l}
1 \\
1
\end{array}\right)=\left(\begin{array}{c}
e^{-2 t} \\
e^{-2 t}
\end{array}\right) .
$$

FIGURE 3.22

Time response of the state variables of the $R L C$ network for $x_{1}(0)=x_{2}(0)=1$.

FIGURE 3.23

Trajectory of the state vector in the $\left(x_{1}, x_{2}\right)$-plane.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0215.jpg?height=332&width=1266&top_left_y=163&top_left_x=370)

The response of the system for these initial conditions is shown in Figure 3.22. The trajectory of the state vector $\left(x_{1}(t), x_{2}(t)\right)$ on the $\left(x_{1}, x_{2}\right)$-plane is shown in Figure 3.23.

The evaluation of the time response is facilitated by the determination of the state transition matrix. Although this approach is limited to linear systems, it is a powerful method and utilizes the familiar signal-flow graph to evaluate the transition matrix.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative design examples. In the first example, we present a detailed look at modeling a large space vehicle (such as a space station) using a state variable model. The state variable model is then used to take a look at the stability of the orientation of the spacecraft in a low Earth orbit. The design process is highlighted in this example. The second example is a printer belt drive design. The relationship between the state variable model and the block diagram is illustrated and, using block diagram reduction methods, the transfer function equivalent of the state variable model is obtained.

\section{EXAMPLE 3.6 Modeling the orientation of a space station}

The International Space Station, shown in Figure 3.24, is a good example of a multipurpose spacecraft that can operate in many different configurations. An important step in the control system design process is to develop a mathematical model of the spacecraft motion. In general, this model describes the translation and attitude motion of the spacecraft under the influence of external forces and torques, and controller and actuator forces and torques. The resulting spacecraft dynamic model 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0216.jpg?height=990&width=1248&top_left_y=154&top_left_x=505)

FIGURE 3.24 The International Space Station. (Courtesy of NASA.)

is a set of highly coupled, nonlinear ordinary differential equations. Our objective is to simplify the model while retaining important system characteristics. This is not a trivial task, but an important, and often neglected component of control engineering. In this example, the rotational motion is considered. The translational motion, while critically important to orbit maintenance, can be decoupled from the rotational motion.

Many spacecraft (such as the International Space Station) will maintain an Earth-pointing attitude. This means that cameras and other scientific instruments pointing down will be able to sense the Earth. Conversely, scientific instruments pointing up will see deep space, as desired. To achieve Earth-pointing attitude, the spacecraft needs an attitude hold control system capable of applying the necessary torques. The torques are the inputs to the system, in this case, the space station. The attitude is the output of the system. The International Space Station employs control moment gyros and reaction control jets as actuators to control the attitude. The control moment gyros are momentum exchangers and are preferable to reaction control jets because they do not expend fuel. They are actuators that consist of a constant-rate flywheel mounted on a set of gimbals. The flywheel orientation is varied by rotating the gimbals, resulting in a change in direction of the flywheel angular momentum. In accord with the basic principle of conservation of angular momentum, changes in control moment gyro momentum must be transferred to the space station, thereby producing a reaction torque. The reaction torque can be employed to control the space station attitude. However, there is a maximum limit of control that can be provided by the control moment gyro. When that maximum is attained, the device is said to have reached saturation. So, while control moment gyros do not expend fuel, they can provide only a limited amount of control. In practice, it is possible to control the attitude of the space station while simultaneously desaturating the control moment gyros.

Several methods for desaturating the control moment gyros are available, but using existing natural environmental torques is the preferred method because it minimizes the use of the reaction control jets. A clever idea is to use gravity gradient torques (which occur naturally) to continuously desaturate the momentum exchange devices. Due to the variation of the Earth's gravitational field over the International Space Station, the total moment generated by the gravitational forces about the spacecraft's center of mass is nonzero. This nonzero moment is called the gravity gradient torque. A change in attitude changes the gravity gradient torque acting on the vehicle. Thus, combining attitude control and momentum management becomes a matter of compromise.

The elements of the design process emphasized in this example are illustrated in Figure 3.25. We can begin the modeling process by defining the attitude of the

FIGURE 3.25

Elements of the control system design process emphasized in the spacecraft control example.
Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0217.jpg?height=1037&width=1270&top_left_y=1095&top_left_x=332)

space station using the three angles, $\theta_{2}(t)$ (the pitch angle), $\theta_{3}(t)$ (the yaw angle), and $\theta_{1}(t)$ (the roll angle). These three angles represent the attitude of the space station relative to the desired Earth-pointing attitude. When $\theta_{1}(t)=\theta_{2}(t)=\theta_{3}(t)=0$, the space station is oriented in the desired direction. The goal is to keep the space station oriented in the desired attitude while minimizing the amount of momentum exchange required by the control momentum gyros (keeping in mind that we want to avoid saturation). The control goal can be stated as

\section{Control Goal}

Minimize the roll, yaw, and pitch angles in the presence of persistent external disturbances while simultaneously minimizing the control moment gyro momentum.

The time rate of change of the angular momentum of a body about its center of mass is equal to the sum of the external torques acting on that body. Thus the attitude dynamics of a spacecraft are driven by externally acting torques. The main external torque acting on the space station is due to gravity. Since we treat the Earth as a point mass, the gravity gradient torque [30] acting on the spacecraft is given by

$$
\mathbf{T}_{g}(t)=3 n^{2} \mathbf{c}(t) \times \mathbf{I c}(t)
$$

where $n$ is the orbital angular velocity ( $n=0.0011 \mathrm{rad} / \mathrm{s}$ for the space station), and $\mathbf{c}(t)$ is

$$
\mathbf{c}(t)=\left[\begin{array}{c}
-\sin \theta_{2}(t) \cos \theta_{3}(t) \\
\sin \theta_{1}(t) \cos \theta_{2}(t)+\cos \theta_{1}(t) \sin \theta_{2}(t) \sin \theta_{3}(t) \\
\cos \theta_{1}(t) \cos \theta_{2}(t)-\sin \theta_{1}(t) \sin \theta_{2}(t) \sin \theta_{3}(t)
\end{array}\right] .
$$

The notation ' $X$ ' denotes vector cross-product. Matrix I is the spacecraft inertia matrix and is a function of the space station configuration. It also follows from Equation (3.95) that the gravity gradient torques are a function of the attitude $\theta_{1}(t), \theta_{2}(t)$, and $\theta_{3}(t)$. We want to maintain a prescribed attitude (that is Earth-pointing $\left.\theta_{1}=\theta_{2}=\theta_{3}=0\right)$, but sometimes we must deviate from that attitude so that we can generate gravity gradient torques to assist in the control moment gyro momentum management. Therein lies the conflict; as engineers we often are required to develop control systems to manage conflicting goals.

Now we examine the effect of the aerodynamic torque acting on the space station. Even at the high altitude of the space station, the aerodynamic torque does affect the attitude motion. The aerodynamic torque acting on the space station is generated by the atmospheric drag force that acts through the center of pressure. In general, the center of pressure and the center of mass do not coincide, so aerodynamic torques develop. In low Earth orbit, the aerodynamic torque is a sinusoidal function that tends to oscillate around a small bias. The oscillation in the torque is primarily a result of the Earth's diurnal atmospheric bulge. Due to heating, the atmosphere closest to the Sun extends further into space than the atmosphere on the side of the Earth away from the Sun. As the space station travels around the Earth (once every 90 minutes or so), it moves through varying air densities, thus causing a cyclic aerodynamic torque. Also, the space station solar panels rotate as they track the Sun. This results in another cyclic component of aerodynamic torque. The aerodynamic torque is generally much smaller than the gravity gradient torque. Therefore, for design purposes we can ignore the atmospheric drag torque and view it as a disturbance torque. We would like the controller to minimize the effects of the aerodynamic disturbance on the spacecraft attitude.

Torques caused by the gravitation of other planetary bodies, magnetic fields, solar radiation and wind, and other less significant phenomena are much smaller than the Earth's gravity-induced torque and aerodynamic torque. We ignore these torques in the dynamic model and view them as disturbances.

Finally, we need to discuss the control moment gyros themselves. First, we will lump all the control moment gyros together and view them as a single source of torque. We represent the total control moment gyro momentum with the variable $\mathbf{h}(t)$. We need to know and understand the dynamics in the design phase to manage the angular momentum. But since the time constants associated with these dynamics are much shorter than for attitude dynamics, we can ignore the dynamics and assume that the control moment gyros can produce precisely and without a time delay the torque demanded by the control system.

Based on the above discussion, a simplified nonlinear model that we can use as the basis for the control design is

$$
\begin{aligned}
\dot{\Theta}(t) & =\mathbf{R}(\Theta) \Omega(t)+\mathbf{n}, \\
\mathbf{I} \dot{\Omega}(t) & =-\Omega(t) \times \mathbf{I} \Omega(t)+3 n^{2} \mathbf{c}(t) \times \mathbf{I} \mathbf{c}(t)-\mathbf{u}(t), \\
\dot{\mathbf{h}}(t) & =-\Omega(t) \times \mathbf{h}(t)+\mathbf{u}(t),
\end{aligned}
$$

where

$$
\begin{gathered}
\mathbf{R}(\Theta)=\frac{1}{\cos \theta_{3}(t)}\left[\begin{array}{ccc}
\cos \theta_{3}(t) & -\cos \theta_{1}(t) \sin \theta_{3}(t) & \sin \theta_{1}(t) \sin \theta_{3}(t) \\
0 & \cos \theta_{1}(t) & -\sin \theta_{1}(t) \\
0 & \sin \theta_{1}(t) \cos \theta_{3}(t) & \cos \theta_{1}(t) \cos \theta_{3}(t)
\end{array}\right] \\
\mathbf{n}=\left(\begin{array}{l}
0 \\
n \\
0
\end{array}\right), \quad \Omega=\left(\begin{array}{l}
\omega_{1}(t) \\
\omega_{2}(t) \\
\omega_{3}(t)
\end{array}\right), \quad \Theta=\left(\begin{array}{c}
\theta_{1}(t) \\
\theta_{2}(t) \\
\theta_{3}(t)
\end{array}\right), \quad \mathbf{u}=\left(\begin{array}{c}
u_{1}(t) \\
u_{2}(t) \\
u_{3}(t)
\end{array}\right),
\end{gathered}
$$

where $\mathbf{u}(t)$ is the control moment gyro input torque, $\Omega(t)$ in the angular velocity, $\mathbf{I}$ is the moment of inertia matrix, and $\mathbf{n}$ is the orbital angular velocity. Two good references that describe the fundamentals of spacecraft dynamic modeling are [26] and [27]. There have been many papers dealing with space station control and momentum management. One of the first to present the nonlinear model in Equations (3.96-3.98) is Wie et al. [28]. Other related information about the model and the control problem in general appears in [29-33]. Articles related to advanced control topics on the space station can be found in [34-40]. Researchers are developing nonlinear control laws based on the nonlinear model in Equations (3.96)-(3.98). Several good articles on this topic appear in [41-50]. Equation (3.96) represents the kinematics - the relationship between the Euler angles, denoted by $\Theta(t)$, and the angular velocity vector, $\Omega(t)$. Equation (3.97) represents the space station attitude dynamics. The terms on the right side represent the sum of the external torques acting on the spacecraft. The first torque is due to inertia cross-coupling. The second term represents the gravity gradient torque, and the last term is the torque applied to the spacecraft from the actuators. The disturbance torques (due to such factors as the atmosphere) are not included in the model used in the design. Equation (3.98) represents the control moment gyro total momentum.

The conventional approach to spacecraft momentum management design is to develop a linear model, representing the spacecraft attitude and control moment gyro momentum by linearizing the nonlinear model. This linearization is accomplished by a standard Taylor series approximation. Linear control design methods can then be readily applied. For linearization purposes we assume that the spacecraft has zero products of inertia (that is, the inertia matrix is diagonal) and the aerodynamic disturbances are negligible. The equilibrium state that we linearize about is

$$
\begin{aligned}
\Theta & =\mathbf{0}, \\
\boldsymbol{\Omega} & =\left(\begin{array}{c}
0 \\
-n \\
0
\end{array}\right) \\
\mathbf{h} & =\mathbf{0},
\end{aligned}
$$

and where we assume that

$$
\mathbf{I}=\left[\begin{array}{ccc}
\mathrm{I}_{1} & 0 & 0 \\
0 & \mathrm{I}_{2} & 0 \\
0 & 0 & \mathrm{I}_{3}
\end{array}\right]
$$

In reality, the inertia matrix, $\mathbf{I}$, is not a diagonal matrix. Neglecting the off-diagonal terms is consistent with the linearization approximations and is a common assumption. Applying the Taylor series approximations yields the linear model, which as it turns out decouples the pitch axis from the roll/yaw axis.

The linearized equations for the pitch axis are

$$
\left(\begin{array}{c}
\dot{\theta}_{2}(t) \\
\dot{\omega}_{2}(t) \\
\dot{h}_{2}(t)
\end{array}\right)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
3 n^{2} \Delta_{2} & 0 & 0 \\
0 & 0 & 0
\end{array}\right]\left(\begin{array}{c}
\theta_{2}(t) \\
\omega_{2}(t) \\
h_{2}(t)
\end{array}\right)+\left[\begin{array}{c}
-0 \\
-1 / I_{2} \\
-1
\end{array}\right] u_{2}(t)
$$

where

$$
\Delta_{2}:=\frac{I_{3}-I_{1}}{I_{2}} .
$$

The subscript 2 refers to the pitch axis terms, the subscript 1 is for the roll axis terms, and 3 is for the yaw axis terms. The linearized equations for the roll/yaw axes are 

$$
\begin{aligned}
\left(\begin{array}{c}
\dot{\theta}_{1}(t) \\
\dot{\theta}_{3}(t) \\
\dot{\omega}_{1}(t) \\
\dot{\omega}_{3}(t) \\
\dot{h}_{1}(t) \\
\dot{h}_{3}(t)
\end{array}\right]=\left[\begin{array}{cccccc}
0 & n & 1 & 0 & 0 & 0 \\
-n & 0 & 0 & 1 & 0 & 0 \\
-3 n^{2} \Delta_{1} & 0 & 0 & -n \Delta_{1} & 0 & 0 \\
0 & 0 & -n \Delta_{3} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & n \\
0 & 0 & 0 & 0 & -n & 0
\end{array}\right]\left(\begin{array}{c}
\theta_{1}(t) \\
\theta_{3}(t) \\
\omega_{1}(t) \\
\omega_{3}(t) \\
h_{1}(t) \\
h_{3}(t)
\end{array}\right) \\
+\left[\begin{array}{cc}
-0 & -0 \\
-0 & -0 \\
-1 / I_{1} & -0 \\
-0 & -1 / I_{3} \\
-1 & -0 \\
-0 & -1
\end{array}\right]\left(u_{3}(t)\right. \\
u_{3}(t)
\end{aligned}
$$

where

$$
\Delta_{1}:=\frac{I_{2}-I_{3}}{I_{1}} \quad \text { and } \quad \Delta_{3}:=\frac{I_{1}-I_{2}}{I_{3}} .
$$

Consider the analysis of the pitch axis. Define the state-vector as

and the output as

$$
\mathbf{x}(t):=\left(\begin{array}{c}
\theta_{2}(t) \\
\omega_{2}(t) \\
h_{2}(t)
\end{array}\right),
$$

$$
y(t)=\theta_{2}(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
$$

Here we are considering the spacecraft attitude, $\theta_{2}(t)$, as the output of interest. We can just as easily consider both the angular velocity, $\omega_{2}(t)$, and the control moment gyro momentum, $h_{2}(t)$, as outputs. The state variable model is

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t), \\
y(t)=\mathbf{C x}(t)+\mathbf{D} u(t),
\end{gathered}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
3 n^{2} \Delta_{2} & 0 & 0 \\
0 & 0 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{c}
0 \\
-1 / I_{2} \\
1
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right], \quad \mathbf{D}=[0]
\end{aligned}
$$

and where $u(t)$ is the control moment gyro torque in the pitch axis. The solution to the state differential equation, given in Equation (3.101), is

$$
\mathbf{x}(t)=\boldsymbol{\Phi}(t) \mathbf{x}(0)+\int_{0}^{t} \boldsymbol{\Phi}(t-\tau) \mathbf{B} u(\tau) d \tau,
$$

where

$$
\begin{gathered}
\Phi(t)=\exp (\mathbf{A} t)=\mathscr{L}^{-1}\left\{(s \mathbf{I}-\mathbf{A})^{-1}\right\} \\
=\left[\begin{array}{ccc}
\frac{1}{2}\left(e^{\sqrt{3 n^{2} \Delta_{2} t}}+e^{-\sqrt{3 n^{2} \Delta_{2} t}}\right) & \frac{1}{2 \sqrt{3 n^{2} \Delta_{2}}\left(e^{\sqrt{3 n^{2} \Delta_{2} t}}-e^{-\sqrt{3 n^{2} \Delta_{2} t}}\right)} & 0 \\
\frac{\sqrt{3 n^{2} \Delta_{2}}}{2}\left(e^{\sqrt{3 n^{2} \Delta_{2} t}}-e^{-\sqrt{3 n^{2} \Delta_{2} t}}\right) & \frac{1}{2}\left(e^{\sqrt{3 n^{2} \Delta_{2} t}}+e^{-\sqrt{3 n^{2} \Delta_{2} t}}\right) & 0 \\
0 & 0 & 1
\end{array}\right] .
\end{gathered}
$$

We can see that if $\Delta_{2}>0$, then some elements of the state transition matrix will have terms of the form $e^{a t}$, where $a>0$. This indicates that our system is unstable. Also, if we are interested in the output, $y(t)=\theta_{2}(t)$, we have

$$
y(t)=\mathbf{C x}(t) .
$$

With $\mathbf{x}(t)$ given by

$$
\mathbf{x}(t)=\boldsymbol{\Phi}(t) \mathbf{x}(0)+\int_{0}^{t} \boldsymbol{\Phi}(t-\tau) \mathbf{B} u(\tau) d \tau,
$$

it follows that

$$
y(t)=\mathbf{C} \boldsymbol{\Phi}(t) \mathbf{x}(0)+\int_{0}^{t} \mathbf{C} \boldsymbol{\Phi}(t-\tau) \mathbf{B} u(\tau) d \tau .
$$

The transfer function relating the output $Y(s)$ to the input $U(s)$ is

$$
G(s)=\frac{Y(s)}{U(s)}=\mathbf{C}(s \mathbf{I}-\mathbf{A})^{-1} \mathbf{B}=-\frac{1}{I_{2}\left(s^{2}-3 n^{2} \Delta_{2}\right)} .
$$

The characteristic equation is

$$
s^{2}-3 n^{2} \Delta_{2}=\left(s+\sqrt{3 n^{2} \Delta_{2}}\right)\left(s-\sqrt{3 n^{2} \Delta_{2}}\right)=0 .
$$

If $\Delta_{2}>0$ (that is, if $I_{3}>I_{1}$ ), then we have two real poles-one in the left halfplane and the other in the right half-plane. For spacecraft with $I_{3}>I_{1}$, we can say that an Earth-pointing attitude is an unstable orientation. This means that active control is necessary.

Conversely, when $\Delta_{2}<0$ (that is, when $I_{1}>I_{3}$ ), the characteristic equation has two imaginary roots at

$$
s= \pm j \sqrt{3 n^{2}\left|\Delta_{2}\right|}
$$

This type of spacecraft is marginally stable. In the absence of any control moment gyro torques, the spacecraft will oscillate around the Earth-pointing orientation for any small initial deviation from the desired attitude. 

\section{EXAMPLE 3.7 Printer belt drive modeling}

A commonly used low-cost printer for a computer uses a belt drive to move the printing device laterally across the printed page [11]. The printing device may be a laser printer, a print ball, or thermal printhead. An example of a belt drive printer with a DC motor actuator is shown in Figure 3.26. In this model, a light sensor is used to measure the position of the printing device, and the belt tension adjusts the spring flexibility of the belt. The goal of the design is to determine the effect of the belt spring constant $k$ and select appropriate parameters for the motor, the belt pulley, and the controller. To achieve the analysis, we will determine a model of the belt-drive system and select many of its parameters. Using this model, we will obtain the signal-flow graph model and select the state variables. We then will determine an appropriate transfer function for the system and select its other parameters, except for the spring constant. Finally, we will examine the effect of varying the spring constant within a realistic range.

We propose the model of the belt-drive system shown in Figure 3.27. This model assumes that the spring constant of the belt is $k$, the radius of the pulley is $r$, the angular rotation of the motor shaft is $\theta(t)$, and the angular rotation of the righthand pulley is $\theta_{p}(t)$. The mass of the printing device is $m$, and its position is $y(t)$. A light sensor is used to measure $y(t)$, and the output of the sensor is a voltage $v_{1}(t)$,

FIGURE 3.26

Printer belt-drive system.
FIGURE 3.27

Printer belt-drive model.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0223.jpg?height=1074&width=1168&top_left_y=1038&top_left_x=370)where $v_{1}(t)=k_{1} y(t)$. The controller provides an output voltage $v_{2}(t)$, where $v_{2}(t)$ is a function of $v_{1}(t)$. The voltage $v_{2}(t)$ is connected to the field of the motor. Let us assume that we can use the linear relationship

$$
v_{2}(t)=-\left(k_{2} \frac{d v_{1}(t)}{d t}+k_{3} v_{1}(t)\right),
$$

and elect to use $k_{2}=0.1$ and $k_{3}=0$ (velocity feedback).

The inertia of the motor and pulley is $J=J_{\text {motor }}+J_{\text {pulley. We plan to }}$ use a moderate-DC motor. Selecting a typical 1/8-hp DC motor, we find that $J=0.01 \mathrm{~kg} \mathrm{~m}^{2}$, the field inductance is negligible, the field resistance is $R=2 \Omega$, the motor constant is $K_{m}=2 \mathrm{Nm} / \mathrm{A}$, and the motor and pulley friction is $b=0.25 \mathrm{Nms} / \mathrm{rad}$. The radius of the pulley is $r=0.15 \mathrm{~m}, m=0.2 \mathrm{~kg}$, and $k_{1}=1 \mathrm{~V} / \mathrm{m}$.

We now proceed to write the equations of the motion for the system; note that $y(t)=r \theta_{p}(t)$. Then the tension from equilibrium $T_{1}$ is

$$
T_{1}(t)=k\left(r \theta(t)-r \theta_{p}(t)\right)=k(r \theta(t)-y(t)) .
$$

The tension from equilibrium $T_{2}(t)$ is

$$
T_{2}(t)=k(y(t)-r \theta(t)) .
$$

The net tension at the mass $m$ is

$$
T_{1}(t)-T_{2}(t)=m \frac{d^{2} y(t)}{d t^{2}}
$$

and

$$
\begin{aligned}
T_{1}(t)-T_{2}(t) & =k(r \theta(t)-y(t))-k(y(t)-r \theta(t)) \\
& =2 k(r \theta(t)-y(t))=2 k x_{1}(t),
\end{aligned}
$$

where the first state variable is $x_{1}(t)=r \theta(t)-y(t)$. Let the second state variable be $x_{2}(t)=d y(t) / d t$, and use Equations (3.102) and (3.103) to obtain

$$
\frac{d x_{2}(t)}{d t}=\frac{2 k}{m} x_{1}(t) \text {. }
$$

The first derivative of $x_{1}(t)$ is

$$
\frac{d x_{1}(t)}{d t}=r \frac{d \theta(t)}{d t}-\frac{d y(t)}{d t}=r x_{3}(t)-x_{2}(t)
$$

when we select the third state variable as $x_{3}(t)=d \theta(t) / d t$. We now require a differential equation describing the motor rotation. When $L=0$, we have the field current $i(t)=v_{2}(t) / R$ and the motor torque $T_{m}(t)=K_{m} i(t)$. Therefore,

$$
T_{m}(t)=\frac{K_{m}}{R} v_{2}(t)
$$

and the motor torque provides the torque to drive the belts plus the disturbance or undesired load torque, so that

$$
T_{m}(t)=T(t)+T_{d}(t) .
$$

The torque $T(t)$ drives the shaft to the pulley, so that

$$
T(t)=J \frac{d^{2} \theta(t)}{d t^{2}}+b \frac{d \theta(t)}{d t}+r T_{1}(t)-r T_{2}(t) .
$$

Therefore,

$$
\frac{d x_{3}(t)}{d t}=\frac{d^{2} \theta(t)}{d t^{2}}
$$

Hence,

$$
\frac{d x_{3}(t)}{d t}=\frac{T_{m}(t)-T_{d}(t)}{J}-\frac{b}{J} x_{3}(t)-\frac{2 k r}{J} x_{1}(t)
$$

where

$$
T_{m}(t)=\frac{K_{m}}{R} v_{2}(t), \quad \text { and } \quad v_{2}(t)=-k_{1} k_{2} \frac{d y(t)}{d t}=-k_{1} k_{2} x_{2}(t) .
$$

Thus, we obtain

$$
\frac{d x_{3}(t)}{d t}=\frac{-K_{m} k_{1} k_{2}}{J R} x_{2}(t)-\frac{b}{J} x_{3}(t)-\frac{2 k r}{J} x_{1}(t)-\frac{T_{d}(t)}{J} .
$$

Equations (3.104)-(3.106) are the three first-order differential equations required to describe this system. The matrix differential equation is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & -1 & r \\
\frac{2 k}{m} & 0 & 0 \\
\frac{-2 k r}{J} & \frac{-K_{m} k_{1} k_{2}}{J R} & \frac{-b}{J}
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
0 \\
\frac{-1}{J}
\end{array}\right] T_{d}(t) .
$$

The signal-flow graph and block diagram models representing the matrix differential equation are shown in Figure 3.28, where we include the identification of the node for the disturbance torque $T_{d}(t)$.

We can use the flow graph to determine the transfer function $X_{1}(s) / T_{d}(s)$. The goal is to reduce the effect of the disturbance $T_{d}(s)$, and the transfer function will show us how to accomplish this goal. Using Mason's signal-flow gain formula, we obtain

$$
\frac{X_{1}(s)}{T_{d}(s)}=\frac{-\frac{r}{J} s^{-2}}{1-\left(L_{1}(s)+L_{2}(s)+L_{3}(s)+L_{4}(s)\right)+L_{1}(s) L_{2}(s)},
$$

FIGURE 3.28

Printer belt drive. (a) Signal-flow graph. (b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0226.jpg?height=513&width=1079&top_left_y=167&top_left_x=599)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0226.jpg?height=470&width=1225&top_left_y=781&top_left_x=507)

(b)

where

$$
L_{1}(s)=\frac{-b}{J} s^{-1}, L_{2}(s)=\frac{-2 k}{m} s^{-2}, L_{3}(s)=\frac{-2 k r^{2} s^{-2}}{J}, \text { and } L_{4}(s)=\frac{-2 k K_{m} k_{1} k_{2} r s^{-3}}{m J R}
$$

We therefore have

$$
\frac{X_{1}(s)}{T_{d}(s)}=\frac{-\left(\frac{r}{J}\right) s}{s^{3}+\left(\frac{b}{J}\right) s^{2}+\left(\frac{2 k}{m}+\frac{2 k r^{2}}{J}\right) s+\left(\frac{2 k b}{J m}+\frac{2 k K_{m} k_{1} k_{2} r}{J m R}\right)}
$$

We can also determine the closed-loop transfer function using block diagram reduction methods, as illustrated in Figure 3.29. Remember, there is no unique path to follow in reducing the block diagram; however, there is only one correct solution (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0227.jpg?height=465&width=1061&top_left_y=165&top_left_x=443)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0227.jpg?height=355&width=1058&top_left_y=693&top_left_x=445)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0227.jpg?height=240&width=1061&top_left_y=1110&top_left_x=443)

FIGURE 3.29

Printer belt drive block diagram reduction. (d)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0227.jpg?height=108&width=1073&top_left_y=1411&top_left_x=430)

in the end. The original block diagram is shown in Figure 3.28(b). The result of the first step is shown in Figure 3.29(a), where the upper feedback loop has been reduced to a single transfer function. The second step illustrated in Figure 3.29(b) then reduces the two lower feedback loops to a single transfer function. In the third step shown in Figure 3.29(c), the lower feedback loop is closed and then the remaining transfer functions in series in the lower loop are combined. The final step closed-loop transfer function is shown in Figure 3.29(d).

Substituting the parameter values, we obtain

$$
\frac{X_{1}(s)}{T_{d}(s)}=\frac{-15 s}{s^{3}+25 s^{2}+14.5 k s+265 k} .
$$

We wish to select the spring constant $k$ so that the state variable $x_{1}(t)$ will quickly decline to a low value when a disturbance occurs. For test purposes, consider a step disturbance $T_{d}(s)=a / s$. Recalling that $x_{1}(t)=r \theta(t)-y(t)$, we thus seek a small magnitude for $x_{1}$ so that $y$ is nearly equal to the desired $r \theta$. If we have a perfectly stiff belt with $k \rightarrow \infty$, then $y(t)=r \theta(t)$ exactly. With a step disturbance, $T_{d}(s)=a / s$, we have

$$
X_{1}(s)=\frac{-15 a}{s^{3}+25 s^{2}+14.5 k s+265 k} .
$$

The final value theorem gives

$$
\lim _{t \rightarrow \infty} x_{1}(t)=\lim _{s \rightarrow 0} s X_{1}(s)=0
$$

and thus the steady-state value of $x_{1}(t)$ is zero. We need to use a realistic value for $k$ in the range $1 \leq k \leq 40$. For an average value of $k=20$, we have

$$
\begin{aligned}
X_{1}(s) & =\frac{-15 a}{s^{3}+25 s^{2}+290 s+5300} \\
& =\frac{-15 a}{(s+22.56)\left(s^{2}+2.44 s+234.93\right)} .
\end{aligned}
$$

The characteristic equation has one real root and two complex roots. The partial fraction expansion yields

$$
\frac{X_{1}(s)}{a}=\frac{A}{s+22.56}+\frac{B s+C}{(s+1.22)^{2}+(15.28)^{2}},
$$

where we find $A=-0.0218, B=0.0218$, and $C=-0.4381$. Clearly with these small residues, the response to the unit disturbance is relatively small. Because $A$ and $B$ are small compared to $C$, we may approximate $X_{1}(s)$ as

$$
\frac{X_{1}(s)}{a} \cong \frac{-0.4381}{(s+1.22)^{2}+(15.28)^{2}}
$$

Taking the inverse Laplace transform, we obtain

$$
\frac{x_{1}(t)}{a} \cong-0.0287 e^{-1.22 t} \sin 15.28 t
$$

The actual response of $x_{1}$ is shown in Figure 3.30. This system will reduce the effect of the unwanted disturbance to a relatively small magnitude. Thus we have achieved our design objective. FIGURE 3.30

Response of $x_{1}(t)$ to a step disturbance: peak value $=-0.0325$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0229.jpg?height=689&width=1083&top_left_y=154&top_left_x=371)

\subsection{ANALYSIS OF STATE VARIABLE MODELS USING CONTROL DESIGN SOFTWARE}

The time-domain method utilizes a state-space representation of the system model, given by

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \text { and } \quad y(t)=\mathbf{C x}(t)+\mathbf{D} u(t) .
$$

The vector $\mathbf{x}(t)$ is the state of the system, $\mathbf{A}$ is the constant $n \times n$ system matrix, $\mathbf{B}$ is the constant $n \times m$ input matrix, $\mathbf{C}$ is the constant $p \times n$ output matrix, and $\mathbf{D}$ is a constant $p \times m$ matrix. The number of inputs, $m$, and the number of outputs, $p$, are taken to be one, since we are considering only single-input, single-output (SISO) problems. Therefore $y(t)$ and $u(t)$ are not bold (matrix) variables.

The main elements of the state-space representation in Equation (3.114) are the state vector $\mathbf{x}(t)$ and the constant matrices $(\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{D})$. Two new functions covered in this section are ss and Isim. We also consider the use of the expm function to calculate the state transition matrix.

Given a transfer function, we can obtain an equivalent state-space representation and vice versa. The function tf can be used to convert a state-space representation to a transfer function representation; the function ss can be used to convert a transfer function representation to a state-space representation. These functions are shown in Figure 3.31, where sys_tf represents a transfer function model and sys_ss is a state-space representation.

For instance, consider the third-order system

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{2 s^{2}+8 s+6}{s^{3}+8 s^{2}+16 s+6} .
$$

FIGURE 3.31

(a) The ss function.

(b) Linear system model conversion.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0230.jpg?height=468&width=534&top_left_y=166&top_left_x=519)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0230.jpg?height=464&width=518&top_left_y=168&top_left_x=1065)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0230.jpg?height=717&width=931&top_left_y=754&top_left_x=219)

(a) m-file script.

(b) Output printout. (a)

\begin{tabular}{|c|c|c|c|}
\hline \multicolumn{4}{|c|}{ >>convert } \\
\hline \multicolumn{4}{|c|}{$a=$} \\
\hline & $x 1$ & $x 2$ & x3 \\
\hline$x 1$ & -8 & -4 & -1.5 \\
\hline$x 2$ & 4 & 0 & 0 \\
\hline$x 3$ & 0 & 1 & 0 \\
\hline \multicolumn{4}{|c|}{$b=$} \\
\hline & u1 & & \\
\hline$x 1$ & 2 & & \\
\hline$x 2$ & 0 & & \\
\hline$x 3$ & 0 & & \\
\hline \multicolumn{4}{|c|}{$C=$} \\
\hline & $x 1$ & $x 2$ & x3 \\
\hline $\mathrm{y} 1$ & 1 & 1 & 0.75 \\
\hline \multicolumn{4}{|c|}{$d=$} \\
\hline & u1 & & \\
\hline $\mathrm{y} 1$ & 0 & & \\
\hline
\end{tabular}

(b)

We can obtain a state-space representation using the ss function, as shown in Figure 3.32. A state-space representation of Equation (3.115) is given by Equation (3.114), where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{rrr}
-8 & -4 & -1.5 \\
4 & 0 & 0 \\
0 & 1 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
2 \\
0 \\
0
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{lll}
1 & 1 & 0.75
\end{array}\right], \quad \text { and } \quad \mathbf{D}=[0] .
\end{aligned}
$$

The state-space representation of the transfer function in Equation (3.115) is depicted in Figure 3.33. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0231.jpg?height=527&width=1397&top_left_y=162&top_left_x=219)

FIGURE 3.33 Block diagram with $\mathrm{X}_{1}(\mathrm{~s})$ defined as the leftmost state variable.

The state variable representation is not unique. For example, another equally valid state variable representation is given by

$$
\mathbf{A}=\left[\begin{array}{rrc}
-8 & -2 & -0.75 \\
8 & 0 & 0 \\
0 & 1 & 0
\end{array}\right], \mathbf{B}=\left[\begin{array}{c}
0.125 \\
0 \\
0
\end{array}\right], \mathbf{C}=\left[\begin{array}{lll}
16 & 8 & 6
\end{array}\right], \mathbf{D}=[0]
$$

It is possible that when using the ss function, the state variable representation provided by your control design software will be different from the above two examples depending on the specific software and version.

The time response of the system in Equation (3.114) is given by the solution to the vector integral equation

$$
\mathbf{x}(t)=\exp (\mathbf{A} t) \mathbf{x}(0)+\int_{0}^{t} \exp [\mathbf{A}(t-\tau)] \mathbf{B} u(\tau) d \tau
$$

The matrix exponential function in Equation (3.116) is the state transition matrix, $\Phi(t)$, where

$$
\boldsymbol{\Phi}(t)=\exp (\mathbf{A} t)
$$

We can use the function expm to compute the transition matrix for a given time, as illustrated in Figure 3.34. The $\operatorname{expm}(\mathrm{A})$ function computes the matrix exponential. In contrast, the $\exp (\mathrm{A})$ function calculates $e^{a_{i j}}$ for each of the elements $a_{i j} \in \mathbf{A}$.

For example, let us consider the $R L C$ network of Figure 3.3 described by the state-space representation of Equation (3.18) with

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & -2 \\
1 & -3
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
2 \\
0
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right], \quad \text { and } \quad \mathbf{D}=0
$$

FIGURE 3.34

Computing the state transition matrix for a given time, $\Delta t=d t$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0232.jpg?height=228&width=689&top_left_y=182&top_left_x=542)

The initial conditions are $x_{1}(0)=x_{2}(0)=1$ and the input $u(t)=0$. At $t=0.2$, the state transition matrix is as given in Figure 3.34. The state at $t=0.2$ is predicted by the state transition methods to be

$$
\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)_{t=0.2}=\left[\begin{array}{cc}
0.9671 & -0.2968 \\
0.1484 & 0.5219
\end{array}\right]\left(\begin{array}{l}
x_{1} \\
x_{2}
\end{array}\right)_{t=0}=\left(\begin{array}{l}
0.6703 \\
0.6703
\end{array}\right) \text {. }
$$

The time response of the system of Equation (3.115) can also be obtained by using the Isim function. The Isim function can accept as input nonzero initial conditions as well as an input function, as shown in Figure 3.35. Using the Isim function, we can calculate the response for the $R L C$ network as shown in Figure 3.36.

The state at $t=0.2$ is predicted with the Isim function to be $x_{1}(0.2)=$ $x_{2}(0.2)=0.6703$. If we can compare the results obtained by the Isim function and by multiplying the initial condition state vector by the state transition matrix, we find identical results.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0232.jpg?height=168&width=1076&top_left_y=1304&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0232.jpg?height=440&width=851&top_left_y=1577&top_left_x=633)

(b)
FIGURE 3.35

The Isim function for calculating the output and state response. FIGURE 3.36

Computing the time response for nonzero initial conditions and zero input using Isim.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0233.jpg?height=494&width=1280&top_left_y=162&top_left_x=378)

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

Advanced disks have as many as 8000 tracks per $\mathrm{cm}$. These tracks are typically $1 \mu \mathrm{m}$ wide. Thus, there are stringent requirements on the accuracy of the reader head position and of the movement from one track to another. In this chapter, we will develop a state variable model of the disk drive system that will include the effect of the flexure mount.

Since we want a lightweight arm and flexure for rapid movement, we must consider the effect of the flexure, which is a very thin mount made of spring steel. Again, we wish to accurately control the position of the head $y(t)$ as shown in Figure 3.37(a). We will attempt to derive a model for the system shown in Figure 3.37(a). Here we identify the motor mass as $M_{1}$ and the head mount mass as $M_{2}$. The flexure spring is represented by the spring constant $k$. The force $u(t)$ to drive the mass $M_{1}$ is generated by the DC motor. If the spring is absolutely rigid (nonspringy), then we obtain the simplified model shown in Figure 3.37(b). Typical parameters for the two-mass system are given in Table 3.1.

Let us obtain the transfer function model of the simplified system of Figure 3.37(b). Note that $M=M_{1}+M_{2}=20.5 \mathrm{~g}=0.0205 \mathrm{~kg}$. Then we have

$$
M \frac{d^{2} y(t)}{d t^{2}}+b_{1} \frac{d y(t)}{d t}=u(t)
$$

FIGURE 3.37

(a) Model of the two-mass system with a spring flexure. (b) Simplified model with a rigid spring.

FIGURE 3.38

Transfer function model of head reader device with a rigid spring.
Table 3.1 Typical Parameters of the Two-Mass Model

\begin{tabular}{lll} 
Parameter & Symbol & Value \\
\hline Motor mass & $M_{1}$ & $20 \mathrm{~g}=0.02 \mathrm{~kg}$ \\
Flexure spring & $k$ & $10 \leq k \leq \infty$ \\
Head mounting mass & $M_{2}$ & $0.5 \mathrm{~g}=0.0005 \mathrm{~kg}$ \\
Head position & $x_{2}(t)$ & variable in $\mathrm{mm}$ \\
Friction at mass 1 & $b_{1}$ & $410 \times 10^{-3} \mathrm{~N} /(\mathrm{m} / \mathrm{s})$ \\
Field resistance & $R$ & $1 \Omega$ \\
Field inductance & $L$ & $1 \mathrm{mH}$ \\
Motor constant & $K_{m}$ & $0.1025 \mathrm{~N} \mathrm{~m} / \mathrm{A}$ \\
Friction at mass 2 & $b_{2}$ & $4.1 \times 10^{-3} \mathrm{~N} /(\mathrm{m} / \mathrm{s})$ \\
\hline
\end{tabular}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0234.jpg?height=268&width=734&top_left_y=882&top_left_x=508)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0234.jpg?height=191&width=411&top_left_y=958&top_left_x=1281)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0234.jpg?height=245&width=814&top_left_y=1258&top_left_x=508)

Therefore, the transfer function model is

$$
\frac{Y(s)}{U(s)}=\frac{1}{s\left(M s+b_{1}\right)} .
$$

For the parameters of Table 3.1, we obtain

$$
\frac{Y(s)}{U(s)}=\frac{1}{s(0.0205 s+0.410)}=\frac{48.78}{s(s+20)} .
$$

The transfer function model of the head reader, including the effect of the motor coil, is shown in Figure 3.38. When $R=1 \Omega, L=1 \mathrm{mH}$, and $K_{m}=0.1025$, we obtain

$$
G(s)=\frac{Y(s)}{V(s)}=\frac{5000}{s(s+20)(s+1000)} .
$$

Now let us obtain the state variable model of the two-mass system shown in Figure 3.37(a). Write the differential equations as

$$
\begin{aligned}
& \text { Mass } M_{1}: M_{1} \frac{d^{2} q(t)}{d t^{2}}+b_{1} \frac{d q(t)}{d t}+k q(t)-k y(t)=u(t) \\
& \text { Mass } M_{2}: M_{2} \frac{d^{2} y(t)}{d t^{2}}+b_{2} \frac{d y(t)}{d t}+k y(t)-k q(t)=0
\end{aligned}
$$

To develop the state variable model, we choose the state variables as $x_{1}(t)=q(t)$ and $x_{2}(t)=y(t)$. Then we have

$$
x_{3}(t)=\frac{d q(t)}{d t} \quad \text { and } \quad x_{4}(t)=\frac{d y(t)}{d t} .
$$

Then, in matrix form,

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

and we have

$$
\mathbf{x}(t)=\left(\begin{array}{c}
q(t) \\
y(t) \\
\dot{q}(t) \\
\dot{y}(t)
\end{array}\right), \quad \mathbf{B}=\left[\begin{array}{c}
0 \\
0 \\
1 / M_{1} \\
0
\end{array}\right]
$$

and

$$
\mathbf{A}=\left[\begin{array}{cccc}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-k / M_{1} & k / M_{1} & -b_{1} / M_{1} & 0 \\
k / M_{2} & -k / M_{2} & 0 & -b_{2} / M_{2}
\end{array}\right]
$$

Note that the output is $\dot{y}(t)=x_{4}(t)$. Also, for $L=0$ or negligible inductance, then $u(t)=K_{m} v(t)$. For the typical parameters and for $k=10$, we have

$$
\mathbf{B}=\left[\begin{array}{c}
0 \\
0 \\
50 \\
0
\end{array}\right] \text { and } \mathbf{A}=\left[\begin{array}{cccc}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-500 & +500 & -20.5 & 0 \\
+20000 & -20000 & 0 & -8.2
\end{array}\right]
$$

The response of $\dot{y}(t)$ for $u(t)=1, t>0$ is shown in Figure 3.39. This response is quite oscillatory, and it is clear that we want a very rigid flexure with $k>100$. FIGURE 3.39 Response of $y$ for a step input for the two-mass model with $k=10$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0236.jpg?height=992&width=784&top_left_y=172&top_left_x=532)

\subsection{SUMMARY}

In this chapter, we have considered the description and analysis of systems in the time domain. The concept of the state of a system and the definition of the state variables of a system were discussed. The selection of a set of state variables of a system was examined, and the nonuniqueness of the state variables was noted. The state differential equation and the solution for $\mathbf{x}(t)$ were discussed. Alternative signal-flow graph and block diagram model structures were considered for representing the transfer function (or differential equation) of a system. Using Mason's signal-flow gain formula, we noted the ease of obtaining the flow graph model. The state differential equation representing the flow graph and block diagram models was also examined. The time response of a linear system and its associated transition matrix was discussed, and the utility of Mason's signal-flow gain formula for obtaining the transition matrix was illustrated. A detailed analysis of a space station model development was presented for a realistic scenario where the attitude control is accomplished in conjunction with minimizing the actuator control. The relationship between modeling with state variable forms and control system design was established. The use of control design software to convert a transfer function to state variable form and calculate the state transition matrix was discussed and illustrated. The chapter concluded with the development of a state variable model for the Sequential Design Example: Disk Drive Read System. 

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. The state variables of a system comprise a set of variables that describe the future response of the system, when given the present state, all future excitation inputs, and the mathematical model describing the dynamics.

True or False

2. The matrix exponential function describes the unforced response of the system and is called the state transition matrix.

True or False

3. The outputs of a linear system can be related to the state variables and the input signals by the state differential equation.

True or False

4. A time-invariant control system is a system for which one or more of the parameters of the system may vary as a function of time.

True or False

5. A state variable representation of a system can always be written in diagonal form.

True or False

6. Consider a system with the mathematical model given by the differential equation:

$$
5 \frac{d^{3} y(t)}{d t^{3}}+10 \frac{d^{2} y(t)}{d t^{2}}+5 \frac{d y(t)}{d t}+2 y(t)=u(t) .
$$

A state variable representation of the system is:

a.

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rrc}
-2 & -1 & -0.4 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0 \\
0
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{lll}
0 & 0 & 0.2
\end{array}\right] \mathbf{x}(t)
\end{aligned}
$$

b. $\dot{\mathbf{x}}(t)=\left[\begin{array}{rrc}-5 & -1 & -0.7 \\ 1 & 0 & 0 \\ 0 & -1 & 0\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}-1 \\ 0 \\ 0\end{array}\right] u(t)$

$$
y(t)=\left[\begin{array}{lll}
0 & 0 & 0.2
\end{array}\right] \mathbf{x}(t)
$$

c. $\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}-2 & -1 \\ 1 & -0\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}1 \\ 0\end{array}\right] u(t)$

$$
y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t)
$$

d.

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrc}
-2 & -1 & -0.4 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{lll}
0 & 0 & 0.2
\end{array}\right] \mathbf{x}(t)
\end{aligned}
$$

For Problems 7 and 8, consider the system represented by

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(\mathrm{t})+\mathbf{B} u(t),
$$

where

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & 5 \\
0 & 0
\end{array}\right] \quad \text { and } \quad \mathbf{B}=\left[\begin{array}{l}
1 \\
0
\end{array}\right]
$$

7. The associated state-transition matrix is:
a. $\Phi(t)=[5 t]$
b. $\boldsymbol{\Phi}(t)=\left[\begin{array}{cc}1 & 5 t \\ 0 & 1\end{array}\right]$
c. $\boldsymbol{\Phi}(t)=\left[\begin{array}{cc}1 & 5 t \\ 1 & 1\end{array}\right.$
d. $\Phi(t)=\left[\begin{array}{ccc}1 & 5 t & t^{2} \\ 0 & 1 & t \\ 0 & 0 & 1\end{array}\right]$

8. For the initial conditions $x_{1}(0)=x_{2}(0)=1$, the response $x(t)$ for the zero-input response is:
a. $x_{1}(t)=(1+t), x_{2}(t)=1$ for $t \geq 0$
b. $x_{1}(t)=(5+t), x_{2}(t)=t$ for $t \geq 0$
c. $x_{1}(t)=(5 t+1), x_{2}(t)=1$ for $t \geq 0$
d. $x_{1}(t)=x_{2}(t)=1$ for $t \geq 0$

9. A single-input, single-output system has the state variable representation

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{cc}
0 & -1 \\
-5 & -10
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
0 & 10
\end{array}\right] \mathbf{x}(t)
\end{aligned}
$$

The transfer function of the system $T(s)=Y(s) / U(s)$ is:
a. $T(s)=\frac{-50}{s^{3}+5 s^{2}+50 s}$
b. $T(s)=\frac{s+10}{s^{2}+10 s-5}$
c. $T(s)=\frac{-5}{s+5}$
d. $T(s)=\frac{-50}{s^{2}+5 s+5}$

10. The differential equation model for two first-order systems in series is

$$
\ddot{x}(t)+4 \dot{x}(t)+3 x(t)=u(t),
$$

where $u(t)$ is the input of the first system and $x(t)$ is the output of the second system. The response $x(t)$ of the system to a unit impulse $u(t)$ is:
a. $x(t)=e^{-t}-2 e^{-2 t}$
b. $x(t)=\frac{1}{2} e^{-2 t}-\frac{1}{3} e^{-3 t}$
c. $x(t)=\frac{1}{2} e^{-t}-\frac{1}{2} e^{-3 t}$
d. $x(t)=e^{-t}-e^{-3 t}$

11. A first-order dynamic system is represented by the differential equation

$$
5 \dot{x}(t)+x(t)=u(t) .
$$

The corresponding transfer function and state-space representation are
a. $G(s)=\frac{1}{1+5 s} \quad$ and $\quad \begin{gathered}\dot{x}=-0.2 x+0.2 u \\ y=x\end{gathered}$
b. $G(s)=\frac{10}{1+5 s} \quad$ and $\quad \dot{x}=\begin{array}{r}-0.2 x+u \\ y=x\end{array}$
c. $G(s)=\frac{1}{s+5} \quad$ and $\quad \begin{array}{r}\dot{x}=-5 x+u \\ y=x\end{array}$

d. None of the above

Consider the block diagram in Figure 3.40 for Problems 12 through 14:

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0239.jpg?height=302&width=1080&top_left_y=597&top_left_x=483)

FIGURE 3.40 Block diagram for the Skills Check.

12. The effect of the input $R(s)$ and the disturbance $T_{d}(s)$ on the output $Y(s)$ can be considered independently of each other because:

a. This is a linear system, therefore we can apply the principle of superposition.

b. The input $R(s)$ does not influence the disturbance $T_{d}(s)$.

c. The disturbance $T_{d}(s)$ occurs at high frequency, while the input $R(s)$ occurs at low frequency.

d. The system is causal.

13. The state-space representation of the closed-loop system from $R(s)$ to $Y(s)$ is:

a. $\dot{x}(t)=-10 x(t)+10 K r(t)$

$$
y(t)=x(t)
$$

b. $\dot{x}(t)=-(10+10 K) x(t)+r(t)$

$$
y(t)=10 x(t)
$$

c. $\dot{x}(t)=-(10+10 K) x(t)+10 K r(t)$

$$
y(t)=x(t)
$$

d. None of the above

14. The steady-state error $E(s)=Y(s)-R(s)$ due to a unit step disturbance $T_{d}(s)=1 / s$ is:
a. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=\infty$
b. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=1$
c. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=\frac{1}{K+1}$
d. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=K+1$

15. A system is represented by the transfer function

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{5(s+10)}{s^{3}+10 s^{2}+20 s+50} .
$$

A state variable representation is:

a. $\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}-10 & -20 & -50 \\ -1 & 0 & 0 \\ 0 & -1 & 0\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}1 \\ 1 \\ 0\end{array}\right] u(t)$

$y(t)=\left[\begin{array}{lll}0 & 5 & 50\end{array}\right] \mathbf{x}(t)$

b. $\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}-10 & -20 & -50 \\ -1 & 0 & 0 \\ 0 & -1 & 0\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}1 \\ 0 \\ 0\end{array}\right] u(t)$

$y(t)=\left[\begin{array}{lll}0 & 5 & 50\end{array}\right] \mathbf{x}(t)$

c. $\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}-10 & -20 & -50 \\ 1 & 0 & 0 \\ 0 & 1 & 0\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}1 \\ 1 \\ 0\end{array}\right] u(t)$

$y(t)=\left[\begin{array}{lll}0 & 5 & 50\end{array}\right] \mathbf{x}(t)$

d. $\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}-10 & -20 \\ 0 & -1\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}1 \\ 0\end{array}\right] u(t)$

$y(t)=\left[\begin{array}{ll}0 & 5\end{array}\right] \mathbf{x}(t)$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. State vector The differential equation for the state vector $\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)$.

b. State of a The matrix exponential function that describes the unforced resystem sponse of the system.

c. Time-varying The mathematical domain that incorporates the time response system and the description of a system in terms of time, $t$.

d. Transition Vector containing all $n$ state variables, $x_{1}, x_{2}, \ldots x_{n}$. matrix

e. State variables

A set of numbers such that the knowledge of these numbers and the input function will, with the equations describing the dynamics, provide the future state of the system.

f. State A system for which one or more parameters may vary with time.

differential

equation

g. Time domain The set of variables that describe the system.

\section{EXERCISES}

E3.1 For the spring-mass-damper model shown in Figure E3.1, identify a set of state variables.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0240.jpg?height=193&width=607&top_left_y=1872&top_left_x=221)

FIGURE E3.1 Spring-mass-damper model.
E3.2 The voltage-current relationship for a series $R L C$ circuit can be represented by the differential equation

$$
v(t)=R i(t)+L \frac{d i(t)}{d t}+v_{c}(t),
$$

where $v(t)$ is the voltage source, $i(t)$ is the current, and $v_{c}(t)$ is the voltage across the capacitor. Put the equations in state variable form, and set up the matrix $R=L=C=1$. E3.3 The system in E3.3 can be represented by the state vector differential equation

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t),
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-1 & -1
\end{array}\right]
$$

Find the (a) characteristic equation and (b) characteristic roots of the system.

Answer: (a) $\lambda^{2}+\lambda+1=0 ;$ (b) $-0.5+0.866 i$,

$$
-0.5-0.866 i
$$

E3.4 Obtain a state variable matrix for a system with a differential equation

$$
\frac{d^{4} y(t)}{d t^{4}}=\frac{d^{2} y(t)}{d t^{2}}+y(t)+u(t) .
$$

E3.5 A system is represented by a block diagram as shown in Figure E3.5. Write the state equations in the form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t)+\mathbf{D} u(t)
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0241.jpg?height=235&width=804&top_left_y=974&top_left_x=87)

FIGURE E3.5 Block diagram.

E3.6 Consider the system

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \mathbf{x}(t) .
$$

(a) Find the state transition matrix $\boldsymbol{\Phi}(t)$. (b) For the initial conditions $x_{1}(0)=x_{2}(0)=1$, find $\mathbf{x}(t)$.

Answer: (b) $x_{1}(t)=1+t, x_{2}(t)=1, t \geq 0$

E3.7 Consider the spring and mass shown in Figure 3.3 where $M=1 \mathrm{~kg}, k=100 \mathrm{~N} / \mathrm{m}$, and $b=20 \mathrm{Ns} / \mathrm{m}$.

(a) Find the state vector differential equation. (b) Find the roots of the characteristic equation for this system.
$\begin{aligned} & \text { Answer: } \\ & \text { (a) } \dot{\mathbf{x}}(t)\end{aligned}=\left[\begin{array}{rr}0 & 1 \\ -100 & -20\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}0 \\ 1\end{array}\right] u(t)$
(b) $s=-10,-10$

E3.8 Consider the system

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & -8 & -2
\end{array}\right] \mathbf{x}(t) .
$$

Find the characteristic equation, and the roots of the characteristic equation.
E3.9 A multi-loop block diagram is shown in Figure E3.9. The state variables are denoted by $x_{1}(t)$ and $x_{2}(t)$. (a) Determine a state variable representation of the closed-loop system where the output is denoted by $y(t)$ and the input is $r(t)$. (b) Determine the characteristic equation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0241.jpg?height=383&width=769&top_left_y=392&top_left_x=846)

FIGURE E3.9 Multi-loop feedback control system.

E3.10 A hovering vehicle control system is represented by two state variables, and [13]

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 6 \\
-1 & -5
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) .
$$

(a) Find the roots of the characteristic equation.

(b) Find the state transition matrix $\boldsymbol{\Phi}(t)$.

Answer:

(a) $s=-3,-2$

(b) $\boldsymbol{\Phi}(t)=\left[\begin{array}{cc}3 e^{-2 t}-2 e^{-3 t} & -6 e^{-3 t}+6 e^{-2 t} \\ e^{-3 t}-e^{-2 t} & 3 e^{-3 t}-2 e^{-2 t}\end{array}\right]$

E3.11 Determine a state variable representation for the system described by the transfer function

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{4(s+3)}{(s+2)(s+6)} .
$$

E3.12 Use a state variable model to describe the circuit of Figure E3.12. Obtain the response to an input unit step when the initial current is zero, and the initial capacitor voltage is zero.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0241.jpg?height=226&width=722&top_left_y=1672&top_left_x=857)

FIGURE E3.12 RLC series circuit.

E3.13 A system is described by the two differential equations

$$
\frac{d y(t)}{d t}+y(t)-2 u(t)+a w(t)=0
$$

and

$$
\frac{d w(t)}{d t}-b y(t)+4 u(t)=0,
$$

where $w(t)$ and $y(t)$ are functions of time, and $u(t)$ is an input. (a) Select a set of state variables. (b) Write the matrix differential equation and specify the elements of the matrices. (c) Find the characteristic roots of the system in terms of the parameters $a$ and $b$.

Answer: (c) $s=-1 / 2 \pm \sqrt{1-4 a b} / 2$

E3.14 Develop the state-space representation of a radioactive material of mass $M$ to which additional radioactive material is added at the rate $r(t)=K u(t)$, where $K$ is a constant. Identify the state variables. Assume that the mass decay is proportional to the mass present.

E3.15 Consider the case of the two masses connected as shown in Figure E3.15. The sliding friction of each mass has the constant $b$. Determine a state variable matrix differential equation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0242.jpg?height=273&width=745&top_left_y=863&top_left_x=239)

FIGURE E3.15 Two-mass system.

E3.16 Two carts with negligible rolling friction are connected as shown in Figure E3.16. An input force is $u(t)$. The output is the position of cart 2, that is, $y(t)=q(t)$. Determine a state space representation of the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0242.jpg?height=221&width=697&top_left_y=1407&top_left_x=263)

FIGURE E3.16 Two carts with negligible rolling friction.

E3.17 Determine a state variable differential matrix equation for the circuit shown in Figure E3.17:

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0242.jpg?height=250&width=792&top_left_y=1820&top_left_x=239)

FIGURE E3.17 $R C$ circuit.
E3.18 Consider a system represented by the following differential equations:

$$
\begin{gathered}
R i_{1}(t)+L_{1} \frac{d i_{1}(t)}{d t}+v(t)=v_{a}(t) \\
L_{2} \frac{d i_{2}(t)}{d t}+v(t)=v_{b}(t) \\
i_{1}(t)+i_{2}(t)=C \frac{d v(t)}{d t}
\end{gathered}
$$

where $R, L_{1}, L_{2}$, and $C$ are given constants, and $v_{a}(t)$ and $v_{b}(t)$ are inputs. Let the state variables be defined as $x_{1}(t)=i_{1}(t), x_{2}(t)=i_{2}(t)$, and $x_{3}(t)=v(t)$. Obtain a state variable representation of the system where the output is $x_{3}(t)$.

E3.19 A single-input, single-output system has the matrix equations

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-4 & -7
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t)
$$

and

$$
y(t)=\left[\begin{array}{ll}
4 & 0
\end{array}\right] \mathbf{x}(t) .
$$

Determine the transfer function $G(s)=Y(s) / U(s)$.

E3.20 For the simple pendulum shown in Figure E3.20, the nonlinear equations of motion are given by

$$
\ddot{\theta}(t)+\frac{g}{L} \sin \theta(t)+\frac{k}{m} \dot{\theta}(t)=0,
$$

where $g$ is gravity, $L$ is the length of the pendulum, $m$ is the mass attached at the end of the pendulum (assume the rod is massless), and $k$ is the coefficient of friction at the pivot point.

(a) Linearize the equations of motion about the equilibrium condition $\theta_{0}=0^{\circ}$.

(b) Obtain a state variable representation of the system. The system output is the angle $\theta(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0242.jpg?height=520&width=701&top_left_y=1551&top_left_x=1047)

FIGURE E3.20 Simple pendulum. E3.21 A single-input, single-output system is described by

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-1 & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
y(t)=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t)
\end{gathered}
$$

Obtain the transfer function $G(s)=Y(s) / U(s)$ and determine the response of the system to a unit step input.

E3.22 Consider the system in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t)
\end{aligned}
$$

with

$$
\mathbf{A}=\left[\begin{array}{ll}
3 & 2 \\
3 & 4
\end{array}\right], \mathbf{B}=\left[\begin{array}{r}
1 \\
-1
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \text {, and } \mathbf{D}=[0] .
$$

(a) Compute the transfer function $G(s)=Y(s) / U(s)$. (b) Determine the poles and zeros of the system. (c) If possible, represent the system as a first-order system

$$
\begin{aligned}
& \dot{x}(t)+a x(t)+b u(t) \\
& y(t)+c x(t)+d u(t)
\end{aligned}
$$

where $a, b, c$, and $d$ are scalars such that the transfer function is the same as obtained in (a).

E3.23 Consider a system modeled via the third-order differential equation

$$
\begin{aligned}
& \dddot{x}(t)+3 \ddot{x}(t)+3 \dot{x}(t)+x(t) \\
= & \dddot{u}(t)+2 \ddot{u}(t)+4 \dot{u}(t)+u(t) .
\end{aligned}
$$

Develop a state variable representation and obtain a block diagram of the system assuming the output is $x(t)$ and the input is $u(t)$.

\section{PROBLEMS}

P3.1 A spring-mass-damper system is shown in Figure P3.1. (a) Identify a suitable set of state variables. (b) Obtain the set of first-order differential equations in terms of the state variables. (c) Write the state differential equation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0243.jpg?height=301&width=743&top_left_y=1051&top_left_x=87)

FIGURE P3.1 Spring-mass-damper system.

P3.2 A balanced bridge network is shown in Figure P3.2.

(a) Show that the $\mathbf{A}$ and $\mathbf{B}$ matrices for this circuit are

$$
\begin{gathered}
\mathbf{A}=\left[\begin{array}{cc}
-2 /\left(\left(R_{1}+R_{2}\right) C\right) & 0 \\
0 & -2 R_{1} R_{2} /\left(\left(R_{1}+R_{2}\right) L\right)
\end{array}\right] \\
\mathbf{B}=1 /\left(R_{1}+R_{2}\right)\left[\begin{array}{cc}
1 / C & 1 / C \\
R_{2} / L & -R_{2} / L
\end{array}\right] .
\end{gathered}
$$

(b) Sketch the block diagram. The state variables are $\left(x_{1}(t), x_{2}(t)\right)=\left(v_{c}(t), i_{L}(t)\right)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0243.jpg?height=324&width=748&top_left_y=1816&top_left_x=85)

P3.3 An $R L C$ network is shown in Figure P3.3. Define the state variables as $x_{1}(t)=i_{L}(t)$ and $x_{2}(t)=v_{c}(t)$. Obtain the state differential equation.

Partial answer:

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 / L \\
-1 / C & -1 /(R C)
\end{array}\right]
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0243.jpg?height=263&width=798&top_left_y=1188&top_left_x=857)

FIGURE P3.3 RLC circuit.

P3.4 The transfer function of a system is

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{s^{2}+4 s+12}{s^{3}+4 s^{2}+8 s+12} .
$$

Sketch the block diagram and obtain a state variable model.

P3.5 A closed-loop control system is shown in Figure P3.5. (a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$. (b) Determine a state variable model and sketch a block diagram model in phase variable form.

P3.6 Determine the state variable matrix equation for the circuit shown in Figure P3.6. Let $x_{1}(t)=v_{1}(t), x_{2}(t)=v_{2}(t)$, and $x_{3}(t)=i(t)$. FIGURE P3.5

Closed-loop

system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0244.jpg?height=306&width=967&top_left_y=487&top_left_x=521)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0244.jpg?height=258&width=1532&top_left_y=155&top_left_x=222)

\section{$R L C$ circuit.}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0244.jpg?height=329&width=755&top_left_y=849&top_left_x=225)

FIGURE P3.7 Submarine depth control.

P3.7 An automatic depth-control system for a robot submarine is shown in Figure P3.7. The depth is measured by a pressure transducer. The gain of the stern plane actuator is $K=1$ when the vertical velocity is $25 \mathrm{~m} / \mathrm{s}$. The submarine has the transfer function

$$
G(s)=\frac{(s+2)^{2}}{s^{2}+2},
$$

and the feedback transducer is $H(s)=s+3$. Determine a state variable representation for the system.

P3.8 The soft landing of a lunar module descending on the moon can be modeled as shown in Figure P3.8. Define the state variables as $x_{1}(t)=y(t), x_{2}(t)=$ $\dot{y}(t), x_{3}(t)=m(t)$, and the control as $u=\dot{m}(t)$. Assume that $g$ is the gravity constant on the moon. Find a state variable model for this system. Is this a linear model?

P3.9 A speed control system using fluid flow components is to be designed. The system is a pure fluid control system because it does not have any moving mechanical parts. The fluid may be a gas or a liquid. A system is desired that maintains the speed within $0.5 \%$ of the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0244.jpg?height=484&width=609&top_left_y=847&top_left_x=1069)

FIGURE P3.8 Lunar module landing control.

desired speed by using a tuning fork reference and a valve actuator. Fluid control systems are insensitive and reliable over a wide range of temperature, electromagnetic and nuclear radiation, acceleration, and vibration. The amplification within the system is achieved by using a fluid jet deflection amplifier. The system can be designed for a $500-\mathrm{kW}$ steam turbine with a speed of $12,000 \mathrm{rpm}$. The block diagram of the system is shown in Figure P3.9. In dimensionless units, we have $b=0.1, J=1$, and $K_{1}=0.5$. (a) Determine the closed-loop transfer function

$$
T(s)=\frac{\omega(s)}{R(s)} .
$$

(b) Determine a state variable representation. (c) Determine the characteristic equation obtained from the $\mathbf{A}$ matrix. FIGURE P3.9

Steam turbine control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0245.jpg?height=372&width=1174&top_left_y=153&top_left_x=368)

P3.10 Many control systems must operate in two dimensions, for example, the $x$ - and the $y$-axes. A two-axis control system is shown in Figure P3.10, where a set of state variables is identified. The gain of each axis is $K_{1}$ and $K_{2}$, respectively. (a) Obtain the state differential equation. (b) Find the characteristic equation from the A matrix. (c) Determine the state transition matrix for $K_{1}=1$ and $K_{2}=2$.

P3.11 A system is described by

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)
$$

where

$$
\mathbf{A}=\left[\begin{array}{rr}
0 & 1 \\
-2 & -3
\end{array}\right]
$$

and $x_{1}(0)=1$ and $x_{2}(0)=0$. Determine $x_{1}(t)$ and $x_{2}(t)$.
P3.12 A system is described by its transfer function

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{8(s+5)}{s^{3}+12 s^{2}+44 s+48} .
$$

(a) Determine a state variable model.

(b) Determine the state transition matrix, $\boldsymbol{\Phi}(t)$.

P3.13 Consider again the spring-mass-damper system of Problem P3.1 when $M=1, b=6$, and $k=8$. (a) Determine whether the system is stable by finding the characteristic equation with the aid of the $\mathbf{A}$ matrix. (b) Determine the state transition matrix of the system. (c) When the initial velocity is $1 \mathrm{~m} / \mathrm{s}$ and initial displacement is $1 \mathrm{~m} / \mathrm{s}$, determine the response of the system with $F(t)=0$.
FIGURE P3.10

Two-axis system. (a) Signal-flow graph. (b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0245.jpg?height=346&width=903&top_left_y=1210&top_left_x=412)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0245.jpg?height=397&width=757&top_left_y=1655&top_left_x=485)

(b) P3.14 Determine a state variable representation for a system with the transfer function

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{s+50}{s^{4}+12 s^{3}+10 s^{2}+34 s+50} .
$$

P3.15 Obtain a block diagram and a state variable representation of this system.

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{14(s+4)}{s^{3}+10 s^{2}+31 s+16} .
$$

P3.16 The dynamics of a controlled submarine are significantly different from those of an aircraft, missile, or surface ship. This difference results primarily from the moment in the vertical plane due to the buoyancy effect. Therefore, it is interesting to consider the control of the depth of a submarine. The equations describing the dynamics of a submarine can be obtained by using Newton's laws and the angles defined in Figure P3.16. To simplify the equations, we will assume that $\theta(t)$ is a small angle and the velocity $v$ is constant and equal to $25 \mathrm{ft} / \mathrm{s}$. The state variables of the submarine, considering only vertical control, are $x_{1}(t)=\theta(t), x_{2}(t)=\dot{\theta}(t)$, and $x_{3}(t)=\alpha(t)$, where $\alpha(t)$ is the angle of attack. Thus the state vector differential equation for this system, when the submarine has an Albacore type hull, is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
-0.01 & -0.11 & 0.12 \\
0 & 0.07 & -0.3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
-0.1 \\
+0.1
\end{array}\right] u(t),
$$

where $u(t)=\delta_{s}(t)$, the deflection of the stern plane. (a) Determine whether the system is stable. (b) Determine the response of the system to a stern plane step command of $0.285^{\circ}$ with the initial conditions equal to zero.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0246.jpg?height=348&width=741&top_left_y=1416&top_left_x=222)

FIGURE P3.16 Submarine depth control.

P3.17 A system is described by the state variable equations

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rrr}
1 & 1 & -1 \\
4 & 3 & 0 \\
-2 & 1 & 10
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
4
\end{array}\right] u(t), \\
y(t) & =\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine $G(s)=Y(s) / U(s)$.
P3.18 Consider the control of the robot shown in Figure P3.18. The motor turning at the elbow moves the wrist through the forearm, which has some flexibility as shown [16]. The spring has a spring constant $k$ and friction-damping constant $b$. Let the state variables be $x_{1}(t)=\phi_{1}(t)-\phi_{2}(t)$ and $x_{2}(t)=\omega_{1}(t) / \omega_{0}$, where

$$
\omega_{0}^{2}=\frac{k\left(J_{1}+J_{2}\right)}{J_{1} J_{2}} .
$$

Write the state variable equation in matrix form when $x_{3}(t)=\omega_{2}(t) / \omega_{0}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0246.jpg?height=176&width=722&top_left_y=613&top_left_x=1008)

FIGURE P3.18 An industrial robot. (Courtesy of GCA Corporation.)

P3.19 Consider the system described by

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-4 & -4
\end{array}\right] \mathbf{x}(t),
$$

where $\mathbf{x}(t)=\left(\mathrm{x}_{1}(\mathrm{t}), \mathrm{x}_{2}(\mathrm{t})\right)^{\mathrm{T}}$. (a) Compute the state transition matrix $\boldsymbol{\Phi}(t, 0)$. (b) Using the state transition matrix from (a) and for the initial conditions $x_{1}(0)=1$ and $x_{2}(0)=-1$, find the solution $\mathbf{x}(t)$ for $t \geq 0$.

P3.20 A nuclear reactor that has been operating in equilibrium at a high thermal-neutron flux level is suddenly shut down. At shutdown, the density $X$ of xenon 135 and the density $I$ of iodine 135 are $7 \times 10^{16}$ and $3 \times 10^{15}$ atoms per unit volume, respectively. The half-lives of $\mathrm{I}_{135}$ and $\mathrm{Xe}_{135}$ nucleides are 6.7 and 9.2 hours, respectively. The decay equations are $[15,19]$

$$
\dot{I}(t)=-\frac{0.693}{6.7} I(t), \quad \dot{X}(t)=-\frac{0.693}{9.2} X(t)-I(t) .
$$

Determine the concentrations of $\mathrm{I}_{135}$ and $\mathrm{Xe}_{135}$ as functions of time following shutdown by determining (a) the transition matrix and the system response.

(b) Verify that the response of the system is that shown in Figure P3.20.

P3.21 Consider the block diagram in Figure P3.21.

(a) Verify that the transfer function is

$$
G(s)=\frac{Y(s)}{U(s)}=\frac{h_{1} s+h_{0}+a_{1} h_{1}}{s^{2}+a_{1} s+a_{0}} .
$$

(b) Show that a state variable model is given by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{cc}
0 & 1 \\
-a_{0} & -a_{1}
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
h_{1} \\
h_{0}
\end{array}\right] u(t), \\
y(t) & =\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

FIGURE P3.20 Nuclear reactor response.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0247.jpg?height=764&width=851&top_left_y=154&top_left_x=372)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0247.jpg?height=369&width=755&top_left_y=963&top_left_x=88)

FIGURE P3.21 Model of second-order system.

P3.22 Determine a state variable model for the circuit shown in Figure P3.22. The state variables are $x_{1}(t)=$ $i(t), x_{2}(t)=v_{1}(t)$, and $x_{3}(t)=v_{2}(t)$. The output variable is $v_{0}(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0247.jpg?height=256&width=762&top_left_y=1655&top_left_x=87)

FIGURE P3.22 RLC circuit.

P3.23 The two-tank system shown in Figure P3.23(a) is controlled by a motor adjusting the input valve and ultimately varying the output flow rate. The system has the transfer function

$$
\frac{Q_{0}(s)}{I(s)}=G(s)=\frac{1}{s^{3}+10 s^{2}+29 s+20}
$$

for the block diagram shown in Figure P3.23(b). Obtain a state variable model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0247.jpg?height=376&width=741&top_left_y=1282&top_left_x=862)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0247.jpg?height=169&width=750&top_left_y=1750&top_left_x=867)

(b)

FIGURE P3.23 A two-tank system with the motor current controlling the output flow rate. (a) Physical diagram. (b) Block diagram. P3.24 It is desirable to use well-designed controllers to maintain building temperature with solar collector space-heating systems. One solar heating system can be described by [10]

$$
\frac{d x_{1}(t)}{d t}=3 x_{1}(t)+u_{1}(t)+u_{2}(t),
$$

and

$$
\frac{d x_{2}(t)}{d t}=2 x_{2}(t)+u_{2}(t)+d(t)
$$

where $x_{1}(t)=$ temperature deviation from desired equilibrium, and $x_{2}(t)=$ temperature of the storage material (such as a water tank). Also, $u_{1}(t)$ and $u_{2}(t)$ are the respective flow rates of conventional and solar heat, where the transport medium is forced air. A solar disturbance on the storage temperature (such as overcast skies) is represented by $d(t)$. Write the matrix equations and solve for the system response when $u_{1}(t)=0, u_{2}(t)=1$, and $d(t)=1$, with zero initial conditions.

P3.25 A system has the following differential equation:

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-2 & -3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] r(t)
$$

Determine $\boldsymbol{\Phi}(t)$ and its transform $\boldsymbol{\Phi}(s)$ for the system.

P3.26 A system has a block diagram as shown in Figure P3.26. Determine a state variable model and the state transition matrix $\boldsymbol{\Phi}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0248.jpg?height=280&width=753&top_left_y=1351&top_left_x=223)

FIGURE P3.26 Feedback system.

P3.27 A gyroscope with a single degree of freedom is shown in Figure P3.27. Gyroscopes sense the angular motion of a system and are used in automatic flight control systems. The gimbal moves about the output axis $O B$. The input is measured around the input axis $O A$. The equation of motion about the output axis is obtained by equating the rate of change of angular momentum to the sum of torques. Obtain a statespace representation of the gyro system.

P3.28 A two-mass system is shown in Figure P3.28. The rolling friction constant is $b$. Determine a state

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0248.jpg?height=414&width=696&top_left_y=167&top_left_x=1035)

FIGURE P3.27 Gyroscope.

variable representation when the output variable is $y_{2}(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0248.jpg?height=263&width=682&top_left_y=842&top_left_x=1016)

FIGURE P3.28 Two-mass system.

P3.29 There has been considerable engineering effort directed at finding ways to perform manipulative operations in space-for example, assembling a space station and acquiring target satellites. To perform such tasks, space shuttles carry a remote manipulator system (RMS) in the cargo bay [4, 12,21]. The RMS has proven its effectiveness on recent shuttle missions, but now a new design approach can be considered-a manipulator with inflatable arm segments. Such a design might reduce manipulator weight by a factor of four while producing a manipulator that, prior to inflation, occupies only one-eighth as much space in the cargo bay as the present RMS.

The use of an RMS for constructing a space structure in the shuttle bay is shown in Figure P3.29(a), and a model of the flexible RMS arm is shown in Figure P3.29(b), where $J$ is the inertia of the drive motor and $L$ is the distance to the center of gravity of the load component. Derive the state equations for this system.

P3.30 Obtain the state equations for the two-input and one-output circuit shown in Figure P3.30, where the output is $i_{2}(t)$.

P3.31 Extenders are robot manipulators that extend (that is, increase) the strength of the human arm in 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0249.jpg?height=336&width=605&top_left_y=152&top_left_x=163)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0249.jpg?height=252&width=548&top_left_y=575&top_left_x=187)

(b)

FIGURE P3.29 Remote manipulator system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0249.jpg?height=251&width=720&top_left_y=966&top_left_x=87)

FIGURE P3.30 Two-input RLC circuit.

load-maneuvering tasks (Figure P3.31) [19, 22]. The system is represented by the transfer function

$$
\frac{Y(s)}{U(s)}=G(s)=\frac{30}{s^{2}+4 s+3},
$$

where $U(s)$ is the force of the human hand applied to the robot manipulator, and $Y(s)$ is the force of the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0249.jpg?height=363&width=697&top_left_y=1625&top_left_x=75)

FIGURE P3.31 Extender for increasing the strength of the human arm in load maneuvering tasks. robot manipulator applied to the load. Determine a state variable model and the state transition matrix for the system.

P3.32 A drug taken orally is ingested at a rate $r(t)$. The mass of the drug in the gastrointestinal tract is denoted by $m_{1}(t)$ and in the bloodstream by $m_{2}(t)$. The rate of change of the mass of the drug in the gastrointestinal tract is equal to the rate at which the drug is ingested minus the rate at which the drug enters the bloodstream, a rate that is taken to be proportional to the mass present. The rate of change of the mass in the bloodstream is proportional to the amount coming from the gastrointestinal tract minus the rate at which mass is lost by metabolism, which is proportional to the mass present in the blood. Develop a state space representation of this system.

For the special case where the coefficients of $\boldsymbol{A}$ are equal to 1 (with the appropriate sign), determine the response when $m_{1}(0)=1$ and $m_{2}(0)=0$. Plot the state variables versus time and on the $x_{1}-x_{2}$ state plane.

P3.33 The attitude dynamics of a rocket are represented by

$$
\frac{Y(s)}{U(s)}=G(s)=\frac{1}{s^{2}}
$$

and state variable feedback is used where $x_{1}(t)=y(t), x_{2}(t)=\dot{y}(t)$, and $u(t)=-x_{2}(t)-0.5 x_{1}(t)$. Determine the roots of the characteristic equation of this system and the response of the system when the initial conditions are $x_{1}(0)=0$ and $x_{2}(0)=1$. The input $U(s)$ is the applied torques, and $Y(s)$ is the rocket attitude.

P3.34 A system has the transfer function

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{6}{s^{3}+6 s^{2}+11 s+6} .
$$

(a) Construct a state variable representation of the system.

(b) Determine the element $\phi_{11}(t)$ of the state transition matrix for this system.

P3.35 Determine a state-space representation for the system shown in Figure P3.35. The motor inductance is negligible, the motor constant is $K_{m}=10$, the back electromagnetic force constant is $K_{b}=0.0706$, the motor friction is negligible. The motor and valve inertia is $J=0.006$, and the area of the tank is $50 \mathrm{~m}^{2}$. Note that the motor is controlled by the armature current $i_{a}(t)$. Let $x_{1}(t)=h(t), x_{2}(t)=\theta(t)$, and $x_{3}(t)=\dot{\theta}(t)$. Assume that $q_{1}(t)=80 \theta(t)$, where $\theta(t)$ is the shaft angle. The output flow is $q_{0}(t)=50 h(t)$. FIGURE P3.35

One-tank system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0250.jpg?height=438&width=1025&top_left_y=148&top_left_x=520)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0250.jpg?height=543&width=327&top_left_y=674&top_left_x=446)

FIGURE P3.36 one damper.
FIGURE P3.37

A block diagram model of a thirdorder system.
P3.36 Consider the two-mass system in Figure P3.36. Find a state variable representation of the system. Assume the output is $x(t)$.

P3.37 Consider the block diagram in Figure P3.37. Using the block diagram as a guide, obtain the state variable model of the system in the form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t) .
\end{aligned}
$$

Using the state variable model as a guide, obtain a third-order differential equation model for the system.

Two-mass system with two springs and

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0250.jpg?height=696&width=1100&top_left_y=1383&top_left_x=506)



\section{ADVANCED PROBLEMS}

AP3.1 Consider the electromagnetic suspension system shown in Figure AP3.1. An electromagnet is located at the upper part of the experimental system. Using the electromagnetic force $f$, we want to suspend the iron ball. Note that this simple electromagnetic suspension system is essentially unworkable. Hence feedback control is indispensable. As a gap sensor, a standard induction probe of the type of eddy current is placed below the ball [20].

Assume that the state variables are $x_{1}(t)=x(t)$, $x_{2}(t)=\dot{x}(t)$, and $x_{3}(t)=i(t)$. The electromagnet has an inductance $L=0.508 \mathrm{H}$ and a resistance $R=23.2 \Omega$. Use a Taylor series approximation for the electromagnetic force. The current is $i_{1}(t)=I_{0}+i(t)$, where $I_{0}=1.06 \mathrm{~A}$ is the operating point and $i(t)$ is the variable. The mass $m$ is equal to $1.75 \mathrm{~kg}$. The gap is $x_{g}(t)=X_{0}+x(t)$, where $X_{0}=4.36 \mathrm{~mm}$ is the operating point and $x(t)$ is the variable. The electromagnetic force is $f(t)=k\left(i_{1}(t) / x_{g}(t)\right)^{2}$, where $k=2.9 \times 10^{-4} \mathrm{~N} \mathrm{~m}^{2} / \mathrm{A}^{2}$. Determine the matrix differential equation and the equivalent transfer function $X(s) / V(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0251.jpg?height=597&width=515&top_left_y=1056&top_left_x=222)

FIGURE AP3.1 Electromagnetic suspension system.

AP3.2 A two-mass model of a robot arm is shown in Figure AP3.2. Determine the transfer function $Y(s) / F(s)$, and use the transfer function to obtain a state-space representation of the system.

AP3.3 The control of an autonomous vehicle motion from one point to another point depends on accurate control of the position of the vehicle [16]. The control of the autonomous vehicle position $Y(s)$ is obtained by the system shown in Figure AP3.3. Obtain a state variable representation of the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0251.jpg?height=191&width=496&top_left_y=262&top_left_x=881)

FIGURE AP3.2 The spring-mass-damper system of a robot arm.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0251.jpg?height=268&width=727&top_left_y=583&top_left_x=878)

FIGURE AP3.3 Position control.

AP3.4 Front suspensions have become standard equipment on mountain bikes. Replacing the rigid fork that attaches the bicycle's front tire to its frame, such suspensions absorb bump impact energy, shielding both frame and rider from jolts. Commonly used forks, however, use only one spring constant and treat bump impacts at high and low speeds - impacts that vary greatly in severity - essentially the same.

A suspension system with multiple settings that are adjustable while the bike is in motion would be attractive. One air and coil spring with an oil damper is available that permits an adjustment of the damping constant to the terrain as well as to the rider's weight [17]. The suspension system model is shown in Figure AP3.4, where $b$ is adjustable. Select the appropriate value for $b$ so that the bike accommodates (a) a large bump at high speeds and (b) a small bump at low speeds. Assume that $k_{2}=1$ and $k_{1}=2$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0251.jpg?height=406&width=510&top_left_y=1641&top_left_x=996)

FIGURE AP3.4 Shock absorber. AP3.5 Figure AP3.5 shows a mass $M$ suspended from another mass $m$ by means of a light rod of length $L$. Obtain a state variable model using a linear model assuming a small angle for $\theta(t)$. Assume the output is the angle, $\theta(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0252.jpg?height=392&width=736&top_left_y=359&top_left_x=225)

FIGURE AP3.5 Mass suspended from cart.

AP3.6 Consider a crane moving in the $x$ direction while the mass $m$ moves in the $z$ direction, as shown in Figure AP3.6. The trolley motor and the hoist motor are very powerful with respect to the mass of the trolley, the hoist wire, and the load $m$. Consider the input control variables as the distances $D(t)$ and $R(t)$. Also assume that $\theta(t)<50^{\circ}$. Determine a linear model, and describe the state variable differential equation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0252.jpg?height=346&width=741&top_left_y=1163&top_left_x=222)

FIGURE AP3.6 A crane moving in the $x$-direction while the mass moves in the $z$-direction.

AP3.7 Consider the single-input, single-output system described by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
-1 & 1 \\
0 & 0
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
2 & 1
\end{array}\right]
$$

Assume that the input is a linear combination of the states, that is,

$$
u(t)=-\mathbf{K} \mathbf{x}(t)+r(t),
$$

where $r(t)$ is the reference input. The matrix $\mathrm{K}=\left[\begin{array}{ll}K_{1} & K_{2}\end{array}\right]$ is known as the gain matrix. Substituting $u(t)$ into the state variable equation gives the closed-loop system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =[\mathbf{A}-\mathbf{B K}] \mathbf{x}(t)+\mathbf{B} r(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t) .
\end{aligned}
$$

The design process involves finding $\mathbf{K}$ so that the eigenvalues of $\mathbf{A - B K}$ are at desired locations in the left-half plane. Compute the characteristic polynomial associated with the closed-loop system and determine values of $\mathbf{K}$ so that the closed-loop eigenvalues are in the left-half plane.

AP3.8 A system for dispensing radioactive fluid into capsules is shown in Figure AP3.8(a). The horizontal axis moving the tray of capsules is actuated by a linear motor. The $x$-axis control is shown in Figure AP3.8(b). (a) Obtain a state variable model of the closed-loop system with input $r(t)$ and output $y(t)$. (b) Determine the characteristic roots of the system and compute $K$ such that the characteristic values are all co-located at $s_{1}=-3, s_{2}=-3$, and $s_{3}=-3$. (c) Determine analytically the unit step-response of the closed-loop system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0252.jpg?height=697&width=738&top_left_y=1018&top_left_x=1014)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0252.jpg?height=195&width=736&top_left_y=1817&top_left_x=1015)

(b)

FIGURE AP3.8 Automatic fluid dispenser. 

\section{DESIGN PROBLEMS}

CDP3.1 The traction drive uses the capstan drive system shown in Figure CDP2.1. Neglect the effect of the motor inductance and determine a state variable model for the system. The parameters are given in Table CDP2.1. The friction of the slide is negligible.

DP3.1 A spring-mass-damper system, as shown in Figure 3.3, is used as a shock absorber for a large high-performance motorcycle. The original parameters selected are $m=1 \mathrm{~kg}, b=9 \mathrm{~N} \mathrm{~s} / m$, and $k=20 \mathrm{~N} / m$. (a) Determine the system matrix, the characteristic roots, and the transition matrix $\Phi(t)$. The harsh initial conditions are assumed to be $y(0)=1$ and $d y /\left.d t\right|_{t=0}=2$. (b) Plot the response of $y(t)$ and $\dot{y}(t)$ for the first two seconds. (c) Redesign the shock absorber by changing the spring constant and the damping constant in order to reduce the effect of a high rate of acceleration force $\dot{y}(t)$ on the rider. The mass must remain constant at $1 \mathrm{~kg}$.

DP3.2 A system has the state variable matrix equation in phase variable form

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-a & -b
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
d
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

It is desired that the canonical diagonal form of the differential equation be

$$
\begin{aligned}
& \dot{\mathbf{z}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-10 & -2
\end{array}\right] \mathbf{z}(t)+\left[\begin{array}{l}
1 \\
1
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{ll}
1 & -1
\end{array}\right] \mathbf{z}(t) .
\end{aligned}
$$

Determine the parameters $a, b$, and $d$ to yield the required diagonal matrix differential equation.

DP3.3 An aircraft arresting gear is used on an aircraft carrier as shown in Figure DP3.3. The linear model of each energy absorber has a drag force $f_{D}(t)=K_{D} \dot{x}_{3}(t)$. It is desired to halt the airplane within $30 \mathrm{~m}$ after engaging the arresting cable [13]. The speed of the aircraft on landing is $60 \mathrm{~m} / \mathrm{s}$. Select the required constant $K_{D}$, and plot the response of the state variables.

DP3.4 The Mile-High Bungi Jumping Company wants you to design a bungi jumping system (that is a cord) so that the jumper cannot hit the ground when his or her mass is less than $100 \mathrm{~kg}$, but greater than $50 \mathrm{~kg}$. Also, the company wants a hang time (the time a jumper is moving up and down) greater than 25 seconds, but less than 40 seconds. Determine the characteristics of the cord. The jumper stands on a platform $90 \mathrm{~m}$ above the ground, and the cord will be attached to a fixed beam secured $10 \mathrm{~m}$ above the platform. Assume that the jumper is $2 \mathrm{~m}$ tall and the cord is attached at the waist (1 m high).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0253.jpg?height=840&width=1279&top_left_y=1278&top_left_x=339)

FIGURE DP3.3

Aircraft arresting gear. DP3.5 Consider the single-input, single-output system described by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{rr}
0 & 1 \\
-4 & -5
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{lll}
1 & 0
\end{array}\right]
$$

Assume that the input is a linear combination of the states, that is,

$$
u(t)=-\mathbf{K x}(t)+r(t),
$$

where $r(t)$ is the reference input. Determine $\mathbf{K}=\left[\begin{array}{ll}K_{1} & K_{2}\end{array}\right]$ so that the closed-loop system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =[\mathbf{A}-\mathbf{B K}] \mathbf{x}(t)+\mathbf{B} r(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t)
\end{aligned}
$$

possesses closed-loop eigenvalues at $r_{1}$ and $r_{2}$. Note that if $r_{1}=\sigma+j \omega$ is a complex number, then $r_{2}=\sigma-j \omega$ is its complex conjugate.

\section{COMPUTER PROBLEMS}

CP3.1 Determine a state variable representation for the following transfer functions (with unity feedback) using the ss function:
(a) $G(s)=\frac{1}{s+1}$
(b) $G(s)=\frac{s^{2}+s+1}{2 s^{2}+s+1}$
(c) $G(s)=\frac{s+1}{3 s^{3}+2 s^{2}+s+1}$

CP3.2 By using the tf function, determine the transfer function representation for the state variable models based on your answers for CP3.1. Show that the transfer function is the same.

CP3.3 Consider the $R L C$ circuit shown in Figure CP3.3. Determine the transfer function $V_{2}(s) / V_{1}(s)$.

(a) Determine the state variable representation when $R=1 \Omega, L=0.5 \mathrm{H}$, and $C=1 \mathrm{~F}$.

(b) Using the state variable representation from part (a), plot the unit step response with the step function.

CP3.4 Consider the system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-4 & -1 & -6
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t), \\
y(t) & =\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0254.jpg?height=236&width=646&top_left_y=717&top_left_x=1013)

FIGURE CP3.3 RLC circuit.

(a) Using the tf function, determine the transfer function $Y(s) / U(s)$.

(b) Plot the response of the system to the initial condition $\mathbf{x}(0)=\left[\begin{array}{lll}0 & -1 & 1\end{array}\right]^{T}$ for $0 \leq t \leq 20$.

(c) Compute the state transition matrix using the expm function, and determine $\mathbf{x}(t)$ at $t=20$ for the initial condition given in part (b). Compare the result with the system response obtained in part (b).

CP3.5 Consider the two systems

$$
\begin{aligned}
\dot{\mathbf{x}}_{1}(t) & =\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-4 & -5 & -8
\end{array}\right] \mathbf{x}_{1}(t)+\left[\begin{array}{l}
0 \\
0 \\
4
\end{array}\right] u(t), \\
y(t) & =\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}_{1}(t)
\end{aligned}
$$

and

$$
\begin{gathered}
\dot{\mathbf{x}}_{2}(t)=\left[\begin{array}{rrr}
0.5000 & 0.5000 & 0.7071 \\
-0.5000 & -0.5000 & 0.7071 \\
-6.3640 & -0.7071 & -8.000
\end{array}\right] \mathbf{x}_{2}(t)+\left[\begin{array}{l}
0 \\
0 \\
4
\end{array}\right] u(t), \\
y(t)=\left[\begin{array}{lll}
0.7071 & -0.7071 & 0
\end{array}\right] \mathbf{x}_{2}(t) .
\end{gathered}
$$

(a) Using the tf function, determine the transfer function $Y(s) / U(s)$ for system (1).

(b) Repeat part (a) for system (2).

(c) Compare the results in parts (a) and (b) and comment.

CP3.6 Consider the closed-loop control system in Figure CP3.6.

(a) Determine a state variable representation of the controller.

(b) Repeat part (a) for the process.

(c) With the controller and process in state variable form, use the series and feedback functions to compute a closed-loop system representation in state variable form and plot the closed-loop system impulse response.

CP3.7 Consider the following system:

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rr}
0 & 1 \\
-4 & -7
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t)
\end{aligned}
$$

with

$$
\mathbf{x}(0)=\left(\begin{array}{l}
1 \\
0
\end{array}\right)
$$

Using the Isim function obtain and plot the system response (for $x_{1}(t)$ and $x_{2}(t)$ ) when $u(t)=0$.

CP3.8 Consider the state variable model with parameter $K$ given by

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-2 & -K & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Plot the characteristic values of the system as a function of $K$ in the range $0 \leq K \leq 100$. Determine that range of $K$ for which all the characteristic values lie in the left half-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0255.jpg?height=243&width=847&top_left_y=998&top_left_x=470)

FIGURE CP3.6 A closed-loop feedback control system.

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) False; Word Match (in order, top to bottom): f, d, g, a, b, c, e (5) False

Multiple Choice: (6) a; (7) b; (8) c; (9) b; (10) c; (11) a; (12) a; (13) c; (14) c; (15) c

\section{TERMS AND CONCEPTS}

Canonical form A fundamental or basic form of the state variable model representation, including phase variable canonical form, input feedforward canonical form, diagonal canonical form, and Jordan canonical form.

Diagonal canonical form A decoupled canonical form displaying the $n$ distinct system poles on the diagonal of the state variable representation $\mathbf{A}$ matrix.
Fundamental matrix See Transition matrix.

Input feedforward canonical form A canonical form described by $n$ feedback loops involving the $a_{n}$ coefficients of the $n$th order denominator polynomial of the transfer function and feedforward loops obtained by feeding forward the input signal.

Jordan canonical form A block diagonal canonical form for systems that do not possess distinct system poles. Matrix exponential function An important matrix function, defined as $e^{\mathbf{A} t}=\mathrm{I}+\mathbf{A} t+(\mathbf{A} t)^{2} / 2 !+\cdots+$ $(\mathbf{A} t)^{k} / k !+\cdots$, that plays a role in the solution of linear constant coefficient differential equations.

Output equation The algebraic equation that relates the state vector $\mathbf{x}$ and the inputs $\mathbf{u}$ to the outputs $\mathbf{y}$ through the relationship $\mathbf{y}=\mathbf{C x}+\mathbf{D u}$.

Phase variable canonical form A canonical form described by $n$ feedback loops involving the $a_{n}$ coefficients of the $n$th order denominator polynomial of the transfer function and $m$ feedforward loops involving the $b_{m}$ coefficients of the $m$ th order numerator polynomial of the transfer function.

Phase variables The state variables associated with the phase variable canonical form.

Physical variables The state variables representing the physical variables of the system.

State differential equation The differential equation for the state vector: $\dot{\mathbf{x}}=\mathbf{A x}+\mathbf{B u}$.
State of a system A set of numbers such that the knowledge of these numbers and the input function will, with the equations describing the dynamics, provide the future state of the system.

State-space representation A time-domain model comprising the state differential equation $\dot{\mathbf{x}}=\mathbf{A x}+\mathbf{B u}$ and the output equation, $\mathbf{y}=\mathbf{C x}+\mathbf{D u}$.

State variables The set of variables that describe the system.

State vector The vector containing all $n$ state variables, $x_{1}, x_{2}, \ldots, x_{n}$.

Time domain The mathematical domain that incorporates the time response and the description of a system in terms of time $t$.

Time-varying system A system for which one or more parameters may vary with time.

Transition matrix $\boldsymbol{\Phi}(t)$ The matrix exponential function that describes the unforced response of the system. 

\section{CHAPTER \\ Feedback Control System Characteristics}

4.1 Introduction 257

4.2 Error Signal Analysis 259

4.3 Sensitivity of Control Systems to Parameter Variations 261

4.4 Disturbance Signals in a Feedback Control System 264

4.5 Control of the Transient Response 269

4.6 Steady-State Error 272

4.7 The Cost of Feedback 274

4.8 Design Examples 275

4.9 Control System Characteristics Using Control Design Software 285

4.10 Sequential Design Example: Disk Drive Read System 291

4.11 Summary 295

\section{PREVIEW}

In this chapter, we explore the role of error signals to characterize feedback control system performance, including the reduction of sensitivity to model uncertainties, disturbance rejection, measurement noise attenuation, steady-state errors, and transient response characteristics. The error signal is employed in the feedback control system via negative feedback. We discuss the sensitivity of a system to parameter changes, since it is desirable to minimize the effects of parameter variations and uncertainties. We also wish to diminish the effect of unwanted disturbances and measurement noise on the ability of the system to track a desired input. We then describe the transient and steady-state performance of a feedback system and show how this performance can be readily improved with feedback. The chapter concludes with a system performance analysis of the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 4, students should be able to:

$\square$ Explain the central role of error signals in analysis of control systems.

$\square \quad$ Identify the improvements afforded by feedback control in reducing system sensitivity to parameter changes, disturbance rejection, and measurement noise attenuation.

$\square$ Describe the differences between controlling the transient response and the steady-state response of a system.

$\square \quad$ State the benefits and costs of feedback in the control design process. 

\subsection{INTRODUCTION}

A control system is defined as an interconnection of components forming a system that will provide a desired system response. Because the desired system response is known, a signal proportional to the error between the desired and the actual response is generated. The use of this signal to control the process results in a closed-loop sequence of operations that is called a feedback system. This closed-loop sequence of operations is shown in Figure 4.1. The introduction of feedback to improve the control system is often necessary. It is interesting that this is also the case for systems in nature, such as biological and physiological systems; feedback is inherent in these systems. For example, the human heart rate control system is a feedback control system. To illustrate the characteristics and advantages of introducing feedback, we consider a single-loop feedback system. Although many control systems are multiloop, a thorough comprehension of the benefits of feedback can best be obtained from the single-loop system and then extended to multiloop systems.

An open-loop system, or a system without feedback, is shown in Figure 4.2. The disturbance, $T_{d}(s)$, directly influences the output, $Y(s)$. In the absence of feedback, the control system is highly sensitive to disturbances and to both knowledge of and variations in parameters of $G(s)$.

If the open-loop system does not provide a satisfactory response, then a suitable cascade controller, $G_{\mathrm{c}}(s)$, can be inserted preceding the process, $G(s)$, as shown in Figure 4.3. Then it is necessary to design the cascade transfer function, $G_{\mathrm{c}}(s) G(s)$, so that the resulting transfer function provides the desired transient response. This is known as open-loop control.

FIGURE 4.1

A closed-loop system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0258.jpg?height=556&width=572&top_left_y=1208&top_left_x=519)

FIGURE 4.2

An open-loop system with a disturbance input, $T_{d}(s)$ (a) Signal-flow graph. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0258.jpg?height=242&width=480&top_left_y=1805&top_left_x=517)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0258.jpg?height=228&width=604&top_left_y=1824&top_left_x=1053)

(b) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0259.jpg?height=223&width=586&top_left_y=166&top_left_x=149)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0259.jpg?height=223&width=849&top_left_y=185&top_left_x=766)

(b)

FIGURE 4.3 Open-loop control system (without feedback). (a) Signal-flow graph. (b) Block diagram.

An open-loop system operates without feedback and directly generates the output in response to an input signal.

By contrast, a closed-loop negative feedback control system is shown in Figure 4.4.

A closed-loop system uses a measurement of the output signal and a comparison with the desired output to generate an error signal that is used by the controller to adjust the actuator.

FIGURE 4.4 A closed-loop control system. (a) Signal-flow graph. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0259.jpg?height=435&width=672&top_left_y=1142&top_left_x=666)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0259.jpg?height=409&width=1223&top_left_y=1656&top_left_x=393)

(b) Despite the cost and increased system complexity, closed-loop feedback control has the following advantages:

Decreased sensitivity of the system to variations in the parameters of the process.

- Improved rejection of the disturbances.

- Improved measurement noise attenuation.

- Improved reduction of the steady-state error of the system.

- Easy control and adjustment of the transient response of the system.

In this chapter, we examine how the application of feedback can result in the benefits listed above. Using the notion of a tracking error signal, it will be readily apparent that it is possible to utilize feedback with a controller in the loop to improve system performance.

\subsection{ERROR SIGNAL ANALYSIS}

The closed-loop feedback control system shown in Figure 4.4 has three inputs$R(s), T_{d}(s)$, and $N(s)$ - and one output, $Y(s)$. The signals $T_{d}(s)$ and $N(s)$ are the disturbance and measurement noise signals, respectively. Define the tracking error as

$$
E(s)=R(s)-Y(s) .
$$

For ease of discussion, we will consider a unity feedback system, that is, $H(s)=1$, in Figure 4.4. The influence of a nonunity feedback element in the loop will be considered later.

After some block diagram manipulation, we find that the output is given by

$$
Y(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} R(s)+\frac{G(s)}{1+G_{c}(s) G(s)} T_{d}(s)-\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} N(s) .
$$

Therefore, with $E(s)=R(s)-Y(s)$, we have

$$
E(s)=\frac{1}{1+G_{c}(s) G(s)} R(s)-\frac{G(s)}{1+G_{c}(s) G(s)} T_{d}(s)+\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} N(s) .
$$

Define the function

$$
L(s)=G_{c}(s) G(s) .
$$

The function, $L(s)$, is known as the loop gain and plays a fundamental role in control system analysis [12]. In terms of $L(s)$, the tracking error is given by

$$
E(s)=\frac{1}{1+L(s)} R(s)-\frac{G(s)}{1+L(s)} T_{d}(s)+\frac{L(s)}{1+L(s)} N(s)
$$

We can define the function

$$
F(s)=1+L(s)
$$

Then, in terms of $F(s)$, we define the sensitivity function as

$$
S(s)=\frac{1}{F(s)}=\frac{1}{1+L(s)} .
$$

Similarly, in terms of the loop gain, we define the complementary sensitivity function as

$$
C(s)=\frac{L(s)}{1+L(s)} .
$$

In terms of the functions $S(s)$ and $C(s)$, we can write the tracking error as

$$
E(s)=S(s) R(s)-S(s) G(s) T_{d}(s)+C(s) N(s) .
$$

Examining Equation (4.7), we see that (for a given $G(s)$ ), if we want to minimize the tracking error, we want both $S(s)$ and $C(s)$ to be small. Remember that $S(s)$ and $C(s)$ are both functions of the controller, $G_{c}(s)$, which the control engineer designs. However, the following special relationship between $S(s)$ and $C(s)$ holds

$$
S(s)+C(s)=1 .
$$

Clearly, we cannot simultaneously make $S(s)$ and $C(s)$ small, hence design compromises must be made.

To analyze the tracking error equation, we need to understand what it means for a transfer function to be "large" or to be "small." The discussion of magnitude of a transfer function is the subject of Chapters 8 and 9 on frequency response methods. However, for our purposes here, we describe the magnitude of the loop gain $L(s)$ by considering the magnitude $|L(j \omega)|$ over the range of frequencies, $\omega$, of interest.

Considering the tracking error in Equation (4.4), it is evident that, for a given $G(s)$, to reduce the influence of the disturbance, $T_{d}(s)$, on the tracking error, $E(s)$, we desire $L(s)$ to be large over the range of frequencies that characterize the disturbances. That way, the transfer function $G(s) /(1+L(s))$ will be small, thereby reducing the influence of $T_{d}(s)$. Since $L(s)=G_{c}(s) G(s)$, this implies that we need to design the controller $G_{c}(s)$ to have a large magnitude over the important range of frequencies. Conversely, to attenuate the measurement noise, $N(s)$, and reduce the influence on the tracking error, we desire $L(s)$ to be small over the range of frequencies that characterize the measurement noise. The transfer function $L(s) /(1+L(s)$ ) will be small, thereby reducing the influence of $N(s)$. Again, since $L(s)=G_{c}(s) G(s)$, that implies that we need to design the controller $G_{c}(s)$ to have a small magnitude over the important range of frequencies. Fortunately, the apparent conflict between wanting to make $G_{c}(s)$ large to reject disturbances and the wanting to make $G_{c}(s)$ small to attenuate measurement noise can be addressed in the design phase by making the loop gain, $L(s)$, large at low frequencies (generally associated with the frequency range of disturbances), and making $L(s)$ small at high frequencies (generally associated with measurement noise).

More discussion on disturbance rejection and measurement noise attenuation follows in the subsequent sections. Next, we discuss how we can use feedback to reduce the sensitivity of the system to variations and uncertainty in parameters in the process, $G(s)$. This is accomplished by analyzing the tracking error in Equation (4.2) when $T_{d}(s)=N(s)=0$. 

\subsection{SENSITIVITY OF CONTROL SYSTEMS TO PARAMETER VARIATIONS}

A process, represented by the transfer function $G(s)$ is subject to a changing environment, aging, uncertainty in the exact values of the process parameters, and other factors that affect a control process. In the open-loop system, all these errors and changes result in a changing and inaccurate output. However, a closed-loop system senses the change in the output due to the process changes and attempts to correct the output. The sensitivity of a control system to parameter variations is of prime importance. A primary advantage of a closed-loop feedback control system is its ability to reduce the system's sensitivity $[1-4,18]$.

For the closed-loop case, if $G_{c}(s) G(s) \gg 1$ for all complex frequencies of interest, we can use Equation (4.2) to obtain (letting $T_{d}(s)=0$ and $N(s)=0$ )

$$
Y(s) \cong R(s) \text {. }
$$

The output is approximately equal to the input. However, the condition $G_{c}(s) G(s) \gg 1$ may cause the system response to be highly oscillatory and even unstable. But the fact that increasing the magnitude of the loop gain reduces the effect of $G(s)$ on the output is a useful result. Therefore, the first advantage of a feedback system is that the effect of the variation of the parameters of the process, $G(s)$, is reduced.

Suppose the process (or plant) $G(s)$ undergoes a change such that the true plant model is $G(s)+\Delta G(s)$. The change in the plant may be due to a changing external environment or it may represent the uncertainty in certain plant parameters. We consider the effect on the tracking error $E(s)$ due to $\Delta G(s)$. Utilizing the principle of superposition, we let $T_{d}(s)=N(s)=0$ and consider only the reference input $R(s)$. From Equation (4.3), it follows that

$$
E(s)+\Delta E(s)=\frac{1}{1+G_{c}(s)(G(s)+\Delta G(s))} R(s) .
$$

Then the change in the tracking error is

$$
\Delta E(s)=\frac{-G_{c}(s) \Delta G(s)}{\left(1+G_{c}(s) G(s)+G_{c}(s) \Delta G(s)\right)\left(1+G_{c}(s) G(s)\right)} R(s) .
$$

Since we usually find that $G_{c}(s) G(s) \gg G_{c}(s) \Delta G(s)$, we have

$$
\Delta E(s) \approx \frac{-G_{c}(s) \Delta G(s)}{(1+L(s))^{2}} R(s) .
$$

We see that the change in the tracking error is reduced by the factor $1+L(s)$, which is generally greater than 1 over the range of frequencies of interest.

For large $L(s)$, we have $1+L(s) \approx L(s)$, and we can approximate the change in the tracking error by

$$
\Delta E(s) \approx-\frac{1}{L(s)} \frac{\Delta G(s)}{G(s)} R(s) .
$$

Larger magnitude $L(s)$ translates into smaller changes in the tracking error (that is, reduced sensitivity to changes in $\Delta G(s)$ in the process). Also, larger $L(s)$ implies smaller sensitivity, $S(s)$. The question arises, how do we define sensitivity? The system sensitivity is defined as the ratio of the percentage change in the system transfer function to the percentage change of the process transfer function. The system transfer function is

$$
T(s)=\frac{Y(s)}{R(s)},
$$

and therefore the sensitivity is defined as

$$
S=\frac{\Delta T(s) / T(s)}{\Delta G(s) / G(s)} .
$$

In the limit, for small incremental changes, Equation (4.11) becomes

$$
S=\frac{\partial T / T}{\partial G / G}=\frac{\partial \ln \mathrm{T}}{\partial \ln \mathrm{G}} .
$$

\section{System sensitivity is the ratio of the change in the system transfer function to the change of a process transfer function (or parameter) for a small incremental change.}

The sensitivity of the open-loop system to changes in the plant $G(s)$ is equal to 1 . The sensitivity of the closed-loop is readily obtained by using Equation (4.12). The system transfer function of the closed-loop system is

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} .
$$

Therefore, the sensitivity of the feedback system is

$$
S_{G}^{T}=\frac{\partial T}{\partial G} \cdot \frac{G}{T}=\frac{G_{c}}{\left(1+G_{c} G\right)^{2}} \cdot \frac{G}{G G_{c} /\left(1+G_{c} G\right)}
$$

or

$$
S_{G}^{T}=\frac{1}{1+G_{c}(s) G(s)}
$$

We find that the sensitivity of the system may be reduced below that of the openloop system by increasing $L(s)=G_{c}(s) G(s)$ over the frequency range of interest. Note that $S_{G}^{T}$ in Equation (4.12) is exactly the same as the sensitivity function $S(s)$ given in Equation (4.5).

Often, we seek to determine $S_{\alpha}^{T}$, where $\alpha$ is a parameter within the transfer function, $G(s)$. Using the chain rule yields

$$
S_{\alpha}^{T}=S_{G}^{T} S_{\alpha}^{G}
$$

Very often, the transfer function of the system $T(s)$ is a fraction of the form [1]

$$
T(s, \alpha)=\frac{N(s, \alpha)}{D(s, \alpha)},
$$

where $\alpha$ is a parameter that may be subject to variation due to the environment. Then we may obtain the sensitivity to $\alpha$ by rewriting Equation (4.11) as

$$
S_{\alpha}^{T}=\frac{\partial \ln \mathrm{T}}{\partial \ln \alpha}=\left.\frac{\partial \ln \mathrm{N}}{\partial \ln \alpha}\right|_{\alpha=\alpha_{0}}-\left.\frac{\partial \ln \mathrm{D}}{\partial \ln \alpha}\right|_{\alpha=\alpha_{0}}=S_{\alpha}^{N}-S_{\alpha}^{D},
$$

where $\alpha_{0}$ is the nominal value of the parameter.

An important advantage of feedback control systems is the ability to reduce the effect of the variation of parameters of a control system by adding a feedback loop. To obtain highly accurate open-loop systems, the components of the open-loop, $G(s)$, must be selected carefully in order to meet the exact specifications. However, a closed-loop system allows $G(s)$ to be less accurately specified because the sensitivity to changes or errors in $G(s)$ is reduced by the loop gain $L(s)$. This benefit of closed-loop systems is a profound advantage. A simple example will illustrate the value of feedback for reducing sensitivity.

\section{EXAMPLE 4.1 Feedback amplifier}

An amplifier used in many applications has a gain $-K_{a}$, as shown in Figure 4.5(a). The output voltage is

$$
V_{\mathrm{o}}(s)=-K_{a} V_{\text {in }}(s) .
$$

We often add feedback using a potentiometer $R_{p}$, as shown in Figure 4.5(b). The transfer function of the amplifier without feedback is

$$
T(s)=-K_{a},
$$

and the sensitivity to changes in the amplifier gain is

$$
S_{K_{a}}^{T}=1 .
$$

The block diagram model of the amplifier with feedback is shown in Figure 4.6, where

FIGURE 4.5

(a) Open-loop amplifier.

(b) Amplifier with feedback.

$$
\beta=\frac{R_{2}}{R_{1}}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0264.jpg?height=263&width=491&top_left_y=1748&top_left_x=507)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0264.jpg?height=315&width=625&top_left_y=1736&top_left_x=1033)

(b) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0265.jpg?height=353&width=680&top_left_y=167&top_left_x=88)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0265.jpg?height=247&width=715&top_left_y=187&top_left_x=826)

(b)

FIGURE 4.6 Block diagram model of feedback amplifier assuming $R_{p} \gg R_{0}$ of the amplifier.

and

$$
R_{p}=R_{1}+R_{2} \text {. }
$$

The closed-loop transfer function of the feedback amplifier is

$$
T(s)=\frac{-K_{a}}{1+K_{a} \beta} .
$$

The sensitivity of the closed-loop feedback amplifier is

$$
S_{K_{a}}^{T}=S_{G}^{T} S_{K_{a}}^{G}=\frac{1}{1+K_{a} \beta} .
$$

If $K_{a}$ is large, the sensitivity is low. For example, if

$$
K_{a}=10^{4} \text { and } \beta=0.1,
$$

we have

$$
S_{K_{a}}^{T}=\frac{1}{1+10^{3}} \approx \frac{1}{1000}
$$

or the magnitude is one-thousandth of the magnitude of the open-loop amplifier.

We shall return to the concept of sensitivity in subsequent chapters. These chapters will emphasize the importance of sensitivity in the design and analysis of control systems.

\subsection{DISTURBANCE SIGNALS IN A FEEDBACK CONTROL SYSTEM}

Many control systems are subject to extraneous disturbance signals that cause the system to provide an inaccurate output. Electronic amplifiers have inherent noise generated within the integrated circuits or transistors; radar antennas are subjected to wind gusts; and many systems generate unwanted distortion signals due to nonlinear elements. An important effect of feedback in a control system is the reduction of the effect of disturbance signals. A disturbance signal is an unwanted input signal that affects the output signal. The benefit of feedback systems is that the effect of distortion, noise, and unwanted disturbances can be effectively reduced.

\section{Disturbance Rejection}

When $R(s)=N(s)=0$, it follows from Equation (4.4) that

$$
E(s)=-S(s) G(s) T_{d}(s)=-\frac{G(s)}{1+L(s)} T_{d}(s) .
$$

For a fixed $G(s)$ and a given $T_{d}(s)$, as the loop gain $L(s)$ increases, the effect of $T_{d}(s)$ on the tracking error decreases. In other words, the sensitivity function $S(s)$ is small when the loop gain is large. We say that large loop gain leads to good disturbance rejection. More precisely, for good disturbance rejection, we require a large loop gain over the frequencies of interest associated with the expected disturbance signals.

In practice, the disturbance signals are often low frequency. When that is the case, we say that we want the loop gain to be large at low frequencies. This is equivalent to stating that we want to design the controller $G_{c}(s)$ so that the sensitivity function $S(s)$ is small at low frequencies.

As a specific example of a system with an unwanted disturbance, let us consider again the speed control system for a steel rolling mill [19]. The rolls, which process steel, are subjected to large load changes or disturbances. As a steel bar approaches the rolls (see Figure 4.7), the rolls are empty. However, when the bar engages in the rolls, the load on the rolls increases immediately to a large value. This loading effect can be approximated by a step change of disturbance torque.

The transfer function model of an armature-controlled DC motor with a load torque disturbance was determined in Example 2.5 and is shown in Figure 4.8, where it is assumed that $L_{a}$ is negligible. Let $R(s)=0$ and examine $E(s)=-\omega(s)$, for a disturbance $T_{d}(s)$.

FIGURE 4.7

Steel rolling mill.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0266.jpg?height=256&width=646&top_left_y=1457&top_left_x=505)

FIGURE 4.8 Open-loop speed control system (without tachometer feedback).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0266.jpg?height=327&width=1077&top_left_y=1784&top_left_x=506)

The change in speed due to the load disturbance is then

$$
E(s)=-\omega(s)=\frac{1}{J s+b+K_{m} K_{b} / R_{a}} T_{d}(s) .
$$

The steady-state error in speed due to the load torque, $T_{d}(s)=D / s$, is found by using the final-value theorem. Therefore, for the open-loop system, we have

$$
\begin{aligned}
\lim _{t \rightarrow \infty} E(t) & =\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} s \frac{1}{J_{s}+b+K_{m} K_{b} / R_{a}}\left(\frac{D}{s}\right) \\
& =\frac{D}{b+K_{m} K_{b} / R_{a}}=-\omega_{0}(\infty) .
\end{aligned}
$$

The closed-loop speed control system is shown in block diagram form in Figure 4.9. The closed-loop system is shown in signal-flow graph and block diagram form in Figure 4.10, where $G_{1}(s)=K_{a} K_{m} / R_{a}, G_{2}(s)=1 /\left(J_{s}+b\right)$, and $H(s)=K_{t}+K_{b} / K_{a}$. The error, $E(s)=-\omega(s)$, of the closed-loop system of Figure 4.10 is:

$$
E(s)=-\omega(s)=\frac{G_{2}(s)}{1+G_{1}(s) G_{2}(s) H(s)} T_{d}(s) .
$$

Then, if $G_{1} G_{2} H(s)$ is much greater than 1 over the range of $s$, we obtain the approximate result

$$
E(s) \approx \frac{1}{G_{1}(s) H(s)} T_{d}(s) .
$$

Therefore, if $G_{1}(s) H(s)$ is made sufficiently large, the effect of the disturbance can be decreased by closed-loop feedback. Note that

$$
G_{1}(s) H(s)=\frac{K_{a} K_{m}}{R_{a}}\left(K_{t}+\frac{K_{b}}{K_{a}}\right) \approx \frac{K_{a} K_{m} K_{t}}{R_{a}},
$$

FIGURE 4.9

Closed-loop speed tachometer control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0267.jpg?height=444&width=1263&top_left_y=1669&top_left_x=370)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0268.jpg?height=296&width=630&top_left_y=153&top_left_x=221)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0268.jpg?height=296&width=853&top_left_y=172&top_left_x=900)

(b)

FIGURE 4.10 Closed-loop system. (a) Signal-flow graph model. (b) Block diagram model.

since $K_{a} \gg K_{b}$. Thus, we seek a large amplifier gain, $K_{a}$, while minimizing $R_{a}$. The error for the system shown in Figure 4.10 is

$$
E(s)=R(s)-\omega(s),
$$

and $R(s)=\omega_{d}(s)$, the desired speed. Let $R(s)=0$ and examine $\omega(s)$ yielding

$$
\omega(s)=\frac{-1}{J s+b+\left(K_{m} / R_{a}\right)\left(K_{t} K_{a}+K_{b}\right)} T_{d}(s) .
$$

The steady-state output is obtained by utilizing the final-value theorem, and we have

$$
\lim _{t \rightarrow \infty} \omega(t)=\lim _{s \rightarrow 0}(s \omega(s))=\frac{-1}{b+\left(K_{m} / R_{a}\right)\left(K_{t} K_{a}+K_{b}\right)} D
$$

when the amplifier gain $K_{a}$ is sufficiently high, we have

$$
\omega(\infty) \approx \frac{-R_{a}}{K_{a} K_{m} K_{t}} D=\omega_{c}(\infty)
$$

The ratio of closed-loop to open-loop steady-state speed output due to an undesired disturbance is

$$
\frac{\omega_{c}(\infty)}{\omega_{0}(\infty)}=\frac{R_{a} b+K_{m} K_{b}}{K_{a} K_{m} K_{t}}
$$

and is usually less than 0.02 .

\section{Measurement Noise Attenuation}

When $R(s)=T_{d}(s)=0$, it follows from Equation (4.4) that

$$
E(s)=C(s) N(s)=\frac{L(s)}{1+L(s)} N(s)
$$

As the loop gain $L(s)$ decreases, the effect of $N(s)$ on the tracking error decreases. In other words, the complementary sensitivity function $C(s)$ is small when the loop gain $L(s)$ is small. If we design $G_{c}(s)$ such that $L(s) \ll 1$, then the noise is attenuated because

$$
C(s) \approx L(s) .
$$

We see that small loop gain leads to good noise attenuation. More precisely, for effective measurement noise attenuation, we need a small loop gain over the frequencies associated with the expected noise signals.

In practice, measurement noise signals are often high frequency. Thus we want the loop gain to be low at high frequencies. This is equivalent to a small complementary sensitivity function at high frequencies. The separation of disturbances (at low frequencies) and measurement noise (at high frequencies) is very fortunate because it gives the control system designer a way to approach the design process: the controller should be high gain at low frequencies and low gain at high frequencies. Remember that by low and high we mean that the loop gain magnitude is low/high at the various high/low frequencies. It is not always the case that the disturbances are low frequency or that the measurement noise is high frequency. If the frequency separation does not exist, the design process usually becomes more involved (for example, we may have to use notch filters to reject disturbances at known high frequencies). A noise signal that is prevalent in many systems is the noise generated by the measurement sensor. This noise, $N(s)$, can be represented as shown in Figure 4.4. The effect of the noise on the output is

$$
Y(s)=\frac{-G_{c}(s) G(s)}{1+G_{c}(s) G(s)} N(s),
$$

which is approximately

$$
Y(s) \simeq-N(s)
$$

for large loop gain $L(s)=G_{c}(s) G(s)$. This is consistent with the earlier discussion that smaller loop gain leads to measurement noise attentuation. Clearly, the designer must shape the loop gain appropriately.

The equivalency of sensitivity, $S_{G}^{T}$, and the response of the closed-loop system tracking error to a reference input can be illustrated by considering Figure 4.4. The sensitivity of the system to $G(s)$ is

$$
S_{G}^{T}=\frac{1}{1+G_{c}(s) G(s)}=\frac{1}{1+L(s)} .
$$

The effect of the reference on the tracking error (with $T_{d}(s)=0$ and $N(s)=0$ ) is

$$
\frac{E(s)}{R(s)}=\frac{1}{1+G_{c}(s) G(s)}=\frac{1}{1+L(s)} .
$$

In both cases, we find that the undesired effects can be alleviated by increasing the loop gain. Feedback in control systems primarily reduces the sensitivity of the system to parameter variations and the effect of disturbance inputs. Note that the measures taken to reduce the effects of parameter variations or disturbances are equivalent, and fortunately, they reduce simultaneously. As a final illustration, consider the effect of the noise on the tracking error,

$$
\frac{E(s)}{T_{d}(s)}=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}=\frac{L(s)}{1+L(s)} .
$$

We find that the undesired effects of measurement noise can be alleviated by decreasing the loop gain. Keeping in mind the relationship

$$
S(s)+C(s)=1,
$$

the trade-off in the design process is evident.

\subsection{CONTROL OF THE TRANSIENT RESPONSE}

One of the most important characteristics of control systems is their transient response. The transient response is the response of a system as a function of time before steady-state. Because the purpose of control systems is to provide a desired response, the transient response often must be adjusted until it is satisfactory. If an open-loop control system does not provide a satisfactory response, then the loop transfer function, $G_{c}(s) G(s)$, must be adjusted. To make this concept more comprehensible, consider a specific control system which may be operated in an open- or closed-loop manner. A speed control system, as shown in Figure 4.11, is often used in industrial processes to move materials and products. The transfer function of the open-loop system (without feedback) is given by

$$
\frac{\omega(s)}{V_{a}(s)}=G(s)=\frac{K_{1}}{\tau_{1} s+1}
$$

where

$$
K_{1}=\frac{K_{m}}{R_{a} b+K_{b} K_{m}} \quad \text { and } \quad \tau_{1}=\frac{R_{a} J}{R_{a} b+K_{b} K_{m}}
$$

FIGURE 4.11

Open-loop speed control system (without feedback).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0270.jpg?height=366&width=985&top_left_y=1708&top_left_x=500)

FIGURE 4.12

(a) Open-loop speed control system.

(b) Closed-loop speed control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0271.jpg?height=132&width=985&top_left_y=148&top_left_x=446)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0271.jpg?height=259&width=1118&top_left_y=367&top_left_x=370)

(b)

In the case of a steel mill, the inertia of the rolls is quite large, and a large armature-controlled motor is required. If the steel rolls are subjected to a step command

$$
R(s)=\frac{k_{2} E}{s}
$$

the output response of the open-loop control system shown in Figure 4.12(a)

$$
\omega(s)=K_{a} G(s) R(s) .
$$

The transient speed change is then

$$
\omega(t)=K_{a} K_{1}\left(k_{2} E\right)\left(1-e^{-t / \tau_{1}}\right) .
$$

If this transient response is too slow, we must choose another motor with a different time constant $\tau_{1}$, if possible. However, because $\tau_{1}$ is dominated by the load inertia, $J$, it may not be possible to achieve much alteration of the transient response.

A closed-loop speed control system is easily obtained by using a tachometer to generate a voltage proportional to the speed, as shown in Figure 4.12(b). This voltage is subtracted from the potentiometer voltage and amplified as shown in Figure 4.12. The closed-loop transfer function is

$$
\frac{\omega(s)}{R(s)}=\frac{K_{a} G(s)}{1+K_{a} K_{t} G(s)}=\frac{K_{a} K_{1} / \tau_{1}}{s+\left(1+K_{a} K_{t} K_{1}\right) / \tau_{1}} .
$$

The amplifier gain, $K_{a}$, may be adjusted to meet the required transient response specifications. Also, the tachometer gain constant, $K_{t}$, may be varied, if necessary.

The transient response to a step change in the input command is

$$
\omega(t)=\frac{K_{a} K_{1}}{1+K_{a} K_{t} K_{1}}\left(k_{2} E\right)\left(1-e^{-p t}\right),
$$

FIGURE 4.13

The response of the open-loop and closed-loop speed control system when $\tau=10$ and $K_{1} K_{a} K_{t}=100$. The time to reach $98 \%$ of the final value for the open-loop and closed-loop system is 40 seconds and 0.4 seconds, respectively.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0272.jpg?height=687&width=852&top_left_y=153&top_left_x=522)

where $p=\left(1+K_{a} K_{t} K_{1}\right) / \tau_{1}$. Because the load inertia is assumed to be very large, we alter the response by increasing $K_{a}$. Thus, we have the approximate response

$$
\omega(t) \approx \frac{1}{K_{t}}\left(k_{2} E\right)\left[1-\exp \left(\frac{-\left(K_{a} K_{t} K_{1}\right) t}{\tau_{1}}\right)\right] .
$$

For a typical application, the open-loop pole might be $1 / \tau_{1}=0.10$, whereas the closed-loop pole could be at least $\left(K_{a} K_{t} K_{1}\right) / \tau_{1}=10$, a factor of one hundred in the improvement of the speed of response. To attain the gain $K_{a} K_{t} K_{1}$, the amplifier gain $K_{a}$ must be reasonably large, and the armature voltage signal to the motor and its associated torque signal must be larger for the closed-loop than for the open-loop operation. Therefore, a higher-power motor will be required to avoid saturation of the motor. The responses of the closed-loop system and the open-loop system are shown in Figure 4.13. Note the rapid response of the closed-loop system relative to the open-loop system.

While we are considering this speed control system, it will be worthwhile to determine the sensitivity of the open- and closed-loop systems. As before, the sensitivity of the open-loop system to a variation in the motor constant or the potentiometer constant $k_{2}$ is unity. The sensitivity of the closed-loop system to a variation in $K_{m}$ is

$$
S_{K_{m}}^{T}=S_{G}^{T} S_{K_{m}}^{G} \approx \frac{\left[s+\left(1 / \tau_{1}\right)\right]}{s+\left(K_{a} K_{t} K_{1}+1\right) / \tau_{1}} .
$$

Using the typical values given in the previous paragraph, we have

$$
S_{K_{m}}^{T} \approx \frac{(s+0.10)}{s+10} .
$$

We find that the sensitivity is a function of $s$ and must be evaluated for various values of frequency. This type of frequency analysis is straightforward but will be deferred until a later chapter. However, it is clearly seen that at a specific low frequency-for example, $s=j \omega=j 1$ - the magnitude of the sensitivity is approximately $\left|S_{K_{m}}^{T}\right| \cong 0.1$.

\subsection{STEADY-STATE ERROR}

A feedback control system provides the engineer with the ability to adjust the transient response. In addition, as we have seen, the sensitivity of the system and the effect of disturbances can be reduced significantly. However, as a further requirement, we must examine and compare the final steady-state error for an open-loop and a closed-loop system. The steady-state error is the error after the transient response has decayed, leaving only the continuous response.

The error of the open-loop control system shown in Figure 4.3 is

$$
E_{0}(s)=R(s)-Y(s)=\left(1-G_{c}(s) G(s)\right) R(s),
$$

when $T_{d}(s)=0$. Figure 4.4 shows the closed-loop system. When $T_{d}(s)=0$ and $N(s)=0$, and we let $H(s)=1$, the tracking error is given by

$$
E_{c}(s)=\frac{1}{1+G_{c}(s) G(s)} R(s)
$$

To calculate the steady-state error, we use the final-value theorem

$$
\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s E(s) .
$$

Therefore, using a unit step input as a comparable input, we obtain for the openloop system

$$
\begin{aligned}
e_{o}(\infty) & =\lim _{s \rightarrow 0} s\left(1-G_{c}(s) G(s)\right)\left(\frac{1}{s}\right)=\lim _{s \rightarrow 0}\left(1-G_{c}(s) G(s)\right) \\
& =1-G_{c}(0) G(0) .
\end{aligned}
$$

For the closed-loop system we have

$$
e_{c}(\infty)=\lim _{s \rightarrow 0} s\left(\frac{1}{1+G_{c}(s) G(s)}\right)\left(\frac{1}{s}\right)=\frac{1}{1+G_{c}(0) G(0)}
$$

The value of $G_{\mathrm{c}}(s) G(s)$ when $s=0$ is often called the DC gain and is normally greater than one. Therefore, the open-loop control system will usually have a steady-state error of significant magnitude. By contrast, the closed-loop system with a reasonably large DC loop gain $L(0)=G_{c}(0) G(0)$ will have a small steady-state error.

Upon examination of Equation (4.49), we note that the open-loop control system can possess a zero steady-state error by adjusting and calibrating the systems DC gain, $G_{\mathrm{c}}(0) G(0)$, so that $G_{c}(0) G(0)=1$. Therefore, we may logically ask, What is the advantage of the closed-loop system in this case? To answer this question, we return to the concept of the sensitivity of the system to parameter uncertainty in $G(s)$ and changes over time in those parameters. In the open-loop control system, we may calibrate the system so that $G_{c}(0) G(0)=1$, but during the operation of the system, it is inevitable that the parameters of $G(s)$ will change due to environmental changes and that the DC gain of the system will no longer be equal to 1 . Because it is an open-loop control system, the steady-state error will not equal zero. By contrast, the closed-loop feedback system continually monitors the steady-state error and provides an actuating signal to reduce the steady-state error. Because systems are susceptible to parameter drift, environmental effects, and calibration errors, negative feedback provides benefits.

The advantage of the closed-loop system is that it reduces the steady-state error resulting from parameter changes and calibration errors. This may be illustrated by an example. Consider a unity feedback system with a process transfer function and controller

$$
G(s)=\frac{K}{\tau s+1} \text { and } G_{c}(s)=\frac{K_{a}}{\tau_{1} s+1},
$$

respectively. Which could represent a thermal control process, a voltage regulator, or a water-level control process. For a specific setting of the desired input variable, which may be represented by the normalized unit step input function, we have $R(s)=1 / s$. Then the steady-state error of the open-loop system is, as in Equation (4.49),

$$
e_{0}(\infty)=1-G_{c}(0) G(0)=1-K K_{a}
$$

when a consistent set of dimensional units is utilized for $R(s)$ and $K K_{a}$. The error for the closed-loop system is

$$
E_{c}(s)=R(s)-T(s) R(s)
$$

where $T(s)=G_{c}(s) G(s) /\left(1+G_{c}(s) G(s)\right)$. The steady-state error is

$$
e_{c}(\infty)=\lim _{s \rightarrow 0} s\{1-T(s)\} \frac{1}{s}=1-T(0) .
$$

Then we have

$$
e_{c}(\infty)=1-\frac{K K_{a}}{1+K K_{a}}=\frac{1}{1+K K_{a}}
$$

For the open-loop control system, we would calibrate the system so that $K K_{a}=1$ and the steady-state error is zero. For the closed-loop system, we would set a large gain $K K_{a}$. If $K K_{a}=100$, the closed-loop system steady-state error is $e_{c}(\infty)=1 / 101$.

If the process gain drifts or changes by $\Delta K / K=0.1$ (a $10 \%$ change), the magnitude of the open-loop steady-state error is $\left|\Delta e_{o}(\infty)\right|=0.1$. Then the percent change from the calibrated setting is

$$
\frac{\left|\Delta e_{o}(\infty)\right|}{|r(t)|}=\frac{0.10}{1}
$$

or $10 \%$. By contrast, the steady-state error of the closed-loop system, with $\Delta K / K=0.1$, is $e_{c}(\infty)=1 / 91$ if the gain decreases. Thus, the change is

$$
\Delta e_{c}(\infty)=\frac{1}{101}-\frac{1}{91}
$$

and the relative change is

$$
\frac{\Delta e_{c}(\infty)}{|r(t)|}=0.0011
$$

or $0.11 \%$. This is a significant improvement, since the closed-loop relative change is two orders of magnitude lower than that of the open-loop system.

\subsection{THE COST OF FEEDBACK}

The advantages of using feedback control have an attendant cost. The first cost of feedback is an increased number of components and complexity in the system. To add the feedback, it is necessary to consider several feedback components; the measurement component (sensor) is the key one. The sensor is often the most expensive component in a control system. Furthermore, the sensor introduces noise into the system.

The second cost of feedback is the loss of gain. For example, in a single-loop system, the loop gain is $G_{c}(s) G(s)$ and is reduced to $G_{c}(s) G(s) /\left(1+G_{c}(s) G(s)\right)$ in a unity negative feedback system. The closed-loop gain is smaller by a factor of $1 /\left(1+G_{c}(s) G(s)\right)$, which is exactly the factor that reduces the sensitivity of the system to parameter variations and disturbances. Usually, we have extra loop gain available, and we are more than willing to trade it for increased control of the system response.

The final cost of feedback is the introduction of the possibility of instability. Even when the open-loop system is stable, the closed-loop system may not be always stable.

The addition of feedback to dynamic systems causes more challenges for the designer. However, for most cases, the advantages far outweigh the disadvantages, and a feedback system is desirable. Therefore, it is necessary to consider the additional complexity and the problem of stability when designing a control system.

We want the output of the system, $Y(s)$, to equal the input, $R(s)$. We might ask, Why not set $G_{c}(s) G(s)=1$ ? (See Figure 4.3, assuming $T_{d}(s)=0$.) In other words, why not let $G_{c}(s)$ be the inverse of the process $G(s)$. The answer to this question becomes apparent once we recall that the process $G(s)$ represents a real process and possesses dynamics that may not appear directly in the transfer function model. Additionally, the parameter in $G(s)$ may be uncertain or vary with time. Hence, we cannot perfectly set $G_{c}(s) G(s)=1$ in practice. There are other issues that also arise, thus it is not advisable to design the open-loop control system in this fashion. 

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples: the English Channel boring machine and a blood pressure control problem during anesthesia. The English Channel boring machine example focuses on the closed-loop system response to disturbances. The example on blood pressure control is a more in-depth look at the control design problem. Since patient models in the form of transfer functions are difficult to obtain from basic biological and physical principles, a different approach using measured data is discussed. The positive impact of closed-loop feedback control is illustrated in the context of design.

\section{EXAMPLE 4.2 English Channel boring machines}

The tunnel under the English Channel from France to Great Britain is 23.5 miles long and is bored 250 feet below sea level at its lowest-point. The tunnel is a critical link between Europe and Great Britain, making it possible to travel from London to Paris in 2 hours and 15 minutes using the Channel Tunnel Rail Link (known as High Speed 1).

The boring machines, operating from both ends of the channel, bored toward the middle. To link up accurately in the middle of the channel, a laser guidance system kept the machines precisely aligned. A model of the boring machine control is shown in Figure 4.14, where $Y(s)$ is the actual angle of direction of travel of the boring machine and $R(s)$ is the desired angle. The effect of load on the machine is represented by the disturbance, $T_{d}(s)$.

The design objective is to select the gain $K$ so that the response to input angle changes is desirable while we maintain minimal error due to the disturbance. The output due to the two inputs is

$$
Y(s)=\frac{K+11 s}{s^{2}+12 s+K} R(s)+\frac{1}{s^{2}+12 s+K} T_{d}(s) .
$$

Thus, to reduce the effect of the disturbance, we wish to set the gain greater than 10 . When we select $K=100$ and let the disturbance be zero, we have the step response for a unit step input $r(t)$, as shown in Figure 4.15. When the input $r(t)=0$ and we determine the response to the unit step disturbance, we obtain $y(t)$ as shown in Figure 4.15. The effect of the disturbance is quite small. If we set the gain $K$ equal to 20 , we obtain the responses of $y(t)$ due to a unit step input $r(t)$ and disturbance

FIGURE 4.14 A block diagram model of a boring machine control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0276.jpg?height=308&width=1117&top_left_y=1765&top_left_x=505)

FIGURE 4.15

The response $y(t)$ to a unit input step input (solid line) and a unit disturbance step (dashed line) with $T_{d}(s)=1 / s$ for $K=100$.

FIGURE 4.16

The response $y(t)$ for a unit step input (solid line) and for a unit step disturbance (dashed line) for $K=20$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0277.jpg?height=1244&width=868&top_left_y=156&top_left_x=374)

$T_{d}(t)$ displayed together in Figure 4.16. When $K=100$, the percent overshoot is $22 \%$ and the settling time is $0.7 \mathrm{~s}$. When $K=20$, the percent overshoot is $3.9 \%$ and the settling time is $0.9 \mathrm{~s}$.

The steady-state error of the system to a unit step input $R(s)=1 / s$ is

$$
\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s \frac{1}{1+\frac{K+11 s}{s(s+1)}\left(\frac{1}{s}\right)}=0 .
$$

The steady-state value of $y(t)$ when the disturbance is a unit step, $T_{d}(s)=1 / s$, and the desired value is $r(t)=0$ is

$$
\lim _{t \rightarrow \infty} y(t)=\lim _{s \rightarrow 0}\left[\frac{1}{s(s+12)+K}\right]=\frac{1}{K} .
$$

Thus, the steady-state value is 0.01 and 0.05 for $K=100$ and 20, respectively. Finally, we examine the sensitivity of the system to a change in the process $G(s)$ using Equation (4.12). Then

$$
S_{G}^{T}=\frac{s(s+1)}{s(s+12)+K} .
$$

For low frequencies $(|s|<1)$, the sensitivity can be approximated by

$$
S_{G}^{T} \simeq \frac{s}{K}
$$

where $K \geq 20$. Thus, the sensitivity of the system is reduced by increasing the gain, $K$. In this case, we choose $K=20$ for a reasonable design compromise.

\section{EXAMPLE 4.3 Blood pressure control during anesthesia}

The objectives of anethesia are to eliminate pain, awareness, and natural reflexes so that surgery can be conducted safely. Before about 150 years ago, alcohol, opium, and cannabis were used to achieve these goals, but they proved inadequate [23]. Pain relief was insufficient both in magnitude and duration; too little pain medication and the patient felt great pain, too much medication and the patient died or became comatose. In the 1850 s ether was used successfully in the United States in tooth extractions, and shortly thereafter other means of achieving unconsciousness safely were developed, including the use of chloroform and nitrous oxide.

In a modern operating room, the depth of anesthesia is the responsibility of the anesthetist. Many vital parameters, such as blood pressure, heart rate, temperature, blood oxygenation, and exhaled carbon dioxide, are controlled within acceptable bounds by the anesthetist. Of course, to ensure patient safety, adequate anesthesia must be maintained during the entire surgical procedure. Any assistance that the anesthetist can obtain automatically will increase the safety margins by freeing the anesthetist to attend to other functions not easily automated. This is an example of human computer interaction for the overall control of a process. Clearly, patient safety is the ultimate objective. Our control goal then is to develop an automated system to regulate the depth of anesthesia. This function is amenable to automatic control and in fact is in routine use in clinical applications [24, 25].

We consider how to measure the depth of anesthesia. Many anesthetists regard mean arterial pressure (MAP) as the most reliable measure of the depth of anesthesia [26]. The level of the MAP serves as a guide for the delivery of inhaled anesthesia. Based on clinical experience and the procedures followed by the anesthetist, we determine that the variable to be controlled is the mean arterial pressure.

The elements of the control system design process emphasized in this example are illustrated in Figure 4.17. From the control system design perspective, the control goal can be stated in more concrete terms:

\section{Control Goal}

Regulate the mean arterial pressure to any desired set-point and maintain the prescribed set-point in the presence of unwanted disturbances. Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0279.jpg?height=1016&width=1322&top_left_y=242&top_left_x=313)

FIGURE 4.17 Elements of the control system design process emphasized in the blood pressure control example.

Associated with the stated control goal, we identify the variable to be controlled:

\section{Variable to Be Controlled}

\section{Mean arterial pressure (MAP).}

Because it is our desire to develop a system that will be used in clinical applications, it is essential to establish realistic design specifications. In general terms the control system should have minimal complexity while satisfying the control specifications. Minimal complexity translates into increased system reliability and decreased cost.

The closed-loop system should respond rapidly and smoothly to changes in the MAP set-point (made by the anesthetist) without excessive overshoot. The closedloop system should minimize the effects of unwanted disturbances. There are two important categories of disturbances: surgical disturbances, such as skin incisions and measurement errors, such as calibration errors and random stochastic noise. For example, a skin incision can increase the MAP rapidly by $10 \mathrm{mmHg}$ [26]. Finally, since we want to apply the same control system to many different patients and we cannot (for practical reasons) have a separate model for each patient, we must have a closed-loop system that is insensitive to changes in the process parameters (that is, it meets the specifications for many different people).

Based on clinical experience [24], we can explicitly state the control specifications as follows:

\section{Control Design Specifications}

DS1 Settling time less than 20 minutes for a 10\% step change from the MAP set-point.

DS2 Percent overshoot less than $15 \%$ for a $10 \%$ step change from the MAP set-point.

DS3 Zero steady-state tracking error to a step change from the MAP set-point.

DS4 Zero steady-state error to a step surgical disturbance input (of magnitude $|d(t)| \leq 50$ ) with a maximum response less than $\pm 5 \%$ of the MAP set-point.

DS5 Minimum sensitivity to process parameter changes.

We cover the notion of percent overshoot (DS1) and settling time (DS2) more thoroughly in Chapter 5. They fall more naturally in the category of system performance. The remaining three design specifications, DS3-DS5, covering steady-state tracking errors (DS3), disturbance rejection (DS4), and system sensitivity to parameter changes (DS5) are the main topics of this chapter. The last specification, DS5, is somewhat vague; however, this is a characteristic of many real-world specifications. In the system configuration, Figure 4.18, we identify the major system elements as the controller, anesthesia pump/vaporizer, sensor, and patient.

The system input $R(s)$ is the desired mean arterial pressure change, and the output $Y(s)$ is the actual pressure change. The difference between the desired and the measured blood pressure change forms a signal used by the controller to determine value settings to the pump/vaporizer that delivers anesthesia vapor to the patient.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0280.jpg?height=562&width=1491&top_left_y=1427&top_left_x=294)

FIGURE 4.18 Blood pressure control system configuration. The model of the pump/vaporizer depends directly on the mechanical design. We will assume a simple pump/vaporizer, where the rate of change of the output vapor is equal to the input valve setting, or

$$
\dot{u}(t)=v(t) .
$$

The transfer function of the pump is thus given by

$$
G_{p}(s)=\frac{U(s)}{V(s)}=\frac{1}{s} .
$$

This is equivalent to saying that, from an input-output perspective, the pump has the impulse response

$$
h(t)=1 \quad t \geq 0 .
$$

Developing an accurate model of a patient is much more involved. Because the physiological systems in the patient (especially in a sick patient) are not easily modeled, a modeling procedure based on knowledge of the underlying physical processes is not practical. Even if such a model could be developed, it would, in general, be a nonlinear, time-varying, multi-input, multi-output model. This type of model is not directly applicable here in our linear, time-invariant, single-input, single-output system setting.

On the other hand, if we view the patient as a system and take an input-output perspective, we can use the familiar concept of an impulse response. Then if we restrict ourselves to small changes in blood pressure from a given set-point (such as $100 \mathrm{mmHg}$ ), we might make the case that in a small region around the set-point the patient behaves in a linear time-invariant fashion. This approach fits well into our requirement to maintain the blood pressure around a given set-point (or baseline). The impulse response approach to modeling the patient response to anesthesia has been used successfully in the past [27].

Suppose that we take a black-box approach and obtain the impulse response in Figure 4.19 for a hypothetical patient. Notice that the impulse response initially has a time delay. This reflects the fact that it takes a finite amount of time for the patient MAP to respond to the infusion of anesthesia vapor. We ignore the timedelay in our design and analysis, but we do so with caution. In subsequent chapters we will learn to handle time delays. We keep in mind that the delay does exist and should be considered in the analysis at some point.

A reasonable fit of the data shown in Figure 4.19 is given by

$$
y(t)=t e^{-p t} \quad t \geq 0,
$$

where $p=2$ and time $(t)$ is measured in minutes. Different patients are associated with different values of the parameter $p$. The corresponding transfer function is

$$
G(s)=\frac{1}{(s+p)^{2}} .
$$

For the sensor we assume a perfect noise-free measurement and

$$
H(s)=1 .
$$

Therefore, we have a unity feedback system. FIGURE 4.19 Mean arterial pressure (MAP) impulse response for a hypothetical patient.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0282.jpg?height=821&width=1037&top_left_y=152&top_left_x=521)

A good controller for this application is a proportional-integral-derivative (PID) controller:

$$
G_{c}(s)=K_{P}+s K_{D}+\frac{K_{I}}{s}=\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s},
$$

where $K_{P}, K_{D}$, and $K_{I}$ are the controller gains to be determined to satisfy all design specifications. The selected key parameters are as follows:

\section{Select Key Tuning Parameters}

Controller gains $K_{P}, K_{D}$, and $K_{I}$.

We begin the analysis by considering the steady-state errors. The tracking error (shown in Figure 4.18 with $T_{d}(s)=0$ and $N(s)=0$ ) is

$$
E(s)=R(s)-Y(s)=\frac{1}{1+G_{c}(s) G_{p}(s) G(s)} R(s),
$$

or

$$
E(s)=\frac{s^{4}+2 p s^{3}+p^{2} s^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}} R(s) .
$$

Using the final-value theorem, we determine that the steady-state tracking error is

$$
\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} \frac{R_{0}\left(s^{4}+2 p s^{3}+p^{2} s^{2}\right)}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}}=0,
$$

where $R(s)=R_{0} / s$ is a step input of magnitude $R_{0}$. Therefore,

$$
\lim _{t \rightarrow \infty} e(t)=0 .
$$

With a PID controller, we expect a zero steady-state tracking error (to a step input) for any nonzero values of $K_{P}, K_{D}$, and $K_{I}$. The integral term, $K_{I} / s$, in the PID controller is the reason that the steady-state error to a unit step is zero. Thus design specification DS3 is satisfied.

When considering the effect of a step disturbance input, we let $R(s)=0$ and $N(s)=0$. We want the steady-state output $Y(s)$ to be zero for a step disturbance. The transfer function from the disturbance $T_{d}(s)$ to the output $Y(s)$ is

$$
\begin{aligned}
Y(s) & =\frac{-G(s)}{1+G_{c}(s) G_{p}(s) G(s)} T_{d}(s) \\
& =\frac{-s^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}} T_{d}(s) .
\end{aligned}
$$

When

$$
T_{d}(s)=\frac{D_{0}}{s}
$$

we find that

$$
\lim _{s \rightarrow 0} s Y(s)=\lim _{s \rightarrow 0} \frac{-D_{0} s^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}}=0 .
$$

Therefore,

$$
\lim _{t \rightarrow \infty} y(t)=0 \text {. }
$$

Thus a step disturbance of magnitude $D_{0}$ will produce no output in the steady-state, as desired.

The sensitivity of the closed-loop transfer function to changes in $p$ is given by

$$
S_{p}^{T}=S_{G}^{T} S_{p}^{G} .
$$

We compute $S_{p}^{G}$ as follows:

$$
S_{p}^{G}=\frac{\partial G(s)}{\partial p} \frac{p}{G(s)}=\frac{-2 p}{s+p},
$$

and

$$
S_{G}^{T}=\frac{1}{1+G_{c}(s) G_{p}(s) G(s)}=\frac{s^{2}(s+p)^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}} .
$$

Therefore,

$$
S_{p}^{T}=S_{G}^{T} S_{p}^{G}=-\frac{2 p(s+p) s^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}}
$$

Table 4.1 PID Controller Gains and System Performance Results

\begin{tabular}{lllllll} 
PID & $K_{\boldsymbol{P}}$ & $\boldsymbol{K}_{\boldsymbol{D}}$ & $\boldsymbol{K}_{\boldsymbol{I}}$ & $\begin{array}{l}\text { Input response } \\
\text { overshoot (\%) }\end{array}$ & $\begin{array}{l}\text { Settling } \\
\text { time (min) }\end{array}$ & $\begin{array}{l}\text { Disturbance response } \\
\text { overshoot (\%) }\end{array}$ \\
\hline 1 & 6 & 4 & 1 & 14.0 & 10.9 & 5.25 \\
2 & 5 & 7 & 2 & 14.2 & 8.7 & 4.39 \\
3 & 6 & 4 & 4 & 39.7 & 11.1 & 5.16 \\
\hline
\end{tabular}

We must evaluate the sensitivity function $S_{p}^{T}$, at various values of frequency. For low frequencies we can approximate the system sensitivity $S_{p}^{T}$ by

$$
S_{p}^{T} \approx \frac{2 p^{2} s^{2}}{K_{I}} .
$$

So at low frequencies and for a given $p$ we can reduce the system sensitivity to variations in $p$ by increasing the PID gain, $K_{I}$. Suppose that three PID gain sets have been proposed, as shown in Table 4.1. With $p=2$ and the PID gains given as the cases 1-3 in Table 4.1, we can plot the magnitude of the sensitivity $S_{p}^{T}$ as a function of frequency for each PID controller. The result is shown in Figure 4.20. We see that by using the PID 3 controller with the gains $K_{P}=6, K_{D}=4$, and $K_{I}=4$, we have the smallest system sensitivity (at low frequencies) to changes in the process parameter, $p$. PID 3 is the controller with the largest gain $K_{I}$. As the frequency increases we see in Figure 4.20 that the sensitivity increases, and that PID 3 has the highest peak sensitivity.

FIGURE 4.20

System sensitivity to variations in the parameter $p$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0284.jpg?height=813&width=1023&top_left_y=1294&top_left_x=519)

FIGURE 4.21

Mean arterial pressure (MAP) step input response with $R(s)=10 / s$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0285.jpg?height=807&width=1021&top_left_y=166&top_left_x=374)

Now we consider the transient response. Suppose we want to reduce the MAP by a $10 \%$ step change. The associated input is

$$
R(s)=\frac{R_{0}}{s}=\frac{10}{s} .
$$

The step response for each PID controller is shown in Figure 4.21. PID 1 and PID 2 meet the settling time and overshoot specifications; however PID 3 has excessive overshoot. The overshoot is the amount the system output exceeds the desired steadystate response. In this case the desired steady-state response is a $10 \%$ decrease in the baseline MAP. When a $15 \%$ overshoot is realized, the MAP is decreased by $11.5 \%$, as illustrated in Figure 4.21. The settling time is the time required for the system output to settle within a certain percentage (for example, $2 \%$ ) of the desired steady-state output amplitude. We cover the notions of overshoot and settling time more thoroughly in Chapter 5. The overshoot and settling times are summarized in Table 4.1.

We conclude the analysis by considering the disturbance response. From previous analysis we know that the transfer function from the disturbance input $T_{d}(s)$ to the output $Y(s)$ is

$$
\begin{aligned}
Y(s) & =\frac{-G(s)}{1+G_{c}(s) G_{p}(s) G(s)} T_{d}(s) \\
& =\frac{-s^{2}}{s^{4}+2 p s^{3}+\left(p^{2}+K_{D}\right) s^{2}+K_{P} s+K_{I}} T_{d}(s) .
\end{aligned}
$$

To investigate design specification DS4, we compute the disturbance step response with

$$
T_{d}(s)=\frac{D_{0}}{s}=\frac{50}{s} .
$$

FIGURE 4.22 Mean arterial pressure (MAP) disturbance step response.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0286.jpg?height=819&width=1018&top_left_y=155&top_left_x=521)

This is the maximum magnitude disturbance $\left(\left|T_{d}(t)\right|=D_{0}=50\right)$. Since any step disturbance of smaller magnitude (that is, $\left|T_{d}(t)\right|=D_{0}<50$ ) will result in a smaller maximum output response, we need only to consider the maximum magnitude step disturbance input when determining whether design specification DS4 is satisfied.

The unit step disturbance for each PID controller is shown in Figure 4.22. Controller PID 2 meets design specification DS4 with a maximum response less than $\pm 5 \%$ of the MAP set-point, while controllers PID 1 and 3 nearly meet the specification. The peak output values for each controller are summarized in Table 4.1.

In summary, given the three PID controllers, we would select PID 2 as the controller of choice. It meets all the design specifications while providing a reasonable insensitivity to changes in the plant parameter.

\subsection{CONTROL SYSTEM CHARACTERISTICS USING CONTROL DESIGN SOFTWARE}

In this section, the advantages of feedback will be illustrated with two examples. In the first example, we will introduce feedback control to a speed tachometer system in an effort to reject disturbances. The tachometer speed control system example can be found in Section 4.5 . The reduction in system sensitivity to process variations, adjustment of the transient response, and reduction in steady-state error will be demonstrated using the English Channel boring machine example of Section 4.8.

\section{EXAMPLE 4.4 Speed control system}

The open-loop block diagram description of the armature-controlled DC motor with a load torque disturbance $T_{d}(s)$ is shown in Figure 4.8. The values for the various parameters are given in Table 4.2. We have two inputs to our system, $V_{a}(s)$ and Table 4.2 Tachometer Control System Parameters

\begin{tabular}{lllllll}
$\boldsymbol{R}_{\boldsymbol{a}}$ & $\boldsymbol{K}_{\boldsymbol{m}}$ & $\mathrm{J}$ & $\mathrm{b}$ & $\boldsymbol{K}_{b}$ & $\boldsymbol{K}_{\boldsymbol{a}}$ & $\boldsymbol{K}_{\boldsymbol{t}}$ \\
\hline $1 \Omega$ & $10 \mathrm{Nm} / \mathrm{A}$ & $2 \mathrm{~kg} \mathrm{~m}^{2}$ & $0.5 \mathrm{Nm} \mathrm{s}$ & $0.1 \mathrm{Vs}$ & 54 & $1 \mathrm{Vs}$ \\
\hline
\end{tabular}

$T_{d}(s)$. Relying on the principle of superposition, which applies to our linear system, we consider each input separately. To investigate the effects of disturbances on the system, we let $V_{a}(s)=0$ and consider only the disturbance $T_{d}(s)$. Conversely, to investigate the response of the system to a reference input, we let $T_{d}(s)=0$ and consider only the input $V_{a}(s)$.

The closed-loop speed tachometer control system block diagram is shown in Figure 4.9. The values for $K_{a}$ and $K_{t}$ are given in Table 4.2.

If our system displays good disturbance rejection, then we expect the disturbance $T_{d}(s)$ to have a small effect on the output $\omega(s)$. Consider the open-loop system in Figure 4.8 first. We can compute the transfer function from $T_{d}(s)$ to $\omega(s)$ and evaluate the output response to a unit step disturbance (that is, $T_{d}(s)=1 / s$ ). The time response to a unit step disturbance is shown in Figure 4.23(a). The script shown in Figure 4.23(b) is used to analyze the open-loop speed tachometer system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0287.jpg?height=421&width=820&top_left_y=975&top_left_x=465)

(a)

FIGURE 4.23

Analysis of the open-loop speed control system.

(a) Response.

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0287.jpg?height=528&width=958&top_left_y=1520&top_left_x=383)

The open-loop transfer function (from Equation (4.26)) is

$$
\frac{\omega(s)}{T_{d}(s)}=\frac{-1}{2 s+1.5}=\text { sys_o, }
$$

where sys_o represents the open-loop transfer function in the script. Since our desired value of $\omega(t)$ is zero (remember that $V_{a}(s)=0$ ), the steady-state error is just the final value of $\omega(t)$, which we denote by $\omega_{o}(t)$ to indicate open-loop. The steady-state error, shown on the plot in Figure 4.23(a), is approximately the value of the speed when $t=7 \mathrm{~s}$. We can obtain an approximate value of the steady-state error by looking at the last value in the output vector $\mathrm{y}_{o}$, which we computed in the process of generating the plot in Figure 4.23(a). The approximate steady-state value of $\omega_{0}$ is

$$
\omega_{o}(\infty) \approx \omega_{o}(7)=-0.66 \mathrm{rad} / \mathrm{s}
$$

The plot verifies that we have reached steady state.

In a similar fashion, we begin the closed-loop system analysis by computing the closed-loop transfer function from $T_{d}(s)$ to $\omega(s)$ and then generating the timeresponse of $\omega(t)$ to a unit step disturbance input. The output response and the script are shown in Figure 4.24. The closed-loop transfer function from the disturbance input (from Equation (4.30)) is

$$
\frac{\omega(s)}{T_{d}(s)}=\frac{-1}{2 s+541.5}=\text { sys_c. }
$$

As before, the steady-state error is just the final value of $\omega(t)$, which we denote by $\omega_{c}(t)$ to indicate that it is a closed-loop. The steady-state error is shown on the plot in Figure 4.24(a). We can obtain an approximate value of the steady-state error by looking at the last value in the output vector $\mathrm{y}_{c}$, which we computed in the process of generating the plot in Figure 4.24(a). The approximate steady-state value of $\omega$ is

$$
\omega_{c}(\infty) \approx \omega_{c}(0.02)=-0.002 \mathrm{rad} / s
$$

We generally expect that $\omega_{c}(\infty) / \omega_{o}(\infty)<0.02$. In this example, the ratio of closedloop to open-loop steady-state speed output due to a unit step disturbance input is

$$
\frac{\omega_{c}(\infty)}{\omega_{o}(\infty)}=0.003
$$

We have achieved a remarkable improvement in disturbance rejection. It is clear that the addition of the negative feedback loop reduced the effect of the disturbance on the output. This demonstrates the disturbance rejection property of closed-loop feedback systems. FIGURE 4.24

Analysis of the closed-loop speed control system.

(a) Response.

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0289.jpg?height=451&width=812&top_left_y=153&top_left_x=469)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0289.jpg?height=681&width=968&top_left_y=735&top_left_x=390)

(b)

\section{EXAMPLE 4.5 English Channel boring machines}

The block diagram description of the English Channel boring machines is shown in Figure 4.14. The transfer function of the output due to the two inputs is (Equation (4.57))

$$
Y(s)=\frac{K+11 s}{s^{2}+12 s+K} R(s)+\frac{1}{s^{2}+12 s+K} T_{d}(s) .
$$

The effect of the control gain, $K$, on the transient response is shown in Figure 4.25 along with the script used to generate the plots. Comparing the two plots in parts (a) and (b), it is apparent that decreasing $K$ decreases the overshoot. Although it is not as obvious from the plots in Figure 4.25, it is also true that decreasing $K$ increases 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0290.jpg?height=388&width=962&top_left_y=159&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0290.jpg?height=348&width=959&top_left_y=656&top_left_x=525)

(b)

FIGURE 4.25

The response to a step input when (a) $K=100$ and (b) $K=20$. (c) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0290.jpg?height=599&width=920&top_left_y=1126&top_left_x=573)

Closed-loop transfer functions.

Choose time interval.

Create subplots with $x$ and $y$ axis labels.

(c)

the settling time. This can be verified by taking a closer look at the data used to generate the plots. This example demonstrates how the transient response can be altered by feedback control gain, $K$. Based on our analysis thus far, we would prefer to use $K=20$. Other considerations must be taken into account before we can establish the final design. Disturbance Response for $K=100$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0291.jpg?height=365&width=994&top_left_y=194&top_left_x=378)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0291.jpg?height=344&width=976&top_left_y=670&top_left_x=394)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0291.jpg?height=651&width=904&top_left_y=1145&top_left_x=459)

Before making the final choice of $K$, it is important to consider the system response to a unit step disturbance, as shown in Figure 4.26. We see that increasing $K$ reduces the steady-state response of $y(t)$ to the step disturbance. The steady-state value of $y(t)$ is 0.05 and 0.01 for $K=20$ and 100 , respectively. The steady-state Table 4.3 Response of the Boring Machine Control System

for $K=20$ and $K=100$

\begin{tabular}{lll} 
& $\boldsymbol{K}=\mathbf{2 0}$ & $\boldsymbol{K}=\mathbf{1 0 0}$ \\
\hline Step Response & & \\
$P . O$. & $4 \%$ & $22 \%$ \\
$T_{S}$ & $1.0 \mathrm{~s}$ & $0.7 \mathrm{~s}$ \\
Disturbance Response & & \\
$\quad e_{S S}$ & $5 \%$ & $1 \%$ \\
\hline
\end{tabular}

errors, percent overshoot, and settling times (2\% criteria) are summarized in Table 4.3. The steady-state values are predicted from the final-value theorem for a unit disturbance input as follows:

$$
\lim _{t \rightarrow \infty} y(t)=\lim _{s \rightarrow 0} s\left\{\frac{1}{s(s+12)+K}\right\} \frac{1}{s}=\frac{1}{K} .
$$

If our only design consideration is disturbance rejection, we would prefer to use $K=100$.

We have just experienced a common trade-off situation in control system design. In this particular example, increasing $K$ leads to better disturbance rejection, whereas decreasing $K$ leads to better performance (that is, less overshoot). The final decision on how to choose $K$ rests with the designer. Although control design software can certainly assist in the control system design, it cannot replace the engineer's decision-making capability and intuition.

The final step in the analysis is to look at the system sensitivity to changes in the process. The system sensitivity is given by (Equation 4.60),

$$
S_{G}^{T}=\frac{s(s+1)}{s(s+12)+K} .
$$

We can compute the values of $S_{G}^{T}(s)$ for different values of $s$ and generate a plot of the system sensitivity. For low frequencies, we can approximate the system sensitivity by

$$
S_{G}^{T} \simeq \frac{s}{K}
$$

Increasing the gain $K$ reduces the system sensitivity. The system sensitivity plots when $s=j \omega$ are shown in Figure 4.27 for $K=20$.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

The design of a disk drive system is an exercise in compromise and optimization. The disk drive must accurately position the head reader while being able to reduce the effects of parameter changes and external shocks and vibrations. FIGURE 4.27

(a) System sensitivity to plant variations $(s=j \omega)$. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0293.jpg?height=699&width=948&top_left_y=168&top_left_x=429)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0293.jpg?height=459&width=948&top_left_y=984&top_left_x=387)

(b)

The mechanical arm and flexure will resonate at frequencies that may be caused by excitations such as a shock to a notebook computer. Disturbances to the operation of the disk drive include physical shocks, wear or wobble in the spindle bearings, and parameter changes due to component changes. In this section, we will examine the performance of the disk drive system in response to disturbances and changes in system parameters. In addition, we examine the steady-state error of the system for a step command and the transient response as the amplifier gain $K_{a}$ is adjusted.

Let us consider the system shown in Figure 4.28. This closed-loop system uses an amplifier with a variable gain as the controller, and the transfer functions are FIGURE 4.28

Control system for disk drive head reader.

FIGURE 4.29

Disk drive head control system with the typical parameters.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0294.jpg?height=744&width=1274&top_left_y=158&top_left_x=500)

shown in Figure 4.29. First, we will determine the steady states for a unit step input, $R(s)=1 / s$, when $T_{d}(s)=0$. When $H(s)=1$, we obtain

$$
E(s)=R(s)-Y(s)=\frac{1}{1+K_{a} G_{1}(s) G_{2}(s)} R(s) .
$$

Therefore,

$$
\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s\left[\frac{1}{1+K_{a} G_{1}(s) G_{2}(s)}\right] \frac{1}{s} .
$$

Then the steady-state error is $e(\infty)=0$ for a step input. This performance is obtained in spite of changes in the system parameters.

Now let us determine the transient performance of the system as $K_{a}$ is adjusted. The closed-loop transfer function (with $T_{d}(s)=0$ ) is

$$
\begin{aligned}
T(s) & =\frac{Y(s)}{R(s)}=\frac{K_{a} G_{1}(s) G_{2}(s)}{1+K_{a} G_{1}(s) G_{2}(s)} \\
& =\frac{5000 K_{a}}{s^{3}+1020 s^{2}+20000 s+5000 K_{a}} .
\end{aligned}
$$

Using the script shown in Figure 4.30(a), we obtain the response of the system for $K_{a}=10$ and $K_{a}=80$, shown in Figure 4.30(b). Clearly, the system is faster in responding to the command input when $K_{a}=80$, but the response is unacceptably oscillatory.

Now let us determine the effect of the disturbance $T_{d}(s)=1 / s$ when $R(s)=0$. We wish to decrease the effect of the disturbance to an insignificant level. Using FIGURE 4.30

Closed-loop response. (a) m-file script. (b) Step response for $K_{a}=10$ and $K_{a}=80$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0295.jpg?height=291&width=599&top_left_y=196&top_left_x=597)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0295.jpg?height=817&width=1021&top_left_y=610&top_left_x=374)

(b)

the system of Figure 4.29, we obtain the response $Y(s)$ for the input $T_{d}(s)$ when $K_{a}=80$ as

$$
Y(s)=\frac{G_{2}(s)}{1+K_{a} G_{1}(s) G_{2}(s)} T_{d}(s) .
$$

Using the script shown in Figure 4.31(a), we obtain the response of the system when $K_{a}=80$ and $T_{d}(s)=1 / s$, as shown in Figure 4.31(b). In order to further reduce the effect of the disturbance, we would need to raise $K_{a}$ above 80 . However, the response to a step command $r(t)=1, t>0$ is unacceptably oscillatory. In the next chapter, we attempt to determine the best value for $K_{a}$, given our requirement for a quick, yet nonoscillatory response. FIGURE 4.31

Disturbance

step response.

(a) m-file script.

(b) Disturbance

response for

$K_{a}=80$.
$\mathrm{Ka}=80$;

$\mathrm{nf}=[5000] ; \mathrm{df}=[111000] ;$ sysf=tf(nf,df);

$\mathrm{ng}=[1]$; dg=[1 20 0]; sysg=tf(ng,dg);

sys=feedback(sysg,Ka*sysf);

sys $=-$ sys;

$\mathrm{t}=[0: 0.01: 2]$;

$\mathrm{y}=\operatorname{step}($ sys, $\mathrm{t})$;

plot(t,y), grid

ylabel('y(t)'), xlabel('Time (s)'), grid
Select $K_{a}$.

Disturbance enters summer with a negative sign.

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0296.jpg?height=569&width=964&top_left_y=659&top_left_x=522)

(b)

\subsection{SUMMARY}

The fundamental reasons for using feedback, despite its cost and additional complexity, are as follows:

1. Decrease in the sensitivity of the system to variations in the parameters of the process.

2. Improvement in the rejection of the disturbances.

3. Improvement in the attenuation of measurement noise.

4. Improvement in the reduction of the steady-state error of the system.

5. Ease of control and adjustment of the transient response of the system.

The loop gain $L(s)=G_{c}(s) G(s)$ plays a fundamental role in control system analysis. Associated with the loop gain we can define the sensitivity and complementary sensitivity functions as

$$
S(s)=\frac{1}{1+L(s)} \text { and } \mathrm{C}(s)=\frac{L(s)}{1+L(s)},
$$

respectively. The tracking error is given by

$$
E(s)=S(s) R(s)-S(s) G(s) T_{d}(s)+C(s) N(s) .
$$

In order to minimize the tracking error, $E(s)$, we desire to make $S(s)$ and $C(s)$ small. Because the sensitivity and complementary sensitivity functions satisfy the constraint

$$
S(s)+C(s)=1,
$$

we are faced with the fundamental trade-off in control system design between rejecting disturbances and reducing sensitivity to plant changes on the one hand, and attenuating measurement noise on the other hand.

Feedback control systems possess many beneficial characteristics. Thus, it is not surprising that there is a multitude of feedback control systems in industry, government, and nature.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 4.32 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0297.jpg?height=318&width=1136&top_left_y=1224&top_left_x=425)

FIGURE 4.32 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. One of the most important characteristics of control systems is their transient response.

True or False

2. The system sensitivity is the ratio of the change in the system transfer function to the change of a process transfer function for a small incremental change.

True or False

3. A primary advantage of an open-loop control system is the ability to reduce the system's sensitivity.

True or False

4. A disturbance is a desired input signal that affects the system output signal.

True or False 5. An advantage of using feedback is a decreased sensitivity of the system to variations in the parameters of the process.

True or False

6. The loop transfer function of the system in Figure 4.32 is

$$
G_{c}(s) G(s)=\frac{50}{\tau s+10} .
$$

The sensitivity of the closed-loop system to small changes in $\tau$ is:
a. $S_{\tau}^{T}(s)=-\frac{\tau s}{\tau s+60}$
b. $S_{\tau}^{T}(s)=\frac{\tau}{\tau s+10}$
c. $S_{\tau}^{T}(s)=\frac{\tau}{\tau s+60}$
d. $S_{\tau}^{T}(s)=-\frac{\tau s}{\tau s+10}$

7. Consider the two systems in Figure 4.33 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0298.jpg?height=184&width=750&top_left_y=809&top_left_x=733)

(i)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0298.jpg?height=188&width=750&top_left_y=1070&top_left_x=735)

(ii)

FIGURE 4.33 Two feedback systems with gains $K_{1}$ and $K_{2}$.

These systems have the same transfer function when $K_{1}=K_{2}=100$. Which system is most sensitive to variations in the parameter $K_{1}$ ? Compute the sensitivity using the nominal values $K_{1}=K_{2}=100$.

a. System (i) is more sensitive and $S_{K_{1}}^{T}=0.01$

b. System (ii) is more sensitive and $S_{K_{1}}^{T}=0.1$

c. System (ii) is more sensitive and $S_{K_{1}}^{T}=0.01$

d. Both systems are equally sensitive to changes in $K_{1}$.

8. Consider the closed-loop transfer function

$$
T(s)=\frac{A_{1}+k A_{2}}{A_{3}+k A_{4}},
$$

where $A_{1}, A_{2}, A_{3}$, and $A_{4}$ are constants. Compute the sensitivity of the system to variations in the parameter $k$.
a. $S_{k}^{T}=\frac{k\left(A_{2} A_{3}-A_{1} A_{4}\right)}{\left(A_{3}+k A_{4}\right)\left(A_{1}+k A_{2}\right)}$
b. $S_{k}^{T}=\frac{k\left(A_{2} A_{3}+A_{1} A_{4}\right)}{\left(A_{3}+k A_{4}\right)\left(A_{1}+k A_{2}\right)}$ c. $S_{k}^{T}=\frac{k\left(A_{1}+k A_{2}\right)}{\left(A_{3}+k A_{4}\right)}$

d. $S_{k}^{T}=\frac{k\left(A_{3}+k A_{4}\right)}{\left(A_{1}+k A_{2}\right)}$

Consider the block diagram in Figure 4.32 for Problems 9-12 where $G_{c}(s)=K_{1}$ and $G(s)=\frac{K}{s+K_{1} K_{2}}$. $T_{d}(s)=0$.

9. The closed-loop transfer function is:
a. $T(s)=\frac{K K_{1}^{2}}{s+K_{1}\left(K+K_{2}\right)}$
b. $T(s)=\frac{K K_{1}}{s+K_{1}\left(K+K_{2}\right)}$
c. $T(s)=\frac{K K_{1}}{s-K_{1}\left(K+K_{2}\right)}$
d. $T(s)=\frac{K K_{1}}{s^{2}+K_{1} K s+K_{1} K_{2}}$

10. The sensitivity $S_{K_{1}}^{T}$ of the closed-loop system to variations in $K_{1}$ is:
a. $S_{K_{1}}^{T}(s)=\frac{K s}{\left(s+K_{1}\left(K+K_{2}\right)\right)^{2}}$
b. $S_{K_{1}}^{T}(s)=\frac{2 s}{s+K_{1}\left(K+K_{2}\right)}$
c. $S_{K_{1}}^{T}(s)=\frac{s}{s+K_{1}\left(K+K_{2}\right)}$
d. $S_{K_{1}}^{T}(s)=\frac{K_{1}\left(s+K_{1} K_{2}\right)}{\left(s+K_{1}\left(K+K_{2}\right)\right)^{2}}$

11. The sensitivity $S_{K}^{T}$ of the closed-loop system to variations in $K$ is:
a. $S_{K}^{T}(s)=\frac{s+K_{1} K_{2}}{s+K_{1}\left(K+K_{2}\right)}$
b. $S_{K}^{T}(s)=\frac{K s}{\left(s+K_{1}\left(K+K_{2}\right)\right)^{2}}$
c. $S_{K}^{T}(s)=\frac{s+K K_{1}}{s+K_{1} K_{2}}$
d. $S_{K}^{T}(s)=\frac{K_{1}\left(s+K_{1} K_{2}\right)}{\left(s+K_{1}\left(K+K_{2}\right)\right)^{2}}$

12. The steady-state tracking error to a unit step input $R(s)=1 / s$ with $T_{d}(s)=0$ is:
a. $e_{s s}=\frac{K}{K+K_{2}}$
b. $e_{s s}=\frac{K_{2}}{K+K_{2}}$
c. $e_{s s}=\frac{K_{2}}{K_{1}\left(K+K_{2}\right)}$
d. $e_{s s}=\frac{K_{1}}{K+K_{2}}$ Consider the block diagram in Figure 4.32 for Problems 13-14 with $G_{c}(s)=K$ and $G(s)=\frac{b}{s+1}$.

13. The sensitivity $S_{b}^{T}$ is:
a. $S_{b}^{T}=\frac{1}{s+K b+1}$
b. $S_{b}^{T}=\frac{s+1}{s+K b+1}$
c. $S_{b}^{T}=\frac{s+1}{s+K b+2}$
d. $S_{b}^{T}=\frac{s}{s+K b+2}$

14. Compute the minimal value of $K$ so that the steady-state error due to a unit step disturbance is less than $10 \%$.
a. $K=1-\frac{1}{b}$
b. $K=b$
c. $K=10-\frac{1}{b}$
d. The steady-state error is $\infty$ for any $K$.

15. A process is designed to follow a desired path described by

$$
r(t)=\left(5-t+0.5 t^{2}\right) u(t)
$$

where $r(t)$ is the desired response and $u(t)$ is a unit step function. Consider the unity feedback system in Figure 4.32. Compute the steady-state error $(E(s)=R(s)-Y(s)$ with $T_{d}(s)=0$ ) when the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{10(s+1)}{s^{2}(s+5)} .
$$
a. $e_{s s}=\lim _{t \rightarrow \infty} e(t) \rightarrow \infty$
b. $e_{s s}=\lim _{t \rightarrow \infty} e(t)=1$
c. $e_{s s}=\lim _{t \rightarrow \infty} e(t)=0.5$
d. $e_{s s}=\lim _{t \rightarrow \infty} e(t)=0$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Instability

b. Steady-state error

c. System sensitivity

d. Components
An unwanted input signal that affects the system output signal.

The difference between the desired output, $R(s)$, and the actual output, $Y(s)$.

A system without feedback that directly generates the output in response to an input signal.

The error when the time period is large and the transient response has decayed leaving the continuous response. e. Disturbance signal

f. Transient response

g. Complexity

h. Error signal

i. Closed-loop system

j. Loss of gain

k. Open-loop system
The ratio of the change in the system transfer function to the change of a process transfer function (or parameter) for a small incremental change.

The response of a system as a function of time.

A system with a measurement of the output signal and a comparison with the desired output to generate an error signal that is applied to the actuator.

A measure of the structure, intricateness, or behavior of a system that characterizes the relationships and interactions between various components.

The parts, subsystems, or subassemblies that comprise a total system.

An attribute of a system that describes a tendency of the system to depart from the equilibrium condition when initially displaced.

A reduction in the amplitude of the ratio of the output signal to the input signal through a system, usually measured in decibels.

\section{EXERCISES}

E4.1 A digital audio system is designed to minimize the effect of disturbances as shown in Figure E4.1. As an approximation, we may represent $G(s)=K_{2}$.

(a) Calculate the sensitivity of the system due to $K_{2}$. (b) Calculate the effect of the disturbance noise $T_{d}(s)$ on $V_{\mathrm{o}}(s)$. (c) What value would you select for $K_{1}$ to minimize the effect of the disturbance?

E4.2 A closed-loop system is used to track the sun to obtain maximum power from a photovoltaic array. The tracking system may be represented by a unity feedback control system and

$$
G_{\mathrm{c}}(s) G(s)=\frac{100}{\tau s+1},
$$

where $\tau=3 \quad$ s nominally. (a) Calculate the sensitivity of this system for a small change in $\tau$. (b) Calculate the time constant of the closed-loop system response.

Answers: $S=-3 s /(3 s+101) ; \tau_{c}=3 / 101 \mathrm{~s}$

E4.3 A robotic arm and camera could be used to pick fruit, as shown in Figure E4.3(a). The camera is used to close the feedback loop to a microcomputer, which controls the arm $[8,9]$. The transfer function for the process is

$$
G(s)=\frac{K}{(s+5)^{2}} .
$$

(a) Calculate the expected steady-state error of the gripper for a step command $A$ as a function of $K$. (b) Name a possible disturbance signal for this system.

Answers: (a) $e_{s s}=\frac{A}{1+K / 25}$

E4.4 A magnetic disk drive requires a motor to position a read/write head over tracks of data on a spinning disk, as shown in Figure E4.4. The motor and head may be represented by the transfer function

$$
G(s)=\frac{10}{s(\tau s+1)},
$$

where $\tau=0.001 \mathrm{~s}$. The controller takes the difference of the actual and desired positions and generates an error. This error is multiplied by an amplifier $K$. (a) What is the steady-state position error for a step change in the desired input? (b) Calculate
FIGURE E4.1

Digital audio system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0301.jpg?height=263&width=983&top_left_y=1884&top_left_x=374)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0302.jpg?height=541&width=647&top_left_y=153&top_left_x=276)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0302.jpg?height=219&width=683&top_left_y=770&top_left_x=263)

(b)

FIGURE E4.3 Robot fruit picker.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0302.jpg?height=492&width=757&top_left_y=1118&top_left_x=221)

FIGURE E4.4 Disk drive control.

the required $K$ in order to yield a steady-state error of $0.1 \mathrm{~mm}$ for a ramp input of $10 \mathrm{~cm} / \mathrm{s}$.

Answers: $e_{s s}=0 ; K=100$

E4.5 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{10 K}{s(s+b)} .
$$

Determine the relationship between the steady-state error to a ramp input and the gain $K$ and system parameter $b$. For what values of $K$ and $b$ can we guarantee that the magnitude of the steady-state error to a ramp input is less than 0.1 ?
E4.6 A feedback system has the closed-loop transfer function given by

$$
T(s)=\frac{s^{2}+p s+20}{s^{3}+p s^{2}+4 s+(1-p)} .
$$

Compute the sensitivity of the closed-loop transfer function to changes in the parameter $p$, where $p>0$. Compute the steady-state error to a unit step input as a function of the parameter $p$.

E4.7 In laser cutting, it is important for the focusing lens to be placed at an angle perpendicular to the laser, so that the laser beam can be focused. An unfocused laser beam causes an elliptical beam shape, a visual example of a steady-state error. Draw the block diagram of an autofocus system, and describe how the system works.

E4.8 Four-wheel drive automobiles are popular in regions where winter road conditions are often slippery due to snow and ice. A four-wheel drive vehicle with antilock brakes uses a sensor to keep each wheel rotating to maintain traction. One such system is shown in Figure E4.8. Find the closed-loop response of this system as it attempts to maintain a constant speed of the wheel. Determine the response when $R(s)=A / s$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0302.jpg?height=209&width=738&top_left_y=1053&top_left_x=1014)

FIGURE E4.8 Four-wheel drive auto.

E4.9 Submersibles with clear plastic hulls have the potential to revolutionize underwater leisure. One small submersible vehicle has a depth-control system as illustrated in Figure E4.9.

(a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$

(b) Determine the sensitivity $S_{K_{1}}^{T}$ and $S_{K}^{T}$.

(c) Determine the steady-state error due to a disturbance $T_{d}(s)=1 / s$.

(d) Calculate the response $y(t)$ for a step input $R(s)=1 / s$ when $K=2$ and $K_{2}=3$ and $1<K_{1}<10$. Select $K_{1}$ for the fastest response.

E4.10 Consider the feedback control system shown in Figure E4.10. (a) Determine the steady-state error for a step input in terms of the gain, $K$. (b) Determine the overshoot for the step response for $40 \leq K \leq 400$. (c) Plot the overshoot and the steady-state error versus $K$.

E4.11 Consider the closed-loop system in Figure E4.11, where

$$
G(s)=\frac{K}{s+10} \quad \text { and } \quad H(s)=\frac{14}{s^{2}+5 s+6} .
$$

FIGURE E4.9

Depth control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0303.jpg?height=438&width=1045&top_left_y=162&top_left_x=409)

FIGURE E4.10

Feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0303.jpg?height=332&width=1042&top_left_y=615&top_left_x=373)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0303.jpg?height=280&width=624&top_left_y=998&top_left_x=149)

FIGURE E4.11 Closed-loop system with nonunity feedback.

(a) Compute the transfer function $T(s)=Y(s) /$ $R(s)$.

(b) Define the tracking error to be $E(s)=R(s)$ $Y(s)$. Compute $E(s)$ and determine the steadystate tracking error due to a unit step input, that is, let $R(s)=1 / s$.

(c) Compute the transfer function $Y(s) / T_{d}(s)$ and determine the steady-state error of the output due to a unit step disturbance input, that is, let $T_{d}(s)=1 / s$.

(d) Compute the sensitivity $S_{K}^{T}$.

E4.12 In Figure E4.12, consider the closed-loop system with measurement noise $N(s)$, where

$G(s)=\frac{100}{s+100}, \quad G_{c}(s)=K_{1}, \quad$ and $\quad H(s)=\frac{K_{2}}{s+5}$.

In the following analysis, the tracking error is defined to be $E(s)=R(s)-Y(s)$ :

(a) Compute the transfer function $T(s)=Y(s) / R(s)$ and determine the steady-state tracking error due

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0303.jpg?height=278&width=753&top_left_y=1002&top_left_x=863)

FIGURE E4.12 Closed-loop system with nonunity feedback and measurement noise.

to a unit step response, that is, let $R(s)=1 / s$ and assume that $N(s)=0$.

(b) Compute the transfer function $Y(s) / N(s)$ and determine the steady-state tracking error due to a unit step disturbance response, that is, let $N(s)=1 / s$ and assume that $R(s)=0$. Remember, in this case, the desired output is zero.

(c) If the goal is to track the input while rejecting the measurement noise (in other words, while minimizing the effect of $N(s)$ on the output), how would you select the parameters $K_{1}$ and $K_{2}$ ?

E4.13 A closed-loop system is used in a high-speed steel rolling mill to control the accuracy of the steel strip thickness. The transfer function for the process shown in Figure E4.13 can be represented as

$$
G(s)=\frac{1}{s(s+20)} .
$$

Calculate the sensitivity of the closed-loop transfer function to changes in the controller gain $K$. FIGURE E4.13

Control system for a steel rolling mill. (a) Signal flow graph. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0304.jpg?height=404&width=764&top_left_y=158&top_left_x=747)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0304.jpg?height=336&width=1230&top_left_y=660&top_left_x=519)

(b)

E4.14 Consider the unity feedback system shown in Figure E4.14. The system has two parameters, the controller gain $K$ and the constant $K_{1}$ in the process.

(a) Calculate the sensitivity of the closed-loop transfer function to changes in $K_{1}$.

(b) How would you select a value for $K$ to minimize the effects of external disturbances, $T_{d}(s)$ ?
E4.15 Reconsider the unity feedback system discussed in E4.14. This time select $K=120$ and $K_{1}=10$. The closed-loop system is depicted in Figure E4.15.

(a) Calculate the steady-state error of the closedloop system due to a unit step input, $R(s)=1 / s$, with $T_{d}(s)=0$. Recall that the tracking error is defined as $E(s)=R(s)-Y(s)$.

(b) Calculate the steady-state response, $y_{\mathrm{ss}}=$ $\lim _{t \rightarrow \infty} y(t)$, when $T_{d}(s)=1 / s$ and $R(s)=0$.
FIGURE E4.14

Closed-loop feedback system with two parameters, $K$ and $K_{1}$.
FIGURE E4.15 Closed-loop feedback system with $K=120$ and $K_{1}=10$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0304.jpg?height=672&width=1054&top_left_y=1446&top_left_x=508)

\section{PROBLEMS}

P4.1 The open-loop transfer function of a fluid-flow system can be written as

$$
G(s)=\frac{\Delta Q_{2}(s)}{\Delta Q_{1}(s)}=\frac{1}{\tau s+1},
$$

where $\tau=R C, R$ is a constant equivalent to the resistance offered by the orifice so that $1 / R=1 / 2 k H_{0}{ }^{-1 / 2}$, and $C=$ the cross-sectional area of the tank. Since $\Delta H=R \Delta Q_{2}$, we have the following for the transfer function relating the head to the input change:

$$
G_{1}(s)=\frac{\Delta H(s)}{\Delta Q_{1}(s)}=\frac{R}{R C s+1} .
$$

For a closed-loop feedback system, a float-level sensor and valve may be used as shown in Figure P4.1. Assuming the float is a negligible mass, the valve is controlled so that a reduction in the flow rate, $\Delta Q_{1}$, is proportional to an increase in head, $\Delta H$, or $\Delta Q_{1}=-K \Delta H$. Draw a signal flow graph or block diagram. Determine and compare the open-loop and closed-loop systems for (a) sensitivity to changes in the equivalent coefficient $R$ and the feedback coefficient $K$, (b) the ability to reduce the effects of a disturbance in the level $\Delta H(s)$, and (c) the steady-state error of the level (head) for a step change of the input $\Delta Q_{1}(s)$.

P4.2 It is important to ensure passenger comfort on ships by stabilizing the ship's oscillations due to

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0305.jpg?height=346&width=705&top_left_y=1243&top_left_x=111)

waves [13]. Most ship stabilization systems use fins or hydrofoils projecting into the water to generate a stabilization torque on the ship. A simple diagram of a ship stabilization system is shown in Figure P4.2. The rolling motion of a ship can be regarded as an oscillating pendulum with a deviation from the vertical of $\theta(t)$ degrees and a typical period of $3 \mathrm{~s}$. The transfer function of a typical ship is

$$
G(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}},
$$

where $\omega_{n}=3.5 \mathrm{rad} / \mathrm{s}$ and $\zeta=0.3$. With this low damping factor $\zeta$, the oscillations continue for several cycles, and the rolling amplitude can reach $18^{\circ}$ for the expected amplitude of waves in a normal sea. Determine and compare the open-loop and closedloop system for (a) sensitivity to changes in the actuator constant $K_{a}$ and the roll sensor $K_{1}$, and (b) the ability to reduce the effects of step disturbances of the waves. Note that the desired roll $\theta_{d}(s)$ is zero degrees. (c) Find a range of $K_{1}$ and $K_{a}$ such that the steady-state tracking error reduced by $90 \%$ or more than a step disturbance magnitude where $T_{d}(s)=A / s$.

P4.3 One of the most important variables that must be controlled in industrial and chemical systems is temperature. A simple representation of a thermal control system is shown in Figure P4.3 [14]. The temperature $\mathcal{T}$ of the process is controlled by the heater with a resistance $R$. An approximate representation of the dynamic linearly relates the heat loss from the process to the temperature difference $\mathcal{T}-\mathcal{T}_{e}$. This relation holds if the temperature difference is relatively small and the energy storage of the heater and the vessel walls is negligible. It is assumed that $E_{h}(s)=k_{a} E_{b} E(s)$, where $k_{a}$ is the constant of the

FIGURE P4.1 Tank level control.

FIGURE P4.2

Ship stabilization system. The effect of the waves is a torque $T_{d}(s)$ on the ship.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0305.jpg?height=436&width=360&top_left_y=1673&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0305.jpg?height=391&width=849&top_left_y=1712&top_left_x=789)

(b) FIGURE P4.3

Temperature control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0306.jpg?height=442&width=1060&top_left_y=155&top_left_x=519)

actuator. The linearized open-loop response of the system is

$$
\mathcal{T}(s)=\frac{k_{1} k_{a} E_{b}}{\tau s+1} E(s)+\frac{\mathcal{T}_{e}(s)}{\tau s+1},
$$

where

$$
\begin{aligned}
& \tau=M C /(\rho A), \\
& M=\text { mass in tank, } \\
& A=\text { surface area of tank, } \\
& \rho=\text { heat transfer constant }, \\
& C=\text { specific heat constant, and } \\
& k_{1}=\text { a dimensionality constant. }
\end{aligned}
$$

Determine and compare the open-loop and closed-loop systems for (a) sensitivity to changes in the constant $K=k_{1} k_{a} E_{b}$; (b) the ability to reduce the effects of a step disturbance in the environmental temperature $\Delta \mathcal{T}_{e}(s)$; and (c) the steady-state error of the temperature controller for a step change in the input, $E_{\mathrm{des}}(s)$.
P4.4 A control system has two forward paths, as shown in Figure P4.4. (a) Determine the overall transfer function $T(s)=Y(s) / R(s)$. (b) Calculate the sensitivity, $S_{G}^{T}$, using Equation (4.16). (c) Does the sensitivity depend on $U(s)$ or $M(s)$ ?

P4.5 Large microwave antennas have become increasingly important for radio astronomy and satellite tracking. A large antenna with a diameter of $60 \mathrm{ft}$, for example, is susceptible to large wind gust torques. A proposed antenna is required to have an error of less than $20^{\circ}$ in a $35 \mathrm{mph}$ wind. Experiments show that this wind force exerts a maximum disturbance at the antenna of $200,000 \mathrm{ft}$ $\mathrm{lb}$ at $35 \mathrm{mph}$, or the equivalent to 10 volts at the input $T_{d}(s)$ to the amplidyne. One problem of driving large antennas is the form of the system transfer function that possesses a structural resonance. The antenna servosystem is shown in Figure P4.5. The transfer function of the antenna, drive motor, and amplidyne is approximated by

$$
G(s)=\frac{\omega_{n}^{2}}{s\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)},
$$

FIGURE P4.4

Two-path system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0306.jpg?height=294&width=946&top_left_y=1514&top_left_x=508)

FIGURE P4.5

Antenna control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0306.jpg?height=318&width=1216&top_left_y=1840&top_left_x=516)

where $\zeta=0.707$ and $\omega_{n}=10$. The transfer function of the power amplifier is approximately

$$
G_{1}(s)=\frac{k_{a}}{\tau s+1},
$$

where $\tau=0.2 \mathrm{~s}$. (a) Determine the sensitivity of the system to a change of the parameter $k_{a}$. (b) The system is subjected to a disturbance $T_{d}(s)=1 / s$. Determine the required magnitude of $k_{a}$ in order to maintain the steady-state error of the system less than $20^{\circ}$ when the input $R(s)$ is zero. (c) Determine the error of the system when subjected to a disturbance $T_{d}(s)=10 / s$ when it is operating as an open-loop system $\left(k_{s}=0\right)$ with $R(s)=0$.

P4.6 An automatic speed control system will be necessary for passenger cars traveling on the automatic highways of the future. A model of a feedback speed control system for a standard vehicle is shown in Figure P4.6. The load disturbance due to a percent grade $\Delta T_{d}(s)$ is also shown. The engine gain $K_{e}$ varies within the range of 10 to 1000 for various models of automobiles. The engine time constant $\tau_{e}$ is 20 seconds. (a) Determine the sensitivity of the system to changes in the engine gain $K_{e}$. (b) Determine the effect of the load torque on the speed. (c) Determine the constant percent grade $\Delta T_{d}(s)=\Delta d / s$ for which the vehicle stalls (velocity $V(s)=0$ ) in terms of the gain factors. Note that since the grade is constant, the steady-state solution is sufficient. Assume that $R(s)=30 / \mathrm{s} \mathrm{km} / \mathrm{hr}$ and that $K_{e} K_{1} \gg 1$. When $K_{g} / K_{1}=2$, what percent grade $\Delta d$ would cause the automobile to stall?
P4.7 A robot uses feedback to control the orientation of each joint axis. The load effect varies due to varying load objects and the extended position of the arm. The system will be deflected by the load carried in the gripper. Thus, the system may be represented by Figure P4.7, where the load torque is $T_{d}(s)=D / s$. Assume $R(s)=0$ at the index position. (a) What is the effect of $T_{d}(s)$ on $Y(s)$ ? (b) Determine the sensitivity of the closed loop to $k_{2}$. (c) What is the steady-state error when $R(s)=1 / s$ and $T_{d}(s)=0$ ?

P4.8 Extreme temperature changes result in many failures of electronic circuits [1]. Temperature control feedback systems reduce the change of temperature by using a heater to overcome outdoor low temperatures. A block diagram of one system is shown in Figure P4.8. The effect of a drop in environmental temperature is a step decrease in $T_{d}(s)$. The actual temperature of the electronic circuit is $Y(s)$. The dynamics of the electronic circuit temperature change are represented by the transfer function.

$$
G(s)=\frac{100}{s^{2}+25 s+100} .
$$

(a) Determine the sensitivity of the system to $K$. (b) Obtain the effect of the disturbance $T_{d}(s)$ on the output $Y(s)$.

(c) Find the range of $K$ such that the output $Y(s)$ is less than $10 \%$ of the step disturbance input with magnitude $A$ (that is, $\left.T_{d}(s)=A / s\right)$.
FIGURE P4.6

Automobile speed control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0307.jpg?height=864&width=1278&top_left_y=1296&top_left_x=358)

Load disturbance

angle
FIGURE P4.7

Robot control system. FIGURE P4.8

Temperature control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0308.jpg?height=280&width=1061&top_left_y=156&top_left_x=523)

P4.9 A useful unidirectional sensing device is the photoemitter sensor [15]. A light source is sensitive to the emitter current flowing and alters the resistance of the photosensor. Both the light source and the photoconductor are packaged in a single four-terminal device. This device provides a large gain and total isolation. A feedback circuit utilizing this device is shown in Figure P4.9(a), and a typical nonlinear resistancecurrent characteristic is shown in Figure P4.9(b). The resistance curve can be represented by the equation

$$
\log _{10} R=\frac{0.175}{(i-0.005)^{1 / 2}},
$$

where $i$ is the lamp current. The normal operating point is obtained when $v_{\text {in }}=2.0 \mathrm{~V}$, and $v_{\mathrm{o}}=35 \mathrm{~V}$. (a) Determine the closed-loop transfer function of the system. (b) Determine the sensitivity of the system to changes in the gain, $K$.

P4.10 For a paper processing plant, it is important to maintain a constant tension on the continuous sheet of paper between the wind-off and wind-up rolls. The tension varies as the widths of the rolls change, and an adjustment in the take-up motor speed is necessary, as shown in Figure P4.10. If the wind-up motor speed is uncontrolled, as the paper transfers from the wind-off roll to the wind-up roll, the velocity $v_{0}(t)$ decreases and the tension of the paper drops $[10,14]$. The three-roller and spring combination provides a measure of the tension of the paper. The spring force is equal to $k_{1} Y(s)$, and the linear differential transformer, rectifier, and amplifier may be represented by $E_{0}(s)=-k_{2} Y(s)$. Therefore, the

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0308.jpg?height=530&width=584&top_left_y=1071&top_left_x=1126)

(b)

\section{Photosensor} system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0308.jpg?height=522&width=626&top_left_y=1075&top_left_x=468)

(a)
FIGURE P4.10

Paper tension control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0308.jpg?height=421&width=1247&top_left_y=1690&top_left_x=522)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0309.jpg?height=421&width=1268&top_left_y=156&top_left_x=354)

(a)

FIGURE P4.11

Paper-making control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0309.jpg?height=195&width=747&top_left_y=674&top_left_x=612)

(b)

measure of the tension is described by the relation $2 T(s)=k_{1} Y(s)$, where $Y(s)$ is the deviation from the equilibrium condition, and $T(s)$ is the vertical component of the deviation in tension from the equilibrium condition. The time constant of the motor is $\tau=L_{a} / R_{a}$, and the linear velocity of the wind-up roll is twice the angular velocity of the motor, that is, $V_{0}(s)=2 \omega_{0}(s)$. The equation of the motor is then

$$
E_{0}(s)=\frac{1}{K_{m}}\left[\tau s \omega_{0}(s)+\omega_{0}(s)\right]+k_{3} \Delta T(s),
$$

where $\Delta T(s)=$ a tension disturbance. (a) Draw the closed-loop block diagram for the system, including the disturbance $\Delta T(s)$. (b) Add the effect of a disturbance in the wind-off roll velocity $\Delta V_{1}(s)$ to the block diagram. (c) Determine the sensitivity of the system to the motor constant $K_{m}$. (d) Determine the steady-state error in the tension when a step disturbance in the input velocity, $\Delta V_{1}(s)=A / s$, occurs.

P4.11 One important objective of the paper-making process is to maintain uniform consistency of the stock output as it progresses to drying and rolling. A diagram of the thick stock consistency dilution control system is shown in Figure P4.11(a). The amount of water added determines the consistency. The block diagram of the system is shown in Figure P4.11(b). Let $H(s)=1$ and

$$
G_{c}(s)=\frac{K}{8 s+1}, \quad G(s)=\frac{1}{3 s+1} .
$$

Determine (a) the closed-loop transfer function $T(s)=Y(s) / R(s)$, (b) the sensitivity $S_{K}^{T}$, and (c) the steady-state error for a step change in the desired consistency $R(s)=A / s$. (d) Calculate the value of $K$ required for an allowable steady-state error of $2 \%$.

P4.12 Two feedback systems are shown in Figures P4.12(a) and (b). (a) Evaluate the closed-loop transfer functions $T_{1}$ and $T_{2}$ for each system. (b) Compare the sensitivities of the two systems with respect to the parameter $K_{1}$ for the nominal values of $K_{1}=K_{2}=1$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0309.jpg?height=200&width=661&top_left_y=1542&top_left_x=902)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0309.jpg?height=200&width=758&top_left_y=1810&top_left_x=858)

(b)

FIGURE P4.12 Two feedback systems. FIGURE P4.13

Closed-loop

system.

FIGURE P4.14

Hypersonic airplane speed control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0310.jpg?height=516&width=926&top_left_y=154&top_left_x=522)

P4.13 One form of a closed-loop transfer function is

$$
T(s)=\frac{G_{1}(s)+k G_{2}(s)}{G_{3}(s)+k G_{4}(s)} .
$$

(a) Show that

$$
S_{k}^{T}=\frac{k\left(G_{2} G_{3}-G_{1} G_{4}\right)}{\left(G_{3}+k G_{4}\right)\left(G_{1}+k G_{2}\right)} .
$$

(b) Determine the sensitivity of the system shown in Figure P4.13, using the equation verified in part (a).

P4.14 A proposed hypersonic plane would climb to 80,000 feet, fly 3800 miles per hour, and cross the Pacific in 2 hours. Control of the aircraft speed could be represented by the model in Figure P4.14. (a) Find the sensitivity of the closed-loop transfer function $T(s)$ to a small change in the parameter $a$. (b) What is the range of the parameter $a$ for a stable closed-loop system?
P4.15 Figure P4.15 shows the model of a two-tank system containing a heated liquid, where $T_{0}(s)$ is the temperature of the fluid flowing into the first tank and $T_{2}(s)$ is the temperature of the liquid flowing out of the second tank. The system of two tanks has a heater in the first tank with a controllable heat input $Q$. The time constants are $\tau_{1}=10 \mathrm{~s}$ and $\tau_{2}=50 \mathrm{~s}$. (a) Determine $T_{2}(s)$ in terms of $T_{0}(s)$ and $T_{2 d}(s)$. (b) If $T_{2 d}(s)$, the desired output temperature, is changed instantaneously from $T_{2 d}(s)=A / s$ to $T_{2 d}(s)=2 A / s$, where $T_{0}(s)=A / s$, determine the transient response of $T_{2}(s)$ when $G_{c}(s)=K=500$.

(c) Find the steady-state error $e_{s s}$ for the system of part (b), where $E(s)=T_{2 d}(s)-T_{2}(s)$.

P4.16 The steering control of a modern ship may be represented by the system shown in Figure P4.16 $[16,20]$. (a) Find the steady-state effect of a constant wind force represented by $T_{d}(s)=1 / s$ for $K=10$ and $K=25$. Assume that the rudder input $R(s)$
FIGURE P4.15

Two-tank temperature control.

FIGURE P4.16

Ship steering control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0310.jpg?height=694&width=1196&top_left_y=1410&top_left_x=519)is zero, without any disturbance, and has not been adjusted. (b) Show that the rudder can then be used to bring the ship deviation back to zero.

P4.17 A robot gripper, shown in part (a) of Figure $\mathrm{P} 4.17$, is to be controlled so that it closes to an angle $\theta$ by using a DC motor control system, as shown in part (b). The model of the control system is shown in part (c), where $K_{m}=30$, $R_{f}=1 \Omega, K_{f}=K_{i}=1, J=0.1$, and $b=1$. (a) Determine the response $\theta(t)$ of the system to a step change in $\theta_{d}(t)$ when $K=20$. (b) Assuming $\theta_{d}(t)=0$, find the effect of a load disturbance $T_{d}(s)=A / s$. (c) Determine the steady-state error $e_{s s}$ when the input is $r(t)=t, t>0$. (Assume that $T_{d}(s)=0$.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0311.jpg?height=564&width=1495&top_left_y=480&top_left_x=111)

(a)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0311.jpg?height=358&width=1266&top_left_y=1145&top_left_x=223)

(c)

FIGURE P4.17 Robot gripper control.

\section{ADVANCED PROBLEMS}

AP4.1 A tank level regulator control is shown in Figure AP4.1(a). It is desired to regulate the level $H(s)$ in response to a disturbance change $Q_{3}(s)$. The block diagram shows small variable changes about the equilibrium conditions so that the desired $H_{d}(s)=0$. Determine the equation for the error $E(s)$, and determine the steady-state error for a unit step disturbance when (a) $G(s)=K$ and (b) $G(s)=K / s$.
AP4.2 The shoulder joint of a robotic arm uses a DC motor with armature control and a set of gears on the output shaft. The model of the system is shown in Figure AP4.2 with a disturbance torque $T_{d}(s)$ which represents the effect of the load. Determine the steady-state error when the desired angle input is a step so that $\theta_{d}(s)=A / s, G_{c}(s)=K$, and the disturbance input is zero. When $\theta_{d}(s)=0$ and the load FIGURE AP4.1

A tank level

regulator.
FIGURE AP4.2

Robot joint control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0312.jpg?height=357&width=887&top_left_y=151&top_left_x=714)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0312.jpg?height=219&width=1266&top_left_y=610&top_left_x=503)

(b)
Load disturbance

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0312.jpg?height=287&width=1263&top_left_y=1037&top_left_x=507)

FIGURE AP4.3

Machine tool feedback.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0312.jpg?height=348&width=1155&top_left_y=1407&top_left_x=537)

effect is $T_{d}(s)=M / s$, determine the steady-state error when (a) $G_{c}(s)=K$ and (b) $G_{c}(s)=K / s$.

AP4.3 A machine tool is designed to follow a desired path so that

$$
r(t)=(1-t) u(t),
$$

where $u(t)$ is the unit step function. The machine tool control system is shown in Figure AP4.3. (a) Determine the steady-state error when $R(s)$ is the desired path as given and $T_{d}(s)=0$.

(b) Plot the error $e(t)$ for the desired path for part (a) for $0<t \leq 10 \mathrm{~s}$.

(c) If $R(s)=0$, find the steady-state error when $T_{d}(s)=1 / s$.

(d) Plot the error $e(t)$ for part (c) for $0<t \leq 10 \mathrm{~s}$. FIGURE AP4.4

DC motor with feedback.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0313.jpg?height=395&width=1268&top_left_y=167&top_left_x=349)

Surgical

disturbance

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0313.jpg?height=278&width=1263&top_left_y=684&top_left_x=352)

FIGURE AP4.5

Blood pressure control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0313.jpg?height=320&width=574&top_left_y=995&top_left_x=969)

FIGURE AP4.6 A proportional integral controller using an operational amplifier.

(c) Determine and plot the transient response $V_{2}(s)$ for a step input $V_{1}(s)=1 / s$.

AP4.7 A feedback control system with sensor noise and a disturbance input is shown in Figure AP4.7. The goal is to reduce the effects of the noise and the disturbance. Let $R(s)=0$.

(a) Determine the effect of the disturbance on $Y(s)$.

(b) Determine the effect of the noise on $Y(s)$.

(c) Choose gains $K$ and $K_{1}$ so that the effect of steady-state error due to the disturbance and the noise is minimized. Assume $T_{d}(s)=A / s$, and $N(s)=B / s$.

AP4.8 The block diagram of a machine-tool control system is shown in Figure AP4.8.

(a) Determine the transfer function $T(s)=Y(s) /$ $R(s)$.

(b) Determine the sensitivity $S_{b}^{T}$.

(c) Select $K$ and $K_{1}$ so that the effects of a unit step disturbance are minimized. FIGURE AP4.7

Feedback system with noise.

FIGURE AP4.8

Machine-tool

control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0314.jpg?height=463&width=1023&top_left_y=152&top_left_x=505)

Sensor noise

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0314.jpg?height=355&width=1012&top_left_y=693&top_left_x=517)

\section{DESIGN PROBLEMS}

CDP4.1 A capstan drive for a table slide is described in CDP2.1. The position of the slide $x$ is measured with a capacitance gauge, as shown in Figure CDP4.1, which is very linear and accurate. Sketch the model of the feedback system and determine the response of the system when the controller is an amplifier and $H(s)=1$. Determine the step response for several selected values of the amplifier gain $G_{c}(s)=K_{a}$.
DP4.1 A closed-loop speed control system is subjected to a disturbance due to a load, as shown in Figure DP4.1. The desired speed is $\omega_{d}(t)=100 \mathrm{rad} / s$, and the load disturbance is a unit step input $T_{d}(s)=1 / s$. Assume that the speed has attained the no-load speed of $100 \mathrm{rad} / \mathrm{s}$ and is in steady state. (a) Determine the steady-state effect of the load disturbance, and (b) plot $(t)$ for the step disturbance for various values of gain $K$. Comment on the effect
FIGURE CDP4.1

The model of the feedback system with a capacitance measurement sensor. The tachometer may be mounted on the motor (optional), and the switch will normally be open.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0314.jpg?height=505&width=1206&top_left_y=1615&top_left_x=507)

FIGURE DP4.1

Speed control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0315.jpg?height=315&width=983&top_left_y=151&top_left_x=372)

of the gain $K$ on the steady-state error due to the load disturbance.

DP4.2 The control of the roll angle of an airplane is achieved by using the torque developed by the ailerons. A linear model of the roll control system for a small experimental aircraft is shown in Figure DP4.2, where

$$
G(s)=\frac{1}{s^{2}+5 s+10} .
$$

The goal is to maintain a small roll angle due to disturbances. Select an appropriate gain $K K_{1}$ that will reduce the effect of the disturbance while attaining a desirable transient response to a step disturbance. To obtain a desirable transient response, let $K K_{1}<50$.

DP4.3 Consider the system shown in Figure DP4.3.

(a) Determine the range of $K_{1}$ allowable so that the steady state tracking error is $e_{\mathrm{ss}} \leq 1 \%$.

(b) Determine a suitable value for $K_{1}$ and $K$ so that the magnitude of the steady-state error to a wind disturbance $T_{d}(t)=2 t \mathrm{mrad} / s, 0 \leq t<5 \mathrm{~s}$, is less than $0.1 \mathrm{mrad}$.

DP4.4 Lasers have been used in eye surgery for many years. They can cut tissue or aid in coagulation [17]. The laser allows the ophthalmologist to apply heat to a location in the eye in a controlled manner.
Many procedures use the retina as a laser target. The retina is the thin sensory tissue that rests on the Inner surface of the back of the eye and is the actual transducer of the eye, converting light energy into electrical pulses. On occasion, this layer will detach from the wall, resulting in death of the detached area from lack of blood and leading to partial or total blindness in that eye. A laser can be used to "weld" the retina into its proper place on the inner wall.

Automated control of position enables the ophthalmologist to indicate to the controller where lesions should be inserted. The controller then monitors the retina and controls the laser's position so that each lesion is placed at the proper location. A wide-angle video-camera system is required to monitor the movement of the retina, as shown in Figure DP4.4(a). If the eye moves during the irradiation, the laser must be either redirected or turned off. The position-control system is shown in Figure DP4.4(b). Select an appropriate gain for the controller so that the transient response to a step change in $R(s)$ is satisfactory and the effect of the disturbance due to noise in the system is minimized. Also, ensure that the steady-state error for a step input command is zero. Determine the largest value of $K>0$ to ensure closed-loop stability.
FIGURE DP4.2

Control of the roll angle of an airplane.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0315.jpg?height=592&width=1056&top_left_y=1525&top_left_x=374)

FIGURE DP4.3

Speed control system. FIGURE DP4.4

Laser eye surgery system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0316.jpg?height=485&width=1020&top_left_y=155&top_left_x=673)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0316.jpg?height=306&width=1028&top_left_y=781&top_left_x=634)

(b)
DP4.5 An op-amp circuit can be used to generate a rapidly exponentially decaying signal. The circuit shown in Figure DP4.5 can generate the signal $v_{2}(t)=-e^{-1000 t}, t>0$, when the input $v_{1}(t)$ is a unit step input [6]. Select appropriate values for the resistors and capacitor. Assume an ideal op-amp.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0316.jpg?height=339&width=647&top_left_y=1390&top_left_x=222)

FIGURE DP4.5 Op-amp circuit.

DP4.6 A hydrobot is under consideration for remote exploration under the ice of Europa, a moon of the giant planet Jupiter. Figure DP4.6(a) shows one artistic version of the mission. The hydrobot is a selfpropelled underwater vehicle that would analyze the chemical composition of the water in a search for signs of life. An important aspect of the vehicle is a controlled vertical descent to depth in the presence of underwater currents. A simplified control feedback system is shown in Figure DP4.6(b). The parameter $J>0$ is the pitching moment of inertia. (a) Suppose that $G_{c}(s)=K$. For what range of $K$ is the system stable? (b) What is the steady-state error to a unit step disturbance when $G_{c}(s)=K$ ? (c) Suppose that $G_{c}(s)=K_{p}+K_{D} s$. For what range of $K_{p}$ and $K_{D}$ is the system stable? (d) What is the steady-state error to a unit step disturbance when $G_{c}(s)=K_{p}+K_{D} s$ ?

DP4.7 Interest in unmanned underwater vehicles (UUVs) has been increasing recently, with a large number of possible applications being considered. These include intelligence-gathering, mine detection, and surveillance applications. Regardless of the intended mission, a strong need exists for reliable and robust control of the vehicle. The proposed vehicle is shown in Figure DP4.7 (a) [28].

We want to control the vehicle through a range of operating conditions. The vehicle is 30 feet long with a vertical sail near the front. The control inputs are stern plane, rudder, and shaft speed commands. In this case, we wish to control the vehicle roll by using the stern planes. The control system is shown in Figure DP4.7(b), where $R(s)=0$, the desired roll angle, and $T_{d}(s)=1 / s$. Suppose that the controller is

$$
G_{c}(s)=K(s+2) \text {. }
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0317.jpg?height=612&width=771&top_left_y=155&top_left_x=374)

(a)

FIGURE DP4.6

(a) Europa exploration under the ice. (Used with permission. Courtesy of NASA.)

(b) Feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0317.jpg?height=258&width=741&top_left_y=833&top_left_x=373)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0317.jpg?height=351&width=947&top_left_y=1151&top_left_x=392)

(a)

FIGURE DP4.7

Control of an underwater vehicle.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0317.jpg?height=247&width=988&top_left_y=1596&top_left_x=376)

(b) (a) Design the controller gain $K$ such that the maximum roll angle error due the unit step disturbance input is less than 0.05. (b) Compute the steady-state roll angle error to the disturbance input and explain the result.
DP4.8 A new suspended, mobile, remote-controlled video camera system to bring three-dimensional mobility to professional football is shown in Figure DP4.8(a) [29]. The camera can be moved over the field, as well as up and down. The motor control on 

\section{FIGURE DP4.8}

\section{Remote-controlled}

TV camera.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0318.jpg?height=350&width=555&top_left_y=166&top_left_x=804)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0318.jpg?height=254&width=1043&top_left_y=616&top_left_x=518)

(b)

each pulley is represented by the system in Figure DP4.8(b), where the nominal values are $\tau_{1}=20$ $\mathrm{ms}$ and $\tau_{2}=2 \mathrm{~ms}$. (a) Compute the sensitivity
$S_{\tau_{1}}^{T}$ and the sensitivity $S_{\tau_{2}}^{T}$. (b) Design the controller gain $K$ such that the steady-state tracking error to a unit step disturbance is less than 0.05 .

\section{COMPUTER PROBLEMS}

CP4.1 Consider a system with the following closed-loop transfer function

$$
T(s)=\frac{1}{s^{2}+2 s+2} .
$$

Obtain the step response, and determine the percent overshoot. What is the steady-state error?

CP4.2 Consider the closed-loop transfer function

$$
T(s)=\frac{1}{s^{2}+s+1} .
$$

When the input is a unit ramp input, the desired steady-state error of the output is zero. Using the Isim function, show that the steady-state error to a unit ramp input is one.
CP4.3 Consider a unity feedback system with

$$
G(s)=\frac{(s+1)(s+2)}{s^{2}(s+3)(s+4)} .
$$

Show that the system will have a finite steady-state error to a parabolic input. Why does the system have a finite steady-state error?

CP4.4 Consider the feedback system in Figure CP4.4. Obtain the step responses for controller gain $K=1,5$, and 10. (a) Develop an m-file to compute the closed-loop transfer function $T(s)=Y(s) / R(s)$, and plot the unit step response. (b) In the same $\mathrm{m}$-file, compute the transfer function from the disturbance
FIGURE CP4.4

Unity feedback system with controller gain $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0318.jpg?height=310&width=1023&top_left_y=1804&top_left_x=505)

$T_{d}(s)$ to the output $Y(s)$ and plot the unit step disturbance response. (c) From the plots in (a) and (b) above, plot the combined steady-state tracking error to the unit step input and the steady-state tracking error to the unit step disturbance input for controller gain $K=1,5$, and 10. (d) From the plots in (c) above, estimate the maximum tracking error to the combined unit step input and unit step disturbance input. At what gain does the maximum tracking error occur?

CP4.5 Consider the closed-loop control system shown in Figure CP4.5. Develop an $\mathrm{m}$-file script to assist in the search for a value of $k$ so that the percent overshoot to a unit step input is approximately P.O. $\approx 10 \%$. The script should compute the closed-loop transfer function $T(s)=Y(s) / R(s)$ and generate the step response. Verify graphically that the steady-state error to a unit step input is zero.

CP4.6 Consider the closed-loop control system shown in Figure CP4.6. The controller gain is $K=2$. The nominal value of the plant parameter is $a=1$.
The nominal value is used for design purposes only, since in reality the value is not precisely known. The objective of our analysis is to investigate the sensitivity of the closed-loop system to the parameter $a$.

(a) When $a=1$, show analytically that the steady-state value of $Y(s)$ is equal to 2 when $R(s)$ is a unit step. Verify that the unit step response is within $2 \%$ of the final value after 4 seconds.

(b) The sensitivity of the system to changes in the parameter $a$ can be investigated by studying the effects of parameter changes on the transient response. Plot the unit step response for $a=0.5,2$, and 5. Discuss the results.

CP4.7 Consider the torsional mechanical system in Figure CP4.7(a). The torque due to the twisting of the shaft is $-k \theta(s)$; the damping torque due to the braking device is $-b \theta(s)$; the disturbance torque is $T_{d}(s)$; the input torque is $R(s)$; and the moment of inertia of the mechanical system is $J$. The transfer function of the torsional mechanical system is

$$
G(s)=\frac{1 / J}{s^{2}+(b / J) s+k / J} .
$$

FIGURE CP4.5

A closed-loop negative feedback control system.

FIGURE CP4.6 A closed-loop control system with uncertain parameter $a$.
FIGURE CP4.7

(a) A torsional mechanical system. (b) The torsional mechanical system feedback control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0319.jpg?height=548&width=830&top_left_y=1113&top_left_x=375)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0319.jpg?height=339&width=498&top_left_y=1733&top_left_x=372)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0319.jpg?height=299&width=792&top_left_y=1765&top_left_x=860)

(b) A closed-loop control system for the system is shown in Figure CP4.7(b). Suppose the desired angle $\theta_{d}=0^{\circ}, k=5, b=0.9$, and $J=1$.

(a) Determine the open-loop response $\theta(s)$ of the system for a unit step disturbance.

(b) With the controller gain $K_{0}=50$, determine the closed-loop response, $\theta(s)$, to a unit step disturbance.

(c) Plot the open-loop versus the closed-loop response to the disturbance input. Discuss your results and make an argument for using closed-loop feedback control to improve the disturbance rejection properties of the system.

CP4.8 A negative feedback control system is depicted in Figure CP4.8. Suppose that our design objective is to find a controller $G_{c}(s)$ of minimal complexity such that our closed-loop system can track a unit step input with a steady-state error of zero.

(a) As a first try, consider a simple proportional controller

$$
G_{c}(s)=K,
$$

where $K$ is a fixed gain. Let $K=2$. Plot the unit step response and determine the steadystate error from the plot.

(b) Now consider a more complex controller

$$
G_{c}(s)=K_{0}+\frac{K_{1}}{s},
$$

where $K_{0}=2$ and $K_{1}=20$. This controller is known as a proportional, integral (PI) controller. Plot the unit step response, and determine the steady-state error from the plot.

(c) Compare the results from parts (a) and (b), and discuss the trade-off between controller complexity and steady-state tracking error performance.

CP4.9 Consider the closed-loop system in Figure $\mathrm{CP} 4.9$, whose transfer function is

$$
G(s)=\frac{10 s}{s+100} \quad \text { and } \quad H(s)=\frac{5}{s+50} .
$$

(a) Obtain the closed-loop transfer function $T(s)=Y(s) / R(s)$ and the unit step response; that is, let $R(s)=1 / s$ and assume that $N(s)=0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0320.jpg?height=186&width=656&top_left_y=166&top_left_x=1055)

FIGURE CP4.9 Closed-loop system with nonunity feedback and measurement noise.

(b) Obtain the disturbance response when

$$
N(s)=\frac{100}{s^{2}+100}
$$

is a sinusoidal input of frequency $\omega=10 \mathrm{rad} / \mathrm{s}$. Assume that $R(s)=0$.

(c) In the steady-state, what is the frequency and peak magnitude of the disturbance response from part (b)?

CP4.10 Consider the closed-loop system is depicted in Figure CP4.10. The controller gain $K$ can be modified to meet the design specifications.

(a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$.

(b) Plot the response of the closed-loop system for $K=5,10$, and 50 .

(c) When the controller gain is $K=10$, determine the steady-state value of $y(t)$ when the disturbance is a unit step, that is, when $T_{d}(s)=1 / s$ and $R(s)=0$.

CP4.11 Consider the nonunity feedback system is depicted in Figure CP4.11.

(a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$.

(b) For $K=10,12$, and 15, plot the unit step responses. Determine the steady-state errors and the settling times from the plots.

For parts (a) and (b), develop a m-file that computes the closed-loop transfer function and generates the plots for varying $K$.
FIGURE CP4.8

A simple single-loop feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0320.jpg?height=235&width=817&top_left_y=1877&top_left_x=518)

FIGURE CP4.10

Closed-loop

feedback system

with external

disturbances.

FIGURE CP4.11

Closed-loop system with a sensor in the feedback loop.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0321.jpg?height=734&width=1020&top_left_y=154&top_left_x=374)

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) False; (5) True

Multiple Choice: (6) a; (7) b; (8) a; (9) b; (10) c; (11) a; (12) b; (13) b; (14) c; (15) c
Word Match (in order, top to bottom): e, h, k, b, c, f, i, $\mathrm{g}, \mathrm{d}, \mathrm{a}, \mathrm{j}$

\section{TERMS AND CONCEPTS}

Closed-loop system A system with a measurement of the output signal and a comparison with the desired output to generate an error signal that is applied to the actuator.

Complexity A measure of the structure, intricateness, or behavior of a system that characterizes the relationships and interactions between various components.

Components The parts, subsystems, or subassemblies that comprise a total system.

Disturbance signal An unwanted input signal that affects the system's output signal.

Error signal The difference between the desired output $R(s)$ and the actual output $Y(s)$. Therefore, $E(s)=R(s)-Y(s)$.

Instability An attribute of a system that describes a tendency of the system to depart from the equilibrium condition when initially displaced.

Loop gain The ratio of the feedback signal to the controller actuating signal. For a unity feedback system we have $L(s)=G_{c}(s) G(s)$.
Loss of gain A reduction in the amplitude of the ratio of the output signal to the input signal through a system, usually measured in decibels.

Open-loop system A system without feedback that directly generates the output in response to an input signal.

Steady-state error The error when the time period is large and the transient response has decayed, leaving the continuous response.

System sensitivity The ratio of the change in the system transfer function to the change of a process transfer function (or parameter) for a small incremental change.

\section{Tracking error See error signal.}

Transient response The response of a system as a function of time before steady-state. 

\author{
$5.1 \quad$ Introduction 322 \\ 5.2 Test Input Signals 322 \\ 5.3 Performance of Second-Order Systems 325 \\ 5.4 Effects of a Third Pole and a Zero on the Second-Order System \\ Response 330 \\ 5.5 The s-Plane Root Location and the Transient Response 335 \\ 5.6 The Steady-State Error of Feedback Control Systems 337 \\ 5.7 Performance Indices 344 \\ 5.8 The Simplification of Linear Systems 349 \\ 5.9 Design Examples 352 \\ 5.10 System Performance Using Control Design Software 364 \\ 5.11 Sequential Design Example: Disk Drive Read System 370 \\ 5.12 Summary 372
}

\title{
PREVIEW
}

The ability to adjust the transient and steady-state response of a control system is a beneficial outcome of the design of control systems. In this chapter, we introduce the time-domain performance specifications and use key input signals to test the response of the control system. The correlation between the system performance and the location of the transfer function poles and zeros is discussed. We develop relationships between the performance specifications and the natural frequency and damping ratio for second-order systems. Relying on the notion of dominant poles, we can extrapolate the ideas associated with second-order systems to those of higher order. The concept of a performance index is also considered. We present a set of quantitative performance indices that adequately represent the performance of the control system. The chapter concludes with a performance analysis of the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 5, students should be able to:

$\square \quad$ Identify key test signals used in controls and describe the resulting transient response characteristics of second-order systems to test signal inputs.

$\square \quad$ Recognize the direct relationship between the pole locations of second-order systems and the transient response.

$\square \quad$ Identify the design formulas that relate the second-order pole locations to percent overshoot, settling time, rise time, and time to peak.

$\square$ Explain the impact of a zero and a third pole on the second-order system response.

$\square \quad$ Describe optimal control as measured with performance indices. 

\subsection{INTRODUCTION}

The ability to adjust the transient and steady-state performance is a distinct advantage of feedback control systems. To analyze and design a control system, we must define and measure its performance. Based on the desired performance of the control system, the controller parameters are adjusted to provide the desired response. Because control systems are inherently dynamic, their performance is usually specified in terms of both the transient response and the steady-state response. The transient response is the response that disappears with time. The steady-state response is the response that exists for a long time following an input signal initiation.

The design specifications for control systems normally include several time-response indices for a specified input command, as well as a desired steadystate accuracy. In the course of the design, the specifications are often revised to effect a compromise. Therefore, specifications are seldom a rigid set of requirements, but rather an attempt to quantify the desired performance. The effective compromise and adjustment of specifications are graphically illustrated in Figure 5.1. The parameter $p$ may minimize the performance measure $M_{2}$ if we select $p$ as a very small value. However, this results in large measure $M_{1}$, an undesirable situation. If the performance measures are equally important, the crossover point at $p_{\min }$ provides the best compromise. This type of compromise is often encountered in feedback control system design. It is clear that if the original specifications called for both $M_{1}$ and $M_{2}$ to be minimized, the specifications could not be simultaneously met; they would then have to be altered to allow for the compromise resulting with $p_{\min }[1,10,15,20]$.

The specifications, which are stated in terms of the measures of performance, indicate the quality of the system to the designer. In other words, the performance measures help to answer the question, How well does the system perform the task for which it was designed?

\subsection{TEST INPUT SIGNALS}

Time-domain performance specifications are important indices because control systems are inherently time-domain systems. The transient response is of prime interest for control system designers. It is necessary to determine initially whether

FIGURE 5.1

Two performance measures versus parameter $p$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0323.jpg?height=489&width=1042&top_left_y=1635&top_left_x=373)



\section{Table 5.1 Test Signal Inputs}

\begin{tabular}{|c|c|c|}
\hline Test Signal & $r(t)$ & $R(s)$ \\
\hline Step & $\begin{aligned} r(t) & =A, t>0 \\
& =0, t<0\end{aligned}$ & $R(s)=A / s$ \\
\hline Ramp & $\begin{aligned} r(t) & =A t, t>0 \\
& =0, t<0\end{aligned}$ & $R(s)=A / s^{2}$ \\
\hline Parabolic & $\begin{aligned} r(t) & =A t^{2}, t>0 \\
& =0, t<0\end{aligned}$ & $R(s)=2 A / s$ \\
\hline
\end{tabular}

the system is stable; we can achieve this goal by using the techniques of ensuing chapters. If the system is stable, the response to a specific input signal will provide several measures of the performance. However, because the actual input signal of the system is usually unknown, a standard test input signal is normally chosen. This approach is quite useful because there is a reasonable correlation between the response of a system to a standard test input and the system's ability to perform under normal operating conditions. Furthermore, using a standard input allows the designer to compare several competing designs. Many control systems experience input signals that are very similar to the standard test signals.

The standard test input signals commonly used are the step input, the ramp input, and the parabolic input. These inputs are shown in Figure 5.2. The equations representing these test signals are given in Table 5.1, where the Laplace transform can be obtained by using Table 2.3 and a more complete list of Laplace transform pairs can be found at the MCS website. The ramp signal is the integral of the step input, and the parabola is the integral of the ramp input. A unit impulse function is also useful for test signal purposes. The unit impulse is based on a rectangular function

$$
f_{\epsilon}(t)=\left\{\begin{array}{cc}
1 / \epsilon, & -\frac{\epsilon}{2} \leq t \leq \frac{\epsilon}{2} \\
0, & \text { otherwise, }
\end{array}\right.
$$

where $\epsilon>0$. As $\in$ approaches zero, the function $f_{\epsilon}(t)$ approaches the unit impulse function $\delta(t)$, which has the following properties

$$
\int_{-\infty}^{\infty} \delta(t) d t=1 \text { and } \int_{-\infty}^{\infty} \delta(t-a) g(t) d t=g(a) .
$$

FIGURE 5.2

Test input signals: (a) step, (b) ramp, and (c) parabolic.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0324.jpg?height=266&width=303&top_left_y=1786&top_left_x=507)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0324.jpg?height=263&width=285&top_left_y=1790&top_left_x=864)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0324.jpg?height=263&width=285&top_left_y=1790&top_left_x=1217)

(c) The impulse input is useful when we consider the convolution integral for the output $y(t)$ in terms of an input $r(t)$, which is written as

$$
y(t)=\int_{-\infty}^{t} g(t-\tau) r(\tau) d \tau=\mathscr{L}^{-1}\{G(s) R(s)\} .
$$

The relationship in Equation (5.2) represents the open-loop input-output relationship of a system $G(s)$. If the input is a unit impulse function, we have

$$
y(t)=\int_{-\infty}^{t} g(t-\tau) \delta(\tau) d \tau
$$

The integral has a value only at $\tau=0$; therefore,

$$
y(t)=g(t),
$$

the impulse response of the system $G(s)$. The impulse response test signal can often be used for a dynamic system by subjecting the system to a large-amplitude, narrow-width pulse of area $A$.

The standard test signals are of the general form

$$
r(t)=t^{n}
$$

and the Laplace transform is

$$
R(s)=\frac{n !}{s^{n+1}} .
$$

Hence, the response to one test signal may be related to the response of another test signal of the form of Equation (5.4). The step input signal is the easiest to generate and evaluate and is usually chosen for performance tests.

Consider the response of a system $G(s)$ for a unit step input, $R(s)=1 / s$, when

$$
G(s)=\frac{9}{s+10} \text {. }
$$

Then the output is

$$
Y(s)=\frac{9}{s(s+10)}
$$

the response during the transient period is

$$
y(t)=0.9\left(1-e^{-10 t}\right)
$$

and the steady-state response is

$$
y(\infty)=0.9 .
$$

If the error is $E(s)=R(s)-Y(s)$, then the steady-state error is

$$
e_{\mathrm{Ss}}=\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} \frac{s+1}{s+10}=0.1 .
$$



\subsection{PERFORMANCE OF SECOND-ORDER SYSTEMS}

Let us consider a single-loop second-order system and determine its response to a unit step input. A closed-loop feedback control system is shown in Figure 5.3. The closed-loop transfer function is

$$
Y(s)=\frac{G(s)}{1+G(s)} R(s) .
$$

We may rewrite Equation (5.6) as

$$
Y(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} R(s) .
$$

With a unit step input, we obtain

$$
Y(s)=\frac{\omega_{n}^{2}}{s\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)},
$$

from which it follows that

$$
y(t)=1-\frac{1}{\beta} e^{-\zeta \omega_{n} t} \sin \left(\omega_{n} \beta t+\theta\right)
$$

where $\beta=\sqrt{1-\zeta^{2}}, \theta=\cos ^{-1} \zeta$, and $0<\zeta<1$. The response of this secondorder system for various values of the damping ratio $\zeta$ is shown in Figure 5.4. As $\zeta$ decreases, the closed-loop poles approach the imaginary axis, and the response becomes increasingly oscillatory.

The Laplace transform of the unit impulse is $R(s)=1$, and therefore the output for an impulse is

$$
Y(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

The response for an impulse function input is then

$$
y(t)=\frac{\omega_{n}}{\beta} e^{-\zeta \omega_{n} t} \sin \left(\omega_{n} \beta t\right),
$$

FIGURE 5.3

Second-order closed-loop control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0326.jpg?height=301&width=738&top_left_y=1731&top_left_x=1014)

(b) FIGURE 5.4

Transient response of a second-order system for a step input.
FIGURE 5.5

Response of a second-order system for an impulse input.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0327.jpg?height=1614&width=1078&top_left_y=155&top_left_x=372)

which is the derivative of the response to a step input. The impulse response of the second-order system is shown in Figure 5.5 for several values of the damping ratio $\zeta$.

Standard performance measures are often defined in terms of the step response of the closed-loop system as shown in Figure 5.6. The swiftness of the response is measured by the rise time $T_{r}$ and the peak time $T_{p}$. For underdamped systems with an overshoot, the $0-100 \%$ rise time is a useful index. If the system is overdamped, then the peak time is not defined, and the $10-90 \%$ rise time $T_{r 1}$ is normally used. FIGURE 5.6

Step response of a second-order system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0328.jpg?height=710&width=1148&top_left_y=167&top_left_x=508)

The similarity with which the actual response matches the step input is measured by the percent overshoot and settling time $T_{s}$. The percent overshoot is defined as

$$
\text { P.O. }=\frac{M_{P t}-f v}{f v} \times 100 \%
$$

for a unit step input, where $M_{p t}$ is the peak value of the time response, and $f v$ is the final value of the response. Normally, $f v$ is the magnitude of the input, but many systems have a final value significantly different from the desired input magnitude. For the system with a unit step represented by Equation (5.8), we have $f v=1$.

The settling time, $T_{s}$, is defined as the time required for the system to settle within a certain percentage $\delta$ of the input amplitude. This band of $\pm \delta$ is shown in Figure 5.6. For the second-order system with closed-loop damping constant $\zeta \omega_{n}$ and a response described by Equation (5.9), we seek to determine the time $T_{s}$ for which the response remains within $2 \%$ of the final value. This occurs approximately when

$$
e^{-\zeta \omega_{n} T_{s}}<0.02
$$

or

$$
\zeta \omega_{n} T_{s} \cong 4
$$

Therefore, we have

$$
T_{s}=4 \tau=\frac{4}{\zeta \omega_{n}}
$$

Hence, we define the settling time as four time constants (that is, $\tau=1 / \zeta \omega_{n}$ ) of the dominant roots of the characteristic equation. The steady-state error of the system may be measured on the step response of the system as shown in Figure 5.6. The transient response of the system may be described in terms of two factors:

1. The swiftness of response, as represented by the rise time and the peak time.

2. The closeness of the response to the desired response, as represented by the overshoot and settling time.

As it turns out, these are often contradictory requirements; thus, a compromise must be obtained. To obtain an explicit relation for $M_{p t}$ and $T_{p}$ as a function of $\zeta$, one can differentiate Equation (5.9) and set it equal to zero yielding

$$
\dot{y}(t)=\frac{\omega_{n}}{\beta} e^{-J \omega_{n} t} \sin \left(\omega_{n} \beta t\right)=0,
$$

which is equal to zero when $\omega_{n} \beta t=n \pi$, where $n=0,1,2, \ldots$. The first nonzero time this is equal to zero is when $n=1$. Thus, we find that the peak time relationship for this second-order system is

$$
T_{p}=\frac{\pi}{\omega_{n} \sqrt{1-\zeta^{2}}}
$$

and the peak response is

$$
M_{p t}=1+e^{-\zeta \pi / \sqrt{1-\zeta^{2}}}
$$

Therefore, the percent overshoot is

$$
\text { P.O. }=100 e^{-\zeta \pi / \sqrt{1-\zeta^{2}}}
$$

The percent overshoot versus the damping ratio, $\zeta$, is shown in Figure 5.7. Also, the normalized peak time, $\omega_{n} T_{p}$, is shown versus the damping ratio, $\zeta$, in Figure 5.7. Upon inspection of Figure 5.7, we see that we are confronted with a necessary compromise between the swiftness of response and the allowable percent overshoot.

FIGURE 5.7

Percent overshoot and normalized peak time versus damping ratio $\zeta$ for a secondorder system (Equation 5.8).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0329.jpg?height=631&width=739&top_left_y=1491&top_left_x=374)

FIGURE 5.8

Normalized rise time, $T_{r 11}$, versus $\zeta$ for a second-order system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0330.jpg?height=614&width=741&top_left_y=154&top_left_x=523)

The swiftness of step response can be measured as the time it takes to rise from $10 \%$ to $90 \%$ of the magnitude of the step input. This is the definition of the rise time, $T_{r 1}$, shown in Figure 5.6. The normalized rise time, $\omega_{n} T_{r 1}$, versus $\zeta(0.05 \leq \zeta \leq 0.95)$ is shown in Figure 5.8. Although it is difficult to obtain exact analytic expressions for $T_{r 1}$, we can utilize the linear approximation

$$
T_{r 1}=\frac{2.16 \zeta+0.60}{\omega_{n}},
$$

which is accurate for $0.3 \leq \zeta \leq 0.8$. This linear approximation is shown in Figure 5.8.

The swiftness of a response to a step input as described by Equation (5.17) is dependent on $\zeta$ and $\omega_{n}$. For a given $\zeta$, the response is faster for larger $\omega_{n}$, as shown in Figure 5.9. Note that the percent overshoot is independent of $\omega_{n}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0330.jpg?height=649&width=889&top_left_y=1475&top_left_x=508)

\section{FIGURE 5.9}

The step response for $\zeta=0.2$ for $\omega_{n}=1$ and $\omega_{n}=10$. FIGURE 5.10 The step response for $\omega_{n}=5$ with $\zeta=0.7$ and $\zeta=1$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0331.jpg?height=616&width=849&top_left_y=153&top_left_x=375)

For a given $\omega_{n}$, the response is faster for lower $\zeta$, as shown in Figure 5.10. The swiftness of the response, however, will be limited by the overshoot that can be accepted.

\subsection{EFFECTS OF A THIRD POLE AND A ZERO ON THE SECOND-ORDER SYSTEM RESPONSE}

The curves presented in Figure 5.7 are exact only for the second-order system of Equation (5.8). However, they provide important information because many systems possess a dominant pair of roots and the step response can be estimated by utilizing Figure 5.7. This approach, although an approximation, avoids the evaluation of the inverse Laplace transformation in order to determine the percent overshoot and other performance measures. For example, for a third-order system with a closed-loop transfer function

$$
T(s)=\frac{1}{\left(s^{2}+2 \zeta s+1\right)(\gamma s+1)},
$$

the $s$-plane diagram is shown in Figure 5.11. This third-order system is normalized with $\omega_{n}=1$. The performance (as indicated by the percent overshoot, P.O., and the settling time, $T_{s}$ ), is adequately represented by the second-order system approximation when [4]

$$
|1 / \gamma| \geq 10\left|\zeta \omega_{n}\right| .
$$

In other words, the response of a third-order system can be approximated by the dominant roots of the second-order system as long as the real part of the dominant roots is less than one tenth of the real part of the third root $[15,20]$.

Consider the third-order system

$$
T(s)=\frac{1}{\left(s^{2}+2 \zeta \omega_{n} s+1\right)(\gamma s+1)}
$$

FIGURE 5.11

An s-plane diagram of a third-order system.

FIGURE 5.12

Comparison of two third-order systems with a second-order system (dashed line) illustrating the concept of dominant poles when $|1 / \gamma| \geq 10 \zeta \omega_{n}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0332.jpg?height=1502&width=1174&top_left_y=166&top_left_x=518)

where $\omega_{n}=1.0, \zeta=0.45$, and $\gamma=1.0$. In this case, $|1 / \gamma| \not 10 \zeta \omega_{n}$. The system poles are at $s_{1,2}=-0.45 \pm 0.89 i$ and $s_{3}=-1.0$. As illustrated in Figure 5.12, the percent overshoot is P.O. $=10.9 \%$, the settling time (to within $2 \%$ of the final value) is $T_{s}=8.84 \mathrm{~s}$, and the rise time $T_{r 1}=2.16 \mathrm{~s}$. Suppose that we have another third-order system with $\omega_{n}=1.0, \zeta=0.45$, and $\gamma=0.22$. Then the system poles are at $s_{1,2}=-0.45 \pm 0.89 i$ (the same as the first system) and $s_{3}=-4.5$. In this case, $|1 / \gamma| \geq 10 \zeta \omega_{n}$ and the complex poles pair are the dominant poles. As illustrated in Figure 5.12, the percent overshoot is P.O. $=20.0 \%$, the settling time is $T_{s}=8.56 \mathrm{~s}$, and the rise time $T_{r 1}=1.6 \mathrm{~s}$. When the complex pair of poles are the dominant poles, we can create the second-order system approximation

$$
\hat{T}(s)=\frac{1}{s^{2}+2 \zeta \omega_{n} s+1}=\frac{1}{s^{2}+0.9 s+1}
$$

and we would expect the percent overshoot, settling time, and rise time to be P.O. = $100 e^{-\zeta \pi / \sqrt{1-\zeta^{2}}}=20.5 \%, T_{s}=4 / \zeta \omega_{n}=8.89 \mathrm{~s}$, and $T_{r 1}=(2.16 \zeta+0.6) / \omega_{n}=1.57 \mathrm{~s}$, respectively. In Figure 5.12, it is evident that for the third-order system satisfying the condition $|1 / \gamma| \geq 10 \zeta \omega_{n}$, the step response more closely matches the response of the second-order system, as expected.

The performance measures associated with the second-order system in Equation (5.10) are precise only for transfer functions without finite zeros. If the transfer function of a system possesses a finite zero and it is located relatively near the dominant complex poles, then the zero will materially affect the transient response of the system. In other words, the transient response of a system with one zero and two poles may be affected by the location of the zero [5]. Consider a system with the system transfer function

$$
T(s)=\frac{\left(\omega_{n}^{2} / a\right)(s+a)}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

We can investigate the response of the system compared to a second-order system without the finite zero. Suppose that $\zeta=0.45$ and let $a / \zeta \omega_{n}=0.5,1,2$, and 10.0. The resulting unit step responses are shown in Figure 5.13. As the ratio $a / \zeta \omega_{n}$ increases, the finite zero moves farther into the left half-plane and away from the poles, and the step response approaches the second-order system response, as expected.

The correlation of the time-domain response of a system with the $s$-plane location of the poles of the closed-loop transfer function is a key concept in understanding system performance in the closed-loop.

\section{EXAMPLE 5.1 Parameter selection}

A single-loop feedback control system is shown in Figure 5.14. We need to select the controller gain $K$ and the parameter $p$ so that the time-domain specifications are satisfied. The transient response to a unit step is specified to have a percent overshoot of P.O. $\leq 5 \%$ and a settling time to within $2 \%$ of the final value of $T_{s} \leq 4 \mathrm{~s}$. For second-order systems, we know the relationship in Equation (5.16) between percent overshoot and $\zeta$, and the relationship in Equation (5.13) between settling time and $\zeta \omega_{n}$. Solving for P.O. $\leq 5 \%$ yields $\zeta \geq 0.69$ and solving for $T_{s} \leq 4 \mathrm{~s}$ yields $\zeta \omega_{n} \geq 1$.

The region that will satisfy both time-domain requirements is shown on the $s$-plane of Figure 5.15. To meet the performance specifications, we can choose $\zeta=0.707(P . O .=4.3 \%)$ and $\zeta \omega_{n}=1\left(T_{s}=4 \mathrm{~s}\right)$. Hence, the desired closed-loop FIGURE 5.13

The response for the second-order transfer function with a zero for four values of the ratio $\mathrm{a} / \zeta \omega_{n}=0.5,1,2$, and 10.0 when $\zeta=0.45$.

FIGURE 5.14

Single-loop feedback control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0334.jpg?height=1370&width=1060&top_left_y=152&top_left_x=502)

poles are $r_{1}=-1+j 1$ and $\hat{r}_{1}=-1-j 1$. Therefore, $\zeta=1 / \sqrt{2}$ and $\omega_{n}=1 / \zeta=\sqrt{2}$. The closed-loop transfer function is

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}=\frac{K}{s^{2}+p s+K}=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

Solving for $K$ and $p$ yields $K=\omega_{n}^{2}=2$ and $p=2 \zeta \omega_{n}=2$. Since this is exactly a second-order system of the form in Equation (5.7), the time-domain performance specifications will be precisely satisfied. FIGURE 5.15

Specifications and root locations on the s-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0335.jpg?height=548&width=534&top_left_y=163&top_left_x=352)

\section{EXAMPLE 5.2 Impact of a zero and an additional pole}

Consider a system with a closed-loop transfer function

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{\frac{\omega_{n}^{2}}{a}(s+a)}{\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)(1+\tau s)} .
$$

Both the zero and the real pole may affect the transient response. If $a \gg \zeta \omega_{n}$ and $\tau \ll 1 / \zeta \omega_{n}$, then the pole and zero will have minimal effect on the step response.

Suppose that we have

$$
T(s)=\frac{1.6(s+2.5)}{\left(s^{2}+6 s+25\right)(0.16 s+1)} .
$$

Note that the DC gain is $T(0)=1$, and we expect a zero steady-state error for a step input. Comparing the two transfer functions, we determine that $\zeta \omega_{n}=3, \tau=0.16$, and $a=2.5$. The poles and the zero are shown on the $s$-plane in Figure 5.16. As an approximation, we neglect the real pole and zero to obtain

$$
T(s) \approx \frac{25}{s^{2}+6 s+25} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0335.jpg?height=506&width=527&top_left_y=1605&top_left_x=376)

FIGURE 5.16

The poles and zeros on the s-plane for a third-order system. We now have $\zeta=0.6$ and $\omega_{n}=5$ for dominant poles. For this second-order system we expect

$$
T_{s}=\frac{4}{\zeta \omega_{n}}=1.33 \mathrm{~s} \text { and } P . O .={ }^{100} e^{-\pi \zeta / \sqrt{1-\zeta^{2}}}=9.5 \% .
$$

For the actual third-order system, we find that the P.O. $=38 \%$ and the $T_{s}=1.6 \mathrm{~s}$. Thus, the effect of the third pole and zero of $T(s)$ cannot be neglected. This is expected since $a \gg \zeta \omega_{n}$ and $\tau \ll 1 / \zeta \omega_{n}$.

The damping ratio plays a fundamental role in closed-loop system performance. As seen in the design formulas for settling time, percent overshoot, peak time, and rise time, the damping ratio is a key factor in determining the overall performance. In fact, for second-order systems, the damping ratio is the only factor determining the value of the percent overshoot to a step input. As it turns out, the damping ratio can be estimated from the response of a system to a step input [12]. The step response of a second-order system for a unit step input is given in Equation (5.9) yields the frequency of the damped sinusoidal term (for $\zeta<1$ ) of

$$
\omega=\omega_{n}\left(1-\zeta^{2}\right)^{1 / 2}=\omega_{n} \beta
$$

and the number of cycles in 1 second is $\omega /(2 \pi)$.

The time constant for the exponential decay is $\tau=1 /\left(\zeta \omega_{n}\right)$ in seconds. The number of cycles of the damped sinusoid during one time constant is

$$
\text { (cycles/time) } \times \tau=\frac{\omega}{2 \pi \zeta \omega_{n}}=\frac{\omega_{n} \beta}{2 \pi \zeta \omega_{n}}=\frac{\beta}{2 \pi \zeta} .
$$

Assuming that the response decays in $n$ visible time constants, we have

$$
\text { cycles visible }=\frac{n \beta}{2 \pi \zeta} \text {. }
$$

For the second-order system, the response remains within $2 \%$ of the steady-state value after four time constants $(4 \tau)$. Hence, $n=4$, and

$$
\text { cycles visible }=\frac{4 \beta}{2 \pi \zeta}=\frac{4\left(1-\zeta^{2}\right)^{1 / 2}}{2 \pi \zeta} \simeq \frac{0.6}{\zeta}
$$

for $0.2 \leq \zeta \leq 0.6$. From the step response, you count the number of cycles visible up to the settling time, and use Equation (5.20) to estimate $\zeta$,

An alternative method of estimating $\zeta$ is to determine the percent overshoot for the step response and use Equation (5.16) to estimate $\zeta$.

\subsection{THE s-PLANE ROOT LOCATION AND THE TRANSIENT RESPONSE}

The transient response of a closed-loop feedback control system can be described in terms of the location of the poles of the transfer function. The closed-loop transfer function is written in general as

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{\sum P_{i}(s) \Delta_{i}(s)}{\Delta(s)},
$$

where $\Delta(s)=0$ is the characteristic equation of the system. For a unity negative feedback control system the characteristic equation reduces to $1+G_{c}(s) G(s)=0$. It is the poles and zeros of $T(s)$ that determine the transient response. However, for a closed-loop system, the poles of $T(s)$ are the roots of the characteristic equation $\Delta(s)=0$. The output of a system (with DC gain $=1$ ) without repeated roots and a unit step input can be formulated as a partial fraction expansion as

$$
Y(s)=\frac{1}{s}+\sum_{i=1}^{M} \frac{A_{i}}{s+\sigma_{i}}+\sum_{k=1}^{N} \frac{B_{k} s+C_{k}}{s^{2}+2 \alpha_{k} s+\left(\alpha_{k}^{2}+\omega_{k}^{2}\right)},
$$

where the $A_{i}, B_{k}$, and $C_{k}$ are constants. The roots of the system must be either $s=-\sigma_{i}$ or complex conjugate pairs such as $s=-\alpha_{k} \pm j \omega_{k}$. Then the inverse transform results in the transient response as the sum of terms

$$
y(t)=1+\sum_{i=1}^{M} A_{i} e^{-\sigma_{i} t}+\sum_{k=1}^{N} D_{k} e^{-\alpha_{k} t} \sin \left(\omega_{k} t+\theta_{k}\right),
$$

where $D_{k}$ is a constant and depends on $B_{k}, C_{k}, \alpha_{k}$, and $\omega_{k}$. The transient response is composed of the steady-state output, exponential terms, and damped sinusoidal terms. For the response to be stable-that is, bounded for a step input-the real part of the poles must be in the left-hand portion of the $s$-plane. The impulse response for various root locations is shown in Figure 5.17. The information imparted by the location of the roots is very descriptive.

It is important for the control system designer to understand the complete relationship of the frequency domain representation of a linear system, the poles and zeros of its transfer function, and its time-domain response to step and other inputs. In such areas as signal processing and control, many of the analysis and design calculations are done in the $s$-plane, where a system model is represented in terms of the poles and zeros of its transfer function $T(s)$. On the other hand, system performance is often analyzed by examining time-domain responses, particularly when dealing with control systems.

FIGURE 5.17 Impulse response for various root locations in the s-plane. (The conjugate root is not shown.)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0337.jpg?height=398&width=552&top_left_y=1472&top_left_x=389)

$\triangle$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0337.jpg?height=702&width=1240&top_left_y=1434&top_left_x=375)The control system designer will envision the effects on the step and impulse responses of adding, deleting, or moving poles and zeros of $T(s)$ in the $s$-plane. Likewise, the designer should visualize the necessary changes for the poles and zeros of $T(s)$, in order to effect desired changes in the step and impulse responses.

An experienced designer is aware of the effects of zero locations on system response, as well. The poles of $T(s)$ determine the particular response modes that will be present, and the zeros of $T(s)$ establish the relative weightings of the individual mode functions. For example, moving a zero closer to a specific pole will reduce the relative contribution to the output response. In other words, the zeros have a direct impact on the values of $A_{i}$ and $D_{k}$ in Equation (5.22). For example, if there is a zero near the pole at $s=-\sigma_{i}$, then $A_{i}$ will be much smaller in magnitude.

\subsection{THE STEADY-STATE ERROR OF FEEDBACK CONTROL SYSTEMS}

One of the fundamental reasons for using feedback, despite its cost and increased complexity, is the attendant improvement in the reduction of the steady-state error of the system. The steady-state error of a stable closed-loop system is usually several orders of magnitude smaller than the error of an open-loop system. The system actuating signal, which is a measure of the system error, is denoted as $E_{a}(s)$. Consider a unity negative feedback system. In the absence of external disturbances, $T_{d}(s)=0$, and measurement noise, $N(s)=0$, the tracking error is

$$
E(s)=\frac{1}{1+G_{c}(s) G(s)} R(s) .
$$

Using the final value theorem and computing the steady-state tracking error yields

$$
\lim _{t \rightarrow \infty} e(t)=e_{\mathrm{ss}}=\lim _{s \rightarrow 0} s \frac{1}{1+G_{c}(s) G(s)} R(s) .
$$

It is useful to determine the steady-state error of the system for the three standard test inputs for the unity feedback system. Later in this section we will consider steady-state tracking errors for nonunity feedback systems.

Step Input. The steady-state error for a step input of magnitude $A$ is therefore

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} \frac{s(A / s)}{1+G_{c}(s) G(s)}=\frac{A}{1+\lim _{s \rightarrow 0} G_{c}(s) G(s)} .
$$

It is the form of the loop transfer function $G_{c}(s) G(s)$ that determines the steadystate error. The loop transfer function is written in general form as

$$
G_{c}(s) G(s)=\frac{K \prod_{i=1}^{M}\left(s+z_{i}\right)}{s^{N} \prod_{k=1}^{Q}\left(s+p_{k}\right)},
$$

where $\prod$ denotes the product of the factors and $z_{i} \neq 0, p_{k} \neq 0$ for any $1 \leq i \leq M$ and $i \leq k \leq Q$. Therefore, the loop transfer function as $s$ approaches zero depends on the number of integrations, $N$. If $N$ is greater than zero, then $\lim _{s \rightarrow 0} G_{c}(s) G(s)$ approaches infinity, and the steady-state error approaches zero. The number of integrations is often indicated by labeling a system with a type number that is equal to $N$.

Consequently, for a type-zero system, $N=0$, the steady-state error is

$$
e_{\mathrm{ss}}=\frac{A}{1+G_{c}(0) G(0)}=\frac{A}{1+K \prod_{i=1}^{M} z_{i} / \prod_{k=1}^{Q} p_{k}}
$$

The constant $G_{c}(0) G(0)$ is denoted by $K_{p}$, the position error constant, and is given by

$$
K_{p}=\lim _{s \rightarrow 0} G_{c}(s) G(s) .
$$

The steady-state tracking error for a step input of magnitude $A$ is thus given by

$$
e_{\mathrm{sS}}=\frac{A}{1+K_{p}}
$$

Hence, the steady-state error for a unit step input with one integration or more, $N \geq 1$, is zero because

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} \frac{A}{1+K \prod z_{i} /\left(s^{N} \prod p_{k}\right)}=\lim _{s \rightarrow 0} \frac{A s^{N}}{s^{N}+K \prod z_{i} / \prod p_{k}}=0 .
$$

Ramp Input. The steady-state error for a ramp (velocity) input with a slope $A$ is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} \frac{s\left(A / s^{2}\right)}{1+G_{c}(s) G(s)}=\lim _{s \rightarrow 0} \frac{A}{s+s G_{c}(s) G(s)}=\lim _{s \rightarrow 0} \frac{A}{s G_{c}(s) G(s)} .
$$

Again, the steady-state error depends upon the number of integrations, $N$. For a type-zero system, $N=0$, the steady-state error is infinite. For a type-one system, $N=1$, the error is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} \frac{A}{s K \prod\left(s+z_{i}\right) /\left[s \prod\left(s+p_{k}\right)\right]},
$$

or

$$
e_{\mathrm{ss}}=\frac{A}{K \prod z_{i} / \prod p_{k}}=\frac{A}{K_{v}}
$$

where $K_{v}$ is designated the velocity error constant. The velocity error constant is computed as

$$
K_{v}=\lim _{s \rightarrow 0} s G_{c}(s) G(s) .
$$

When the transfer function possesses two or more integrations, $N \geq 2$, we obtain a steady-state error of zero. When $N=1$, a steady-state error exists. However, 

\section{Table 5.2 Summary of Steady-State Errors}

\begin{tabular}{llll}
$\begin{array}{l}\text { Number of } \\
\text { Integrations } \\
\text { in } G_{C}(s) G(s),\end{array}$ & Step, $r(t)=A$, & Ramp, $r(t)=A t$, & Parabola, $r(t)=A t^{2} / 2$, \\
\cline { 2 - 4 } Type Number & $R(s)=A / s$ & $R(s)=A / s^{2}$ & $R(s)=A / s^{3}$ \\
\hline 0 & $e_{\mathrm{ss}}=\frac{A}{1+K_{p}}$ & $\infty$ & $\infty$ \\
1 & $e_{\mathrm{ss}}=0$ & $\frac{A}{K_{v}}$ & $\infty$ \\
2 & $e_{\mathrm{Ss}}=0$ & 0 & $\frac{A}{K_{a}}$
\end{tabular}

the steady-state velocity of the output is equal to the velocity of input, as we shall see shortly.

Acceleration Input. When the system input is $r(t)=A t^{2} / 2$, the steady-state error is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} \frac{s\left(A / s^{3}\right)}{1+G_{c}(s) G(s)}=\lim _{s \rightarrow 0} \frac{A}{s^{2} G_{c}(s) G(s)} .
$$

The steady-state error is infinite for one integration. For two integrations, $N=2$, and we obtain

$$
e_{\mathrm{ss}}=\frac{A}{K \prod z_{i} / \prod p_{k}}=\frac{A}{K_{a}}
$$

where $K_{a}$ is designated the acceleration error constant. The acceleration error constant is

$$
K_{a}=\lim _{s \rightarrow 0} s^{2} G_{c}(s) G(s)
$$

When the number of integrations equals or exceeds three, then the steady-state error of the system is zero.

Control systems are often described in terms of their type number and the error constants, $K_{p}, K_{v}$, and $K_{a}$. Definitions for the error constants and the steady-state error for the three inputs are summarized in Table 5.2.

\section{EXAMPLE 5.3 Mobile robot steering control}

A mobile robot may be designed as an assisting device or servant for a severely disabled person [7]. The steering control system for such a robot can be represented by the block diagram shown in Figure 5.18. The steering controller is

$$
G_{c}(s)=K_{1}+K_{2} / s .
$$

FIGURE 5.18 Block diagram of steering control system for a mobile robot.

FIGURE 5.19 Triangular wave response.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0341.jpg?height=732&width=1248&top_left_y=154&top_left_x=368)

Therefore, the steady-state error of the system for a step input when $K_{2}=0$ and $G_{c}(s)=K_{1}$ is

$$
e_{\mathrm{ss}}=\frac{A}{1+K_{p}},
$$

where $K_{p}=K K_{1}$. When $K_{2}$ is greater than zero, we have a type- 1 system,

$$
G_{c}(s)=\frac{K_{1} s+K_{2}}{s},
$$

and the steady-state error is zero for a step input.

If the steering command is a ramp input, the steady-state error is

$$
e_{\mathrm{ss}}=\frac{A}{K_{v}},
$$

where

$$
K_{v}=\lim _{s \rightarrow 0} s G_{c}(s) G(s)=K_{2} K
$$

The transient response of the vehicle to a triangular wave input when $G_{c}(s)=\left(K_{1} s+K_{2}\right) / s$ is shown in Figure 5.19. The transient response clearly shows the effect of the steady-state error, which may not be objectionable if $K_{v}$ is sufficiently large. Note that the output attains the desired velocity as required by the input, but it exhibits a steady-state error.

The control system error constants, $K_{p}, K_{v}$, and $K_{a}$, describe the ability of a system to reduce or eliminate the steady-state error. Therefore, they are utilized as numerical measures of the steady-state performance. The designer determines the error constants for a given system and attempts to determine methods of increasing the error constants while maintaining an acceptable transient response. In the case of the steering control system, we want to increase the gain factor $K K_{2}$ in order to increase $K_{v}$ and reduce the steady-state error. However, an increase in $K K_{2}$ results in an attendant decrease in the system damping ratio $\zeta$ and therefore a more oscillatory response to a step input. Thus, we seek a compromise that provides the largest $K_{v}$ based on the smallest $\zeta$ allowable.

In the preceding discussions, we assumed that we had a unity feedback system. Now we consider nonunity feedback systems. For a system in which the feedback is not unity, the units of the output $Y(s)$ are usually different from the output of the sensor. For example, a speed control system is shown in Figure 5.20. The constants $K_{1}$ and $K_{2}$ account for the conversion of one set of units to another set of units (here we convert rad/s to volts). We can select $K_{1}$, and thus we set $K_{1}=K_{2}$ and move the block for $K_{1}$ and $K_{2}$ past the summing node. Then we obtain the equivalent block diagram shown in Figure 5.21. Thus, we obtain a unity feedback system as desired.

Consider a nonunity negative feedback system with the system $H(s)$ in the feedback loop given by

$$
H(s)=\frac{K_{2}}{\tau s+1}
$$

which has a DC gain of

$$
\lim _{s \rightarrow 0} H(s)=K_{2}
$$

If we set $K_{2}=K_{1}$, then the system is transformed to that of Figure 5.21 for the steady-state calculation. To see this, consider error of the system $E(s)$, where

$$
E(s)=R(s)-Y(s)=[1-T(s)] R(s),
$$

since $Y(s)=T(s) R(s)$. Note that

FIGURE 5.20

A speed control system.

FIGURE 5.21

The speed control system of Figure 5.20 with $K_{1}=K_{2}$.

$$
T(s)=\frac{K_{1} G_{c}(s) G(s)}{1+H(s) G_{c}(s) G(s)}=\frac{(\tau s+1) K_{1} G_{c}(s) G(s)}{\tau s+1+K_{1} G_{c}(s) G(s)},
$$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0342.jpg?height=600&width=1278&top_left_y=1516&top_left_x=508)and therefore,

$$
E(s)=\frac{1+\tau s\left(1-K_{1} G_{c}(s) G(s)\right)}{\tau s+1+K_{1} G_{c}(s) G(s)} R(s) .
$$

Then the steady-state error for a unit step input is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} s E(s)=\frac{1}{1+K_{1} \lim _{s \rightarrow 0} G_{c}(s) G(s)} .
$$

We assume here that

$$
\lim _{s \rightarrow 0} s G_{c}(s) G(s)=0
$$

\section{EXAMPLE 5.4 Steady-state error}

Let us determine the appropriate value of $K_{1}$ and calculate the steady-state error for a unit step input for the system shown in Figure 4.4 when

$$
G_{c}(s)=40, G(s)=\frac{1}{s+5} \text {, and } H(s)=\frac{2}{0.1 s+1} .
$$

Selecting $K_{1}=K_{2}=2$, we can use Equation (5.36) to determine

$$
e_{\mathrm{ss}}=\frac{1}{1+K_{1} \lim _{s \rightarrow 0} G_{c}(s) G(s)}=\frac{1}{1+2(40)(1 / 5)}=\frac{1}{17},
$$

or $5.9 \%$ of the magnitude of the step input.

\section{EXAMPLE 5.5 Nonunity feedback control system}

Let us consider the system of Figure 5.22, where we assume we cannot insert a gain $K_{1}$ following $R(s)$ as we did for the system of Figure 5.20. Then the actual error is given by Equation (5.35), which is

$$
E(s)=[1-T(s)] R(s) .
$$

Let us determine an appropriate gain $K$ so that the steady-state error to a step input is minimized. The steady-state error is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} s[1-T(s)] \frac{1}{s},
$$

where

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s) H(s)}=\frac{K(s+4)}{(s+2)(s+4)+2 K} .
$$

Then we have

$$
T(0)=\frac{4 K}{8+2 K}
$$

FIGURE 5.22

A system with a feedback $H(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0344.jpg?height=313&width=988&top_left_y=154&top_left_x=520)

The steady-state error for a unit step input is

$$
e_{\mathrm{ss}}=1-T(0) \text {. }
$$

Thus, to achieve a zero steady-state error, we require that

$$
T(0)=\frac{4 K}{8+2 K}=1
$$

or $8+2 K=4 K$. Thus, $K=4$ will yield a zero steady-state error. It is unlikely that meeting a steady-state error specification is the only requirement of the feedback control system, so choosing the control as a gain with only one parameter to adjust is probably not practical.

The determination of the steady-state error is simpler for unity feedback systems. However, it is possible to extend the notion of error constants to nonunity feedback systems by first appropriately rearranging the block diagram to obtain an equivalent unity feedback system. Remember that the underlying system must be stable, otherwise our use of the final value theorem will be compromised. Consider the nonunity feedback system in Figure 5.21 and assume that $K_{1}=1$. The closedloop transfer function is

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{G_{c}(s) G(s)}{1+H(s) G_{c}(s) G(s)} .
$$

By manipulating the block diagram appropriately we can obtain the equivalent unity feedback system with

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{Z(s)}{1+Z(s)} \text { where } \mathrm{Z}(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)(H(s)-1)} .
$$

The loop transfer function of the equivalent unity feedback system is $Z(s)$. It follows that the error constants for nonunity feedback systems are given as:

$$
K_{p}=\lim _{s \rightarrow 0} Z(s), K_{v}=\lim _{s \rightarrow 0} s Z(s), \text { and } K_{a}=\lim _{s \rightarrow 0} s^{2} Z(s) .
$$

Note that when $H(s)=1$, then $Z(s)=G_{c}(s) G(s)$ and we maintain the unity feedback error constants. For example, when $H(s)=1$, then $K_{p}=\lim _{s \rightarrow 0} Z(s)=$ $\lim _{s \rightarrow 0} G_{c}(s) G(s)$, as expected. 

\subsection{PERFORMANCE INDICES}

Modern control theory assumes that we can specify quantitatively the required system performance. Then a performance index can be calculated or measured and used to evaluate the system performance. Quantitative measures of the performance of a system are very valuable in the design and operation of control systems.

A system is considered an optimum control system when the system parameters are adjusted so that the index reaches an extremum, commonly a minimum value. To be useful, a performance index must be a number that is always positive or zero. Then the best system is defined as the system that minimizes this index.

\section{A performance index is a quantitative measure of the performance of a system and is chosen so that emphasis is given to the important system specifications.}

A common performance index is the integral of the square of the error, ISE, which is defined as

$$
\mathrm{ISE}=\int_{0}^{T} e^{2}(t) d t
$$

The upper limit $T$ is a finite time selected by the control system designer. It is convenient to choose $T$ as the settling time $T_{s}$. The step response for a specific feedback control system is shown in Figure 5.23(b), and the error in Figure 5.23(c). The error squared is shown in Figure 5.23(d), and the integral of the error squared in Figure 5.23(e). This criterion will discriminate between excessively overdamped and excessively underdamped systems. The minimum value of the integral occurs for a compromise value of the damping. The performance index of Equation (5.37) is mathematically convenient for analytical and computational purposes.

Three other performance indices we might consider include

$$
\begin{aligned}
\text { IAE } & =\int_{0}^{T}|e(t)| d t, \\
\text { ITAE } & =\int_{0}^{T} t|e(t)| d t,
\end{aligned}
$$

and

$$
\operatorname{ITSE}=\int_{0}^{T} t e^{2}(t) d t .
$$

The ITAE is able to reduce the contribution of any large initial errors, as well as to emphasize errors occurring later in the response [6]. The performance index ITAE provides the best selectivity of the performance indices; that is, the minimum value of the integral is readily discernible as the system parameters are varied. FIGURE 5.23

The calculation of the Integral squared error. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0346.jpg?height=1138&width=595&top_left_y=158&top_left_x=632)

The general form of the performance integral is

$$
I=\int_{0}^{T} f(e(t), r(t), y(t), t) d t,
$$

where $f$ is a function of the error, input, output, and time. We can obtain numerous indices based on various combinations of the system variables and time.

\section{EXAMPLE 5.6 Space telescope control system}

Consider a space telescope pointing control system shown in Figure 5.24 [9]. We desire to select the magnitude of the gain, $K_{3}$, to minimize the effect of the disturbance, $T_{d}(s)$. The closed-loop transfer function from the disturbance to the output is

$$
\frac{Y(s)}{T_{d}(s)}=\frac{s\left(s+K_{1} K_{3}\right)}{s^{2}+K_{1} K_{3} s+K_{1} K_{2} K_{p}} .
$$

FIGURE 5.24

A space telescope pointing control system. (a) Block diagram. (b) Signalflow graph.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0347.jpg?height=487&width=1159&top_left_y=154&top_left_x=373)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0347.jpg?height=456&width=1174&top_left_y=734&top_left_x=368)

(b)

Typical values for the constants are $K_{1}=0.5$ and $K_{1} K_{2} K_{p}=2.5$. In this case, the goal is to minimize $y(t)$, where, for a unit step disturbance, the minimum ISE can be analytically calculated. The attitude is

$$
y(t)=\frac{\sqrt{10}}{\beta}\left[e^{-0.25 K_{3} t} \sin \left(\frac{\beta}{2} t+\psi\right)\right]
$$

where $\beta=\sqrt{10-K_{3}^{2} / 4}$. Squaring $y(t)$ and integrating the result yields

$$
\begin{aligned}
I=\int_{0}^{\infty} \frac{10}{\beta^{2}} e^{-0.5 K_{3} t} \sin ^{2}\left(\frac{\beta}{2} t+\psi\right) d t & =\int_{0}^{\infty} \frac{10}{\beta^{2}} e^{-0.5 K_{3} t}\left(\frac{1}{2}-\frac{1}{2} \cos (\beta t+2 \psi)\right) d t \\
& =\frac{1}{K_{3}}+0.1 K_{3} .
\end{aligned}
$$

Differentiating $I$ and equating the result to zero, and solving for $K_{3}$, we obtain

$$
\frac{d I}{d K_{3}}=-K_{3}^{-2}+0.1=0 .
$$

FIGURE 5.25

The performance indices of the telescope control system versus $K_{3}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0348.jpg?height=407&width=727&top_left_y=154&top_left_x=521)

Therefore, the minimum ISE is obtained when $K_{3}=\sqrt{10}=3.2$. This value of $K_{3}$ corresponds to a damping ratio $\zeta=0.50$. The values of ISE and IAE for this system are plotted in Figure 5.25. The minimum for the IAE performance index is obtained when $K_{3}=4.2$ and $\zeta=0.665$. While the ISE criterion is not as selective as the IAE criterion, it is clear that it is possible to solve analytically for the minimum value of ISE. The minimum of IAE is obtained by computing the actual value of IAE for several values of the parameter of interest.

A control system is optimum when the selected performance index is minimized. However, the optimum value of the parameters depends directly on the definition of optimum, that is, the performance index. Therefore, in Example 5.6, we found that the optimum setting varied for different performance indices.

The coefficients that will minimize the ITAE performance criterion for a step input have been determined for the general closed-loop transfer function [6]

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{b_{0}}{s^{n}+b_{n-1} s^{n-1}+\cdots+b_{1} s+b_{0}} .
$$

This transfer function has a steady-state error equal to zero for a step input. Note that the transfer function has $n$ poles and no zeros. The optimum coefficients for the ITAE criterion are given in Table 5.3. The responses using optimum coefficients for a step input are given in Figure 5.26 for ISE, IAE, and ITAE. The responses are provided for normalized time $\omega_{n} t$. Other standard forms based on different performance indices are available and can be useful in aiding the designer to determine the range of coefficients for a specific problem.

Table 5.3 The Optimum Coefficients of $\boldsymbol{T}(\mathbf{s})$ Based on the ITAE Criterion for a Step Input

$$
\begin{gathered}
s+\omega_{n} \\
s^{2}+1.4 \omega_{n} s+\omega_{n}^{2} \\
s^{3}+1.75 \omega_{n} s^{2}+2.15 \omega_{n}^{2} s+\omega_{n}^{3} \\
s^{4}+2.1 \omega_{n} s^{3}+3.4 \omega_{n}^{2} s^{2}+2.7 \omega_{n}^{3} s+\omega_{n}^{4} \\
s^{5}+2.8 \omega_{n} s^{4}+5.0 \omega_{n}^{2} s^{3}+5.5 \omega_{n}^{3} s^{2}+3.4 \omega_{n}^{4} s+\omega_{n}^{5} \\
s^{6}+3.25 \omega_{n} s^{5}+6.60 \omega_{n}^{2} s^{4}+8.60 \omega_{n}^{3} s^{3}+7.45 \omega_{n}^{4} s^{2}+3.95 \omega_{n}^{5} s+\omega_{n}^{6}
\end{gathered}
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0349.jpg?height=755&width=994&top_left_y=159&top_left_x=378)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0349.jpg?height=760&width=995&top_left_y=1008&top_left_x=375)

Step responses of a normalized transfer function using optimum coefficients for (a) ISE, (b) IAE, and (c) ITAE. The response is for normalized time, $w_{n}^{t}$.

(b)

For a ramp input, the coefficients have been determined that minimize the ITAE criterion for the general closed-loop transfer function [6]

$$
T(s)=\frac{b_{1} s+b_{0}}{s^{n}+b_{n-1} s^{n-1}+\cdots+b_{1} s+b_{0}} .
$$

FIGURE 5.26 (Continued)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0350.jpg?height=769&width=993&top_left_y=152&top_left_x=515)

(c)

\section{Table 5.4 The Optimum Coefficients of $\boldsymbol{T}(\mathrm{s})$ Based} on the ITAE Criterion for a Ramp Input

$$
\begin{gathered}
s^{2}+3.2 \omega_{n} s+\omega_{n}^{2} \\
s^{3}+1.75 \omega_{n} s^{2}+3.25 \omega_{n}^{2} s+\omega_{n}^{3} \\
s^{4}+2.41 \omega_{n} s^{3}+4.93 \omega_{n}^{2} s^{2}+5.14 \omega_{n}^{3} s+\omega_{n}^{4} \\
s^{5}+2.19 \omega_{n} s^{4}+6.50 \omega_{n}^{2} s^{3}+6.30 \omega_{n}^{3} s^{2}+5.24 \omega_{n}^{4} s+\omega_{n}^{5}
\end{gathered}
$$

This transfer function has a steady-state error equal to zero for a ramp input. The optimum coefficients for this transfer function are given in Table 5.4. The transfer function, Equation (5.50), implies that the process $G(s)$ has two or more pure integrations, as required to provide zero steady-state error.

\subsection{THE SIMPLIFICATION OF LINEAR SYSTEMS}

It is quite useful to study complex systems with high-order transfer functions by using lower-order approximate models. Several methods are available for reducing the order of a systems transfer function. One relatively simple way to delete a certain insignificant pole of a transfer function is to note a pole that has a negative real part that is much more negative than the other poles. Thus, that pole is expected to affect the transient response insignificantly.

For example, if we have a system with transfer function

$$
G(s)=\frac{K}{s(s+2)(s+30)},
$$

we can safely neglect the impact of the pole at $s=-30$. However, we must retain the steady-state response of the system, so we reduce the system to

$$
G(s)=\frac{(K / 30)}{s(s+2)} \text {. }
$$

A more sophisticated approach attempts to match the frequency response of the reduced-order transfer function with the original transfer function frequency response as closely as possible. Although frequency response methods are covered in Chapter 8, the associated approximation method strictly relies on algebraic manipulation and is presented here. Consider the high-order system be described by the transfer function

$$
G_{H}(s)=K \frac{a_{m} s^{m}+a_{m-1} s^{m-1}+\cdots+a_{1} s+1}{b_{n} s^{n}+b_{n-1} s^{n-1}+\cdots+b_{1} s+1},
$$

in which the poles are in the left-hand $s$-plane and $m \leq n$. The lower-order approximate transfer function is

$$
G_{L}(s)=K \frac{c_{p} s^{p}+\cdots+c_{1} s+1}{d_{g} s^{g}+\cdots+d_{1} s+1},
$$

where $p \leq g<n$. Notice that the gain constant, $K$, is the same for the original and approximate system; this ensures the same steady-state response. The method outlined in Example 5.7 is based on selecting $c_{i}$ and $d_{i}$ in such a way that $G_{L}(s)$ has a frequency response very close to that of $G_{H}(s)$. This is equivalent to stating that $G_{H}(j \omega) / G_{L}(j \omega)$ is required to deviate the least amount from unity for various frequencies. The $c$ and $d$ coefficients are obtained via

$$
M^{(k)}(s)=\frac{d^{k}}{d s^{k}} M(s)
$$

and

$$
\Delta^{(k)}(s)=\frac{d^{k}}{d s^{k}} \Delta(s)
$$

where $M(s)$ and $\Delta(s)$ are the numerator and denominator polynomials of $G_{H}(s) / G_{L}(s)$, respectively. We also define

$$
M_{2 q}=\sum_{k=0}^{2 q} \frac{(-1)^{k+q} M^{(k)}(0) M^{(2 q-k)}(0)}{k !(2 q-k) !}, \quad q=0,1,2 \ldots
$$

and an analogous equation for $\Delta_{2 q}$. The solutions for the $c$ and $d$ coefficients are obtained by equating

$$
M_{2 q}=\Delta_{2 q}
$$

for $q=1,2, \ldots$ up to the number required to solve for the unknown coefficients. 

\section{EXAMPLE 5.7 A simplified model}

Consider the third-order system

$$
G_{H}(s)=\frac{6}{s^{3}+6 s^{2}+11 s+6}=\frac{1}{1+\frac{11}{6} s+s^{2}+\frac{1}{6} s^{3}} .
$$

Using the second-order model

$$
G_{L}(s)=\frac{1}{1+d_{1} s+d_{2} s^{2}},
$$

we determine that

$$
M(s)=1+d_{1} s+d_{2} s^{2}, \quad \text { and } \quad \Delta(s)=1+\frac{11}{6} s+s^{2}+\frac{1}{6} s^{3}
$$

Then we know that

$$
M^{(0)}(s)=1+d_{1} s+d_{2} s^{2},
$$

and $M^{(0)}(0)=1$. Similarly, we have

$$
M^{(1)}=\frac{d}{d s}\left(1+d_{1} s+d_{2} s^{2}\right)=d_{1}+2 d_{2} s .
$$

Therefore, $M^{(1)}(0)=d_{1}$. Continuing this process, we find that

$$
\begin{array}{ll}
M^{(0)}(0)=1 & \Delta^{(0)}(0)=1, \\
M^{(1)}(0)=d_{1} & \Delta^{(1)}(0)=\frac{11}{6}, \\
M^{(2)}(0)=2 d_{2} & \Delta^{(2)}(0)=2, \\
M^{(3)}(0)=0 & \Delta^{(3)}(0)=1 .
\end{array}
$$

We now equate $M_{2 q}=\Delta_{2 q}$ for $q=1$ and 2. We find that, for $q=1$,

$$
\begin{aligned}
M_{2} & =(-1) \frac{M^{(0)}(0) M^{(2)}(0)}{2}+\frac{M^{(1)}(0) M^{(1)}(0)}{1}+(-1) \frac{M^{(2)}(0) M^{(0)}(0)}{2} \\
& =-d_{2}+d_{1}^{2}-d_{2}=-2 d_{2}+d_{1}^{2} .
\end{aligned}
$$

Since the equation for $\Delta_{2}$ is similar, we have

$$
\begin{aligned}
\Delta_{2} & =(-1) \frac{\Delta^{(0)}(0) \Delta^{(2)}(0)}{2}+\frac{\Delta^{(1)}(0) \Delta^{(1)}(0)}{1}+(-1) \frac{\Delta^{(2)}(0) \Delta^{(0)}(0)}{2} \\
& =-1+\frac{121}{36}-1=\frac{49}{36} .
\end{aligned}
$$

Equation (5.53) with $q=1$ requires that $M_{2}=\Delta_{2}$; therefore,

$$
-2 d_{2}+d_{1}^{2}=\frac{49}{36}
$$

Completing the process for $M_{4}=\Delta_{4}$, we obtain

$$
d_{2}^{2}=\frac{7}{18}
$$

Solving Equations (5.61) and (5.62) yields $d_{1}=1.615$ and $d_{2}=0.624$. (The other sets of solutions are rejected because they lead to unstable poles.) The lower-order system transfer function is

$$
G_{L}(s)=\frac{1}{1+1.615 s+0.624 s^{2}}=\frac{1.60}{s^{2}+2.590 s+1.60} .
$$

It is interesting to see that the poles of $G_{H}(s)$ are $s=-1,-2,-3$, whereas the poles of $G_{L}(s)$ are $s=-1.024$ and -1.565 . Because the lower-order model has two poles, we estimate that we would obtain a slightly overdamped step response with a settling time to within $2 \%$ of the final value in approximately 3 seconds.

It is sometimes desirable to retain the dominant poles of the original system, $G_{H}(s)$, in the low-order model. This can be accomplished by specifying the denominator of $G_{L}(s)$ to be the dominant poles of $G_{H}(s)$ and allowing the numerator of $G_{L}(s)$ to be subject to approximation.

Another novel and useful method for reducing the order is the Routh approximation method based on the idea of truncating the Routh table used to determine stability. The Routh approximants can be computed by a finite recursive algorithm [19].

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. The first example is a simplified view of the Hubble space telescope pointing control problem. The Hubble space telescope problem highlights the process of computing controller gains to achieve desired percent overshoot specifications, as well as meeting steady-state error specifications. The second example considers the control of the bank angle of an airplane. The airplane attitude motion control example represents a more in-depth look at the control design problem. Here we consider a complex fourthorder model of the lateral dynamics of the aircraft motion that is approximated by a second-order model using the approximation methods of Section 5.8. The simplified model can be used to gain insight into the controller design and the impact of key controller parameters on the transient performance.

\section{EXAMPLE 5.8 Hubble space telescope control}

The orbiting Hubble space telescope is the most complex and expensive scientific instrument that has ever been built. The telescope's 2.4 meter mirror has the 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0354.jpg?height=367&width=1063&top_left_y=160&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0354.jpg?height=226&width=948&top_left_y=675&top_left_x=594)

(b)

FIGURE 5.27

(a) The Hubble telescope pointing system, (b) reduced block diagram, and (c) system response to a unit step input command and a unit step disturbance input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0354.jpg?height=620&width=830&top_left_y=1033&top_left_x=676)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0354.jpg?height=355&width=43&top_left_y=1135&top_left_x=1519)

(c)

smoothest surface of any mirror made, and its pointing system can center it on a dime 400 miles away [18, 21]. Consider the model of the telescope-pointing system shown in Figure 5.27.

The goal of the design is to choose $K_{1}$ and $K$ so that (1) the percent overshoot of the output to a step command, $r(t)$, is $P . O . \leq 10 \%,(2)$ the steady-state error to a ramp command is minimized, and (3) the effect of a step disturbance is reduced. Since the system has an inner loop, block diagram reduction can be used to obtain the simplified system of Figure 5.27(b). The output due to the two inputs of the system of Figure 5.27(b) is given by

$$
Y(s)=T(s) R(s)+[T(s) / K] T_{d}(s),
$$

where

$$
T(s)=\frac{K G(s)}{1+K G(s)}=\frac{L(s)}{1+L(s)} .
$$

The tracking error is

$$
E(s)=\frac{1}{1+L(s)} R(s)-\frac{G(s)}{1+L(s)} T_{d}(s) .
$$

First, let us select $K$ and $K_{1}$ to meet the percent overshoot requirement for a step input, $R(s)=A / s$. Setting $T_{d}(s)=0$, we have

$$
Y(s)=\frac{K G(s)}{1+K G(s)} R(s)=\frac{K}{s^{2}+K_{1} s+K}\left(\frac{A}{s}\right) .
$$

To set the percent overshoot to P.O. $\leq 10 \%$, we select $\zeta=0.6$. We can use Equation (5.16) to determine that P.O. $=9.5 \%$ for $\zeta=0.6$. We next examine the steady-state error for a ramp, $r(t)=B t, t \geq 0$. Using Equation 5.28 we find

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0}\left\{\frac{B}{s K G(s)}\right\}=\frac{B}{K / K_{1}} .
$$

The steady-state error due to the ramp disturbance is reduced by increasing $K K_{1}$. The steady-state error due to a unit step disturbance is equal to $-1 / K$. The steadystate error due to the step disturbance input can thus be reduced by increasing $K$. In summary, we seek a large $K$ and a large value of $K / K_{1}$ to obtain low steady-state errors due to a step and ramp disturbance, respectively. We also require $\zeta=0.6$ to limit the percent overshoot.

With $\zeta=0.6$, the characteristic equation of the system is

$$
s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=s^{2}+2(0.6) \omega_{n} s+K .
$$

Therefore, $\omega_{n}=\sqrt{K}$, and the second term of the denominator of Equation (5.69) requires $K_{1}=2(0.6) \omega_{n}$. Then $K_{1}=1.2 \sqrt{K}$, so the ratio $K / K_{1}$ is

$$
\frac{K}{K_{1}}=\frac{K}{1.2 \sqrt{K}}=\frac{\sqrt{K}}{1.2} \text {. }
$$

If we select $K=100$, we have $K_{1}=12$ and $K / K_{1}=8.33$. The responses of the system to a unit step input command and a unit step disturbance input are shown in Figure 5.27(c). Note how the effect of the disturbance is relatively insignificant. Finally, we note that the steady-state error for a ramp input is

$$
e_{\mathrm{ss}}=\frac{B}{8.33}=0.12 B \text {. }
$$

This design, using $K=100$, provides acceptable results. 

\section{EXAMPLE 5.9 Attitude control of an airplane}

Each time we fly on a commercial airliner, we experience first-hand the benefits of automatic control systems. These systems assist pilots by improving the handling qualities of the aircraft over a wide range of flight conditions and by providing pilot relief (for such emergencies as going to the restroom) during extended flights. The special relationship between flight and controls began in the early work of the Wright brothers. Using wind tunnels, the Wright brothers applied systematic design techniques to make their dream of powered flight a reality. This systematic approach to design contributed to their success.

Another significant aspect of their approach was their emphasis on flight controls; the brothers insisted that their aircraft be pilot-controlled. Observing birds control their rolling motion by twisting their wings, the Wright brothers built aircraft with mechanical mechanisms that twisted their airplane wings. Today we no longer use wing warping as a mechanism for performing a roll maneuver; instead we control rolling motion by using ailerons, as shown in Figure 5.28. The Wright brothers also used elevators (located forward) for longitudinal control (pitch motion) and rudders for lateral control (yaw motion). Today's aircraft still use both elevators and rudders, although the elevators are generally located on the tail (rearward).

The first controlled, powered, unassisted take-off flight occurred in 1903 with the Wright Flyer I (a.k.a. Kitty Hawk). The first practical airplane, the Flyer III, could fly figure eights and stay aloft for half an hour. Three-axis flight control was a major (and often overlooked) contribution of the Wright brothers. A concise historical perspective is presented in Stevens and Lewis [24]. The continuing desire to fly faster, lighter, and longer fostered further developments in automatic flight control.

The main topic of this chapter is control of the automatic rolling motion of an airplane. The elements of the design process emphasized in this chapter are illustrated in Figure 5.29.

We begin by considering the model of the lateral dynamics of an airplane moving along a steady, wings-level flight path. By lateral dynamics, we mean the attitude motion of the aircraft about the forward velocity. An accurate mathematical model describing the motion (translational and rotational) of an aircraft is a complicated set of highly nonlinear, time-varying, coupled differential equations. A good description of the process of developing such a mathematical model appears in Etkin and Reid [25].

For our purposes a simplified dynamic model is required for the autopilot design process. A simplified model might consist of a transfer function describing

FIGURE 5.28

Control of the bank angle of an airplane using differential deflections of the ailerons.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0356.jpg?height=388&width=944&top_left_y=1730&top_left_x=506)Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0357.jpg?height=1030&width=1159&top_left_y=226&top_left_x=460)

FIGURE 5.29 Elements of the control system design process emphasized in the airplane attitude control example.

the input-output relationship between the aileron deflection and the aircraft bank angle. Obtaining such a transfer function would require many prudent simplifications to the original high-fidelity, nonlinear mathematical model.

Suppose we have a rigid aircraft with a plane of symmetry. The airplane is assumed to be cruising at subsonic or low supersonic $($ Mach $<3)$ speeds. This allows us to make a flat-Earth approximation. We ignore any rotor gyroscopic effects due to spinning masses on the aircraft (such as propellors or turbines). These assumptions allow us to decouple the longitudinal rotational (pitching) motion from the lateral rotational (rolling and yawing) motion.

Of course, we also need to consider a linearization of the nonlinear equations of motion. To accomplish this, we consider only steady-state flight conditions such as

$\square \quad$ Steady, wings-level flight

$\square$ Steady, level turning flight

$\square \quad$ Steady, symmetric pull-up

$\square \quad$ Steady roll. For this example we assume that the airplane is flying at low speed in a steady, wings-level attitude, and we want to design an autopilot to control the rolling motion. We can state the control goal as follows:

\section{Control Goal}

Regulate the airplane bank angle to zero degrees (steady, wings level) and maintain the wings-level orientation in the presence of unpredictable external disturbances.

We identify the variable to be controlled as

\section{Variable to Be Controlled}

Airplane bank angle (denoted by $\phi)$.

Defining system specifications for aircraft control is complicated, so we do not attempt it here. It is a subject in and of itself, and many engineers have spent significant efforts developing good, practical design specifications. The goal is to design a control system such that the dominant closed-loop system poles have satisfactory natural frequency and damping [24]. We must define satisfactory and choose test input signals on which to base our analysis.

The Cooper-Harper pilot opinion ratings provide a way to correlate the feel of the airplane with control design specifications [26]. These ratings address the handling qualities issues. Many flying qualities requirements are specified by government agencies, such as the United States Air Force [27]. The USAF MIL-F$8785 \mathrm{C}$ is a source of time-domain control system design specifications.

For example we might design an autopilot control system for an aircraft in steady, wings-level flight to achieve a P.O. $\leq 20 \%$ to a step input with minimal oscillatory motion and rapid response time (that is, a short time-to-peak). Subsequently we implement the controller in the aircraft control system and conduct flight tests or high-fidelity computer simulations, after which the pilots tell us whether they liked the performance of the aircraft. If the overall performance was not satisfactory, we change the time-domain specification (in this case a percent overshoot specification) and redesign until we achieve a feel and performance that pilots (and ultimately passengers) will accept. Despite the simplicity of this approach and many years of research, precise-control system design specifications that provide acceptable airplane flying characteristics in all cases are still not available [24].

The control design specifications given in this example may seem somewhat contrived. In reality the specifications would be much more involved and, in many ways, less precisely known. But we must begin the design process somewhere. With that approach in mind, we select simple design specifications and begin the iterative design process. The design specifications are

\section{Control Design Specifications}

DS1 Percent overshoot is P.O. $\leq 20 \%$ for a unit step input.

DS2 Fast response time as measured by time-to-peak.

By making the simplifying assumptions discussed above and linearizing about the steady, wings-level flight condition, we can obtain a transfer function model describing the bank angle output, $\phi(s)$, to the aileron deflection input, $\delta_{a}(s)$. The transfer function has the form

$$
\frac{\phi(s)}{\delta_{a}(s)}=\frac{k\left(s-c_{0}\right)\left(s^{2}+b_{1} s+b_{0}\right)}{s\left(s+d_{0}\right)\left(s+e_{0}\right)\left(s^{2}+f_{1} s+f_{0}\right)} .
$$

The lateral (roll/yaw) motion has three main modes: Dutch roll mode, spiral mode, and roll subsidence mode. The Dutch roll mode, which gets its name from its similarities to the motion of an ice speed skater, is characterized by a rolling and yawing motion. The airplane center of mass follows nearly a straightline path, and a rudder impulse can excite this mode. The spiral mode is characterized by a mainly yawing motion with some roll motion. This is a weak mode, but it can cause an airplane to enter a steep spiral dive. The roll subsidence motion is almost a pure roll motion. This is the motion we are concerned with for our autopilot design. The denominator of the transfer function in Equation (5.69) shows two first-order modes (spiral and roll subsidence modes) and a second-order mode (Dutch roll mode).

In general the coefficients $c_{0}, b_{0}, b_{1}, d_{0}, e_{0}, f_{0}, f_{1}$ and the gain $k$ are complicated functions of stability derivatives. The stability derivatives are functions of the flight conditions and the aircraft configuration; they differ for different aircraft types. The coupling between the roll and yaw is included in Equation (5.69).

In the transfer function in Equation (5.69), the pole at $s=-d_{0}$ is associated with the spiral mode. The pole at $s=-e_{0}$ is associated with the roll subsidence mode. Generally, $e_{0} \gg d_{0}$. For an F-16 flying at $500 \mathrm{ft} / \mathrm{s}$ in steady, wings-level flight, we have $e_{0}=3.57$ and $d_{0}=0.0128$ [24]. The complex conjugate poles given by the term $s^{2}+f_{1} s+f_{0}$ represent the Dutch roll motion.

For low angles of attack (such as with steady, wings-level flight), the Dutch roll mode generally cancels out of the transfer function with the $s^{2}+b_{1} s+b_{0}$ term. This is an approximation, but it is consistent with our other simplifying assumptions. Also, we can ignore the spiral mode since it is essentially a yaw motion only weakly coupled to the roll motion. The zero at $s=c_{0}$ represents a gravity effect that causes the aircraft to sideslip as it rolls. We assume that this effect is negligible, since it is most pronounced in a slow roll maneuver in which the sideslip is allowed to build up, and we assume that the aircraft sideslip is small or zero. Therefore we can simplify the transfer function in Equation (5.69) to obtain a single-degree-of-freedom approximation:

$$
\frac{\phi(s)}{\delta_{a}(s)}=\frac{k}{s\left(s+e_{0}\right)} .
$$

For our aircraft we select $e_{0}=1.4$ and $k=11.4$. The associated time-constant of the roll subsidence is $\tau=1 / e_{0}=0.7 \mathrm{~s}$. These values represent a fairly fast rolling motion response.

For the aileron actuator model, we typically use a simple first-order system model,

$$
\frac{\delta_{a}(s)}{e(s)}=\frac{p}{s+p}
$$

where $e(s)=\phi_{d}(s)-\phi(s)$. In this case we select $p=10$. This corresponds to a time constant of $\tau=1 / p=0.1 \mathrm{~s}$. This is a typical value consistent with a fast response. We need to have an actuator with a fast response so that the dynamics of the actively controlled airplane will be the dominant component of the system response. A slow actuator is akin to a time delay that can cause performance and stability problems.

For a high-fidelity simulation, we would need to develop an accurate model of the gyro dynamics. The gyro, typically an integrating gyro, is usually characterized by a very fast response. To remain consistent with our other simplifying assumptions, we ignore the gyro dynamics in the design process. This means we assume that the sensor measures the bank angle precisely. The gyro model is given by a unity transfer function,

$$
K_{g}=1 .
$$

Thus our physical system model is given by Equations (5.70), (5.71), and (5.72).

The controller we select for this design is a proportional controller,

$$
G_{c}(s)=K \text {. }
$$

The system configuration is shown in Figure 5.30. The select key parameter is as follows:

\section{Select Key Tuning Parameter \\ Controller gain $K$.}

The closed-loop transfer function is

$$
T(s)=\frac{\phi(s)}{\phi_{d}(s)}=\frac{114 K}{s^{3}+11.4 s^{2}+14 s+114 K} .
$$

We want to determine analytically the values of $K$ that will give us the desired response, namely, a percent overshoot less than $20 \%$ and a fast time-to-peak. The analytic analysis would be simpler if our closed-loop system were a second-order system (since we have valuable relationships between settling time, percent overshoot, natural frequency and damping ratio); however we have a third-order system, given by $T(s)$ in Equation (5.73). We could consider approximating the third-order transfer function by a second-order transfer function - this is sometimes a very good engineering approach to analysis. There are many methods available to

FIGURE 5.30

Bank angle control autopilot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0360.jpg?height=360&width=1156&top_left_y=1763&top_left_x=518)

obtain approximate transfer functions. Here we use the algebraic method described in Section 5.8 that attempts to match the frequency response of the approximate system as closely as possible to the actual system.

Our transfer function can be rewritten as

$$
T(s)=\frac{1}{1+\frac{14}{114 K} s+\frac{11.4}{114 K} s^{2}+\frac{1}{114 K} s^{3}},
$$

by factoring the constant term out of the numerator and denominator. Suppose our approximate transfer function is given by the second-order system

$$
G_{L}(s)=\frac{1}{1+d_{1} s+d_{2} s^{2}} .
$$

The objective is to find appropriate values of $d_{1}$ and $d_{2}$. As in Section 5.8, we define $M(s)$ and $\Delta(s)$ as the numerator and denominator of $T(s) / G_{L}(s)$. We also define

$$
M_{2 q}=\sum_{k=0}^{2 q} \frac{(-1)^{k+q} M^{(k)}(0) M^{(2 q-k)}(0)}{k !(2 q-k) !}, \quad q=1,2, \ldots,
$$

and

$$
\Delta_{2 q}=\sum_{k=0}^{2 q} \frac{(-1)^{k+q} \Delta^{(k)}(0) \Delta^{(2 q-k)}(0)}{k !(2 q-k) !}, \quad q=1,2, \ldots
$$

Then, forming the set of algebraic equations

$$
M_{2 q}=\Delta_{2 q}, \quad q=1,2, \ldots,
$$

we can solve for the unknown parameters of the approximate function. The index $q$ is incremented until sufficient equations are obtained to solve for the unknown coefficients of the approximate function. In this case, $q=1,2$ since we have two parameters $d_{1}$ and $d_{2}$ to compute.

We have

$$
\begin{aligned}
M(s) & =1+d_{1} s+d_{2} s^{2} \\
M^{(1)}(s) & =\frac{d M}{d s}=d_{1}+2 d_{2} s \\
M^{(2)}(s) & =\frac{d^{2} M}{d s^{2}}=2 d_{2} \\
M^{(3)}(s) & =M^{4}(s)=\cdots=0 .
\end{aligned}
$$

Thus evaluating at $s=0$ yields

$$
\begin{aligned}
& M^{(1)}(0)=d_{1} \\
& M^{(2)}(0)=2 d_{2} \\
& M^{(3)}(0)=M^{(4)}(0)=\cdots=0 .
\end{aligned}
$$

Similarly,

$$
\begin{aligned}
\Delta(s) & =1+\frac{14}{114 K} s+\frac{11.4}{114 K} s^{2}+\frac{s^{3}}{114 K} \\
\Delta^{(1)}(s) & =\frac{d \Delta}{d s}=\frac{14}{114 K}+\frac{22.8}{114 K} s+\frac{3}{114 K} s^{2} \\
\Delta^{(2)}(s) & =\frac{d^{2} \Delta}{d s^{2}}=\frac{22.8}{114 K}+\frac{6}{114 K} s \\
\Delta^{(3)}(s) & =\frac{d^{3} \Delta}{d s^{3}}=\frac{6}{114 K} \\
\Delta^{(4)}(s) & =\Delta^{5}(s)=\cdots=0 .
\end{aligned}
$$

Evaluating at $s=0$, it follows that

$$
\begin{aligned}
& \Delta^{(1)}(0)=\frac{14}{114 K}, \\
& \Delta^{(2)}(0)=\frac{22.8}{114 K}, \\
& \Delta^{(3)}(0)=\frac{6}{114 K}, \\
& \Delta^{(4)}(0)=\Delta^{(5)}(0)=\cdots=0 .
\end{aligned}
$$

Using Equation (5.77) for $q=1$ and $q=2$ yields

$$
M_{2}=-\frac{M(0) M^{(2)}(0)}{2}+\frac{M^{(1)}(0) M^{(1)}(0)}{1}-\frac{M^{(2)}(0) M(0)}{2}=-2 d_{2}+d_{1}^{2},
$$

and

$$
\begin{gathered}
M_{4}=\frac{M(0) M^{(4)}(0)}{0 ! 4 !}-\frac{M^{(1)}(0) M^{(3)}(0)}{1 ! 3 !}+\frac{M^{(2)}(0) M^{(2)}(0)}{2 ! 2 !} \\
-\frac{M^{(3)}(0) M^{(1)}(0)}{3 ! 1 !}+\frac{M^{(4)}(0) M(0)}{4 ! 0 !}=d_{2}^{2} .
\end{gathered}
$$

Similarly using Equation (5.78), we find that

$$
\Delta_{2}=\frac{-22.8}{114 K}+\frac{196}{(114 K)^{2}} \quad \text { and } \quad \Delta_{4}=\frac{101.96}{(114 K)^{2}} .
$$

Thus forming the set of algebraic equations in Equation (5.79),

$$
M_{2}=\Delta_{2} \text { and } M_{4}=\Delta_{4},
$$

we obtain

$$
-2 d_{2}+d_{1}^{2}=\frac{-22.8}{114 K}+\frac{196}{(114 K)^{2}} \quad \text { and } \quad d_{2}^{2}=\frac{101.96}{(114 K)^{2}}
$$

Solving for $d_{1}$ and $d_{2}$ yields

$$
\begin{aligned}
& d_{1}=\frac{\sqrt{196-296.96 K}}{114 K}, \\
& d_{2}=\frac{10.097}{114 K}
\end{aligned}
$$

where we always choose the positive values of $d_{1}$ and $d_{2}$ so that $G_{L}(s)$ has poles in the left half-plane. Thus (after some manipulation) the approximate transfer function is

$$
G_{L}(s)=\frac{11.29 K}{s^{2}+\sqrt{1.92-2.91 K} s+11.29 K} .
$$

We require that $K<0.65$ so that the coefficient of the $s$ term remains a real number.

Our desired second-order transfer function can be written as

$$
G_{L}(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

Comparing coefficients in Equations (5.79) and (5.80) yields

$$
\omega_{n}^{2}=11.29 K \quad \text { and } \quad \zeta^{2}=\frac{0.043}{K}-0.065 \text {. }
$$

The design specification that the percent overshoot P.O. is to be less than $20 \%$ implies that we want $\zeta \geq 0.45$. Setting $\zeta=0.45$ in Equation (5.81) and solving for $K$ yields

$$
K=0.16
$$

With $K=0.16$ we compute

$$
\omega_{n}=\sqrt{11.29 K}=1.34
$$

Then we can estimate the time-to-peak $T_{p}$ from Equation (5.14) to be

$$
T_{p}=\frac{\pi}{\omega_{n} \sqrt{1-\zeta^{2}}}=2.62 \mathrm{~s} .
$$

We might be tempted at this point to select $\zeta>0.45$ so that we reduce the percent overshoot even further than $20 \%$. What happens if we decide to try this approach? From Equation (5.81) we see that $K$ decreases as $\zeta$ increases. Then, since

$$
\omega_{n}=\sqrt{11.29 K}
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0364.jpg?height=830&width=1046&top_left_y=152&top_left_x=500)

FIGURE 5.31 Step response comparison of third-order aircraft model versus second-order approximation.

as $K$ decreases, then $\omega_{n}$ also decreases. But the time-to-peak increases as $\omega_{n}$ decreases. Since our goal is to meet the specification of percent overshoot less than $20 \%$ while minimizing the time-to-peak, we use the initial selection of $\zeta=0.45$ so that we do not increase $T_{p}$ unnecessarily.

The second-order system approximation has allowed us to gain insight into the relationship between the parameter $K$ and the system response, as measured by percent overshoot and time-to-peak. Of course, the gain $K=0.16$ is only a starting point in the design because we in fact have a third-order system and must consider the effect of the third pole (which we have ignored so far).

A comparison of the third-order aircraft model in Equation (5.73) with the second-order approximation in Equation (5.79) for a unit step input is shown in Figure 5.31. The step response of the second-order system is a good approximation of the original system step response, so we would expect that the analytic analysis using the simpler second-order system to provide accurate indications of the relationship between $K$ and the percent overshoot and time-to-peak.

With the second-order approximation, we estimate that with $K=0.16$ the percent overshoot is P.O. $=20 \%$ and the time-to-peak is $T_{p}=2.62 \mathrm{~s}$. As shown in Figure 5.32 the percent overshoot of the original third-order system is P.O. $=20.5 \%$ and the time-to-peak is $T_{p}=2.73 \mathrm{~s}$. Thus, we see that that analytic analysis using the approximate system is an excellent predictor of the actual response. For comparison purposes, we select two variations in the gain and observe the response. For $K=0.1$, the percent overshoot is $P . O .=9.5 \%$ and the time-to-peak is $T_{p}=3.74 \mathrm{~s}$. FIGURE 5.32

Step response of the third-order aircraft model with $K=0.10,0.16$, and 0.20 showing that, as predicted, as $K$ decreases percent overshoot decreases while the time-to-peak increases.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0365.jpg?height=729&width=926&top_left_y=155&top_left_x=466)

For $K=0.2$, the percent overshoot is P.O. $=26.5 \%$ and the time-to-peak is $T_{p}=2.38 \mathrm{~s}$. So as predicted, as $K$ decreases the damping ratio increases, leading to a reduction in the percent overshoot. Also as predicted, as the percent overshoot decreases the time-to-peak increases.

\subsection{SYSTEM PERFORMANCE USING CONTROL DESIGN SOFTWARE}

In this section, we investigate time-domain performance specifications given in terms of transient response to a given input signal and the resulting steady-state tracking errors. We conclude with a discussion of the simplification of linear systems. The function introduced in this section is impulse. We discuss the Isim function and see how these functions are used to simulate a linear system.

Time-Domain Specifications. Time-domain performance specifications are generally given in terms of the transient response of a system to a given input signal. Because the actual input signals are generally unknown, a standard test input signal is used. Consider the second-order system shown in Figure 5.3. The closed-loop output is

$$
Y(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} R(s) .
$$

We have already discussed the use of the step function to compute the step response of a system. Now we address another important test signal: the impulse. 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0366.jpg?height=630&width=996&top_left_y=160&top_left_x=508)

FIGURE 5.33 The impulse function.

The impulse response is the time derivative of the step response. We compute the impulse response with the impulse function shown in Figure 5.33.

We can obtain a plot similar to that of Figure 5.4 with the step function, as shown in Figure 5.34. Using the impulse function, we can obtain a plot similar to that of Figure 5.5. The response of a second-order system for an impulse function input is shown in Figure 5.35. In the script, we set $\omega_{n}=1$, which is equivalent to computing the step response versus $\omega_{n} t$. This gives us a more general plot valid for any $\omega_{n}>0$.

In many cases, it may be necessary to simulate the system response to an arbitrary but known input. In these cases, we use the Isim function. The Isim function is shown in Figure 5.36.

\section{EXAMPLE 5.10 Mobile robot steering control}

The block diagram for a steering control system for a mobile robot is shown in Figure 5.18. Suppose the transfer function of the steering controller is

$$
G_{c}(s)=K_{1}+\frac{K_{2}}{s} .
$$

When the input is a ramp, the steady-state error is

$$
e_{\mathrm{ss}}=\frac{A}{K_{v}},
$$

where

$$
K_{v}=K_{2} K .
$$

FIGURE 5.34

(a) Response of a second-order system to a step input. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0367.jpg?height=696&width=908&top_left_y=153&top_left_x=369)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0367.jpg?height=656&width=854&top_left_y=975&top_left_x=443)

(b)

The effect of the controller constant, $K_{2}$, on the steady-state error is evident from Equation (5.83). Whenever $K_{2}$ is large, the steady-state error is small.

We can simulate the closed-loop system response to a ramp input using the Isim function. The controller gains, $K_{1}$ and $K_{2}$, and the system gain $K$ can be represented symbolically in the script so that various values can be selected and simulated. The results are shown in Figure 5.37 for $K_{1}=K=1, K_{2}=2$, and $\tau=1 / 10$. FIGURE 5.35

(a) Response of a second-order system to an impulse function input. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0368.jpg?height=745&width=980&top_left_y=152&top_left_x=505)

(a)

(b)

Simplification of Linear Systems. It may be possible to develop a lower-order approximate model that closely matches the input-output response of a high-order model. A procedure for approximating transfer functions is given in Section 5.8. We can use computer simulation to compare the approximate model to the actual model, as illustrated in the following example. FIGURE 5.36

The Isim function.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0369.jpg?height=208&width=1038&top_left_y=152&top_left_x=372)

FIGURE 5.37

(a) Transient response of the mobile robot steering control system to a ramp input. (b) $m$-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0369.jpg?height=581&width=851&top_left_y=904&top_left_x=412)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0369.jpg?height=346&width=1005&top_left_y=415&top_left_x=391)

\%Compute the response of the Mobile Robot Control $\%$ System to a triangular wave input $\%$ numg=[10 20]; deng=[1 10 0]; sysg=tf(numg,deng); [sys]=feedback(sysg, [1]); $\mathrm{t}=[0: 0.1: 8.2]$; $\mathrm{v} 1=[0: 0.1: 2]^{\prime} ; \mathrm{v} 2=[2:-0.1:-2]^{\prime} ; \mathrm{v} 3=[-2: 0.1: 0]^{\prime} ;$ $\mathrm{u}=[\mathrm{v} 1 ; \mathrm{v} 2 ; \mathrm{v} 3]$;

$[\mathrm{y}, \mathrm{T}]=\mathrm{Isim}(\mathrm{sys}, \mathrm{u}, \mathrm{t})$; $\operatorname{plot}\left(\mathrm{T}, \mathrm{y}, \mathrm{t}, \mathrm{u}, \mathrm{\prime}^{--} \mathrm{-}\right)$, xlabel('Time (s)'), ylabel('theta (rad)'), grid
$G(s) G_{c}(s)$

Compute triangular wave input.

Linear simulation. 

\section{EXAMPLE 5.11 A simplified model}

Consider the third-order system

$$
G_{H}(s)=\frac{6}{s^{3}+6 s^{2}+11 s+6} .
$$

A second-order approximation is

$$
G_{L}(s)=\frac{1.60}{s^{2}+2.590 s+1.60} .
$$

A comparison of their respective step responses is given in Figure 5.38.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0370.jpg?height=635&width=917&top_left_y=788&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0370.jpg?height=366&width=978&top_left_y=1574&top_left_x=527)

(b)

FIGURE 5.38 (a) Step response comparison for an approximate transfer function versus the actual transfer function. (b) m-file script. 

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this section, we further consider the design process of the disk drive read system. We will specify the desired performance for the system. Then we will attempt to adjust the amplifier gain $K_{a}$ in order to obtain the best performance possible.

Our goal is to achieve the fastest response to a step input $r(t)$ while (1) limiting the percent overshoot and oscillatory nature of the response and (2) reducing the effect of a disturbance on the output position of the read head. The specifications are summarized in Table 5.5.

Let us consider the second-order model of the motor and arm, which neglects the effect of the coil inductance. We then have the closed-loop system shown in Figure 5.39. Then the output when $T_{d}(s)=0$ is

$$
\begin{aligned}
Y(s) & =\frac{5 K_{a}}{s(s+20)+5 K_{a}} R(s) \\
& =\frac{5 K_{a}}{s^{2}+20 s+5 K_{a}} R(s) \\
& =\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} R(s) .
\end{aligned}
$$

Therefore, $\omega_{n}^{2}=5 K_{a}$, and $2 \zeta \omega_{n}=20$. We then determine the response of the system as shown in Figure 5.40. Table 5.6 shows the performance measures for selected values of $K_{a}$.

When $K_{a}$ is increased to 60 , the effect of a disturbance is reduced by a factor of 2 . We can show this by plotting the output, $y(t)$, as a result of a unit step disturbance

\begin{tabular}{ll} 
Table 5.5 & Specifications for the Transient Response \\
Performance Measure & Desired Value \\
\hline Percent overshoot & Less than $5 \%$ \\
Settling time & Less than $250 \mathrm{~ms}$ \\
$\begin{array}{l}\text { Maximum value of response } \\
\text { to a unit step disturbance }\end{array}$ & Less than $5 \times 10^{-3}$ \\
\end{tabular}

FIGURE 5.39

Control system model with a second-order model of the motor and load.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0371.jpg?height=230&width=1179&top_left_y=1842&top_left_x=370)

FIGURE 5.40 Response of the system to a unit step input, $r(t)=1, t>0$. (a) $m$-file script. (b) Response for $K_{a}=30$ and 60 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0372.jpg?height=371&width=454&top_left_y=178&top_left_x=632)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0372.jpg?height=604&width=932&top_left_y=674&top_left_x=503)

(b)

\section{Table 5.6 Response for the Second-Order Model for a Step Input}

\begin{tabular}{llllll}
$K_{a}$ & 20 & 30 & 40 & 60 & 80 \\
\hline Percent overshoot & 0 & $1.2 \%$ & $4.3 \%$ & $10.8 \%$ & $16.3 \%$ \\
Settling time $(s)$ & 0.55 & 0.40 & 0.40 & 0.40 & 0.40 \\
Damping ratio & 1 & 0.82 & 0.707 & 0.58 & 0.50 \\
$\begin{array}{l}\text { Maximum value of the } \\
\text { response } y(t) \text { to a unit }\end{array}$ & $-10 \times 10^{-3}$ & $-6.6 \times 10^{-3}$ & $-5.2 \times 10^{-3}$ & $-3.7 \times 10^{-3}$ & $-2.9 \times 10^{-3}$ \\
disturbance & & & & & \\
\hline
\end{tabular}

input, as shown in Figure 5.41. Clearly, if we wish to meet our goals with this system, we need to select a compromise gain. In this case, we select $K_{a}=40$ as the best compromise. However, this compromise does not meet all the specifications. In the next chapter, we consider again the design process and change the configuration of the control system. FIGURE 5.41

Response of the system to a unit step disturbance, $T_{d}(s)=1 / s$.

(a) m-file script.

(b) Response for $K_{a}=30$ and 60 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0373.jpg?height=320&width=828&top_left_y=167&top_left_x=508)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0373.jpg?height=672&width=939&top_left_y=593&top_left_x=415)

(b)

\subsection{SUMMARY}

In this chapter, we have considered the definition and measurement of the performance of a feedback control system. The concept of a performance measure or index was discussed, and the usefulness of standard test signals was outlined. Then, several performance measures for a standard step input test signal were delineated. For example, the overshoot, peak time, and settling time of the response of the system under test for a step input signal were considered. The fact that the specifications on the desired response are often contradictory was noted, and the concept of a design compromise was proposed. The relationship between the location of the $s$-plane root of the system transfer function and the system response was discussed. A most important measure of system performance is the steady-state error for specific test input signals. Thus, the relationship of the steady-state error of a system in terms of the system parameters was developed by utilizing the final-value theorem. Finally, the utility of an integral performance index was outlined, and several design examples that minimized a system's performance index were completed. Thus, we have been concerned with the definition and usefulness of quantitative measures of the performance of feedback control systems. 

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 5.42 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0374.jpg?height=231&width=772&top_left_y=430&top_left_x=677)

FIGURE 5.42 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. In general, a third-order system can be approximated by a second-order system's dominant roots if the real part of the dominant roots is less than $1 / 10$ of the real part of the third root.

True or False

2. The number of zeros of the forward path transfer function at the origin is called the type number.

True or False

3. The rise time is defined as the time required for the system to settle within a certain percentage of the input amplitude.

True or False

4. For a second-order system with no zeros, the percent overshoot to a unit step is a function of the damping ratio only.

True or False

5. A type-1 system has a zero steady-state tracking error to a ramp input.

True or False Consider the closed-loop control system in Figure 5.42 for Problems 6 and 7 with

$$
L(s)=G_{c}(s) G(s)=\frac{6}{s(s+3)} .
$$

6. The steady-state error to a unit step input $R(s)=1 / s$ is:
a. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=0$
b. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=1 / 2$
c. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=1 / 6$
d. $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t)=\infty$

7. The percent overshoot of the output to a unit step input is:
a. $P . O .=9 \%$
b. $P . O .=1 \%$
c. $P . O .=20 \%$
d. No overshoot

Consider the block diagram of the control system shown in Figure 5.42 in Problems 8 and 9 with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+10)} .
$$

8. Find the value of $K$ so that the system provides an optimum ITAE response for a step input.
a. $K=1.10$
b. $K=12.56$
c. $K=51.02$
d. $K=104.7$

9. Compute the expected percent overshoot to a unit step input for the value of $K$ in Problem 8.
a. $P . O .=1.4 \%$
b. $P . O .=4.6 \%$
c. $P . O .=10.8 \%$
d. No overshoot expected

10. A system has the closed-loop transfer function $T(s)$ given by

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{2500}{(s+20)\left(s^{2}+10 s+125\right)} .
$$

Using the notion of dominant poles, estimate the expected percent overshoot.
a. $P . O . \approx 5 \%$
b. $P . O . \approx 20 \%$
c. $P . O . \approx 50 \%$
d. No overshoot expected

11. Consider the unity feedback control system in Figure 5.42 where

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+5)} .
$$

The design specifications are:

i. Peak time $T_{p} \leq 1.0$

ii. Percent overshoot P.O. $\leq 10 \%$.

With $K$ as the design parameter, it follows that
a. Both specifications can be satisfied.
b. Only the first specification $T_{p} \leq 1.0$ can be satisfied.
c. Only the second specification $P . O . \leq 10 \%$ can be satisfied.
d. Neither specification can be satisfied.

12. Consider the feedback control system in Figure 5.43 where $G(s)=\frac{K}{s+10}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0375.jpg?height=410&width=1115&top_left_y=1646&top_left_x=430)

FIGURE 5.43 Feedback system with integral controller and derivative measurement. The nominal value of $K=10$. Using a $2 \%$ criterion, compute the settling time, $T_{s}$, for a unit step disturbance, $T_{d}(s)=1 / s$, when $R(s)=0$.
a. $T_{s}=0.02 \mathrm{~s}$
b. $T_{s}=0.2 \mathrm{~s}$
c. $T_{s}=1.03 \mathrm{~s}$
d. $T_{s}=4.83 \mathrm{~s}$

13. A plant has the transfer function given by

$$
G(s)=\frac{1}{(1+s)(1+0.5 s)}
$$

and is controlled by a proportional controller $G_{c}(s)=K$, as shown in the block diagram in Figure 5.42. The value of $K$ that yields a steady-state error $E(s)=Y(s)-R(s)$ with a magnitude equal to 0.01 for a unit step input is:
a. $K=49$
b. $K=99$
c. $K=169$
d. None of the above

In Problems 14 and 15, consider the control system in Figure 5.42, where

$$
G(s)=\frac{6}{(s+5)(s+2)} \quad \text { and } \quad G_{c}(s)=\frac{K}{s+50} .
$$

14. A second-order approximate model of the loop transfer function is:
a. $\hat{G}_{c}(s) \hat{G}(s)=\frac{(3 / 25) K}{s^{2}+7 s+10}$
b. $\hat{G}_{c}(s) \hat{G}(s)=\frac{(1 / 25) K}{s^{2}+7 s+10}$
c. $\hat{G}_{c}(s) \hat{G}(s)=\frac{(3 / 25) K}{s^{2}+7 s+500}$
d. $\hat{G}_{c}(s) \hat{G}(s)=\frac{6 K}{s^{2}+7 s+10}$

15. Using the second-order system approximation (see Problem 14), estimate the gain $K$ so that the percent overshoot is approximately $P . O . \approx 15 \%$.
a. $K=10$
b. $K=300$
c. $K=1000$
d. None of the above

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.
a. Unit impulse
b. Rise time
c. Settling time

The time for a system to respond to a step input and rise to a peak response.

The roots of the characteristic equation that cause the dominant transient response of the system.

The number $N$ of poles of the transfer function, $G(s)$, at the origin. d. Type number

e. Percent overshoot

f. Position error constant, $K_{P}$

g. Velocity error constant, $K_{v}$

h. Steady-state response

i. Peak time

j. Dominant roots

k. Test input signal

1. Acceleration error constant, $K_{a}$

m. Transient response

n. Design specifications

o. Performance index

p. Optimum control system
The constant evaluated as $\lim _{s \rightarrow 0} s G(s)$.

An input signal used as a standard test of a system's ability to respond adequately.

The time required for the system output to settle within a certain percentage of the input amplitude.

A set of prescribed performance criteria.

A system whose parameters are adjusted so that the performance index reaches an extremum value.

A quantitative measure of the performance of a system.

The time for a system to respond to a step input and attain a response equal to a percentage of the magnitude of the input.

The amount by which the system output response proceeds beyond the desired response.

The constant evaluated as $\lim _{s \rightarrow 0} s^{2} G(s)$.

The constant evaluated as $\lim _{s \rightarrow 0} G(s)$.

The constituent of the system response that exists a long time following any signal initiation.

The constituent of the system response that disappears with time.

A test input consisting of an impulse of infinite amplitude and zero width, and having an area of unity.

\section{EXERCISES}

E5.1 A laser cutter is used to cut a parabolic path on sheet metal. We want to have a finite steady-state error for the laser beam positioning control system. (a) Which type of number system is required? (How many integrations?) (b) If we want to achieve a zero steady-state error, which type of number system is required?

E5.2 The engine, body, and tires of a racing vehicle affect the acceleration and speed attainable [9]. The speed control of the car is represented by the model shown in Figure E5.2. (a) Calculate the steady-state error of the car to a step command in speed. (b) Calculate overshoot of the speed to a step command.

Answer: (a) $e_{s s}=A / 11$; (b) P.O. $=36 \%$

E5.3 New passenger rail systems that could profitably compete with air travel are under development. Two of these systems, the French TGV and the Japanese Shinkansen, reach speeds of $160 \mathrm{mph}$ [17]. The Trans-rapid, a magnetic levitation train, is shown in Figure E5.3(a).

The use of magnetic levitation and electromagnetic propulsion to provide contactless vehicle

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0377.jpg?height=226&width=757&top_left_y=1352&top_left_x=861)

FIGURE E5.2 Racing car speed control.

movement makes the Transrapid technology radically different. The underside of the carriage (where the wheel trucks would be on a conventional car) wraps around a guideway. Magnets are attached to the wraparound and pull the train to the reaction rail at the bottom of the guideway.

The levitation control is represented by Figure E5.3(b). (a) Select $K$ so that the system provides an optimum ITAE response. (b) Determine the expected percent overshoot to a step input of $I(s)$.

Answer: $K=100 ; 4.6 \%$ 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0378.jpg?height=454&width=680&top_left_y=163&top_left_x=262)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0378.jpg?height=205&width=719&top_left_y=721&top_left_x=245)

(b)

FIGURE E5.3 Levitated train control. (Bernd Mellmann/ Alamy Stock Photo.)

E5.4 A feedback system with negative unity feedback has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{2(s+8)}{s(s+4)} .
$$

(a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$. (b) Find the time response, $y(t)$, for a step input $r(t)=A$ for $t>0$. (c) Determine the percent overshoot of the response. (d) Using the final-value theorem, determine the steady-state value of $y(t)$.

Answer: (b) $y(t)=1-1.07 e^{-3 t} \sin (\sqrt{7} t+1.2)$

E5.5 Consider the feedback system in Figure E5.5. Find $K$ such that the closed-loop system minimizes the ITAE performance criterion for a step input.

E5.6 Consider the block diagram shown in Figure E5.6 [16]. (a) Calculate the steady-state error for a ramp input. (b) Select a value of $K$ that will result in zero percent overshoot to a step input. Provide rapid response.
Plot the poles and zeros of this system and discuss the dominance of the complex poles. What overshoot for a step input do you expect?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0378.jpg?height=271&width=687&top_left_y=316&top_left_x=1030)

Position feedback

FIGURE E5.6 Block diagram with position and velocity feedback.

E5.7 Effective control of insulin injections can result in better lives for diabetic persons. Automatically controlled insulin injection by means of a pump and a sensor that measures blood sugar can be very effective. A pump and injection system has a feedback control as shown in Figure E5.7. Calculate the suitable gain $K$ so that the percent overshoot of the step response due to the drug injection is P.O. $=7 \% . R(s)$ is the desired blood-sugar level and $Y(s)$ is the actual blood-sugar level.

Answer: $K=1.67$

E5.8 A control system for positioning the head of a floppy disk drive has the closed-loop transfer function

$$
T(s)=\frac{0.313(s+0.8)}{(s+0.6)\left(s^{2}+4 s+5\right)} .
$$

Plot the poles and zeros of this system, and discuss the dominance of the third pole. What percent overshoot for a step input do you expect?

E5.9 A unity negative feedback control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+\sqrt{K})} .
$$

(a) Determine the percent overshoot and settling time (using a $2 \%$ settling criterion) due to a unit step input.

(b) For what range of $K$ is the settling time is approximately $T_{s} \leq 1 \mathrm{~s}$ ?
FIGURE E5.5

Feedback system with proportional controller $G_{c}(s)=K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0378.jpg?height=242&width=873&top_left_y=1878&top_left_x=537)

FIGURE E5.7

Blood-sugar level control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0379.jpg?height=346&width=1054&top_left_y=156&top_left_x=395)

E5.10 A second-order control system has the closedloop transfer function $T(s)=Y(s) / R(s)$. The system specifications for a step input follow:

1. Percent overshoot P.O. $\leq 5 \%$.

2. Settling time $T_{s}<4 \mathrm{~s}$.

3. Peak time $T_{p}<1 \mathrm{~s}$.

Show the desired region for the poles of $T(s)$ in order to achieve the desired response. Use a $2 \%$ settling criterion to determine settling time.

E5.11 A system with unity feedback is shown in Figure E5.11. Determine the steady-state error for a step and a ramp input when

$$
G(s)=\frac{10(s+5)}{s(s+2)(s+4)(s+6)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0379.jpg?height=155&width=567&top_left_y=1082&top_left_x=182)

FIGURE E5.11 Unity feedback system.

E5.12 The Ferris wheel is often featured at state fairs and carnivals. George Ferris was born in Galesburg, Illinois, in 1859; he later moved to Nevada and then graduated from Rensselaer Polytechnic Institute in 1881. By 1891, Ferris had considerable experience with iron, steel, and bridge construction. He conceived and constructed his famous wheel for the 1893 Columbian Exposition in Chicago [8]. Consider the requirement that the steady-state speed must be controlled to within $5 \%$ of the desired speed for the Ferris wheel speed control system shown in Figure E5.12.

(a) Determine the required gain $K$ to achieve the steady-state requirement. (b) For the gain of part (a), determine and plot the tracking error for a unit step disturbance. Does the speed change more than $5 \%$ ? (Set $R(s)=0$ and recall that the tracking error $E(s)=R(s)-T(s)$.)

E5.13 For the system with unity feedback shown in Figure E5.11, determine the steady-state error for a step and a ramp input when

$$
G(s)=\frac{20}{s^{2}+14 s+50} .
$$

Answer: $e_{\mathrm{ss}}=0.71$ for a step and $e_{\mathrm{ss}}=\infty$ for a ramp.

E5.14 A feedback system is shown in Figure E5.14.

(a) Determine the steady-state error for a unit step when $K=0.6$ and $G_{p}(s)=1$.

(b) Select an appropriate value for $G_{p}(s)$ so that the steady-state error is equal to zero for the unit step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0379.jpg?height=249&width=750&top_left_y=1237&top_left_x=867)

FIGURE E5.14 Feedback system.

E5.15 A closed-loop control system has a transfer function $T(s)$ as follows:

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{2500}{(s+50)\left(s^{2}+10 s+50\right)} .
$$

\section{Disturbance}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0379.jpg?height=291&width=1131&top_left_y=1823&top_left_x=394)

FIGURE E5.12

Speed control of a Ferris wheel. Plot $y(t)$ for a unit step input when (a) the actual $T(s)$ is used, and (b) using the dominant complex poles. Compare the results.

E5.16 A second-order system is

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{(10 / z)(s+z)}{(s+1)(s+8)} .
$$

Consider the case where $1<z<8$. Obtain the partial fraction expansion, and plot the output for a unit step input for $z=2,4$, and 6 .

E5.17 A closed-loop control system transfer function $T(s)$ has two dominant complex conjugate poles. Sketch the region in the left-hand $s$-plane where the complex poles should be located to meet the given specifications.
(a) $0.6 \leq \zeta \leq 0.8, \quad \omega_{n} \leq 10$
(b) $0.5 \leq \zeta \leq 0.707, \quad \omega_{n} \geq 10$
(c) $\zeta \geq 0.5, \quad 5 \leq \omega_{n} \leq 10$
(d) $\zeta \leq 0.707, \quad 5 \leq \omega_{n} \leq 10$
(c) $\zeta \geq 0.6, \quad \omega_{n} \leq 6$

E5.18 A system is shown in Figure E5.18(a). The response to a unit step, when $K=1$, is shown in Figure E5.18(b). Determine the value of $K$ so that the steady-state error is equal to zero.

Answer: $K=1.25$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0380.jpg?height=132&width=680&top_left_y=1091&top_left_x=262)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0380.jpg?height=317&width=663&top_left_y=1316&top_left_x=278)

(b)

\section{FIGURE E5.18 Feedback system with prefilter.}

E5.19 A second-order system has the closed-loop transfer function

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}}=\frac{20}{s^{2}+5.38 s+20} .
$$

(a) Estimate the percent overshoot P.O., the time to peak $T_{p}$, and the settling time $T_{s}$ of the unit step response.

(b) Obtain the system response to a unit step, and verify the results in part (a).

E5.20 Consider the closed-loop system in Figure E5.20, where

$$
L(s)=\frac{(s+2)}{\left(s^{2}+5 s\right)} K_{a} .
$$

(a) Determine the closed-loop transfer function $T(s)$ $=Y(s) / R(s)$.

(b) Determine the steady-state error of the closedloop system response to a unit ramp input.

(c) Select a value for $K_{a}$ so that the steady-state error of the system response to a unit step input is zero.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0380.jpg?height=277&width=759&top_left_y=1014&top_left_x=994)

FIGURE E5.20 Nonunity closed-loop feedback control system with parameter $K_{a}$.

\section{PROBLEMS}

P5.1 An important problem for television systems is the jumping or wobbling of the picture due to the movement of the camera. This effect occurs when the camera is mounted in a moving truck or airplane. The Dynalens system has been designed to reduce the effect of rapid scanning motion; see Figure P5.1. A maximum scanning motion of $25 \%$ is expected.
Let $K_{g}=K_{t}=1$ and assume that $\tau_{g}$ is negligible. (a) Determine the error of the system $E(s)$. (b) Determine the necessary loop gain $K_{a} K_{m} K_{t}$ when a $1 \%$ steady-state error is allowable. (c) The motor time constant is $\tau_{m}=0.40 \mathrm{~s}$. Determine the necessary loop gain so that the settling time (to within $2 \%$ of the final value of $v_{b}$ ) is $T_{s} \leq 0.03 \mathrm{~s}$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0381.jpg?height=396&width=741&top_left_y=148&top_left_x=88)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0381.jpg?height=323&width=775&top_left_y=624&top_left_x=76)

(b)

FIGURE P5.1 Camera wobble control.

P5.2 A specific closed-loop control system is to be designed for an underdamped response to a step input. The specifications for the system are as follows:

$$
\begin{gathered}
10 \%<P . O .<20 \%, \\
T_{S}<0.6 \mathrm{~s} .
\end{gathered}
$$

(a) Identify the desired area for the dominant roots of the system. (b) Determine the smallest value of a third root $r_{3}$ if the complex conjugate roots are to represent the dominant response. (c) The closed-loop system transfer function $T(s)$ is third-order, and the feedback has a unity gain. Determine the loop transfer function $G(s)=Y(s) / E(s)$ when the settling time to within $2 \%$ of the final value is $T_{s}=0.6 \mathrm{~s}$ and the percent overshoot is P.O. $=20 \%$.

P5.3 A laser beam can be used to weld, drill, etch, cut, and mark metals, as shown in Figure P5.3(a) [14]. Assume we have a work requirement for an accurate laser to mark a linear path with a closed-loop control system, as shown in Figure P5.3(b). Calculate the necessary gains $K$ and $K_{1}$ to result in a steady-state error of $5 \mathrm{~mm}$ for $r(t)=t \mathrm{~mm}$.

P5.4 The loop transfer function of a unity negative feedback system

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+4)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0381.jpg?height=496&width=532&top_left_y=154&top_left_x=976)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0381.jpg?height=174&width=614&top_left_y=746&top_left_x=935)

(b)

FIGURE P5.3 Laser beam control.

A system response to a step input is specified as follows:

$$
\begin{aligned}
T_{p} & =0.25 \mathrm{~s}, \\
\text { P.O. } & =10 \% .
\end{aligned}
$$

(a) Determine whether both specifications can be met simultaneously. (b) If the specifications cannot be met simultaneously, determine a compromise value for $K$ so that the peak time and percent overshoot specifications are relaxed by the same percentage.

P5.5 A space telescope is to be launched to carry out astronomical experiments [8]. The pointing control system is desired to achieve 0.01 minute of arc and track solar objects with apparent motion up to 0.21 arc minute per second. The system is illustrated in Figure P5.5(a). The control system is shown in Figure P5.5(b). Assume that $\tau_{1}=1 \mathrm{~s}$ and $\tau_{2}=0$. (a) Determine the gain $K=K_{1} K_{2}$ required so that the response to a unit step command is as rapid as reasonable with a percent overshoot of P.O. $\leq 5 \%$. (b) Determine the steadystate error of the system for a step and a ramp input.

P5.6 A robot is programmed to have a tool or welding torch follow a prescribed path [7,11]. Consider a robot tool that is to follow a sawtooth path, as shown in Figure P5.6(a). The loop transfer function of the plant is

$$
L(s)=G_{c}(s) G(s)=\frac{20(s+2)}{s(s+1)(s+4)}
$$

FIGURE P5.5

(a) The space telescope. (b) The space telescope pointing control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0382.jpg?height=696&width=1232&top_left_y=151&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0382.jpg?height=233&width=948&top_left_y=951&top_left_x=674)

(1)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0382.jpg?height=287&width=566&top_left_y=1261&top_left_x=639)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0382.jpg?height=167&width=838&top_left_y=1652&top_left_x=517)

(b)

FIGURE P5.6

Robot path control. in Figure P5.7(b). The moment of inertia of the equipment and astronaut is $I=25 \mathrm{~kg} \mathrm{~m}^{2}$. (a) Determine the necessary gain $K_{3}$ to maintain a steady-state error equal to $1 \mathrm{~cm}$ when the input is a unit ramp. (b) With this gain $K_{3}$, determine the necessary gain $K_{1} K_{2}$ in order to restrict the percent overshoot to P.O. $\leq 10 \%$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0383.jpg?height=524&width=640&top_left_y=159&top_left_x=677)

(a)

FIGURE P5.7

(a) Astronaut Bruce McCandless II is shown a few meters away from the Earth-orbiting space shuttle. He used a nitrogenpropelled hand-controlled device called the manned maneuvering unit. (Courtesy of NASA.) (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0383.jpg?height=409&width=1246&top_left_y=774&top_left_x=372)

(b)
P5.8 Photovoltaic arrays generate a DC voltage that can be used to drive DC motors or that can be converted to $\mathrm{AC}$ power and added to the distribution network. It is desirable to maintain the power out of the array at its maximum available as the solar incidence changes during the day. One such closed-loop system is shown in Figure P5.8. The transfer function for the process is

$$
G(s)=\frac{K}{s+40},
$$

where $K=40$. (a) Compute the closed-loop transfer function, and (b) determine the settling time to within $2 \%$ of the final value of the system to a unit step disturbance.

P5.9 Antennas that receive and transmit signals to communication satellites generally include an extremely large horn antenna. The microwave antenna can be $175 \mathrm{ft}$ long and weigh 340 tons. A photo of an antenna is shown in Figure P5.9. Suppose that the communication satellite is $3 \mathrm{ft}$ in diameter and moves at about

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0383.jpg?height=383&width=1023&top_left_y=1728&top_left_x=373)

$16,000 \mathrm{mph}$ at an altitude of 2500 miles. The antenna must be positioned accurately to $0.1^{\circ}$ because the microwave beam is $0.2^{\circ}$ wide and highly attenuated by the large distance. If the antenna is following the moving satellite, determine the Kv necessary for the system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0384.jpg?height=512&width=720&top_left_y=379&top_left_x=242)

FIGURE P5.9 A large antenna receives and transmits signals to a communication satellite. (Gary Woods/Alamy Stock Photo.)

P5.10 A speed control system of an armature-controlled DC motor uses the back emf voltage of the motor as a feedback signal. (a) Draw the block diagram of this system (see Example 2.5). (b) Calculate the steady-state error of this system to a step input command setting the speed to a new level. Assume that $R_{a}=L_{a}=J=b=1$, the motor constant is $K_{m}=1$, and $K_{b}=1$. (c) Select a feedback gain for the back emf signal to yield a step response with a percent overshoot of P.O. $=15 \%$.

P5.11 A unity feedback control system has a process transfer function

$$
\frac{Y(s)}{E(s)}=G(s)=\frac{K}{s} .
$$

The system input is a step function with an amplitude $A$. The initial condition of the system at time $t_{0}$ is $y\left(t_{0}\right)=Q$, where $y(t)$ is the output of the system. The performance index is defined as

$$
I=\int_{0}^{\infty} e^{2}(t) d t
$$

(a) Show that $I=(A-Q)^{2} /(2 K)$. (b) Determine the gain $K$ that will minimize the performance index $I$. Is this gain a practical value? (c) Select a practical value of gain and determine the resulting value of the performance index.
P5.12 Train travel between cities will increase as trains are developed that travel at high speeds, making the travel time from city center to city center equivalent to airline travel time. The Japanese National Railway has a train called the Shinkansen train that travels an average speed of $320 \mathrm{~km} / \mathrm{hr}$ [17]. To maintain a desired speed, a speed control system is proposed that yields a zero steady-state error to a ramp input. A third-order system is sufficient. Determine the optimum system transfer function $T(s)$ for an ITAE performance criterion. Estimate the settling time (with a $2 \%$ criterion) and percent overshoot for a step input when $\omega_{n}=10$.

P5.13 We want to approximate a fourth-order system by a lower-order model. The transfer function of the original system is

$$
\begin{aligned}
G_{H}(s) & =\frac{s^{3}+7 s^{2}+24 s+24}{s^{4}+10 s^{3}+35 s^{2}+50 s+24} \\
& =\frac{s^{3}+7 s^{2}+24 s+24}{(s+1)(s+2)(s+3)(s+4)} .
\end{aligned}
$$

Show that if we obtain a second-order model by the method of Section 5.8, and we do not specify the poles and the zero of $G_{L}(s)$, we have

$$
\begin{aligned}
G_{L}(s) & =\frac{0.2917 s+1}{0.399 s^{2}+1.375 s+1} \\
& =\frac{0.731(s+3.428)}{(s+1.043)(s+2.4)} .
\end{aligned}
$$

P5.14 For the original system of Problem P5.13, we want to find the lower-order model when the poles of the second-order model are specified as -1 and -2 and the model has one unspecified zero. Show that this low-order model is

$$
G_{L}(s)=\frac{0.986 s+2}{s^{2}+3 s+2}=\frac{0.986(s+2.028)}{(s+1)(s+2)} .
$$

P5.15 Consider a unity feedback system with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+3)}{(s+5)\left(s^{2}+4 s+10\right)} .
$$

Determine the value of the gain $K$ such that the percent overshoot to a unit step is minimized.

P5.16 A magnetic amplifier with a low-output impedance is shown in Figure P5.16 in cascade with a low-pass filter and a preamplifier. The amplifier has a high-input impedance and a gain of 1 and is used for adding the signals as shown. Select a value for the capacitance $C$ so that the transfer function $V_{0}(s) / V_{\text {in }}(s)$ has a damping ratio of $1 / \sqrt{2}$. The time constant of the magnetic amplifier is equal to 1 second, and the gain is $K=10$. Calculate the settling time (with a $2 \%$ criterion) of the resulting system. FIGURE P5.16

Feedback amplifier.

FIGURE P5.17

Heart pacemaker.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0385.jpg?height=782&width=1056&top_left_y=153&top_left_x=373)

P5.17 Electronic pacemakers for human hearts regulate the speed of the heart pump. A proposed closed-loop system that includes a pacemaker and the measurement of the heart rate is shown in Figure P5.17 $[2,3]$. The transfer function of the heart pump and the pacemaker is found to be

$$
G(s)=\frac{K}{s(s / 12+1)} .
$$

Design the amplifier gain to yield a system with a settling time to a step disturbance of less than 1 second. The percent overshoot to a step in desired heart rate should be P.O. $\leq 10 \%$. (a) Find a suitable range of $K$. (b) If the nominal value of $K$ is $K=10$, find the sensitivity of the system to small changes in $K$. (c) Evaluate the sensitivity of part (b) at $D C$ (set $s=0$ ). (d) Evaluate the magnitude of the sensitivity at the normal heart rate of 60 beats/minute.

P5.18 Consider the third-order system

$$
G(s)=\frac{1}{s^{3}+5 s^{2}+10 s+1} .
$$

Determine a first-order model with one pole unspecified and no zeros that will represent the third-order system.

P5.19 A closed-loop control system with negative unity feedback has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{8}{s\left(s^{2}+6 s+12\right)} .
$$

(a) Determine the closed-loop transfer function $T(s)$.

(b) Determine a second-order approximation for $T(s)$.

(c) Plot the response of $T(s)$ and the second-order approximation to a unit step input and compare the results.
P5.20 A system is shown in Figure P5.20.

(a) Determine the steady-state error for a unit step input in terms of $K$ and $K_{1}$, where $E(s)=R(s)-Y(s)$.

(b) Select $K_{1}$, so that the steady-state error is zero.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0385.jpg?height=183&width=758&top_left_y=1216&top_left_x=858)

FIGURE P5.20 System with pregain, $K_{1}$.

P5.21 Consider the closed-loop system in Figure P5.21. Determine values of the parameters $k$ and $a$ so that the following specifications are satisfied:

(a) The steady-state error to a unit step input is zero.

(b) The closed-loop system has a percent overshoot of P.O. $\leq 5 \%$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0385.jpg?height=249&width=637&top_left_y=1795&top_left_x=980)

FIGURE P5.21 Closed-loop system with parameters $k$ and $a$. P5.22 Consider the closed-loop system in Figure P5.22, where

$$
G_{c}(s) G(s)=\frac{2}{s+0.2 K} \quad \text { and } \quad H(s)=\frac{2}{2 s+\tau} .
$$

(a) If $\tau=2.43$, determine the value of $K$ such that the steady-state error of the closed-loop system response to a unit step input, is zero.

(b) Determine the percent overshoot and the time to peak of the unit step response when $K$ is as in part (a).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0386.jpg?height=263&width=758&top_left_y=165&top_left_x=997)

FIGURE P5.22 Nonunity closed-loop feedback control system.

\section{ADVANCED PROBLEMS}

AP5.1 Consider the following closed-loop transfer functions

$$
T_{1}(s)=\frac{10(s+1)}{(s+5)\left(s^{2}+2 s+2\right)}
$$

and

$$
T_{2}(s)=\frac{s+10}{(s+5)\left(s^{2}+2 s+2\right)} .
$$

(a) Determine the steady-state error for a unit step input.

(b) Assume that the complex poles dominate, and determine the percent overshoot and settling time to within $2 \%$ of the final value.

(c) Plot the actual system response, and compare it with the estimates of part (b).

AP5.2 A closed-loop system is shown in Figure AP5.2. process.

Plot the response to a unit step input for the system for $\tau_{z}=0,0.05,0.1$, and 0.5 . Record the percent overshoot, rise time, and settling time (with a $2 \%$ criterion) as $\tau_{z}$ varies. Describe the effect of varying $\tau_{z}$. Compare the location of the zero $-1 / \tau_{z}$ with the location of the closed-loop poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0386.jpg?height=189&width=722&top_left_y=1519&top_left_x=241)

FIGURE AP5.2 System with a variable zero.
AP5.3 A closed-loop system is shown in Figure AP5.3. Plot the response to a unit step input for the system with $\tau_{p}=0,0.2,1$, and 4 . Record the percent overshoot, rise time, and settling time (with a $2 \%$ criterion) as $\tau_{p}$ varies. Describe the effect of varying $\tau_{p}$. Compare the location of the open-loop pole $-1 / \tau_{p}$ with the location of the closed-loop poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0386.jpg?height=181&width=722&top_left_y=982&top_left_x=1013)

FIGURE AP5.3 System with a variable pole in the

AP5.4 The speed control of a high-speed train is represented by the system shown in Figure AP5.4 [17]. Determine the equation for steady-state error for $K$ for a unit step input. Consider the three values for $K$ equal to 1,10 , and 100 .

(a) Determine the steady-state error.

(b) Determine and plot the response $y(t)$ for (i) a unit step input $R(s)=1 / s$ and (ii) a unit step disturbance input $T_{d}(s)=1 / s$.

(c) Create a table showing percent overshoot, settling time (with a $2 \%$ criterion), $e_{\mathrm{ss}}$ for $r(t)$, and $\left|y / t_{d}\right|_{\max }$ for the three values of $K$. Select the best compromise value.

FIGURE AP5.4

Speed control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0386.jpg?height=330&width=999&top_left_y=1813&top_left_x=505)

FIGURE AP5.5

System with control parameter $\alpha$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0387.jpg?height=742&width=1092&top_left_y=149&top_left_x=372)

FIGURE AP5.6

DC motor control.

(a) Assume that the complex poles dominate, and estimate the settling time and percent overshoot to a unit step input for $K=1,10,25$, and 50 .

AP5.5 A system with a controller is shown in Figure AP5.5. The zero of the controller may be varied.

(a) Determine the steady-state error for a unit step input for $\alpha=0$ and $\alpha \neq 0$.

(b) Let $\alpha=1,15$, and 75. Plot the response of the system to a unit step input disturbance for the three values of $\alpha$. Compare the results, and select the best value of the three values of $\alpha$.

AP5.6 The block diagram model of an armature-current controlled DC motor is shown in Figure AP5.6.

(a) Determine the steady-state tracking error to a ramp input in terms of $K, K_{b}$, and $K_{m}$.

(b) Let $K_{m}=12$ and $K_{b}=0.01$, and select $K$ so that steady-state tracking error is equal to 1 .

(c) Plot the response to a unit step input and a unit ramp input for 30 seconds. Are the responses acceptable?

AP5.7 Consider the closed-loop system in Figure AP5.7 with transfer functions

$$
G_{c}(s)=K \text { and } \quad G(s)=\frac{1}{(s+5)\left(s^{2}+2 s+1\right)} .
$$

(b) Determine the actual settling time and percent overshoot to a unit step for the values of $K$ in part (a).

(c) Co-plot the results of (a) and (b) and comment.

AP5.8 A unity negative feedback system has an open loop transfer function

$$
G(s)=\frac{K}{s^{2}+8 s} .
$$

Determine the gain $K$ that results in the fastest response without overshoot. What are the corresponding poles?
FIGURE AP5.7

Closed-loop system with unity feedback.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0387.jpg?height=242&width=870&top_left_y=1878&top_left_x=393)

FIGURE AP5.9

Feedback control system with a proportional plus integral controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0388.jpg?height=237&width=985&top_left_y=152&top_left_x=540)

The controller is a proportional plus integral controller with gains $K_{p}$ and $K_{I}$. The objective is to design the controller gains such that the dominant roots have a damping ratio $\zeta$ equal to 0.707 . Determine the resulting peak time and settling time (with a $2 \%$ criterion) of the system to a unit step input.

\section{DESIGN PROBLEMS}

CDP5.1 The capstan drive system of the previous problems (see CDP1.1-CDP4.1) has a disturbance due to changes in the part that is being machined as material is removed. The controller is an amplifier $G_{c}(s)=K_{a}$. Evaluate the effect of a unit step disturbance, and determine the best value of the amplifier gain so that the percent overshoot to a step command $r(t)=A, t>0$ is $P . O . \leq 5 \%$, while reducing the effect of the disturbance as much as possible.

DP5.1 The roll control autopilot of an aircraft is shown in Figure DP5.1. The goal is to select a suitable $K$ so that the response to a step command $\phi_{d}(t)=A, t \geq 0$, will provide a response $\phi(t)$ that is a fast response and has an percent overshoot of P.O. $\leq 20 \%$. (a) Determine the closed-loop transfer function $\phi(s) / \phi_{d}(s)$. (b) Determine the roots of the characteristic equation for $K=0.7,3$, and 6. (c) Using the concept of dominant roots, find the expected percent overshoot and peak time for the approximate second-order system. (d) Plot the actual response and compare with the approximate results of part (c). (e) Select the gain $K$ so that the percent overshoot is $P . O .=16 \%$. What is the resulting peak time?

DP5.2 The design of the control for a welding arm with a long reach requires the careful selection of the parameters [13]. The system is shown in Figure DP5.2. The damping ratio $\zeta$, the gain $K$, and the natural frequency $\omega_{n}$ can be selected. (a) Determine $K$, and $\omega_{n}$ so that the response to a unit step input achieves $T_{p} \leq 1 \mathrm{~s}$ and P.O. $\leq 10 \%$. (b) Plot the response of the system designed in part (a) to a step input.
FIGURE DP5.1

Roll angle control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0388.jpg?height=664&width=1020&top_left_y=1450&top_left_x=508)

FIGURE DP5.2 Welding tip position control. FIGURE DP5.3

Active suspension system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0389.jpg?height=277&width=945&top_left_y=153&top_left_x=372)

DP5.3 Active suspension systems for modern automobiles provide a comfortable firm ride. The design of an active suspension system adjusts the valves of the shock absorber so that the ride fits the conditions. A small electric motor, as shown in Figure DP5.3, changes the valve settings [13]. The controller is a proportional plus integral controller with gains $K_{P}$ and $K_{I}$. Select a design value for $K_{P}, K_{I}$, and the parameter $q$ in order to satisfy the ITAE performance for a step command $R(s)$ with a natural frequency, $\omega_{n}=1 \mathrm{rad} / \mathrm{s}$. Upon completion of your design, assuming that the complex poles dominate, determine the natural frequency of the system for a step input.

DP5.4 The space satellite, as shown in Figure DP5.4 (a), uses a control system to readjust its orientation, as shown in Figure DP5.4 (b).

(a) Determine a second-order model for the closedloop system.

(b) Using the second-order model, select a gain $K$ so that the percent overshoot is $\leq 10 \%$, and the steady-state error to a step is less than $8 \%$. (c) Verify your design by determining the actual performance of the third-order system.

DP5.5 A deburring robot can be used to smooth off machined parts by following a preplanned path (input command signal). In practice, errors occur due to robot inaccuracy, machining errors, large tolerances, and tool wear. These errors can be eliminated using force feedback to modify the path online $[8,11]$.

While force control has been able to address the problem of accuracy, it has been more difficult to solve the contact stability problem. In fact, by closing the force loop and introducing a compliant wrist force sensor (the most common type of force control), one can add to the stability problem.

A model of a robot deburring system is shown in Figure DP5.5. Determine the region of stability for the system for $K_{1}$ and $K_{2}$. Assume both adjustable gains are greater than zero.

DP5.6 The model for a position control system using a DC motor is shown in Figure DP5.6. The goal is to select $K_{1}$ and $K_{2}$ so that the peak time is $T_{p} \leq 0.7 \mathrm{~s}$,
FIGURE DP5.4

Control of a space satellite.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0389.jpg?height=390&width=928&top_left_y=1355&top_left_x=580)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0389.jpg?height=213&width=930&top_left_y=1841&top_left_x=579)

(b) FIGURE DP5.5 Deburring robot.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0390.jpg?height=964&width=1076&top_left_y=150&top_left_x=506)

FIGURE DP5.6

Position control robot.

and the percent overshoot for a step input is $\leq 5 \%$.

DP5.7 A three-dimensional cam for generating a function of two variables is shown in Figure DP5.7(a). Both $x$ and $y$ may be controlled using a position control system [31]. The control of $x$ may be achieved with a DC motor and position feedback of the form shown in Figure DP5.7(b), with the DC motor and load represented by

$$
G(s)=\frac{K}{s(s+p)(s+4)},
$$

where $K=2$ and $p=2$. Design a proportional plus derivative controller

$$
G_{c}(s)=K_{p}+K_{D} s
$$

to achieve a percent overshoot $P . O . \leq 5 \%$ to a unit step input and a settling time $T_{s} \leq 2 \mathrm{~s}$.

DP5.8 Computer control of a robot to spray-paint an automobile is accomplished by the system shown in Figure DP5.8(a) [7]. We wish to investigate the system when $K=1,10$, and 20 . The feedback control
FIGURE DP5.7

(a) Threedimensional cam and (b) $\mathrm{x}$-axis control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0390.jpg?height=487&width=642&top_left_y=1619&top_left_x=483)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0390.jpg?height=170&width=638&top_left_y=1900&top_left_x=1149)

(b) FIGURE DP5.8

Spray-paint robot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0391.jpg?height=468&width=1242&top_left_y=152&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0391.jpg?height=344&width=1021&top_left_y=696&top_left_x=489)

(b) block diagram is shown in Figure DP5.8(b). (a) For the three values of $K$, determine the percent overshoot, the settling time (with a $2 \%$ criterion), and the steadystate error for a unit step input. Record your results in a table. (b) Choose one of the three values of $K$ that provides acceptable performance. (c) For the value selected in part (b), determine the output for a disturbance $T_{d}(s)=1 / s$ when $R(s)=0$.

\section{COMPUTER PROBLEMS}

CP5.1 Consider the closed-loop transfer function

$$
T(s)=\frac{35}{s^{2}+12 s+35} .
$$

Obtain the impulse response analytically, and compare the result to one obtained using the impulse function.

CP5.2 A unity negative feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{2 s+8}{s^{2}\left(s^{2}+5 s+20\right)} .
$$

Using Isim, obtain the response of the closed-loop system to a unit ramp input,

$$
R(s)=1 / s^{2} .
$$

Consider the time interval $0 \leq t \leq 50$. What is the steady-state error?
CP5.3 A working knowledge of the relationship between the pole locations of a second-order system and the transient response is important in control design. With that in mind, consider the following five pole location cases:

(a) $s_{1,2}= \pm j$

(b) $s_{1,2}=-1,-1$

(c) $s_{1,2}=-1,-2$,

(d) $s_{1,2}=-1 \pm j$

(e) $s_{1,2}=1 \pm j$.

Using the impulse and subplot functions, create a plot containing two subplots, with each subplot depicting the pole location and impulse response of each of the five cases listed. Discuss the results. FIGURE CP5.4

Step response of a simple secondorder system.

FIGURE CP5.5

Feedback control system with controller and prefilter.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0392.jpg?height=986&width=1176&top_left_y=152&top_left_x=516)

CP5.4 Consider the unit step response of the simple second-order closed-loop control system shown in Figure CP5.4.

(a) Determine analytically the damping ratio $\xi$ and natural frequency $\omega_{n}$ of the closed-loop system response to a unit step input, and the corresponding closed-loop system transfer function.

(b) Develop an m-file to plot the unit step response of the closed-loop system in (a), and estimate the percent overshoot from the plot. Compare the plot with the step response in Figure CP5.4, and discuss the results.

CP5.5 Consider the feedback system in Figure CP5.5. Develop an m-file to design a controller and prefilter

$$
G_{c}(s)=K \frac{s+z}{s+p} \quad \text { and } \quad G_{p}(s)=\frac{K_{p}}{s+\tau}
$$

such that the ITAE performance criterion is minimized. For $\omega_{n}=0.45$ and $\zeta=0.59$,plot the unit step response and determine the percent overshoot and settling time.

CP5.6 The closed-loop transfer function of a simple second-order system is

$$
\frac{\omega_{n}^{2}}{s^{2}+2 \xi \omega_{n} s+\omega_{n}^{2}} .
$$

Consider the following cases:

1. $\omega_{n}=1, \xi=0.5$,

2. $\omega_{n}=2, \xi=0.5$,
3. $\omega_{n}=3, \xi=0.5$,

4. $\omega_{n}=4, \xi=0.5$,

Develop an m-file to plot the unit step response, and determine the values of peak overshoot $M_{p}$, time to peak $T_{p}$, and settling time $T_{s}$ (with a $2 \%$ criterion) for each of the four cases listed. Discuss the results.

CP5.7 An autopilot designed to hold an aircraft in straight and level flight is shown in Figure CP5.7.

(a) Suppose the controller is a constant gain controller given by $G_{c}(s)=5$. Using the Isim function, compute and plot the ramp response for $\theta_{d}(t)=a t$, where $a=1.5^{\circ} / \mathrm{s}$. Determine the attitude error after 10 seconds.

(b) If we increase the complexity of the controller, we can reduce the steady-state tracking error. With this objective in mind, suppose we replace the constant gain controller with the more sophisticated controller

$$
G_{c}(s)=K_{1}+\frac{K_{2}}{s}=3+\frac{0.8}{s} .
$$

This type of controller is known as a proportional plus integral (PI) controller. Repeat the simulation of part (a) with the PI controller, and compare the steady-state tracking errors of the constant gain controller versus the PI controller. FIGURE CP5.7

An aircraft autopilot block diagram.

FIGURE CP5.8

A missile rate loop autopilot.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0393.jpg?height=478&width=1268&top_left_y=154&top_left_x=373)

CP5.8 The block diagram of a rate loop for a missile autopilot is shown in Figure CP5.8. Using the analytic formulas for second-order systems, predict $M_{p t}, T_{p}$, and $T_{s}$ for the closed-loop system due to a unit step input. Compare the predicted results with the actual unit step response obtained with the step function. Explain any differences.

CP5.9 Develop an $m$-file that can be used to analyze the closed-loop system in Figure CP5.9. Drive the system with a step input, and display the output on a graph. What is the settling time and the percent overshoot?

CP5.10 Develop an $\mathrm{m}$-file to simulate the response of the system in Figure CP5.10 to a parabolic input $R(s)=1 / s^{3}$. What is the steady-state error? Display the output on an $\mathrm{x}-\mathrm{y}$ graph.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0393.jpg?height=249&width=666&top_left_y=1270&top_left_x=128)

FIGURE CP5.9 Nonunity feedback system.
CP5.11 A closed-loop transfer function is given by

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{1}{\left(s^{2}+s\right)} .
$$

(a) Obtain the response of the closed-loop transfer function $T(s)=Y(s) / R(s)$ to a unit step input.

(b) By consecutively adding zeros at $0,-0.5,-1.5$, and -2.5 , determine the step response. Compare the results with the step response in part (a). What conclusions can be drawn regarding the effect of adding a zero to a second-order system?

CP5.12 A closed-loop transfer function is given by

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{12(s+3)}{(s+10)\left(s^{2}+6 s+45\right)} .
$$

(a) Obtain the response of the closed-loop transfer function $T(s)=Y(s) / R(s)$ to a unit step input. What is the settling time $T_{s}$ (use a $2 \%$ criterion) and percent overshoot P.O.?

(b) Neglecting the real pole at $s=-10$, determine the settling time $T_{s}$ and percent overshoot P.O. Compare the results with the actual system response in part (a). What conclusions can be drawn regarding neglecting the pole?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0393.jpg?height=188&width=906&top_left_y=1658&top_left_x=107)

FIGURE CP5.10 Closed-loop system for m-file. 

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) False; (3) False; (4) True; (5) False

Multiple Choice: (6) a; (7) a; (8) c; (9) b; (10) b; (11) a; (12) b; (13) b; (14) a; (15) b
Word Match (in order, top to bottom): i, j, d, g, k, c, n, $\mathrm{p}, \mathrm{o}, \mathrm{b}, \mathrm{e}, \mathrm{l}, \mathrm{f}, \mathrm{h}, \mathrm{m}, \mathrm{a}$

\section{TERMS AND CONCEPTS}

Acceleration error constant, $\boldsymbol{K}_{\boldsymbol{a}}$ The constant evaluated as $\lim \left[s^{2} G_{c}(s) G(s)\right]$. The steady-state error for a parabolic input, $r(t)=A t^{2} / 2$, is equal to $A / K_{a}$.

Design specifications A set of prescribed performance criteria.

Dominant roots The roots of the characteristic equation that cause the dominant transient response of the system.

Optimum control system A system whose parameters are adjusted so that the performance index reaches an extremum value.

Peak time The time for a system to respond to a step input and rise to a peak response.

Percent overshoot The amount by which the system output response proceeds beyond the desired response.

Performance index A quantitative measure of the performance of a system.

Position error constant, $\boldsymbol{K}_{\boldsymbol{p}}$ The constant evaluated as $\lim _{s \rightarrow 0} G_{c}(s) G(s)$. The steady-state error for a step input (of magnitude $A$ ) is equal to $A /\left(1+K_{p}\right)$.

Rise time The time for a system to respond to a step input and attain a response equal to a percentage of the magnitude of the input. The $0-100 \%$ rise time,
$T_{r}$, measures the time to $100 \%$ of the magnitude of the input. Alternatively, $T_{r_{1}}$ measures the time from $10 \%$ to $90 \%$ of the response to the step input.

Settling time The time required for the system output to settle within a certain percentage of the input amplitude.

Steady-state response The constituent of the system response that exists a long time following any signal initiation.

Test input signal An input signal used as a standard test of a system's ability to respond adequately.

Transient response The constituent of the system response that disappears with time.

Type number The number $N$ of poles of the transfer function, $G_{c}(s) G(s)$, at the origin. $G_{c}(s) G(s)$ is the loop transfer function.

Unit impulse A test input consisting of an impulse of infinite amplitude and zero width, and having an area of unity. The unit impulse is used to determine the impulse response.

Velocity error constant, $\mathbf{K}_{v}$ The constant evaluated as $\lim _{s \rightarrow 0}\left[G_{c}(s) G(s)\right]$. The steady-state error for a ramp input (of slope $A$ ) for a system is equal to $A / K_{v}$. 

\section{CHAPTER \\ The Stability of Linear Feedback Systems}
6.1 The Concept of Stability 395
6.2 The Routh-Hurwitz Stability Criterion 399
6.3 The Relative Stability of Feedback Control Systems 407
6.4 The Stability of State Variable Systems 408
6.5 Design Examples 411
6.6 System Stability Using Control Design Software 419
6.7 Sequential Design Example: Disk Drive Read System 425
6.8 Summary $\quad 427$

\section{PREVIEW}

Stability of closed-loop feedback systems is central to control system design. A stable system should exhibit a bounded output if the input is bounded. This is known as bounded-input, bounded-output stability. The stability of a feedback system is directly related to the location of the roots of the characteristic equation of the system transfer function and to the location of the eigenvalues of the system matrix for a system in state variable format. The Routh-Hurwitz method is introduced as a useful tool for assessing system stability. The technique allows us to compute the number of roots of the characteristic equation in the right half plane without actually computing the values of the roots. This gives us a design method for determining values of certain system parameters that will lead to closed-loop stability. For stable systems, we will introduce the notion of relative stability which allows us to characterize the degree of stability. The chapter concludes with a stabilizing controller design based on the Routh-Hurwitz method for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 6, students should be able to:

$\square$ Explain the concept of stability of dynamic systems.

- Describe the key concepts of absolute and relative stability.

$\square$ Explain bounded-input, bounded-output stability.

$\square \quad$ Describe the relationship of the $s$-plane pole locations (for transfer function models) and of the eigenvalue locations (for state variable models) to system stability.

$\square$ Construct a Routh array and employ the Routh-Hurwitz stability criterion to determine stability. 

\subsection{THE CONCEPT OF STABILITY}

When considering the design and analysis of feedback control systems, stability is of the utmost importance. From a practical point of view, a closed-loop feedback system that is unstable is of minimal value. As with all such general statements, there are exceptions; but for our purposes, we will declare that all our control designs must result in a closed-loop stable system. Many physical systems are inherently open-loop unstable, and some systems are even designed to be open-loop unstable. Most modern fighter aircraft are open-loop unstable by design, and without active feedback control assisting the pilot, they cannot fly. Active control is introduced by engineers to stabilize the unstable system - that is, the aircraft - so that other considerations, such as transient performance, can be addressed. Using feedback, we can stabilize unstable systems and then with a judicious selection of controller parameters, we can adjust the transient performance. For open-loop stable systems, we still use feedback to adjust the closed-loop performance to meet the design specifications. These specifications take the form of steady-state tracking errors, percent overshoot, settling time, time to peak, and the other indices.

We can say that a closed-loop feedback system is either stable or it is not stable. This type of stable/not stable characterization is referred to as absolute stability. A system possessing absolute stability is called a stable system-the label of absolute is dropped. Given that a closed-loop system is stable, we can further characterize the degree of stability. This is referred to as relative stability. The pioneers of aircraft design were familiar with the notion of relative stability - the more stable an aircraft was, the more difficult it was to maneuver (that is, to turn). One outcome of the relative instability of modern acrobatic aircraft is high maneuverability. A acrobatic aircraft is less stable than a commercial transport; hence it can maneuver more quickly. As we will discuss later in this section, we can determine that a system is stable (in the absolute sense) by determining that all transfer function poles lie in the left-half $s$-plane, or equivalently, that all the eigenvalues of the system matrix A lie in the left-half $s$-plane. Given that all the poles (or eigenvalues) are in the left-half $s$-plane, we investigate relative-stability by examining the relative locations of the poles (or eigenvalues).

A stable system is defined as a system with a bounded (limited) system response. That is, if the system is subjected to a bounded input or disturbance and the response is bounded in magnitude, the system is said to be stable.

\section{A stable system is a dynamic system with a bounded response to a bounded input.}

The concept of stability can be illustrated by considering a right circular cone placed on a plane horizontal surface. If the cone is resting on its base and is tipped slightly, it returns to its original equilibrium position. This position and response are said to be stable. If the cone rests on its side and is displaced slightly, it rolls with no tendency to leave the position on its side. This position is designated as the neutral stability. FIGURE 6.1

Illustration of stability.

FIGURE 6.2

Stability in the s-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0397.jpg?height=256&width=774&top_left_y=152&top_left_x=373)
(a) Stable
(b) Neutral
(c) Unstable

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0397.jpg?height=304&width=931&top_left_y=516&top_left_x=372)

On the other hand, if the cone is placed on its tip and released, it falls onto its side. This position is said to be unstable. These three positions are illustrated in Figure 6.1.

The stability of a dynamic system is defined in a similar manner. The response to a displacement, or initial condition, will result in either a decreasing, neutral, or increasing response. Specifically, it follows from the definition of stability that a linear system is stable if and only if the absolute value of its impulse response $g(t)$, integrated over an infinite range, is finite. That is, in terms of the convolution integral Equation (5.2) for a bounded input, $\int_{0}^{\infty}|g(t)| d t$ must be finite.

The location in the $s$-plane of the poles of a system indicates the resulting transient response. The poles in the left-hand portion of the s-plane result in a decreasing response for disturbance inputs. Similarly, poles on the $j \omega$-axis and in the right-hand plane result in a neutral and an increasing response, respectively, for a disturbance input. This division of the $s$-plane is shown in Figure 6.2. Clearly, the poles of desirable dynamic systems must lie in the left-hand portion of the s-plane [1-3].

A common example of the potential destabilizing effect of feedback is that of feedback in audio amplifier and speaker systems used for public address in auditoriums. In this case, a loudspeaker produces an audio signal that is an amplified version of the sounds picked up by a microphone. In addition to other audio inputs, the sound coming from the speaker itself may be sensed by the microphone. The strength of this particular signal depends upon the distance between the loudspeaker and the microphone. Because of the attenuating properties of air, a larger distance will cause a weaker signal to reach the microphone. Due to the finite propagation speed of sound waves, there will also be a time delay between the signal produced by the loudspeaker and the signal sensed by the microphone. In this case, the output from the feedback path is added to the external input. This is an example of positive feedback.

As the distance between the loudspeaker and the microphone decreases, we find that if the microphone is placed too close to the speaker, then the system will be unstable. The result of this instability is an excessive amplification and distortion of audio signals and an oscillatory squeal. In terms of linear systems, we recognize that the stability requirement may be defined in terms of the location of the poles of the closed-loop transfer function. A closed-loop system transfer function can be written as

$$
T(s)=\frac{p(s)}{q(s)}=\frac{K \prod_{i=1}^{M}\left(s+z_{i}\right)}{s^{N} \prod_{k=1}^{Q}\left(s+\sigma_{k}\right) \prod_{m=1}^{R}\left[s^{2}+2 \alpha_{m} s+\left(\alpha_{m}^{2}+\omega_{m}^{2}\right)\right]},
$$

where $q(s)=\Delta(s)=0$ is the characteristic equation whose roots are the poles of the closed-loop system. The output response for an impulse function input (when $N=0)$ is then

$$
y(t)=\sum_{k=1}^{Q} A_{k} e^{-\sigma_{k} t}+\sum_{m=1}^{R} B_{m}\left(\frac{1}{\omega_{m}}\right) e^{-\alpha_{m} t} \sin \left(\omega_{m} t+\theta_{m}\right),
$$

where $A_{k}$ and $B_{m}$ are constants that depend on $\sigma_{k}, z_{i}, \alpha_{m}, K$, and $\omega_{m}$. To obtain a bounded response, the poles of the closed-loop system must be in the left-hand portion of the $s$-plane. Thus, a necessary and sufficient condition for a feedback system to be stable is that all the poles of the system transfer function have negative real parts. A system is stable if all the poles of the transfer function are in the lefthand $s$-plane. A system is not stable if not all the roots are in the left-hand plane. If the characteristic equation has simple roots on the imaginary axis ( $j \omega$-axis) with all other roots in the left half-plane, the steady-state output will be sustained oscillations for a bounded input, unless the input is a sinusoid (which is bounded) whose frequency is equal to the magnitude of the $j \omega$-axis roots. For this case, the output becomes unbounded. Such a system is called marginally stable, since only certain bounded inputs (sinusoids of the frequency of the poles) will cause the output to become unbounded. For an unstable system, the characteristic equation has at least one root in the right half of the $s$-plane or repeated $j \omega$ roots; for this case, the output will become unbounded for any input.

For example, if the characteristic equation of a closed-loop system is

$$
(s+10)\left(s^{2}+16\right)=0,
$$

then the system is said to be marginally stable. If this system is excited by a sinusoid of frequency $\omega=4$, the output becomes unbounded.

An example of how mechanical resonance can cause large displacements occurred in a 39-story shopping mall in Seoul, Korea. The Techno-Mart building, shown in Figure 6.3, hosts activities such as physical aerobics, in addition to shopping. After a Tae Bo workout session on the $12^{\text {th }}$ floor with about twenty participants, the building shook for 10 minutes triggering an evacuation for two days [5]. A team of experts concluded that the building was likely excited to mechanical resonance by the vigorous exercise.

To ascertain the stability of a feedback control system, we could determine the roots of the characteristic polynomial $q(s)$. However, we are first interested in determining the answer to the question, Is the system stable? If we calculate the roots of the characteristic equation in order to answer this question, we have determined much more information than is necessary. Therefore, several FIGURE 6.3

Vigorous exercising on the 12th floor likely led to mechanical resonance of the building triggering a two-day evacuation. (Photo courtesy of Truth Leem/ Reuters.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0399.jpg?height=912&width=679&top_left_y=153&top_left_x=352)

methods have been developed that provide the required yes or no answer to the stability question. The three approaches to the question of stability are (1) the $s$-plane approach, (2) the frequency $(j \omega)$ approach, and (3) the time-domain approach.

Industrial robot sales were the highest level ever recorded for a single year in 2013. In fact, since the introduction of industrial robots at the end of the 1960s until 2013, there have been over 2.5 million operational industrial robots sold. The worldwide stock of operational industrial robots at the end of 2013 was in the range of 1.3-1.6 million units. The projections are that from 2015-2017, industrial robot installations will increase by $12 \%$ on average per year [10]. Clearly, the market for industrial robots is dynamic. The worldwide market for service robots is similarly active. The projections for the period 2014-2017 are that approximately 31 million new service robots for personal use (such as vacuum cleaners and lawn mowers) and approximately 134,500 new service robots for professional use will be put into service [10]. As the capability of robots increases, it is reasonable to assume that the numbers in service will continue to rise. Especially interesting are robots with human characteristics, particularly those that can walk upright [21]. The IHMC robot depicted in Figure 6.4 competed in the recent DARPA Robotics Challenge [24]. Examining the IHMC robot in Figure 6.4, one can imagine that it is not inherently stable and that active control is required to keep it upright during the walking motion. In the next sections we present the Routh-Hurwitz stability criterion to investigate system stability by analyzing the characteristic equation without direct computation of the roots. FIGURE 6.4

Team IHMC on the rubble on the first day of the DARPA Robotics Challenge 2015.

(DOD Photo/Alamy Stock Photo.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0400.jpg?height=901&width=605&top_left_y=152&top_left_x=516)

\subsection{THE ROUTH-HURWITZ STABILITY CRITERION}

The discussion and determination of stability has occupied the interest of many engineers. Maxwell and Vyshnegradskii first considered the question of stability of dynamic systems. In the late 1800s, A. Hurwitz and E. J. Routh independently published a method of investigating the stability of a linear system [6, 7]. The Routh-Hurwitz stability method provides an answer to the question of stability by considering the characteristic equation of the system. The characteristic equation is written as

$$
\Delta(s)=q(s)=a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots+a_{1} s+a_{0}=0 .
$$

To ascertain the stability of the system, it is necessary to determine whether any one of the roots of $q(s)$ lies in the right half of the $s$-plane. If Equation (6.3) is written in factored form, we have

$$
a_{n}\left(s-r_{1}\right)\left(s-r_{2}\right) \cdots\left(s-r_{n}\right)=0,
$$

where $r_{i}=i$ th root of the characteristic equation. Multiplying the factors together, we find that

$$
\begin{aligned}
q(s)= & a_{n} s^{n}-a_{n}\left(r_{1}+r_{2}+\cdots+r_{n}\right) s^{n-1} \\
& +a_{n}\left(r_{1} r_{2}+r_{2} r_{3}+r_{1} r_{3}+\cdots\right) s^{n-2} \\
& -a_{n}\left(r_{1} r_{2} r_{3}+r_{1} r_{2} r_{4} \cdots\right) s^{n-3}+\cdots \\
& +a_{n}(-1)^{n} r_{1} r_{2} r_{3} \cdots r_{n}=0 .
\end{aligned}
$$

In other words, for an $n$ th-degree equation, we obtain

$$
\begin{aligned}
q(s)= & a_{n} s^{n}-a_{n}\left(\text { sum of all the roots) } s^{n-1}\right. \\
& +a_{n}\left(\text { sum of the products of the roots taken } 2 \text { at a time) } s^{n-2}\right. \\
& -a_{n}\left(\text { sum of the products of the roots taken } 3 \text { at a time) } s^{n-3}\right. \\
& \left.+\cdots+a_{n}(-1)^{n} \text { (product of all } \mathrm{n} \text { roots }\right)=0 .
\end{aligned}
$$

Examining Equation (6.5), we note that all the coefficients of the polynomial will have the same sign if all the roots are in the left-hand plane. Also, it is necessary that all the coefficients for a stable system be nonzero. These requirements are necessary but not sufficient. That is, we immediately know the system is unstable if they are not satisfied; yet if they are satisfied, we must proceed further to ascertain the stability of the system. For example, when the characteristic equation is

$$
q(s)=(s+2)\left(s^{2}-s+4\right)=\left(s^{3}+s^{2}+2 s+8\right),
$$

the system is unstable, and yet the polynomial possesses all positive coefficients.

The Routh-Hurwitz criterion is a necessary and sufficient criterion for the stability of linear systems. The method was originally developed in terms of determinants, but we shall use the more convenient array formulation. The RouthHurwitz criterion is based on ordering the coefficients of the characteristic equation

$$
a_{n} s^{n}+a_{n-1} s^{n-1}+a_{n-2} s^{n-2}+\cdots+a_{1} s+a_{0}=0
$$

into an array as follows [4]:

$$
\begin{array}{l|cccc}
s^{n} & a_{n} & a_{n-2} & a_{n-4} & \ldots \\
s^{n-1} & a_{n-1} & a_{n-3} & a_{n-5} & \ldots
\end{array} .
$$

Further rows of the array, known as the Routh array, are then completed as

$$
\begin{array}{c|cccc}
s^{n} & a_{n} & a_{n-2} & a_{n-4} & \ldots \\
s^{n-1} & a_{n-1} & a_{n-3} & a_{n-5} & \ldots \\
s^{n-2} & b_{n-1} & b_{n-3} & b_{n-5} & \ldots \\
s^{n-3} & c_{n-1} & c_{n-3} & c_{n-5} & \ldots \\
\vdots & \vdots & \vdots & \vdots & \\
s^{0} & h_{n-1} & & &
\end{array}
$$

where

$$
\begin{aligned}
b_{n-1} & =\frac{a_{n-1} a_{n-2}-a_{n} a_{n-3}}{a_{n-1}}=\frac{-1}{a_{n-1}}\left|\begin{array}{ll}
a_{n} & a_{n-2} \\
a_{n-1} & a_{n-3}
\end{array}\right|, \\
b_{n-3} & =-\frac{1}{a_{n-1}}\left|\begin{array}{cc}
a_{n} & a_{n-4} \\
a_{n-1} & a_{n-5}
\end{array}\right|, \ldots \\
c_{n-1} & =\frac{-1}{b_{n-1}}\left|\begin{array}{ll}
a_{n-1} & a_{n-3} \\
b_{n-1} & b_{n-3}
\end{array}\right|, \ldots
\end{aligned}
$$

and so on. The algorithm for calculating the entries in the array can be followed on a determinant basis or by using the form of the equation for $b_{n-1}$.

The Routh-Hurwitz criterion states that the number of roots of $q(s)$ with positive real parts is equal to the number of changes in sign of the first column of the Routh array. This criterion requires that there be no changes in sign in the first column for a stable system. This requirement is both necessary and sufficient.

Four distinct cases or configurations of the first column array must be considered, and each must be treated separately and requires suitable modifications of the array calculation procedure: (1) No element in the first column is zero; (2) there is a zero in the first column, but some other elements of the row containing the zero in the first column are nonzero; (3) there is a zero in the first column, and the other elements of the row containing the zero are also zero; and (4) as in the third case, but with repeated roots on the $j \omega$-axis.

To illustrate this method clearly, several examples will be presented for each case.

\section{Case 1. No element in the first column is zero.}

\section{EXAMPLE 6.1 Second-order system}

The characteristic polynomial of a second-order system is

$$
q(s)=a_{2} s^{2}+a_{1} s+a_{0} .
$$

The Routh array is written as

$$
\begin{array}{c|cc}
s^{2} & a_{2} & a_{0} \\
s^{1} & a_{1} & 0 \\
s^{0} & b_{1} & 0
\end{array}
$$

where

$$
b_{1}=\frac{a_{1} a_{0}-(0) a_{2}}{a_{1}}=\frac{-1}{a_{1}}\left|\begin{array}{cc}
a_{2} & a_{0} \\
a_{1} & 0
\end{array}\right|=a_{0} .
$$

Therefore, the requirement for a stable second-order system is that all the coefficients be positive or all the coefficients be negative.

\section{EXAMPLE 6.2 Third-order system}

The characteristic polynomial of a third-order system is

$$
q(s)=a_{3} s^{3}+a_{2} s^{2}+a_{1} s+a_{0} .
$$

The Routh array is

\begin{tabular}{c|cc}
$s^{3}$ & $a_{3}$ & $a_{1}$ \\
$s^{2}$ & $a_{2}$ & $a_{0}$ \\
$s^{1}$ & $b_{1}$ & 0 \\
$s^{0}$ & $c_{1}$ & 0
\end{tabular}

where

$$
b_{1}=\frac{a_{2} a_{1}-a_{0} a_{3}}{a_{2}} \quad \text { and } \quad c_{1}=\frac{b_{1} a_{0}}{b_{1}}=a_{0} .
$$

For the third-order system to be stable, it is necessary and sufficient that the coefficients be positive and $a_{2} a_{1}>a_{0} a_{3}$. The condition when $a_{2} a_{1}=a_{0} a_{3}$ results in a marginal stability case, and one pair of roots lies on the imaginary axis in the $s$-plane. This marginal case is recognized as Case 3 because there is a zero in the first column when $a_{2} a_{1}=a_{0} a_{3}$. It will be discussed under Case 3 .

As a final example of characteristic equations that result in no zero elements in the first row, let us consider the polynomial

$$
q(s)=(s-1+j \sqrt{7})(s-1-j \sqrt{7})(s+3)=s^{3}+s^{2}+2 s+24 .
$$

The polynomial satisfies all the necessary conditions because all the coefficients exist and are positive. Therefore, utilizing the Routh array, we have

$$
\begin{array}{l|rr}
s^{3} & 1 & 2 \\
s^{2} & 1 & 24 \\
s^{1} & -22 & 0 \\
s^{0} & 24 & 0
\end{array} .
$$

Because two changes in sign appear in the first column, we find that two roots of $q(s)$ lie in the right-hand plane, and our prior knowledge is confirmed.

Case 2. There is a zero in the first column, but some other elements of the row containing the zero in the first column are nonzero. If only one element in the array is zero, it may be replaced with a small positive number, $\epsilon$, that is allowed to approach zero after completing the array. For example, consider the following characteristic polynomial:

$$
q(s)=s^{5}+2 s^{4}+2 s^{3}+4 s^{2}+11 s+10 .
$$

The Routh array is then

$$
\begin{array}{l|rrr}
s^{5} & 1 & 2 & 11 \\
s^{4} & 2 & 4 & 10 \\
s^{3} & \in & 6 & 0 \\
s^{2} & c_{1} & 10 & 0 \\
s^{1} & d_{1} & 0 & 0 \\
s^{0} & 10 & 0 & 0
\end{array}
$$

where

$$
c_{1}=\frac{4 \epsilon-12}{\epsilon} \quad \text { and } \quad d_{1}=\frac{6 c_{1}-10 \epsilon}{c_{1}} .
$$

When $0<\epsilon \ll 1$, we find that $c_{1}<0$ and $d_{1}>0$. Therefore, there are two sign changes in the first column; hence the system is unstable with two roots in the right half-plane.

\section{EXAMPLE 6.3 Unstable system}

As a final example of the type of Case 2, consider the characteristic polynomial

$$
q(s)=s^{4}+s^{3}+s^{2}+s+K,
$$

where we desire to determine the gain $K$ that results in marginal stability. The Routh array is then

\begin{tabular}{c|ccc}
$s^{4}$ & 1 & 1 & $K$ \\
$s^{3}$ & 1 & 1 & 0 \\
$s^{2}$ & $\in$ & $K$ & 0 \\
$s^{1}$ & $c_{1}$ & 0 & 0 \\
$s^{0}$ & $K$ & 0 & 0
\end{tabular}

where

$$
c_{1}=\frac{\epsilon-K}{\epsilon} .
$$

When $0<\epsilon \ll 1$ and $K>0$, we find that $c_{1}<0$. Therefore, there are two sign changes in the first column; hence, the system is unstable with two roots in the right half-plane. When $0<\epsilon \ll 1$ and $K<0$, we find that $c_{1}>0$, but because the last term in the first column is equal to $K$, we have a sign change in the first column; hence, the system is unstable with one root in the right half-plane. Consequently, the system is unstable for all values of gain $K$.

Case 3. There is a zero in the first column, and the other elements of the row containing the zero are also zero. Case 3 occurs when all the elements in one row are zero or when the row consists of a single element that is zero. This condition occurs when the polynomial contains singularities that are symmetrically located about the origin of the $s$-plane. Therefore, Case 3 occurs when factors such as $(s+\sigma)(s-\sigma)$ or $(s+j \omega)(s-j \omega)$ occur. This problem is circumvented by utilizing the auxiliary polynomial, $U(s)$, which immediately precedes the zero entry in the Routh array. The order of the auxiliary polynomial is always even and indicates the number of symmetrical root pairs.

To illustrate this approach, let us consider a third-order system with the characteristic polynomial

$$
q(s)=s^{3}+2 s^{2}+4 s+K
$$

where $K$ is an adjustable loop gain. The Routh array is then

$$
\begin{array}{c|cc}
s^{3} & 1 & 4 \\
s^{2} & 2 & K \\
s^{1} & \frac{8-K}{2} & 0 \\
s^{0} & K & 0
\end{array}
$$

For a stable system, we require that

$$
0<K<8
$$

When $K=8$, we have two roots on the $j \omega$-axis and a marginal stability case. Note that we obtain a row of zeros (Case 3 ) when $K=8$. The auxiliary polynomial, $U(s)$, is the equation of the row preceding the row of zeros. The equation of the row preceding the row of zeros is, in this case, obtained from the $s^{2}$-row. We recall that this row contains the coefficients of the even powers of $s$, and therefore we have

$$
U(s)=2 s^{2}+K s^{0}=2 s^{2}+8=2\left(s^{2}+4\right)=2(s+j 2)(s-j 2) .
$$

When $K=8$, the factors of the characteristic polynomial are

$$
q(s)=(s+2)(s+j 2)(s-j 2) .
$$

Case 4. Repeated roots of the characteristic equation on the $j \omega$-axis. If the $j \omega$-axis roots of the characteristic equation are simple, the system is neither stable nor unstable; it is instead called marginally stable, since it has an undamped sinusoidal mode. If the $j \omega$-axis roots are repeated, the system response will be unstable with a form $t \sin (\omega t+\phi)$. The Routh-Hurwitz criteria will not reveal this form of instability [20].

Consider the system with a characteristic polynomial

$$
q(s)=(s+1)(s+j)(s-j)(s+j)(s-j)=s^{5}+s^{4}+2 s^{3}+2 s^{2}+s+1 .
$$

The Routh array is

\begin{tabular}{l|rrr}
$s^{5}$ & 1 & 2 & 1 \\
$s^{4}$ & 1 & 2 & 1 \\
$s^{3}$ & $\in$ & $\in$ & 0 \\
$s^{2}$ & 1 & 1 & \\
$s^{1}$ & $\in$ & 0 & \\
$s^{0}$ & 1 & &
\end{tabular}

When $0<\epsilon \ll 1$, we note the absence of sign changes in the first column. However, as $\in \rightarrow 0$, we obtain a row of zero at the $s^{3}$ line and a now of zero at the $s^{1}$ line. The auxiliary polynomial at the $s^{2}$ line is $s^{2}+1$, and the auxiliary polynomial at the $s^{4}$ line is $s^{4}+2 s^{2}+1=\left(s^{2}+1\right)^{2}$, indicating the repeated roots on the $j \omega$-axis. Hence, the system is unstable. 

\section{EXAMPLE 6.4 Fifth-order system with roots on the $\boldsymbol{j} \boldsymbol{\omega}$-axis}

Consider the characteristic polynomial

$$
q(s)=s^{5}+s^{4}+4 s^{3}+24 s^{2}+3 s+63 .
$$

The Routh array is

\begin{tabular}{l|rrr}
$s^{5}$ & 1 & 4 & 3 \\
$s^{4}$ & 1 & 24 & 63 \\
$s^{3}$ & -20 & -60 & 0 \\
$s^{2}$ & 21 & 63 & 0 \\
$s^{1}$ & 0 & 0 & 0
\end{tabular}

Therefore, the auxiliary polynomial is

$$
U(s)=21 s^{2}+63=21\left(s^{2}+3\right)=21(s+j \sqrt{3})(s-j \sqrt{3}),
$$

which indicates that two roots are on the imaginary axis. To examine the remaining roots, we divide by the auxiliary polynomial to obtain

$$
\frac{q(s)}{s^{2}+3}=s^{3}+s^{2}+s+21
$$

Establishing a Routh array for this equation, we have

$$
\begin{array}{c|rr}
s^{3} & 1 & 1 \\
s^{2} & 1 & 21 \\
s^{1} & -20 & 0 \\
s^{0} & 21 & 0
\end{array} .
$$

The two changes in sign in the first column indicate the presence of two roots in the right-hand plane, and the system is unstable. The roots in the right-hand plane are $s=+1 \pm j \sqrt{6}$.

\section{EXAMPLE 6.5 Welding control}

Large welding robots are used in today's auto plants. The welding head is moved to different positions on the auto body, and a rapid, accurate response is required. A block diagram of a welding head positioning system is shown in Figure 6.5.

FIGURE 6.5

Welding head position control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0406.jpg?height=235&width=1037&top_left_y=1882&top_left_x=507)

We desire to determine the range of $K$ and $a$ for which the system is stable. The characteristic equation is

$$
1+G(s)=1+\frac{K(s+a)}{s(s+1)(s+2)(s+3)}=0 .
$$

Therefore, $q(s)=s^{4}+6 s^{3}+11 s^{2}+(K+6) s+K a=0$. Establishing the Routh array, we have

\begin{tabular}{c|ccc}
$s^{4}$ & 1 & 11 & $K a$ \\
$s^{3}$ & 6 & $K+6$ & \\
$s^{2}$ & $b_{3}$ & $K a$ & \\
$s^{1}$ & $c_{3}$ & \\
$s^{0}$ & $K a$ &
\end{tabular}

where

$$
b_{3}=\frac{60-K}{6} \quad \text { and } \quad c_{3}=\frac{b_{3}(K+6)-6 K a}{b_{3}} .
$$

The coefficient $c_{3}$ sets the acceptable range of $K$ and $a$, while $b_{3}$ requires that $K$ be less than 60. Requiring $c_{3} \geq 0$, we obtain

$$
(K-60)(K+6)+36 K a \leq 0 .
$$

The required relationship between $K$ and $a$ is then

$$
a \leq \frac{(60-K)(K+6)}{36 K}
$$

when $a$ is positive. Therefore, if $K=40$, we require $a \leq 0.639$.

Suppose we write the characteristic equation of an $n$ th-order system as

$$
s^{n}+a_{n-1} s^{n-1}+a_{n-2} s^{n-2}+\cdots+a_{1} s+\omega_{n}^{n}=0 .
$$

We divide through by $\omega_{n}^{n}$ and use $\stackrel{*}{s}=s / \omega_{n}$ to obtain the normalized form of the characteristic equation:

$$
\stackrel{*}{n}^{n}+b \stackrel{*}{*}^{n-1}+c \stackrel{*}{s}^{n-2}+\cdots+1=0 .
$$

For example, we normalize

$$
s^{3}+5 s^{2}+2 s+8=0
$$

by dividing through by $8=\omega_{n}^{3}$, obtaining

$$
\frac{s^{3}}{\omega_{n}^{3}}+\frac{5}{2} \frac{s^{2}}{\omega_{n}^{2}}+\frac{2}{4} \frac{s}{\omega_{n}}+1=0,
$$

or

$$
\stackrel{*}{3}^{3}+2.5 \stackrel{*}{2}^{2}+0.5 * s^{*}+1=0,
$$



\section{Table 6.1 The Routh-Hurwitz Stability Criterion}

\section{$n$ Characteristic Equation}

$2 s^{2}+b s+1=0$

$3 s^{3}+b s^{2}+c s+1=0$

$4 s^{4}+b s^{3}+c s^{2}+d s+1=0$

$5 s^{5}+b s^{4}+c s^{3}+d s^{2}+e s+1=0$

$6 s^{6}+b s^{5}+c s^{4}+d s^{3}+e s^{2}+f s+1=0$

Note: The equations are normalized by $\left(\omega_{n}\right)^{n}$.

where $\stackrel{*}{s}=s / \omega_{n}$. In this case, $b=2.5$ and $c=0.5$. Using this normalized form of the characteristic equation, we summarize the stability criterion for up to a sixth-order characteristic equation, as provided in Table 6.1. Note that $b c=1.25$ and the system is stable.

\subsection{THE RELATIVE STABILITY OF FEEDBACK CONTROL SYSTEMS}

The verification of stability using the Routh-Hurwitz criterion provides only a partial answer to the question of stability. The Routh-Hurwitz criterion ascertains the absolute stability of a system by determining whether any of the roots of the characteristic equation lie in the right half of the $s$-plane. However, if the system satisfies the Routh-Hurwitz criterion and is stable, it is desirable to determine the relative stability; that is, it is interesting to investigate the relative damping of each root of the characteristic equation. The relative stability of a system can be defined as the property that is measured by the relative real part of each root or pair of roots. Thus, root $r_{2}$ is relatively more stable than the roots $r_{1}, \hat{r}_{1}$, as shown in Figure 6.6. The relative stability of a system can also be defined in terms of the relative damping coefficients $\zeta$ of each complex root pair and, therefore, in terms of the speed of response and overshoot instead of settling time.

The investigation of the relative stability of each root is important because the location of the closed-loop poles in the $s$-plane determines the performance of the system. Thus, we reexamine the characteristic polynomial $q(s)$ and consider several methods for the determination of relative stability.

FIGURE 6.6

Root locations in the s-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0408.jpg?height=383&width=593&top_left_y=1728&top_left_x=520)

Because the relative stability of a system is determined by the location of the roots of the characteristic equation, a first approach using an $s$-plane formulation is to extend the Routh-Hurwitz criterion to ascertain relative stability. This can be accomplished by utilizing a change of variable, which shifts the $s$-plane axis in order to utilize the Routh-Hurwitz criterion. Examining Figure 6.6, we notice that a shift of the vertical axis in the $s$-plane to $-\sigma_{1}$ will result in the roots $r_{1}, \hat{r}_{1}$ appearing on the shifted axis. The correct magnitude to shift the vertical axis must be obtained on a trial-and-error basis. Then, without solving the fifth-order polynomial $q(s)$, we may determine the real part of the dominant roots $r_{1}, \hat{r}_{1}$.

\section{EXAMPLE 6.6 Axis shift}

Consider the third-order characteristic equation

$$
q(s)=s^{3}+4 s^{2}+6 s+4 .
$$

Setting the shifted variable $s_{n}$ equal to $s+1$, we obtain

$$
\left(s_{n}-1\right)^{3}+4\left(s_{n}-1\right)^{2}+6\left(s_{n}-1\right)+4=s_{n}^{3}+s_{n}^{2}+s_{n}+1 .
$$

Then the Routh array is established as

\begin{tabular}{l|ll}
$s_{n}^{3}$ & 1 & 1 \\
$s_{n}^{2}$ & 1 & 1 \\
$s_{n}^{1}$ & 0 & 0 \\
$s_{n}^{0}$ & 1 & 0
\end{tabular}.

There are roots on the shifted imaginary axis that can be obtained from the auxiliary polynomial

$$
U\left(s_{n}\right)=s_{n}^{2}+1=\left(s_{n}+j\right)\left(s_{n}-j\right)=(s+1+j)(s+1-j) .
$$

The shifting of the $s$-plane axis to ascertain the relative stability of a system is a very useful approach, particularly for higher-order systems with several pairs of closed-loop complex conjugate roots.

\subsection{THE STABILITY OF STATE VARIABLE SYSTEMS}

The stability of a system modeled by a state variable flow graph model can be readily ascertained. If the system we are investigating is represented by a signal-flow graph state model, we obtain the characteristic equation by evaluating the flow graph determinant. If the system is represented by a block diagram model we obtain the characteristic equation using the block diagram reduction methods.

\section{EXAMPLE 6.7 Stability of a second-order system}

A second-order system is described by the two first-order differential equations

$$
\dot{x}_{1}=-3 x_{1}+x_{2} \quad \text { and } \quad \dot{x}_{2}=+1 x_{2}-K x_{1}+K u,
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0410.jpg?height=266&width=835&top_left_y=159&top_left_x=519)

(a)

\section{FIGURE 6.7}

(a) Flow graph model for state variable equations of Example 6.7.

(b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0410.jpg?height=424&width=1038&top_left_y=529&top_left_x=450)

(b)

where $u(t)$ is the input. The flow graph model of this set of differential equations is shown in Figure 6.7(a) and the block diagram model is shown in Figure 6.7(b).

Using Mason's signal-flow gain formula, we note three loops:

$$
L_{1}=s^{-1}, \quad L_{2}=-3 s^{-1}, \quad \text { and } \quad L_{3}=-K s^{-2},
$$

where $L_{1}$ and $L_{2}$ do not share a common node. Therefore, the determinant is

$$
\Delta=1-\left(L_{1}+L_{2}+L_{3}\right)+L_{1} L_{2}=1-\left(s^{-1}-3 s^{-1}-K s^{-2}\right)+\left(-3 s^{-2}\right) .
$$

We multiply by $s^{2}$ to obtain the characteristic equation

$$
s^{2}+2 s+(K-3)=0 .
$$

Since all coefficients must be positive, we require $K>3$ for stability. A similar analysis can be undertaken using the block diagram. Closing the two feedback loops yields the two transfer functions

$$
G_{1}(s)=\frac{1}{s-1} \quad \text { and } \quad G_{2}(s)=\frac{1}{s+3},
$$

as illustrated in Figure 6.7(b). The closed loop transfer function is thus

$$
T(s)=\frac{K G_{1}(s) G_{2}(s)}{1+K G_{1}(s) G_{2}(s)} .
$$

Therefore, the characteristic equation is

$$
\Delta(s)=1+K G_{1}(s) G_{2}(s)=0,
$$

or

$$
\Delta(s)=(s-1)(s+3)+K=s^{2}+2 s+(K-3)=0 .
$$

This confirms the results obtained using signal-flow graph techniques.

A method of obtaining the characteristic equation directly from the vector differential equation is based on the fact that the solution to the unforced system is an exponential function. The vector differential equation without input signals is

$$
\dot{\mathbf{x}}=\mathbf{A x},
$$

where $\mathbf{x}$ is the state vector. The solution is of exponential form, and we can define a constant $\lambda$ such that the solution of the system for one state can be of the form $x_{i}(t)=k_{i} e^{\lambda_{i} t}$. The $\lambda_{i}$ are called the characteristic roots or eigenvalues of the system, which are simply the roots of the characteristic equation. If we let $\mathbf{x}=\mathbf{k} e^{\lambda t}$ and substitute into Equation (6.22), we have

$$
\lambda \mathbf{k} e^{\lambda t}=\mathbf{A} \mathbf{k} e^{\lambda t}
$$

or

$$
\lambda \mathbf{x}=\mathbf{A x}
$$

Equation (6.24) can be rewritten as

$$
(\lambda \mathbf{I}-\mathbf{A}) \mathbf{x}=0,
$$

where $\mathbf{I}$ equals the identity matrix and $\mathbf{0}$ equals the null matrix. This set of simultaneous equations has a nontrivial solution if and only if the determinant vanishesthat is, only if

$$
\operatorname{det}(\lambda \mathbf{I}-\mathbf{A})=0
$$

The $n$ th-order equation in $\lambda$ resulting from the evaluation of this determinant is the characteristic equation, and the stability of the system can be readily ascertained.

\section{EXAMPLE 6.8 Closed epidemic system}

The vector differential equation of the epidemic system is given in Equation (3.63) and repeated here as

$$
\frac{d \mathbf{x}}{d t}=\left[\begin{array}{ccc}
-\alpha & -\beta & 0 \\
\beta & -\gamma & 0 \\
\alpha & \gamma & 0
\end{array}\right] \mathbf{x}+\left[\begin{array}{ll}
1 & 0 \\
0 & 1 \\
0 & 0
\end{array}\right]\left[\begin{array}{l}
u_{1} \\
u_{2}
\end{array}\right] .
$$

The characteristic equation is then

$$
\begin{aligned}
\operatorname{det}(\lambda \mathbf{I}-\mathbf{A}) & =\operatorname{det}\left\{\left[\begin{array}{ccc}
\lambda & 0 & 0 \\
0 & \lambda & 0 \\
0 & 0 & \lambda
\end{array}\right]-\left[\begin{array}{ccc}
-\alpha & -\beta & 0 \\
\beta & -\gamma & 0 \\
\alpha & \gamma & 0
\end{array}\right]\right\} \\
& =\operatorname{det}\left[\begin{array}{ccc}
\lambda+\alpha & \beta & 0 \\
-\beta & \lambda+\gamma & 0 \\
-\alpha & -\gamma & \lambda
\end{array}\right] \\
& =\lambda\left[\lambda^{2}+(\alpha+\gamma) \lambda+\left(\alpha \gamma+\beta^{2}\right)\right]=0
\end{aligned}
$$

Thus, we obtain the characteristic equation of the system. The additional root $\lambda=0$ results from the definition of $x_{3}$ as the integral of $\alpha x_{1}+\gamma x_{2}$, and $x_{3}$ does not affect the other state variables. Thus, the root $\lambda=0$ indicates the integration connected with $x_{3}$. The characteristic equation indicates that the system is marginally stable when $\alpha+\gamma>0$ and $\alpha \gamma+\beta^{2}>0$.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. The first example is a tracked vehicle control problem. In this first example, stability issues are addressed employing the Routh-Hurwitz stability criterion and the outcome is the selection of two key system parameters. The second example illustrates the stability problem robot-controlled motorcycle and how Routh-Hurwitz can be used in the selection of controller gains during the design process. The robot-controlled motorcycle example highlights the design process with special attention to the impact of key controller parameters on stability.

\section{EXAMPLE 6.9 Tracked vehicle turning control}

The design of a turning control for a tracked vehicle involves the selection of two parameters [8]. In Figure 6.8, the system shown in part (a) has the model shown in part (b). The two tracks are operated at different speeds in order to turn the vehicle. We must select $K$ and $a$ so that the system is stable and the steady-state error for a ramp command is less than or equal to $24 \%$ of the magnitude of the command.

The characteristic equation of the feedback system is

$$
1+G_{c}(s) G(s)=0,
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0412.jpg?height=266&width=1012&top_left_y=1443&top_left_x=557)

(a)

FIGURE 6.8

(a) Turning control system for a two-track vehicle. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0412.jpg?height=284&width=1035&top_left_y=1803&top_left_x=508)

(b) or

$$
1+\frac{K(s+a)}{s(s+1)(s+2)(s+5)}=0 .
$$

Therefore, we have

$$
s(s+1)(s+2)(s+5)+K(s+a)=0,
$$

or

$$
s^{4}+8 s^{3}+17 s^{2}+(K+10) s+K a=0 .
$$

To determine the stable region for $K$ and $a$, we establish the Routh array as

\begin{tabular}{c|ccc}
$s^{4}$ & 1 & 17 & $K a$ \\
$s^{3}$ & 8 & $K+10$ & 0 \\
$s^{2}$ & $b_{3}$ & $K a$ & \\
$s^{1}$ & $c_{3}$ & & \\
$s^{0}$ & $K a$ & &
\end{tabular}

where

$$
b_{3}=\frac{126-K}{8} \quad \text { and } \quad c_{3}=\frac{b_{3}(K+10)-8 K a}{b_{3}} .
$$

For the elements of the first column to be positive, we require that $K a, b_{3}$, and $c_{3}$ be positive. Therefore, we require that

$$
\begin{gathered}
K<126, \\
K a>0, \text { and } \\
(K+10)(126-K)-64 K a>0 .
\end{gathered}
$$

The region of stability for $K>0$ is shown in Figure 6.9. The steady-state error to a ramp input $r(t)=A t, t>0$ is

$$
e_{\mathrm{ss}}=A / K_{v},
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0413.jpg?height=614&width=663&top_left_y=1537&top_left_x=372)

The stable region. where

$$
K_{v}=\lim _{s \rightarrow 0} s G_{c} G=K a / 10
$$

Therefore, we have

$$
e_{\mathrm{ss}}=\frac{10 A}{K a} .
$$

When $e_{\mathrm{ss}}$ is equal to $23.8 \%$ of $A$, we require that $K a=42$. This can be satisfied by the selected point in the stable region when $K=70$ and $a=0.6$, as shown in Figure 6.9. Another acceptable design would be attained when $K=50$ and $a=0.84$. We can calculate a series of possible combinations of $K$ and $a$ that can satisfy $K a=42$ and that lie within the stable region, and all will be acceptable design solutions. However, not all selected values of $K$ and $a$ will lie within the stable region. Note that $K$ cannot exceed 126.

\section{EXAMPLE 6.10 Robot-controlled motorcycle}

Consider the robot-controlled motorcycle shown in Figure 6.10. The motorcycle will move in a straight line at constant forward speed $v$. Let $\phi(t)$ denote the angle between the plane of symmetry of the motorcycle and the vertical. The desired angle $\phi_{d}(t)$ is equal to zero, thus

$$
\phi_{d}(s)=0
$$

The design elements highlighted in this example are illustrated in Figure 6.11. Using the Routh-Hurwitz stability criterion will allow us to get to the heart of the matter, that is, to develop a strategy for computing the controller gains while ensuring closed-loop stability. The control goal is

\section{Control Goal}

Control the motorcycle in the vertical position, and maintain the prescribed position in the presence of disturbances.

The variable to be controlled is

\section{Variable to Be Controlled}

The motorcycle position from vertical, $\phi(t)$.

FIGURE 6.10

The robotcontrolled motorcycle.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0414.jpg?height=510&width=722&top_left_y=1648&top_left_x=519)

Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0415.jpg?height=1016&width=1303&top_left_y=240&top_left_x=318)

FIGURE 6.11 Elements of the control system design process emphasized in this robot-controlled motorcycle example.

Since our focus here is on stability rather than transient response characteristics, the control specifications will be related to stability only; transient performance is an issue that we need to address once we have investigated all the stability issues. The control design specification is

\section{Design Specification}

DS1 The closed-loop system must be stable.

The main components of the robot-controlled motorcycle are the motorcycle and robot, the controller, and the feedback measurements. The main subject of the chapter is not modeling, so we do not concentrate on developing the motorcycle dynamics model. We rely instead on the work of others (see [22]). The motorcycle model is given by

$$
G(s)=\frac{1}{s^{2}-\alpha_{1}}
$$

where $\alpha_{1}=g / h, g=9.806 \mathrm{~m} / \mathrm{s}^{2}$, and $h$ is the height of the motorcycle center of gravity above the ground (see Figure 6.10). The motorcycle is unstable with poles at $s= \pm \sqrt{\alpha_{1}}$. The controller is given by where

$$
G_{c}(s)=\frac{\alpha_{2}+\alpha_{3} s}{\tau s+1}
$$

$$
\alpha_{2}=v^{2} /(h c)
$$

and

$$
\alpha_{3}=v L /(h c) \text {. }
$$

The forward speed of the motorcycle is denoted by $v$, and $c$ denotes the wheelbase (the distance between the wheel centers). The length, $L$, is the horizontal distance between the front wheel axle and the motorcycle center of gravity. The time-constant of the controller is denoted by $\tau$. This term represents the speed of response of the controller; smaller values of $\tau$ indicate an increased speed of response. Many simplifying assumptions are necessary to obtain the simple transfer function models in Equations (6.31) and (6.32).

Control is accomplished by turning the handlebar. The front wheel rotation about the vertical is not evident in the transfer functions. Also, the transfer functions assume a constant forward speed $v$ which means that we must have another control system at work regulating the forward speed. Nominal motorcycle and robot controller parameters are given in Table 6.2.

Assembling the components of the feedback system gives us the system configuration shown in Figure 6.12. Examination of the configuration reveals that the robot controller block is a function of the physical system $(h, c$, and $L)$, the operating conditions $(v)$, and the robot time-constant $(\tau)$. No parameters need adjustment unless we physically change the motorcycle parameters and/or speed. In fact, in this example the parameters we want to adjust are in the feedback loop:

\section{Select Key Tuning Parameters}

Feedback gains $K_{P}$ and $K_{D}$.

The key tuning parameters are not always in the forward path; in fact they may exist in any subsystem in the block diagram.

We want to use the Routh-Hurwitz technique to analyze the closed-loop system stability. What values of $K_{P}$ and $K_{D}$ lead to closed-loop stability? A related question that we can pose is, given specific values of $K_{P}$ and $K_{D}$ for the nominal system (that is, nominal values of $\alpha_{1}, \alpha_{2}, \alpha_{3}$, and $\tau$ ), how can the parameters themselves vary while still retaining closed-loop stability?

\begin{tabular}{lc} 
Table 6.2 & Physical Parameters \\
\hline$\tau$ & $0.2 \mathrm{~s}$ \\
$\alpha_{1}$ & $91 / \mathrm{s}^{2}$ \\
$\alpha_{2}$ & $2.71 / \mathrm{s}^{2}$ \\
$\alpha_{3}$ & $1.351 / \mathrm{s}$ \\
$h$ & $1.09 \mathrm{~m}$ \\
$V$ & $2.0 \mathrm{~m} / \mathrm{s}$ \\
$L$ & $1.0 \mathrm{~m}$ \\
$c$ & $1.36 \mathrm{~m}$ \\
\hline
\end{tabular}

FIGURE 6.12

The robot-controlled motorcyle feedback system block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0417.jpg?height=468&width=1063&top_left_y=166&top_left_x=372)

The closed-loop transfer function from $\phi_{d}(s)$ to $\phi(s)$ is

$$
T(s)=\frac{\alpha_{2}+\alpha_{3} s}{\Delta(s)},
$$

where

$$
\Delta(s)=\tau s^{3}+\left(1+K_{D} \alpha_{3}\right) s^{2}+\left(K_{D} \alpha_{2}+K_{P} \alpha_{3}-\tau \alpha_{1}\right) s+K_{P} \alpha_{2}-\alpha_{1} .
$$

The question that we need to answer is for what values of $K_{P}$ and $K_{D}$ does the characteristic equation $\Delta(s)=0$ have all roots in the left half-plane?

We can set up the following Routh array:

$$
\begin{array}{c|cc}
s^{3} & \tau & K_{D} \alpha_{2}+K_{P} \alpha_{3}-\tau \alpha_{1} \\
s^{2} & 1+K_{D} \alpha_{3} & K_{P} \alpha_{2}-\alpha_{1} \\
s & a & \\
1 & K_{P} \alpha_{2}-\alpha_{1} &
\end{array}
$$

where

$$
a=\frac{\left(1+K_{D} \alpha_{3}\right)\left(K_{D} \alpha_{2}+K_{P} \alpha_{3}-\tau \alpha_{1}\right)-\tau\left(\alpha_{2} K_{P}-\alpha_{1}\right)}{1+K_{D} \alpha_{3}} .
$$

By inspecting column 1, we determine that for stability we require

$$
\tau>0, K_{D}>-1 / \alpha_{3}, K_{P}>\alpha_{1} / \alpha_{2}, \text { and } a>0 .
$$

Choosing $K_{D}>0$ satisfies the second inequality (note that $\alpha_{3}>0$ ). In the event $\tau=0$, we would reformulate the characteristic equation and rework the Routh array. We need to determine the conditions on $K_{P}$ and $K_{D}$ such that $a>0$. We find that $a>0$ implies that the following relationship must be satisfied:

$$
\alpha_{2} \alpha_{3} K_{D}^{2}+\left(\alpha_{2}-\tau \alpha_{1} \alpha_{3}+\alpha_{3}^{2} K_{P}\right) K_{D}+\left(\alpha_{3}-\tau \alpha_{2}\right) K_{P}>0 .
$$

Using the nominal values of the parameters $\alpha_{1}, \alpha_{2}, \alpha_{3}$, and $\tau$ (see Table 6.2), for all $K_{D}>0$ and $K_{P}>3.33$, the left hand-side of Equation (6.33) is positive, hence $a>0$. Taking into account all the inequalities, a valid region for selecting the gains is $K_{D}>0$ and $K_{P}>\alpha_{1} / \alpha_{2}=3.33$. Selecting any point $\left(K_{P}, K_{D}\right)$ in the stability region yields a valid (that is, stable) set of gains for the feedback loop. For example, selecting

$$
K_{P}=10 \text { and } K_{D}=5
$$

yields a stable closed-loop system. The closed-loop poles are

$$
s_{1}=-35.2477, s_{2}=-2.4674 \text {, and } s_{3}=-1.0348 .
$$

Since all the poles have negative real parts, we know the system response to any bounded input will be bounded.

For this robot-controlled motorcycle, we do not expect to have to respond to nonzero command inputs (that is, $\phi_{d}(t) \neq 0$ ) since we want the motorcyle to remain upright, and we certainly want to remain upright in the presence of external disturbances. The transfer function for the disturbance $T_{d}(s)$ to the output $\phi(s)$ without feedback is

$$
\phi(s)=\frac{1}{s^{2}-\alpha_{1}} T_{d}(s) .
$$

The characteristic equation is

$$
q(s)=s^{2}-\alpha_{1}=0 .
$$

The system poles are

$$
s_{1}=-\sqrt{\alpha_{1}} \text { and } s_{2}=+\sqrt{\alpha_{1}} .
$$

Thus we see that the motorcycle is unstable; it possesses a pole in the right half-plane. Without feedback control, any external disturbance will result in the motorcycle falling over. Clearly the need for a control system (usually provided by the human rider) is necessary. With the feedback and robot controller in the loop, the closed-loop transfer function from the disturbance to the output is

$$
\frac{\phi(s)}{T_{d}(s)}=\frac{\tau s+1}{\tau s^{3}+\left(1+K_{D} \alpha_{3}\right) s^{2}+\left(K_{D} \alpha_{2}+K_{P} \alpha_{3}-\tau \alpha_{1}\right) s+K_{P} \alpha_{2}-\alpha_{1}} .
$$

The response to a step disturbance is shown in Figure 6.13; the response is stable. The control system manages to keep the motorcycle upright, although it is tilted at about $\phi=0.055 \mathrm{rad}=3.18 \mathrm{deg}$.

It is important to give the robot the ability to control the motorcycle over a wide range of forward speeds. Is it possible for the robot, with the feedback gains as selected $\left(K_{P}=10\right.$ and $\left.K_{D}=5\right)$, to control the motorcycle as the velocity varies? From experience we know that at slower speeds a bicycle becomes more difficult to control. We expect to see the same characteristics in the stability analysis of our system. Whenever possible, we try to relate the engineering problem at hand to real-life experiences. This helps to develop intuition that can be used as a reasonableness check on our solution.

A plot of the roots of the characteristic equation as the forward speed $v$ varies is shown in Figure 6.14. The data in the plot were generated using the nominal values of the feedback gains, $K_{P}=10$ and $K_{D}=5$. We selected these gains for the case where $v=2 \mathrm{~m} / \mathrm{s}$. Figure 6.14 shows that as $v$ increases, the roots of the FIGURE 6.13

Disturbance response with $K_{P}=10$ and $K_{D}=5$.

FIGURE 6.14

Roots of the characteristic equation as the motorcycle velocity varies.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0419.jpg?height=1734&width=1056&top_left_y=154&top_left_x=370)

characteristic equation remain stable (that is, in the left half-plane) with all points negative. But as the motorcycle forward speed decreases, the roots move toward zero, with one root becoming positive at $v=1.15 \mathrm{~m} / \mathrm{s}$. At the point where one root is positive, the motorcycle is unstable. 

\subsection{SYSTEM STABILITY USING CONTROL DESIGN SOFTWARE}

In this section we will see how the computer can assist us in the stability analysis by providing an easy and accurate method for computing the poles of the characteristic equation. For the case of the characteristic equation as a function of a single parameter, it will be possible to generate a plot displaying the movement of the poles as the parameter varies. The section concludes with an example.

The function introduced in this section is the function for, which is used to repeat a number of statements a specific number of times.

Routh-Hurwitz Stability. As stated earlier, the Routh-Hurwitz criterion is a necessary and sufficient criterion for stability. Given a characteristic equation with fixed coefficients, we can use Routh-Hurwitz to determine the number of roots in the right half-plane. For example, consider the characteristic equation

$$
q(s)=s^{3}+s^{2}+2 s+24=0
$$

associated with the closed-loop control system shown in Figure 6.15. The corresponding Routh-Hurwitz array is shown in Figure 6.16. The two sign changes in the first column indicate that there are two roots of the characteristic polynomial in the right half-plane; hence, the closed-loop system is unstable. We can verify the Routh-Hurwitz result by directly computing the roots of the characteristic equation, as shown in Figure 6.17, using the pole function. Recall that the pole function computes the system poles.

Whenever the characteristic equation is a function of a single parameter, the Routh-Hurwitz method can be utilized to determine the range of values that the parameter may take while maintaining stability. Consider the closed-loop feedback system in Figure 6.18. The characteristic equation is

$$
q(s)=s^{3}+2 s^{2}+4 s+K=0 .
$$

Using a Routh-Hurwitz approach, we find that we require $0<K<8$ for stability (see Equation 6.12). We can verify this result graphically. As shown in Figure 6.19(b), we

FIGURE 6.15

Closed-loop control system with

$T(s)=$

$Y(s) / R(s)=1 /\left(s^{3}+\right.$ $\left.s^{2}+2 s+24\right)$.

FIGURE 6.16

Routh array for the closed-loop control system with $T(s)=$ $Y(s) / R(s)=$ $1 /\left(s^{3}+s^{2}+\right.$ $2 s+24)$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0420.jpg?height=644&width=846&top_left_y=1464&top_left_x=506)FIGURE 6.17

Using the pole function to compute the closed-loop control system poles of the system shown in Figure 6.16.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0421.jpg?height=666&width=762&top_left_y=184&top_left_x=374)

FIGURE 6.18

Closed-loop control system with

$T(s)=$

$Y(s) / R(s)=K /\left(s^{3}+\right.$ $\left.2 s^{2}+4 s+4\right)$.

establish a vector of values for $K$ at which we wish to compute the roots of the characteristic equation. Then using the roots function, we calculate and plot the roots of the characteristic equation, as shown in Figure 6.19(a). It can be seen that as $K$ increases, the roots of the characteristic equation move toward the right half-plane as the gain tends toward $K=8$, and eventually into the right half-plane when $K>8$.

The script in Figure 6.19 contains the for function. This function provides a mechanism for repeatedly executing a series of statements a given number of times. The for function connected to an end statement sets up a repeating calculation loop. Figure 6.20 describes the for function format and provides an illustrative example of its usefulness. The example sets up a loop that repeats ten times. During the $i$ th iteration, where $1 \leq i \leq 10$, the $i$ th element of the vector $\mathbf{a}$ is set equal to 20 , and the scalar $b$ is recomputed.

The Routh-Hurwitz method allows us to make definitive statements regarding absolute stability of a linear system. The method does not address the issue of relative stability, which is directly related to the location of the roots of the characteristic equation. Routh-Hurwitz tells us how many poles lie in the right half-plane, but not the specific location of the poles. With control design software, we can easily calculate the poles explicitly, thus allowing us to comment on the relative stability.

\section{EXAMPLE 6.11 Tracked vehicle control}

The block diagram of the control system for the two-track vehicle is shown in Figure 6.8. The design objective is to find $a$ and $K$ such that the system is stable and the steady-state error for a ramp input is less than or equal to $24 \%$ of the command.

We can use the Routh-Hurwitz method to aid in the search for appropriate values of $a$ and $K$. The closed-loop characteristic equation is

$$
q(s)=s^{4}+8 s^{3}+17 s^{2}+(K+10) s+a K=0 .
$$

Using the Routh array, we find that, for stability, we require that

$$
K<126, \frac{126-K}{8}(K+10)-8 a K>0, \text { and } a K>0 .
$$

FIGURE 6.19

(a) Plot of root locations of $q(s)=s^{3}+2 s^{2}+$ $4 \mathrm{~s}+K$ for $0 \leq K \leq 20$. (b) $\mathrm{m}$-file script.

FIGURE 6.20 The for function and an illustrative example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0422.jpg?height=602&width=1058&top_left_y=153&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0422.jpg?height=372&width=680&top_left_y=884&top_left_x=751)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0422.jpg?height=804&width=922&top_left_y=1362&top_left_x=508)FIGURE 6.21

(a) Stability region for $a$ and $K$ for two-track vehicle turning control.

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0423.jpg?height=317&width=799&top_left_y=166&top_left_x=506)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0423.jpg?height=525&width=1021&top_left_y=556&top_left_x=428)

(b)

For positive $K$, it follows that we can restrict our search to $0<K<126$ and $a>0$. Our approach will be to use the computer to help find a parameterized $a$ versus $K$ region in which stability is assured. Then we can find a set of $(a, K)$ belonging to the stable region such that the steady-state error specification is met. This procedure, shown in Figure 6.21, involves selecting a range of values for $a$ and $K$ and computing the roots of the characteristic polynomial for specific values of $a$ and $K$. For each value of $K$, we find the first value of $a$ that results in at least one root of the characteristic equation in the right half-plane. The process is repeated until the entire selected range of $a$ and $K$ is exhausted. The plot of the $(a, K)$ pairs defines the separation between the stable and unstable regions. The region to the left of the plot of $a$ versus $K$ in Figure 6.21 is the stable region.

If we assume that $r(t)=A t, t>0$, then the steady-state error is

$$
e_{\mathrm{ss}}=\lim _{s \rightarrow 0} s \cdot \frac{s(s+1)(s+2)(s+5)}{s(s+1)(s+2)(s+5)+K(s+a)} \frac{A}{s^{2}}=\frac{10 A}{a K},
$$

where we have used the fact that

$$
E(s)=\frac{1}{1+G_{c}(s) G(s)} R(s)=\frac{s(s+1)(s+2)(s+5)}{s(s+1)(s+2)(s+5)+K(s+a)} R(s) .
$$

Given the steady-state specification, $e_{\mathrm{ss}}<0.24 A$, we find that the specification is satisfied when

$$
\frac{10 A}{a K}<0.24 A,
$$

FIGURE 6.22

(a) Ramp response for $a=0.6$ and $K=70$ for twotrack vehicle turning control. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0424.jpg?height=560&width=753&top_left_y=153&top_left_x=564)

(a)

$\%$ Two-track vehicle turning control ramp response

$\%$ with $\mathrm{a}=0.6$ and $\mathrm{K}=70$.

$\%$

$\mathrm{t}=[0: 0.01: 16] ; \mathrm{u}=\mathrm{t}$;

$u=$ unit ramp input

numgc=[1 0.6$] ;$ dengc=[1 1 $]$; sysgc=tf(numgc, dengc);

numg=[70]; deng=[1 $\left.7 \begin{array}{lll}1 & 10 & 0\end{array}\right]$; sysg=tf(numg,deng);

sysa=series(sysgc,sysg);

sys=feedback(sysa,[1]);

$\mathrm{y}=\operatorname{Isim}(\mathrm{sys}, \mathrm{u}, \mathrm{t})$;

Linear simulation

plot(t,y,t,u,'--'), grid

$a=0.6$ and $K=70$

(b)

or

$$
a K>41.67 \text {. }
$$

Any values of $a$ and $K$ that lie in the stable region in Figure 6.21 and satisfy Equation (6.34) will lead to an acceptable design. For example, $K=70$ and $a=0.6$ will satisfy all the design requirements. The closed-loop transfer function (with $a=0.6$ and $K=70)$ is

$$
T(s)=\frac{70 s+42}{s^{4}+8 s^{3}+17 s^{2}+80 s+42} .
$$

The associated closed-loop poles are

$$
\begin{aligned}
& s=-7.0767, \\
& s=-0.5781, \\
& s=-0.1726+j 3.1995, \quad \text { and } \\
& s=-0.1726-j 3.1995 .
\end{aligned}
$$

The corresponding unit ramp input response is shown in Figure 6.22. The steadystate error is less than 0.24 , as desired. The Stability of State Variable Systems. Now let us turn to determining the stability of systems described in state variable form. Suppose we have a system in state-space form as in Equation (6.22). The stability of the system can be evaluated with the characteristic equation associated with the system matrix $\mathbf{A}$. The characteristic equation is

$$
\operatorname{det}(s \mathbf{I}-\mathbf{A})=0 .
$$

The left-hand side of the characteristic equation is a polynomial in $s$. If all of the roots of the characteristic equation have negative real parts (i.e., $\operatorname{Re}\left(s_{i}\right)<0$ ), then the system is stable.

When the system model is given in state variable form, we must calculate the characteristic polynomial associated with the A matrix. In this regard, we have several options. We can calculate the characteristic equation directly from Equation (6.35) by manually computing the determinant of $s \mathbf{I}-\mathbf{A}$. Then, we can compute the roots using the roots function to check for stability, or alternatively, we can use the Routh-Hurwitz method to detect any unstable roots. Unfortunately, the manual computations can become lengthy, especially if the dimension of $\mathbf{A}$ is large. We would like to avoid this manual computation if possible. As it turns out, the computer can assist in this endeavor.

The poly function can be used to compute the characteristic equation associated with $\mathbf{A}$. The poly is used to form a polynomial from a vector of roots. It can also be used to compute the characteristic equation of $\mathbf{A}$, as illustrated in Figure 6.23. The input matrix $\mathbf{A}$ is

$$
\mathbf{A}=\left[\begin{array}{rrr}
-8 & -16 & -6 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right],
$$

and the associated characteristic polynomial is

$$
s^{3}+8 s^{2}+16 s+6=0 .
$$

FIGURE 6.23 Computing the characteristic polynomial of $\mathbf{A}$ with the poly function.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0425.jpg?height=646&width=824&top_left_y=1468&top_left_x=385)If $\mathbf{A}$ is an $n \times n$ matrix, $\operatorname{poly}(\mathbf{A})$ is an $n+1$ element row vector whose elements are the coefficients of the characteristic equation $\operatorname{det}(s \mathbf{I}-\mathbf{A})=0$.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this section, we will examine the stability of the disk drive read system as $K_{a}$ is adjusted and then reconfigure the system.

Let us consider the system as shown in Figure 6.24. Initially, we consider the case where the switch is open. Then the closed-loop transfer function is

$$
\frac{Y(s)}{R(s)}=\frac{K_{a} G_{1}(s) G_{2}(s)}{1+K_{a} G_{1}(s) G_{2}(s)},
$$

where

$$
G_{1}(s)=\frac{5000}{s+1000} \quad \text { and } \quad G_{2}(s)=\frac{1}{s(s+20)} .
$$

The characteristic equation is

$$
s^{3}+1020 s^{2}+20000 s+5000 K_{a}=0 .
$$

The Routh array is

$$
\begin{array}{c|cc}
s^{3} & 1 & 20000 \\
s^{2} & 1020 & 5000 K_{a} \\
s^{1} & b_{1} & \\
s^{0} & 5000 K_{a} &
\end{array}
$$

where

$$
b_{1}=\frac{(20000) 1020-5000 K_{a}}{1020} .
$$

The case $b_{1}=0$ results in marginal stability when $K_{a}=4080$. Using the auxiliary equation, we have

$$
s^{2}+20000=0
$$

FIGURE 6.24

The closed-loop disk drive head system with an optional velocity feedback.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0426.jpg?height=515&width=1263&top_left_y=1605&top_left_x=488)

FIGURE 6.25

Equivalent system with the velocity feedback switch closed.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0427.jpg?height=292&width=1002&top_left_y=155&top_left_x=372)

or the roots of the $j \omega$-axis are $s= \pm j 141.4$. In order for the system to be stable, $K_{a}<4080$.

Now let us add the velocity feedback by closing the switch in the system of Figure 6.24. The closed-loop transfer function for the system is then

$$
\frac{Y(s)}{R(s)}=\frac{K_{a} G_{1}(s) G_{2}(s)}{1+\left[K_{a} G_{1}(s) G_{2}(s)\right]\left(1+K_{1} s\right)},
$$

since the feedback factor is equal to $1+K_{1} s$, as shown in Figure 6.25.

The characteristic equation is

$$
1+\left[K_{a} G_{1}(s) G_{2}(s)\right]\left(1+K_{1} s\right)=0,
$$

or

$$
s(s+20)(s+1000)+5000 K_{a}\left(1+K_{1} s\right)=0 .
$$

Therefore, we have

$$
s^{3}+1020 s^{2}+\left[20000+5000 K_{a} K_{1}\right] s+5000 K_{a}=0 .
$$

The Routh array is

$$
\begin{array}{c|cc}
s^{3} & 1 & 20000+5000 K_{a} K_{1} \\
s^{2} & 1020 & 5000 K_{a} \\
s^{1} & b_{1} & \\
s^{0} & 5000 K_{a} &
\end{array},
$$

where

$$
b_{1}=\frac{1020\left(20000+5000 K_{a} K_{1}\right)-5000 K_{a}}{1020} .
$$

To guarantee stability, it is necessary to select the pair $\left(K_{a}, K_{1}\right)$ such that $b_{1}>0$, where $K_{a}>0$. When $K_{1}=0.05$ and $K_{a}=100$, we can determine the system response using the script shown in Figure 6.26. The settling time (with a $2 \%$ criterion) is approximately $T_{s}=260 \mathrm{~ms}$, and the percent overshoot is P.O. $=0 \%$. The system performance is summarized in Table 6.3. The performance specifications are nearly satisfied, and some iteration of $K_{1}$ is necessary to obtain the desired $T_{s}=250 \mathrm{~ms}$. FIGURE 6.26

Response of the system with velocity feedback. (a) m-file script. (b) Response with $K_{a}=100$ and $K_{1}=0.05$.
$\mathrm{Ka}=100 ; \mathrm{K} 1=0.05$;

$\mathrm{ng} 1=[5000] ; \mathrm{dg} 1=[1$ 1000]; sys $1=\mathrm{tf}(\mathrm{ng} 1, \mathrm{dg} 1)$; ng2=[1]; dg2=[1 20 0]; sys2=tf(ng2,dg2);

$\mathrm{nc}=\left[\begin{array}{ll}\mathrm{K} 1 & 1\end{array}\right] ; \mathrm{dc}=\left[\begin{array}{ll}0 & 1\end{array}\right] ; \mathrm{sysc}=\mathrm{tf}(\mathrm{nc}, \mathrm{dc})$;

Select the velocity feedback gain $K_{1}$ and amplifier gain $K_{a}$.

syso=series $\left(\mathrm{Ka}^{*}\right.$ sys 1 , sys 2$)$;

sys=feedback(syso,sysc); sys=minreal(sys);

$\mathrm{t}=[0: 0.001: 0.5]$;

$\mathrm{y}=$ step(sys,t); plot(t,y)

ylabel('y(t)'), xlabel('Time (s)'), grid

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0428.jpg?height=856&width=932&top_left_y=652&top_left_x=522)

(b)

Table 6.3 Performance of the Disk Drive System Compared to the Specifications

\begin{tabular}{lll} 
Performance Measure & Desired Value & Actual Response \\
\hline $\begin{array}{l}\text { Percent overshoot } \\
\text { Settling time }\end{array}$ & Less than $5 \%$ & $0 \%$ \\
$\begin{array}{l}\text { Maximum response } \\
\text { to a unit disturbance }\end{array}$ & Less than $250 \mathrm{~ms}$ & $260 \mathrm{~ms}$ \\
\hline
\end{tabular}

\subsection{SUMMARY}

In this chapter, we have considered the concept of the stability of a feedback control system. A definition of a stable system in terms of a bounded system response was outlined and related to the location of the poles of the system transfer function in the $s$-plane. The Routh-Hurwitz stability criterion was introduced, and several examples were considered. The relative stability of a feedback control system was also considered in terms of the location of the poles and zeros of the system transfer function in the $s$-plane. The stability of state variable systems was considered.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 6.27 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0429.jpg?height=259&width=873&top_left_y=623&top_left_x=584)

FIGURE 6.27 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. A stable system is a dynamic system with a bounded output response for any input.

True or False

2. A marginally stable system has poles on the $j \omega$-axis.

True or False

3. A system is stable if all poles lie in the right half-plane.

True or False

4. The Routh-Hurwitz criterion is a necessary and sufficient criterion for determining the stability of linear systems.

True or False

5. Relative stability characterizes the degree of stability.

True or False

6. A system has the characteristic equation

$$
q(s)=s^{3}+4 K s^{2}+(5+K) s+10=0 .
$$

The range of $K$ for a stable system is:
a. $K \geq 0.46$
b. $K<0.46$
c. $0<K<0.46$
d. Unstable for all $K$

7. Utilizing the Routh-Hurwitz criterion, determine whether Systems 1 and 2 with the following polynomials are stable or unstable:

$$
\begin{aligned}
& p_{1}(s)=s^{2}+10 s+5, \\
& p_{2}(s)=s^{4}+s^{3}+5 s^{2}+20 s+10 .
\end{aligned}
$$

a. System 1 is stable, System 2 is stable

b. System 1 is unstable, System 2 is stable

c. System 1 is stable, System 2 is unstable

d. System 1 is unstable, System 2 is unstable 8. Consider the feedback control system block diagram in Figure 6.27. Investigate closedloop stability for $G_{c}(s)=K(s+1)$ and $G(s)=\frac{1}{(s+2)(s-1)}$, for the two cases where $K=1$ and $K=3$.
a. Unstable for $K=1$ and stable for $K=3$
b. Unstable for $K=1$ and unstable for $K=3$
c. Stable for $K=1$ and unstable for $K=3$
d. Stable for $K=1$ and stable for $K=3$

9. Consider a unity negative feedback system in Figure 6.27 with loop transfer function where

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(1+0.5 s)\left(1+0.5 s+0.25 s^{2}\right)} .
$$

Determine the value of $K$ for which the closed-loop system is marginally stable.
a. $K=10$
b. $K=3$
c. The system is unstable for all $K$
d. The system is stable for all $K$

10. A system is represented by $\dot{\mathbf{x}}=\mathbf{A x}$, where

$$
\mathbf{A}=\left[\begin{array}{rrc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-5 & -K & -10
\end{array}\right]
$$

The values of $K$ for a stable system are
a. $K<1 / 2$
b. $K>1 / 2$
c. $K=1 / 2$
d. The system is stable for all $K$

11. Use the Routh array to assist in computing the roots of the polynomial
a. $s_{1}=-1 ; s_{2,3}= \pm j \frac{\sqrt{2}}{2}$
b. $s_{1}=1 ; s_{2,3}= \pm j \frac{\sqrt{2}}{2}$
c. $s_{1}=-1 ; s_{2,3}=1 \pm j \frac{\sqrt{2}}{2}$
d. $s_{1}=-1 ; s_{2,3}=1$

$$
q(s)=2 s^{3}+2 s^{2}+s+1=0 .
$$

12. Consider the following unity feedback control system in Figure 6.27 where

$$
G(s)=\frac{1}{(s-2)\left(s^{2}+10 s+45\right)} \text { and } G_{c}(s)=\frac{K(s+0.3)}{s} .
$$

The range of $K$ for stability is
a. $K<260.68$
b. $50.06<K<123.98$
c. $100.12<K<260.68$
d. The system is unstable for all $K>0$ In Problems 13 and 14, consider the system represented in a state-space form

$$
\begin{aligned}
\dot{\mathbf{x}} & =\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-5 & -10 & -5
\end{array}\right] \mathbf{x}+\left[\begin{array}{c}
0 \\
0 \\
20
\end{array}\right] u \\
y & =\left[\begin{array}{lll}
1 & 0 & 1
\end{array}\right] \mathbf{x} .
\end{aligned}
$$

13. The characteristic equation is:
a. $q(s)=s^{3}+5 s^{2}-10 s-6$
b. $q(s)=s^{3}+5 s^{2}+10 s+5$
c. $q(s)=s^{3}-5 s^{2}+10 s-5$
d. $q(s)=s^{2}-5 s+10$

14. Using the Routh-Hurwitz criterion, determine whether the system is stable, unstable, or marginally stable.
a. Stable
b. Unstable
c. Marginally stable
d. None of the above

15. A system has the block diagram representation as shown in Figure 6.27, where $G(s)=\frac{10}{(s+15)^{2}}$ and $G_{c}(s)=\frac{K}{s+80}$, where $K$ is always positive. The limiting gain for a stable system is:
a. $0<K<28875$
b. $0<K<27075$
c. $0<K<25050$
d. Stable for all $K>0$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.
a. Routh-Hurwitz criterion
b. Auxiliary polynomial
c. Marginally stable

d. Stable system

e. Stability

f. Relative stability

g. Absolute stability
A performance measure of a system.

A dynamic system with a bounded system response to a bounded input.

The property that is measured by the relative real part of each root or pair of roots of the characteristic equation.

A criterion for determining the stability of a system by examining the characteristic equation of the transfer function.

The equation that immediately precedes the zero entry in the Routh array.

A system description that reveals whether a system is stable or not stable without consideration of other system attributes such as degree of stability.

A system possesses this type of stability if the zero input response remains bounded as $t \rightarrow \infty$. 

\section{EXERCISES}

E6.1 A system has a characteristic equation $s^{3}+5 K s^{2}+$ $(2+K) s+15=0$. Determine the range of $K$ for a stable system.

Answer: $K>0$

E6.2 A system has a characteristic equation $s^{3}+10 s^{2}+$ $2 s+30=0$. Using the Routh-Hurwitz criterion, show that the system is unstable.

E6.3 A system has the characteristic equation $s^{4}+10 s^{3}+$ $32 s^{2}+37 s+20=0$. Using the Routh-Hurwitz criterion, determine if the system is stable.

E6.4 A control system has the structure shown in Figure E6.4. Determine the gain at which the system will become unstable.

Answer: $K=20 / 7$

E6.5 A unity feedback system has a loop transfer function

$$
L(s)=\frac{K}{s(s+2)(s+5)(s+12)}
$$

where $K=15$. Find the roots of the closed-loop system's characteristic equation.

E6.6 A negative feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1)}{s(s-2)} .
$$

(a) Find the value of the gain when the $\zeta$ of the closed-loop roots is equal to 0.5. (b) Find the value of the gain when the closed-loop system has two roots on the imaginary axis.

E6.7 For the feedback system of Exercise E6.5, find the value of $K$ when two roots lie on the imaginary axis. Determine the value of the roots.

Answer: $s= \pm j 2.5131$
E6.8 Designers have developed small, fast, vertical-takeoff fighter aircraft that are invisible to radar (stealth aircraft). This aircraft concept uses quickly turning jet nozzles to steer the airplane [16]. The control system for the heading or direction control is shown in Figure E6.8. Determine the maximum gain of the system for stable operation.

E6.9 A system has a characteristic equation

$$
s^{3}+2 s^{2}+(K+1) s+8=0 .
$$

Find the range of $K$ for a stable system.

Answer: $K>3$

E6.10 Consider a feedback system with closed-loop transfer function

$$
T(s)=\frac{4}{s^{5}+4 s^{4}+8 s^{3}+8 s^{2}+7 s+4} .
$$

Is the system stable?

E6.11 A system with a transfer function $Y(s) / R(s)$ is

$$
\frac{Y(s)}{R(s)}=\frac{24(s+1)}{s^{4}+6 s^{3}+2 s^{2}+s+3} .
$$

Determine the steady-state error to a unit step input. Is the system stable?

E6.12 A system has the second-order characteristic equation

$$
s^{2}+a s+b=0,
$$

where $a$ and $b$ are constant parameters. Determine the necessary and sufficient conditions for the system to be stable. Is it possible to determine stability of a second-order system just by inspecting the coefficients of the characteristic equation?
FIGURE E6.4

Feedforward system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0432.jpg?height=249&width=1060&top_left_y=1576&top_left_x=505)

FIGURE E6.8

Aircraft heading control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0432.jpg?height=233&width=1018&top_left_y=1883&top_left_x=526)

FIGURE E6.13 Closed-loop system with a proportional plus derivative controller $G_{C}(s)=K_{P}+K_{D} s$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0433.jpg?height=264&width=878&top_left_y=155&top_left_x=370)

E6.13 Consider the feedback system in Figure E6.13. Determine the range of $K_{P}$ and $K_{D}$ for stability of the closed-loop system.

E6.14 By using magnetic bearings, a rotor is supported contactless. The technique of contactless support for rotors becomes more important in light and heavy industrial applications [14]. The matrix differential equation for a magnetic bearing system is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 5 & -1 \\
2 & -4 & 7 \\
-1 & 3 & 4
\end{array}\right] \mathbf{x}(t),
$$

where $\mathbf{x}^{T}(t)=(y(t), \dot{y}(t), i(t)), y(t)=$ bearing gap, and $i(t)$ is the electromagnetic current. Determine whether the system is stable.

Answer: The system is stable.

E6.15 A system has a characteristic equation

$$
\begin{aligned}
q(s)=s^{6}+ & 9 s^{5}+31.25 s^{4}+61.25 s^{3} \\
+ & 67.75 s^{2}+14.75 s+15=0 .
\end{aligned}
$$

(a) Determine whether the system is stable, using the Routh-Hurwitz criterion. (b) Determine the roots of the characteristic equation.

Answer: (a) The system is marginally stable.

(b) $s=-3,-4,-1 \pm 2 j, \pm 0.5 j$

E6.16 A system has a characteristic equation

$$
q(s)=s^{5}+5 s^{4}+12 s^{3}+6 s^{2}+42 s+10=0 .
$$

(a) Determine whether the system is stable, using the Routh-Hurwitz criterion. (b) Determine the roots of the characteristic equation.

E6.17 The matrix differential equation of a state variable model of a system is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
-6 & 1 & -3 \\
4 & -3 & 3 \\
-4 & -1 & -7
\end{array}\right] \mathbf{x}(t)
$$

(a) Determine the characteristic equation. (b) Determine whether the system is stable. (c) Determine the roots of the characteristic equation.

Answer: (a) $q(s)=s^{3}+16 s^{2}+68 s+80=0$
E6.18 A system has a characteristic equation

$$
q(s)=s^{3}+s^{2}+9 s+9=0 .
$$

(a) Determine whether the system is stable, using the Routh-Hurwitz criterion. (b) Determine the roots of the characteristic equation.

E6.19 Determine whether the systems with the following characteristic equations are stable or unstable:
(a) $s^{3}+4 s^{2}+6 s+100=0$,
(b) $s^{4}+6 s^{3}+10 s^{2}+17 s+6=0$, and
(c) $s^{2}+6 s+3=0$.

E6.20 Find the roots of the following polynomials:

(a) $s^{3}+5 s^{2}+8 s+4=0$ and

(b) $s^{3}+9 s^{2}+27 s+27=0$.

E6.21 A system has a transfer function $Y(s) / R(s)=$ $T(s)=1 / s(s+1)$. (a) Is this system stable? (b) If $r(t)$ is a unit step input, determine the response $y(t)$.

E6.22 A system has the characteristic equation

$$
q(s)=s^{3}+15 s^{2}+30 s+K=0 .
$$

Shift the vertical axis to the right by 1 by using $s=s_{n}-1$, and determine the value of gain $K$ so that the complex roots are $s=-1 \pm \sqrt{3} j$.

E6.23 The matrix differential equation of a state variable model of a system is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 1 & k \\
0 & 0 & 1 \\
-1 & -2 & -1
\end{array}\right] \mathbf{x}(t) .
$$

Find the range of $k$ where the system is stable.

E6.24 Consider the system represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{gathered}
\mathbf{A}=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-k & -k & -k
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] \\
\mathbf{C}=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right], \mathbf{D}=[0] .
\end{gathered}
$$

(a) What is the system transfer function? (b) For what E6.26 Consider the closed-loop system in Figure E6.26, values of $k$ is the system stable?

where

E6.25 A closed-loop feedback system is shown in Figure E6.25. For what range of values of the parameters $K$ and $p$ is the system stable?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0434.jpg?height=183&width=760&top_left_y=374&top_left_x=222)

FIGURE E6.25 Closed-loop system with parameters $K$ and $p$.

$$
G(s)=\frac{10}{s-10} \text { and } \quad G_{c}(s)=\frac{1}{2 s+K} .
$$

(a) Determine the characteristic equation associated with the closed-loop system.

(b) Determine the values of $K$ for which the closedloop system is stable.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0434.jpg?height=440&width=712&top_left_y=683&top_left_x=773)

(a)

FIGURE E6.26

Closed-loop feedback control system with parameter $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0434.jpg?height=352&width=1216&top_left_y=1240&top_left_x=519)

(b)

\section{PROBLEMS}

P6.1 Utilizing the Routh-Hurwitz criterion, determine the stability of the following polynomials:
(a) $s^{2}+5 s+2=0$
(b) $s^{3}+4 s^{2}+8 s+4=0$
(c) $s^{3}+2 s^{2}-6 s+20=0$
(d) $s^{4}+s^{3}+2 s^{2}+12 s+10=0$

(e) $s^{4}+s^{3}+3 s^{2}+2 s+K=0$

(f) $s^{5}+s^{4}+2 s^{3}+s+6=0$

(g) $s^{5}+s^{4}+2 s^{3}+s^{2}+s+K=0$

Determine the number of roots, if any, in the righthand plane. If it is adjustable, determine the range of $K$ that results in a stable system. P6.2 An antenna control system was analyzed in Problem P4.5, and it was determined that, to reduce the effect of wind disturbances, the gain of the magnetic amplifier, $k_{a}$, should be as large as possible. (a) Determine the limiting value of gain for maintaining a stable system. (b) We want to have a system settling time equal to 1.5 seconds. Using a shifted axis and the Routh-Hurwitz criterion, determine the value of the gain that satisfies this requirement. Assume that the complex roots of the closed-loop system dominate the transient response. (Is this a valid approximation in this case?)

P6.3 Arc welding is one of the most important areas of application for industrial robots [11]. In most manufacturing welding situations, uncertainties in dimensions of the part, geometry of the joint, and the welding process itself require the use of sensors for maintaining weld quality. Several systems use a vision system to measure the geometry of the puddle of melted metal, as shown in Figure P6.3. This system uses a constant rate of feeding the wire to be melted. (a) Calculate the maximum value for $K$ for the system that will result in a stable system. (b) For half of the maximum value of $K$ found in part (a), determine the roots of the characteristic equation. (c) Estimate the overshoot of the system of part (b) when it is subjected to a step input.
P6.4 A feedback control system is shown in Figure P6.4. The controller and process transfer functions are given by

$$
G_{c}(s)=K \text { and } G(s)=\frac{s+100}{s(s+25)},
$$

and the feedback transfer function is $H(s)=1$ / $(s+50)$. (a) Determine the limiting value of gain $K$ for a stable system. (b) For the gain that results in marginal stability, determine the magnitude of the imaginary roots. (c) Reduce the gain to one-third of the magnitude of the marginal value, and determine the relative stability of the system (1) by shifting the axis and using the Routh-Hurwitz criterion and (2) by determining the root locations. Show the roots are between -4 and -5 .

P6.5 Determine the relative stability of the systems with the following characteristic equations (1) by shifting the axis in the $s$-plane and using the Routh-Hurwitz criterion, and (2) by determining the location of the complex roots in the $s$-plane:
(a) $s^{3}+3 s^{2}+4 s+2=0$.
(b) $s^{4}+9 s^{3}+30 s^{2}+42 s+20=0$.
(c) $s^{3}+19 s^{2}+110 s+200=0$.

P6.6 A unity-feedback control system is shown in Figure P6.6. Determine the stability of the system
FIGURE P6.3

Welder control.

FIGURE P6.4 Nonunity feedback system.

FIGURE P6.6 Unity feedback system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0435.jpg?height=988&width=1114&top_left_y=1124&top_left_x=374)with the following loop transfer functions using the Routh-Hurwitz criterion:
(a) $G_{c}(s) G(s)=\frac{(10 s+30)(s+1)}{s^{2}(s-2)}$
(b) $G_{c}(s) G(s)=\frac{10}{s\left(s^{3}+2 s^{2}+5 s+2\right)}$
(c) $G_{c}(s) G(s)=\frac{s^{2}+s+3}{s(s+1)(s+2)}$

P6.7 The linear model of a phase detector (phase-lock loop) can be represented by Figure P6.7 [9]. The phase-lock systems are designed to maintain zero difference in phase between the input carrier signal and a local voltage-controlled oscillator. The filter for a particular application is chosen as

$$
F(s)=\frac{5(s+60)}{(s+3)(s+100)} .
$$

We want to minimize the steady-state error of the system for a ramp change in the phase information signal. (a) Determine the limiting value of the gain $K_{a} K=K_{v}$ in order to maintain a stable system. (b) A steady-state error equal to $3^{\circ}$ is acceptable for a ramp signal of $120 \mathrm{rad} / \mathrm{s}$. For that value of gain $K_{v}$, determine the location of the roots of the system.
P6.8 A very interesting and useful velocity control system has been designed for a wheelchair control system. A proposed system utilizing velocity sensors mounted in a headgear is shown in Figure P6.8. The headgear sensor provides an output proportional to the magnitude of the head movement. There is a sensor mounted at $90^{\circ}$ intervals so that forward, left, right, or reverse can be commanded. Typical values for the time constants are $\tau_{1}=0.5 \mathrm{~s}, \tau_{2}=1 \mathrm{~s}$, and $\tau_{3}=1 / 4 \mathrm{~s}$.

(a) Determine the limiting gain $K=K_{1} K_{2} K_{3}$ for a stable system.

(b) When the gain $K$ is set equal to one-third of the limiting value, determine whether the settling time (to within $2 \%$ of the final value of the system) is $T_{s} \leq 4 \mathrm{~s}$.

(c) Determine the value of gain that results in a system with a settling time of $T_{s} \leq 4 \mathrm{~s}$. Also, obtain the value of the roots of the characteristic equation when the settling time is $T_{s} \leq 4 \mathrm{~s}$.

P6.9 A cassette tape storage device has been designed for mass-storage [1]. It is necessary to control the velocity of the tape accurately. The speed control of the tape drive is represented by the system shown in Figure P6.9.
FIGURE P6.7

Phase-lock loop system.

FIGURE P6.8 Wheelchair control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0436.jpg?height=938&width=1262&top_left_y=1170&top_left_x=506)

FIGURE P6.9

Tape drive control. (a) Determine the limiting gain for a stable system.

(b) Determine a suitable gain so that the percent overshoot to a step command is P.O. $=5 \%$.

P6.10 Robots can be used in manufacturing and assembly operations that require accurate, fast, and versatile manipulation $[10,11]$. The loop transfer function of a direct-drive arm is

$$
G_{c}(s) G(s)=\frac{K(s+4)}{s\left(s^{3}+5 s^{2}+17 s+10\right)} .
$$

(a) Determine the value of gain $K$ when the system oscillates. (b) Calculate the roots of the closed-loop system for the $K$ determined in part (a).

P6.11 A feedback control system has a characteristic equation

$$
s^{3}+(1+K) s^{2}+10 s+(5+15 K)=0 .
$$

The parameter $K$ must be positive. What is the maximum value $K$ can assume before the system becomes unstable? When $K$ is equal to the maximum value, the system oscillates. Determine the frequency of oscillation.

P6.12 A system has the third-order characteristic equation

$$
s^{3}+a s^{2}+b s+c=0,
$$

where $a, b$, and c are constant parameters. Determine the necessary and sufficient conditions for the system to be stable. Is it possible to determine stability of the system by just inspecting the coefficients of the characteristic equation?

P6.13 Consider the system in Figure P6.13. Determine the conditions on $K, p$, and $z$ that must be satisfied for closed-loop stability. Assume that $K>0, \zeta>0$, and $\omega_{n}>0$.

P6.14 A feedback control system has a characteristic equation

$$
s^{6}+2 s^{5}+12 s^{4}+4 s^{3}+21 s^{2}+2 s+10=0 .
$$

Determine whether the system is stable, and determine the values of the roots.
P6.15 The stability of a motorcycle and rider is an important area for study $[12,13]$. The handling characteristics of a motorcycle must include a model of the rider as well as one of the vehicle. The dynamics of one motorcycle and rider can be represented by the loop transfer function

$$
L(s)=\frac{K\left(s^{2}+40 s+600\right)}{s(s+10)\left(s^{2}+20 s+500\right)\left(s^{2}+80 s+2000\right)} .
$$

(a) As an approximation, calculate the acceptable range of $K$ for a stable unity negative feedback system when the numerator polynomial (zeros) and the denominator polynomial $\left(s^{2}+80 s+2000\right)$ are neglected. (b) Calculate the actual range of acceptable $K$, account for all zeros and poles.

P6.16 A system has a closed-loop transfer function

$$
T(s)=\frac{1}{s^{4}+2 s^{3}+16 s^{2}+20 s+4} .
$$

(a) Determine whether the system is stable. (b) Determine the roots of the characteristic equation. (c) Plot the response of the system to a unit step input.

P6.17 The elevator in Yokohama's 70-story Landmark Tower operates at a peak speed of $45 \mathrm{~km} / \mathrm{hr}$. To reach such a speed without inducing discomfort in passengers, the elevator accelerates for longer periods, rather than more precipitously. Going up, it reaches full speed only at the 27 th floor; it begins decelerating 15 floors later. The result is a peak acceleration similar to that of other skyscraper elevators - a bit less than a tenth of the force of gravity. Admirable ingenuity has gone into making this safe and comfortable. Special ceramic brakes had to be developed; iron ones would melt. Computer-controlled systems damp out vibrations. The lift has been streamlined to reduce the wind noise as it speeds up and down [19]. One proposed control system for the elevator vertical position is shown in Figure P6.17. Determine the range of $K$ for a stable system, where $K>0$.
FIGURE P6.13

Control system with controller with three parameters $K, p$, and $z$.

FIGURE P6.17 Elevator control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0437.jpg?height=494&width=1098&top_left_y=1622&top_left_x=374)P6.18 Consider the case of rabbits and foxes. The number of rabbits is $x_{1}$ and, if left alone, it would grow indefinitely (until the food supply was exhausted) so that

$$
\dot{x}_{1}=k x_{1} \text {. }
$$

However, with foxes present, we have

$$
\dot{x}_{1}=k x_{1}-a x_{2},
$$

where $x_{2}$ is the number of foxes. Now, if the foxes must have rabbits to exist, we have

$$
\dot{x}_{2}=-h x_{2}+b x_{1} \text {. }
$$

Determine whether this system is stable and thus decays to the condition $x_{1}(t)=x_{2}(t)=0$ at $t=\infty$. What are the requirements on $a, b, h$, and $k$ for a stable system? What is the result when $k$ is greater than $h$ ?

P6.19 The goal of vertical takeoff and landing (VTOL) aircraft is to achieve operation from relatively small airports and yet operate as a normal aircraft in level flight [16]. An aircraft taking off in a form similar to a rocket is inherently unstable. A control system using adjustable jets can control the vehicle, as shown in Figure P6.19. (a) Determine the range of gain for which the system is stable. (b) Determine the gain $K$ for which the system is marginally stable and the roots of the characteristic equation for this value of $K$.

P6.20 A personal vertical take-off and landing (VTOL) aircraft is shown in Figure P6.20(a). A possible control system for aircraft altitude is shown in Figure P6.20(b). (a) For $K=17$, determine whether the system is stable.

(b) Determine a range of stability, if any, for $K>0$.

P6.21 Consider the system described in state variable form by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-k_{1} & -k_{2}
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right] \text {, and } \mathbf{C}=\left[\begin{array}{ll}
1 & -1
\end{array}\right] \text {, }
$$
and where $k_{1} \neq k_{2}$ and both $k_{1}$ and $k_{2}$ are real numbers.

(a) Compute the state transition matrix $\Phi(t, 0)$.

(b) Compute the eigenvalues of the system matrix $\mathbf{A}$.

(c) Compute the roots of the characteristic polynomial. (d) Discuss the results of parts (a)-(c) in terms of stability of the system.
FIGURE P6.19 Control of a jump-jet aircraft.

FIGURE P6.20

(a) Personal VTOL aircraft. (Cheskyw/123RF.)

(b) Control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0438.jpg?height=806&width=1042&top_left_y=1012&top_left_x=518)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0438.jpg?height=183&width=917&top_left_y=1877&top_left_x=520)

(b) 

\section{ADVANCED PROBLEMS}

AP6.1 A teleoperated control system incorporates both a person (operator) and a remote machine. The normal teleoperation system is based on a one-way link to the machine and limited feedback to the operator. However, two-way coupling using bilateral information exchange enables better operation [18]. In the case of remote control of a robot, force feedback plus position feedback is useful. The characteristic equation for a teleoperated system, as shown in Figure AP6.1, is

$$
s^{4}+12 s^{3}+K_{1} s^{2}+2 s+10 K_{2}=0,
$$

where $K_{1}$ and $K_{2}$ are feedback gain factors. Determine and plot the region of stability for this system for $K_{1}$ and $K_{2}$.

AP6.2 Consider the case of a navy pilot landing an aircraft on an aircraft carrier. The pilot has three basic tasks. The first task is guiding the aircraft's approach to the ship along the extended centerline of the runway. The second task is maintaining the aircraft on the correct glideslope. The third task is maintaining the correct speed. A model of a lateral position control system is shown in Figure AP6.2. Determine the range of stability for $K \geq 0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0439.jpg?height=292&width=740&top_left_y=1098&top_left_x=91)

FIGURE AP6.1 Model of a teleoperated machine.
AP6.3 A control system is shown in Figure AP6.3. We want the system to be stable and the steady-state error for a unit step input to be less than or equal to 0.1 . (a) Determine the range of $\alpha$ that satisfies the error requirement. (b) Determine the range of $\alpha$ that satisfies the stability requirement. (c) Select an $\alpha$ that meets both requirements.

AP6.4 A bottle-filling line uses a feeder screw mechanism, as shown in Figure AP6.4. The tachometer feedback is used to maintain accurate speed control. Determine and plot the range of $K$ and $p$ that permits stable operation.

AP6.5 Consider the closed-loop system in Figure AP6.5. Suppose that all gains are positive, that is, $K_{1}>0, K_{2}>0, K_{3}>0, K_{4}>0$, and $K_{5}>0$.

(a) Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$.

(b) Obtain the conditions on selecting the gains $K_{1}, K_{2}, K_{3}, K_{4}$, and $K_{5}$, so that the closedloop system is guaranteed to be stable.

(c) Using the results of part (b), select values of the five gains so that the closed-loop system is stable, and plot the unit step response.

AP6.6 A spacecraft with a camera is shown in Figure AP6.6(a). The camera slews about $16^{\circ}$ in a canted plane relative to the base. Reaction jets stabilize the base against the reaction torques from the slewing motors. Suppose that the rotational speed control for the camera slewing has a plant transfer function

$$
G(s)=\frac{1}{(s+1)(s+2)(s+4)}
$$

FIGURE AP6.2

Lateral position control for landing on an aircraft carrier.

FIGURE AP6.3 Third-order unity feedback system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0439.jpg?height=610&width=1260&top_left_y=1504&top_left_x=358)FIGURE AP6.4 Speed control of a bottle-filling line.

(a) System layout.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0440.jpg?height=771&width=1176&top_left_y=151&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0440.jpg?height=229&width=1005&top_left_y=1026&top_left_x=601)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0440.jpg?height=266&width=1176&top_left_y=1339&top_left_x=353)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0440.jpg?height=320&width=1432&top_left_y=1712&top_left_x=225)

(b)

FIGURE AP6.5 Multiloop feedback control system. (a) Signal flow graph. (b) Block diagram. FIGURE AP6.6

(a) Spacecraft with a camera.

(b) Feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0441.jpg?height=581&width=903&top_left_y=152&top_left_x=414)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0441.jpg?height=309&width=1113&top_left_y=824&top_left_x=415)

(b)
A proportional plus derivative controller is used in a system as shown in Figure AP6.6(b), where

$$
G_{c}(s)=K_{p}+K_{D} s,
$$

and where $K_{p}>0$ and $K_{D}>0$. Obtain and plot the relationship between $K_{p}$ and $K_{D}$ that results in a stable closed-loop system.

AP6.7 A human's ability to perform physical tasks is limited not by intellect but by physical strength. If, in an appropriate environment, a machine's mechanical power is closely integrated with a human arm's mechanical strength under the control of the human intellect, the resulting system will be superior to a loosely integrated combination of a human and a fully automated robot.

Extenders are defined as a class of robot manipulators that extend the strength of the human arm while maintaining human control of the task [23]. The defining characteristic of an extender is the transmission of both power and information signals.
The extender is worn by the human; the physical contact between the extender and the human allows the direct transfer of mechanical power and information signals. Because of this unique interface, control of the extender trajectory can be accomplished without any type of joystick or keyboard. The human provides a control system for the extender, while the extender actuators provide most of the strength necessary for the task. The human becomes a part of the extender and "feels" a scaled-down version of the load that the extender is carrying. An extender is shown in Figure AP6.7(a) [23]. The block diagram of the system is shown in Figure AP6.7(b). Consider the proportional plus derivative controller

$$
G_{c}(s)=K_{p}+K_{D} s .
$$

Determine the range of values of the controller gains $K_{P}$ and $K_{D}$ such that the closed-loop system is stable. FIGURE AP6.7

Extender robot control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0442.jpg?height=482&width=717&top_left_y=152&top_left_x=655)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0442.jpg?height=242&width=1307&top_left_y=728&top_left_x=221)

(b)

\section{DESIGN PROBLEMS}

CDP6.1 The capstan drive system of problem CDP5.1 uses the amplifier as the controller. Determine the maximum value of the gain $K_{a}$ before the system becomes unstable.

DP6.1 The control of the spark ignition of an automotive engine requires constant performance over a wide range of parameters [15]. The control system is shown in Figure DP6.1, with a controller gain $K$ to be selected. The parameter $p$ is equal to 2 for many autos but can equal zero for those with high performance.
Select a gain $K$ that will result in a stable system for both values of $p$.

DP6.2 An automatically guided vehicle on Mars is represented by the system in Figure DP6.2. The system has a steerable wheel in both the front and back of the vehicle, and the design requires that $H(s)=K s+1$. Determine (a) the value of $K$ required for stability, (b) the value of $K$ when one root of the characteristic equation is equal to $s=-1$, and (c) the value of the two remaining roots for the gain selected in
FIGURE DP6.1

Automobile engine control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0442.jpg?height=437&width=1086&top_left_y=1675&top_left_x=513)

FIGURE DP6.2

Mars guided vehicle control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0443.jpg?height=243&width=1056&top_left_y=156&top_left_x=375)

part (b). (d) Find the response of the system to a step command for the gain selected in part (b).

DP6.3 A unity negative feedback system with

$$
L(s)=G_{c}(s) G(s)=\frac{K(1+2 s)}{s(1+\tau s)(1+5 s)}
$$

has two parameters to be selected. (a) Determine and plot the regions of stability for this system. (b) Select $\tau$ and $K$ so that the steady-state error to a unit ramp input is less than or equal to 0.1. (c) Determine the percent overshoot for a step input for the design selected in part (b).

DP6.4 The attitude control system of a rocket is shown in Figure DP6.4 [17]. (a) Determine the range of gain $K$ and parameter $m$ so that the system is stable, and plot the region of stability. (b) Select the gain and parameter values so that the steady-state error to a ramp input is less than or equal to $10 \%$ of the input magnitude. (c) Determine the percent overshoot for a step input for the design selected in part (b).

DP6.5 A traffic control system is designed to control the distance between vehicles, as shown in Figure DP6.5 [15]. (a) Determine the range of gain $K$ for which the system is stable. (b) If $K_{m}$ is the maximum value of $K$ so that the characteristic roots are on the $j \omega$-axis, then let $K=K_{m} / N$, where $N$ is to be selected. We want the peak time to be $T_{p} \leq 2 \mathrm{~s}$ and the percent overshoot to be P.O. $\leq 20 \%$. Determine an appropriate value for $N$.

DP6.6 Consider the single-input, single-output system as described by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{rr}
0 & 1 \\
2 & -2
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right] .
$$

Assume that the input is a linear combination of the states, that is,

$$
u(t)=-\mathbf{K x}(t)+r(t),
$$

where $r(t)$ is the reference input. The matrix $\mathbf{K}=$ $\left[\begin{array}{ll}K_{1} & K_{2}\end{array}\right]$ is known as the gain matrix. If you substitute $u(t)$ into the state variable equation you obtain the closed-loop system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =[\mathbf{A}-\mathbf{B K}] \mathbf{x}(t)+\mathbf{B} r(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t) .
\end{aligned}
$$

For what values of $\mathbf{K}$ is the closed-loop system stable? Determine the region of the left half-plane where the desired closed-loop eigenvalues should be placed
FIGURE DP6.4

Rocket attitude

control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0443.jpg?height=586&width=1000&top_left_y=1524&top_left_x=375)

FIGURE DP6.5

Traffic distance control. FIGURE DP6.7

Feedback system with inner and outer loop.

\section{FIGURE DP6.8}

A marginally stable plant with a PD controller in the loop.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0444.jpg?height=716&width=882&top_left_y=155&top_left_x=507)

so that the percent overshoot to a unit step input, $R(s)=1 / s$, is $P . O .<5 \%$ and the settling time is $T_{s}<4 \mathrm{~s}$. Select a gain matrix, $\mathbf{K}$, so that the system step response meets the specifications P.O. $<5 \%$ and $T_{s}<4 s$.

DP6.7 Consider the feedback control system in Figure DP6.7. The system has an inner loop and an outer loop. The inner loop must be stable and have a quick speed of response. (a) Consider the inner loop first. Determine the range of $K_{1}$ resulting in a stable inner loop. That is, the transfer function $Y(s) / U(s)$ must be stable. (b) Select the value of $K_{1}$ in the stable range leading to the fastest step response. (c) For the value of $K_{1}$ selected in (b), determine the range of $K_{2}$ such that the closed-loop system $T(s)=Y(s) / R(s)$ is stable.

DP6.8 Consider the feedback system shown in Figure DP6.8. The process transfer function is marginally stable. The controller is the proportional-derivative (PD) controller

$$
G_{c}(s)=K_{P}+K_{D} s .
$$

Determine if it is possible to find values of $K_{P}$ and $K_{D}$ such that the closed-loop system is stable. If so, obtain values of the controller parameters such that the steadystate tracking error $E(s)=R(s)-Y(s)$ to a unit step input $R(s)=1 / s$ is $e_{\mathrm{ss}}=\lim _{t \rightarrow \infty} e(t) \leq 0.01$ and the damping of the closed-loop system is $\zeta=\sqrt{2} / 2$.

\section{COMPUTER PROBLEMS}

CP6.1 Determine the roots of the following characteristic equations:
(a) $q(s)=s^{3}+3 s^{2}+10 s+14=0$.
(b) $q(s)=s^{4}+8 s^{3}+24 s^{2}+32 s+16=0$.
(c) $q(s)=s^{4}+2 s^{2}+1=0$.

CP6.2 Consider a unity negative feedback system with

$$
G_{c}(s)=K \text { and } G(s)=\frac{s^{2}-s+2}{s^{2}+2 s+1} .
$$

Develop an m-file to compute the roots of the closedloop transfer function characteristic polynomial for $K=1,2$, and 5 . For which values of $K$ is the closedloop system stable?
CP6.3 A unity negative feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+4}{s^{3}+10 s^{2}+4 s+25} .
$$

Develop an m-file to determine the closed-loop transfer function, and show that the roots of the characteristic equation are $s_{1}=-9.79$ and $s_{2,3}=-0.104$ $\pm j 1.7178$.

CP6.4 Consider the closed-loop transfer function

$$
T(s)=\frac{s+6}{s^{3}+4 s^{2}+15 s+42} .
$$

(a) Using the Routh-Hurwitz method, determine whether the system is stable. If it is not stable, how many poles are in the right half-plane? (b) Compute the poles of $T(s)$, and verify the result in part (a).

(c) Plot the unit step response, and discuss the results.

CP6.5 A "paper-pilot" model is sometimes utilized in aircraft control design and analysis to represent the pilot in the loop. A block diagram of an aircraft with a pilot "in the loop" is shown in Figure CP6.5. The variable $\tau$ represents the pilot's time delay. Assume that we have a fast pilot with $\tau=0.1$ and $K=1$. Develop an m-file to obtain the region of stability for $\tau_{1}$ and $\tau_{2}$, changing in the range of 0 to 5 . Show step responses for two points: one inside and one outside of this region.

CP6.6 Consider the feedback control system in Figure CP6.6. Using the for function, develop an m-file script to compute the closed-loop transfer function poles for $0 \leq K \leq 5$ and plot the results denoting the poles with the " $x$ " symbol. Determine the maximum range of $K$ for stability with the Routh-Hurwitz method. Compute the roots of the characteristic equation when $K$ is the minimum value allowed for stability.

CP6.7 Consider a system in state variable form:

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-5 & -12 & -8
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t), \\
y(t)=\left[\begin{array}{lll}
1 & 1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{gathered}
$$

(a) Compute the characteristic equation using the poly function. (b) Compute the roots of the characteristic equation, and determine whether the system is stable. (c) Obtain the response plot of $y(t)$ when $u(t)$ is a unit step and when the system has zero initial conditions.

CP6.8 Consider the feedback control system in Figure CP6.8. (a) Using the Routh-Hurwitz method, determine the range of $K_{1}$ resulting in closed-loop stability. (b) Develop an m-file to plot the pole locations as a function of $0<K_{1}<30$ and comment on the results.

CP6.9 Consider a system represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{gathered}
\mathbf{A}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-k & -15 & -3
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
2 \\
0
\end{array}\right], \\
\mathbf{C}=\left[\begin{array}{lll}
4 & 0 & 1
\end{array}\right], \mathbf{D}=[0]
\end{gathered}
$$

(a) For what values of $k$ is the system stable?

(b) Develop an m-file to plot the pole locations as a function of $0<k<50$, and comment on the results.
FIGURE CP 6.5

An aircraft with a pilot in the loop.

FIGURE CP6.6 A single-loop feedback control system with parameter $K$.

FIGURE CP6.8 Nonunity feedback system with parameter $K_{1}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0445.jpg?height=894&width=1260&top_left_y=1222&top_left_x=376)

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) False; (2) True; (3) False; (4) True; (5) True

Multiple Choice: (6) a; (7) c; (8) a; (9) b; (10) b; (11) a; (12) c; (13) b; (14) a; (15) b
Word Match (in order, top to bottom): e, d, f, a, b, $\mathrm{g}, \mathrm{c}$

\section{TERMS AND CONCEPTS}

Absolute stability A system description that reveals whether a system is stable or not stable without consideration of other system attributes such as degree of stability.

Auxiliary polynomial The equation that immediately precedes the zero entry in the Routh array.

Marginally stable A system is marginally stable if and only if the zero input response remains bounded as $t \rightarrow \infty$.

Relative stability The property that is measured by the relative real part of each root or pair of roots of the characteristic equation.
Routh-Hurwitz criterion A criterion for determining the stability of a system by examining the characteristic equation of the transfer function. The criterion states that the number of roots of the characteristic equation with positive real parts is equal to the number of changes of sign of the coefficients in the first column of the Routh array.

Stability A performance measure of a system. A system is stable if all the poles of the transfer function have negative real parts.

Stable system A dynamic system with a bounded system response to a bounded input. 

\title{
CHAPTER
}

\section{The Root Locus Method}

\author{
7.1 Introduction 447 \\ 7.2 The Root Locus Concept 447 \\ 7.3 The Root Locus Procedure 452 \\ 7.4 Parameter Design by the Root Locus Method 466 \\ 7.5 Sensitivity and the Root Locus 472 \\ 7.6 PID Controllers 477 \\ 7.7 Negative Gain Root Locus 488 \\ 7.8 Design Examples 493 \\ 7.9 The Root Locus Using Control Design Software 502 \\ 7.10 Sequential Design Example: Disk Drive Read System 508 \\ $\mathbf{7 . 1 1}$ Summary $\mathbf{5 1 0}$
}

\section{PREVIEW}

The performance of a feedback system can be described in terms of the location of the roots of the characteristic equation in the $s$-plane. A graph showing how the roots of the characteristic equation move around the $s$-plane as a single parameter varies is known as a root locus plot. The root locus is a powerful tool for designing and analyzing feedback control systems. We will discuss practical techniques for obtaining a sketch of a root locus plot. We also consider computer-generated root locus plots and illustrate their effectiveness in the design process. We show that it is possible to use root locus methods for controller design when more than one parameter varies. This is important because we know that the response of a closed-loop feedback system can be adjusted to achieve the desired performance by judicious selection of one or more controller parameters. The popular PID controller is introduced as a practical controller structure. We also define a measure of sensitivity of a specified root to a small incremental change in a system parameter. The chapter concludes with a controller design based on root locus methods for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 7, students should be able to:

$\square \quad$ Describe the powerful concept of the root locus and its role in control system design.

$\square \quad$ Create a root locus plot by sketching or using computers.

$\square \quad$ Identify the PID controller as a key element of many feedback systems.

$\square$ Explain the role of root locus plots in parameter design and system sensitivity analysis.

$\square$ Design controllers to meet desired specifications using root locus methods. 

\subsection{INTRODUCTION}

The relative stability and the transient performance of a closed-loop control system are directly related to the location of the closed-loop roots of the characteristic equation in the $s$-plane. It is frequently necessary to adjust one or more system parameters in order to obtain suitable root locations. Therefore, it is worthwhile to determine how the roots of the characteristic equation of a given system migrate about the $s$-plane as the parameters are varied; that is, it is useful to determine the locus of roots in the $s$-plane as a parameter is varied. The root locus method was introduced by Evans in 1948 and has been developed and utilized extensively in control engineering practice [1-3]. The root locus technique is a graphical method for sketching the locus of roots in the $s$-plane as a parameter is varied. The root locus method provides the engineer with a measure of the sensitivity of the roots of the system to a variation in the parameter being considered. The root locus technique may be used to great advantage in conjunction with the Routh-Hurwitz criterion.

The root locus method provides graphical information, and therefore an approximate sketch can be used to obtain qualitative information concerning the stability and performance of the system. Furthermore, the locus of roots of the characteristic equation of a multiloop system may be investigated as readily as for a single-loop system. If the root locations are not satisfactory, the necessary parameter adjustments often can be readily ascertained from the root locus [4].

\subsection{THE ROOT LOCUS CONCEPT}

The dynamic performance of a closed-loop control system is described by the closed-loop transfer function

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{p(s)}{q(s)},
$$

where $p(s)$ and $q(s)$ are polynomials in $s$. The roots of the characteristic equation $q(s)$ determine the modes of response of the system. In the case of the simple single-loop system shown in Figure 7.1, we have the characteristic equation

$$
1+K G(s)=0
$$

where $K$ is a variable parameter and $0 \leq K<\infty$. The characteristic roots of the system must satisfy Equation (7.2), where the roots lie in the $s$-plane. Because $s$ is a complex variable, Equation (7.2) may be rewritten in polar form as

$$
|K G(s)| \underline{K G(s)}=-1+j 0,
$$

FIGURE 7.1

Closed-loop control system with a variable parameter $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0448.jpg?height=153&width=792&top_left_y=1956&top_left_x=505)

and therefore it is necessary that

$$
|K G(s)|=1
$$

and

$$
\angle K G(s)=180^{\circ}+k 360^{\circ}
$$

where $k=0, \pm 1, \pm 2, \pm 3, \ldots$

\section{The root locus is the path of the roots of the characteristic equation traced} out in the $s$-plane as a system parameter varies from zero to infinity.

Consider the second-order system shown in Figure 7.2. The characteristic equation is

$$
\Delta(s)=1+K G(s)=1+\frac{K}{s(s+2)}=0,
$$

or, alternatively,

$$
\Delta(s)=s^{2}+2 s+K=s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=0 .
$$

The locus of the roots as the gain $K$ is varied is found by requiring that

$$
|K G(s)|=\left|\frac{K}{s(s+2)}\right|=1
$$

and

$$
\not K G(s)= \pm 180^{\circ}, \pm 540^{\circ}, \ldots
$$

The gain $K$ is varied from zero to infinity. For a second-order system, the roots are

$$
s_{1}, s_{2}=-\zeta \omega_{n} \pm \omega_{n} \sqrt{\zeta^{2}-1}
$$

and for $\zeta<1$, we know that $\theta=\cos ^{-1} \zeta$. Graphically, for two open-loop poles as shown in Figure 7.3, the locus of roots is a vertical line for $\zeta \leq 1$ in order to satisfy the angle requirement, Equation (7.7). For example, as shown in Figure 7.4, at a root $s_{1}$, the angles are

$$
\left\langle\left.\frac{K}{s(s+2)}\right|_{s=s_{1}}=-\angle s_{1}-\angle\left(s_{1}+2\right)=-\left[\left(180^{\circ}-\theta\right)+\theta\right]=-180^{\circ} .\right.
$$

FIGURE 7.2

Unity feedback control system. The gain $K$ is a variable parameter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0449.jpg?height=185&width=780&top_left_y=1935&top_left_x=372)

FIGURE 7.3

Root locus for a second-order system when $K_{e}<K_{1}<K_{2}$. The locus is shown as heavy lines, with arrows indicating the direction of increasing $K$. Note that roots of the characteristic equation are denoted by " $\square$ " on the root locus.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0450.jpg?height=635&width=618&top_left_y=155&top_left_x=519)

This angle requirement is satisfied at any point on the vertical line that is a perpendicular bisector of the line 0 to -2 . Furthermore, the gain $K$ at the particular points is found by using Equation (7.6) as

$$
\left|\frac{K}{s(s+2)}\right|_{s=s_{1}}=\frac{K}{\left|s_{1}\right|\left|s_{1}+2\right|}=1,
$$

and thus

$$
K=\left|s_{1}\right|\left|s_{1}+2\right|,
$$

where $\left|s_{1}\right|$ is the magnitude of the vector from the origin to $s_{1}$, and $\left|s_{1}+2\right|$ is the magnitude of the vector from -2 to $s_{1}$.

For a multiloop closed-loop system, using the Mason's signal-flow gain formula yields

$$
\Delta(s)=1-\sum_{n=1}^{N} L_{n}+\sum_{\substack{n, m \\ \text { nontouching }}} L_{n} L_{m}-\sum_{\substack{n, m, p \\ \text { nontouching }}} L_{n} L_{m} L_{p}+\cdots,
$$

FIGURE 7.4

Evaluation of the angle and gain at $s_{1}$ for gain $K=K_{1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0450.jpg?height=510&width=555&top_left_y=1594&top_left_x=520)

where $L_{n}$ equals the value of the $n$th self-loop transmittance. Hence, we have a characteristic equation, which may be written as

$$
q(s)=\Delta(s)=1+F(s) .
$$

To find the roots of the characteristic equation, we set Equation (7.13) equal to zero and obtain

$$
1+F(s)=0 .
$$

Equation (7.14) may be rewritten as

$$
F(s)=-1+j 0,
$$

and the roots of the characteristic equation must also satisfy this relation.

In general, the function $F(s)$ may be written as

$$
F(s)=\frac{K\left(s+z_{1}\right)\left(s+z_{2}\right)\left(s+z_{3}\right) \cdots\left(s+z_{M}\right)}{\left(s+p_{1}\right)\left(s+p_{2}\right)\left(s+p_{3}\right) \cdots\left(s+p_{n}\right)} .
$$

Then the magnitude and angle requirement for the root locus are

$$
|F(s)|=\frac{K\left|s+z_{1}\right|\left|s+z_{2}\right| \cdots}{\left|s+p_{1}\right|\left|s+p_{2}\right| \cdots}=1
$$

and

$$
\begin{aligned}
\not F(s)=\left\lfloor s+z_{1}\right. & =\not s+z_{2} \\
& +\cdots \\
& -\left(\not s+p_{1}+\not s+p_{2}+\cdots\right)=180^{\circ}+k 360^{\circ},
\end{aligned}
$$

where $k$ is an integer. The magnitude requirement in Equation (7.16) enables us to determine the value of $K$ for a given root location $s_{1}$. A test point in the $s$-plane, $s_{1}$, is verified as a root location when Equation (7.17) is satisfied. All angles are measured in a counterclockwise direction from a horizontal line.

To further illustrate the root locus procedure, let us consider the second-order system of Figure 7.5(a) where $a>0$. The effect of varying the parameter $a$ can

\section{FIGURE 7.5}

(a) Single-loop system. (b) Root locus as a function of the parameter a, where $a>0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0451.jpg?height=505&width=499&top_left_y=1542&top_left_x=1103)

(b) be effectively portrayed by rewriting the characteristic equation for the root locus form with $a$ as the multiplying factor in the numerator. Then the characteristic equation is

$$
1+K G(s)=1+\frac{K}{s(s+a)}=0
$$

or, alternatively,

$$
s^{2}+a s+K=0
$$

Dividing by the factor $s^{2}+K$, we obtain

$$
1+\frac{a s}{s^{2}+K}=0
$$

Then the magnitude criterion is satisfied when

$$
\frac{a\left|s_{1}\right|}{\left|s_{1}^{2}+K\right|}=1
$$

at the root $s_{1}$. The angle criterion is

$$
\not s_{1}-\left(\not s_{1}+j \sqrt{K}+\not s_{1}-j \sqrt{K}\right)= \pm 180^{\circ}, \pm 540^{\circ}, \ldots
$$

In principle, we could construct the root locus by determining the points in the $s$-plane that satisfy the angle criterion. In the next section, we develop a multistep procedure to sketch the root locus. The root locus for the characteristic equation in Equation (7.18) is shown in Figure 7.5(b). Specifically at the root $s_{1}$, the magnitude of the parameter $a$ is found from Equation (7.19) as

$$
a=\frac{\left|s_{1}-j \sqrt{K}\right|\left|s_{1}+j \sqrt{K}\right|}{\left|s_{1}\right|} .
$$

The roots of the system merge on the real axis at the point $s_{2}$ and provide a critically damped response to a step input. The parameter $a$ has a magnitude at the critically damped roots, $s_{2}=\sigma_{2}$, equal to

$$
a=\frac{\left|\sigma_{2}-j \sqrt{K} \| \sigma_{2}+j \sqrt{K}\right|}{\sigma_{2}}=\frac{1}{\sigma_{2}}\left(\sigma_{2}^{2}+K\right)=2 \sqrt{K},
$$

where $\sigma_{2}$ is evaluated from the $s$-plane vector lengths as $\sigma_{2}=\sqrt{K}$. As $a$ increases beyond the critical value, the roots are both real and distinct; one root is larger than $\sigma_{2}$, and one is smaller.

In general, we desire an orderly process for locating the locus of roots as a parameter varies. In the next section, we will develop such an orderly approach to sketching a root locus diagram. 

\subsection{THE ROOT LOCUS PROCEDURE}

The roots of the characteristic equation of a system provide valuable insight concerning the response of the system. To locate the roots of the characteristic equation in a graphical manner on the $s$-plane, we develop an orderly procedure of seven steps that facilitates the rapid sketching of the locus. tion as

Step 1: Prepare the root locus sketch. Begin by writing the characteristic equa-

$$
1+F(s)=0 .
$$

Rearrange the equation, if necessary, so that the parameter of interest, $K$, appears as the multiplying factor in the form,

$$
1+K P(s)=0 .
$$

We are interested in determining the locus of roots when $K$ varies as $0 \leq \mathrm{K}<\infty$. In Section 7.7, we consider the case when $K$ varies as $-\infty<\mathrm{K} \leq 0$.

Factor $P(s)$, and write the polynomial in the form of poles and zeros as follows:

$$
1+K \frac{\prod_{i=1}^{M}\left(s+z_{i}\right)}{\prod_{j=1}^{n}\left(s+p_{j}\right)}=0 .
$$

Locate the poles $-p_{i}$ and zeros $-z_{i}$ on the $s$-plane with selected symbols. By convention, we use " $x$ " to denote poles and "o" to denote zeros.

Rewriting Equation (7.24), we have

$$
\prod_{j=1}^{n}\left(s+p_{j}\right)+K \prod_{i=1}^{M}\left(s+z_{i}\right)=0 .
$$

Note that Equation (7.25) is another way to write the characteristic equation. When $K=0$, the roots of the characteristic equation are the poles of $P(s)$. To see this, consider Equation (7.25) with $K=0$. Then, we have

$$
\prod_{j=1}^{n}\left(s+p_{j}\right)=0 .
$$

When solved, this yields the values of $s$ that coincide with the poles of $P(s)$. Conversely, as $K \rightarrow \infty$, the roots of the characteristic equation are the zeros of $P(s)$. To see this, first divide Equation (7.25) by $K$. Then, we have

$$
\frac{1}{K} \prod_{j=1}^{n}\left(s+p_{j}\right)+\prod_{j=1}^{M}\left(s+z_{j}\right)=0
$$

which, as $K \rightarrow \infty$, reduces to

$$
\prod_{j=1}^{M}\left(s+z_{j}\right)=0 .
$$

When solved, this yields the values of $s$ that coincide with the zeros of $P(s)$. Therefore, we note that the locus of the roots of the characteristic equation $1+K P(s)=0$ begins at the poles of $P(s)$ and ends at the zeros of $P(s)$ as $K$ increases from zero to infinity. For most functions $P(s)$ that we will encounter, several of the zeros of $P(s)$ lie at infinity in the $s$-plane. This is because most of our functions have more poles than zeros. With $n$ poles and $M$ zeros and $n>M$, we have $n-M$ branches of the root locus approaching the $n-M$ zeros at infinity.

Step 2: Locate the segments of the real axis that are root loci. The root locus on the real axis always lies in a section of the real axis to the left of an odd number of poles and zeros. This fact is ascertained by examining the angle criterion of Equation (7.17). These two useful steps in plotting a root locus will be illustrated by a suitable example.

\section{EXAMPLE 7.1 Second-order system}

A feedback control system possesses the characteristic equation

$$
1+G_{c}(s) G(s)=1+\frac{K\left(\frac{1}{2} s+1\right)}{\frac{1}{4} s^{2}+s}=0 .
$$

Step 1: The characteristic equation can be written as

$$
1+K \frac{2(s+2)}{s^{2}+4 s}=0
$$

where

$$
P(s)=\frac{2(s+2)}{s^{2}+4 s} .
$$

The transfer function, $P(s)$, is rewritten in terms of poles and zeros as

$$
1+K \frac{2(s+2)}{s(s+4)}=0 .
$$

To determine the locus of roots for the gain $0 \leq K<\infty$, we locate the poles and zeros on the real axis as shown in Figure 7.6(a).

FIGURE 7.6

(a) The zero and poles of a secondorder system, (b) the root locus segments, and (c) the magnitude of each vector at $s_{1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0454.jpg?height=231&width=366&top_left_y=1837&top_left_x=506)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0454.jpg?height=259&width=379&top_left_y=1792&top_left_x=902)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0454.jpg?height=277&width=454&top_left_y=1769&top_left_x=1297)

(c) Step 2: The angle criterion is satisfied on the real axis between the points 0 and -2 , because the angle from pole $p_{1}$ at the origin is $180^{\circ}$, and the angle from the zero and pole $p_{2}$ at $s=-4$ is zero degrees. The locus begins at the pole and ends at the zeros, and therefore the locus of roots appears as shown in Figure 7.6(b), where the direction of the locus as $K$ is increasing $(K \uparrow)$ is shown by an arrow. We note that because the system has two real poles and one real zero, the second locus segment ends at a zero at negative infinity. To evaluate the gain $K$ at a specific root location on the locus, we use the magnitude criterion, Equation (7.16). For example, the gain $K$ at the root $s=s_{1}=-1$ is found from (7.16) as

$$
\frac{(2 K)\left|s_{1}+2\right|}{\left|s_{1}\right|\left|s_{1}+4\right|}=1
$$

or

$$
K=\frac{|-1||-1+4|}{2|-1+2|}=\frac{3}{2} .
$$

This magnitude can also be evaluated graphically, as shown in Figure 7.6(c). For the gain of $K=3 / 2$, one other root exists, located on the locus to the left of the pole at -4 . The location of the second root is found graphically to be located at $s=-6$, as shown in Figure 7.6(c).

Now, we determine the number of separate loci, $S L$. Because the loci begin at the poles and end at the zeros, the number of separate loci is equal to the number of poles since the number of poles is greater than or equal to the number of zeros. Therefore, as we found in Figure 7.6, the number of separate loci is equal to two because there are two poles and one zero.

Note that the root loci must be symmetrical with respect to the horizontal real axis because the complex roots must appear as pairs of complex conjugate roots.

We now return to developing a general list of root locus steps.

Step 3: The loci proceed to the zeros at infinity along asymptotes centered at $\sigma_{A}$ and with angles $\phi_{A}$. When the number of finite zeros of $P(s), M$, is less than the number of poles $n$ by the number $N=n-M$, then $N$ sections of loci must end at zeros at infinity. These sections of loci proceed to the zeros at infinity along asymptotes as $K$ approaches infinity. These linear asymptotes are centered at a point on the real axis given by

$$
\sigma_{A}=\frac{\sum \text { poles of } \mathrm{P}(s)-\sum \text { zeros of } \mathrm{P}(s)}{n-M}=\frac{\sum_{j=1}^{n}\left(-p_{j}\right)-\sum_{i=1}^{M}\left(-z_{i}\right)}{n-M} .
$$

The angle of the asymptotes with respect to the real axis is

$$
\phi_{A}=\frac{2 k+1}{n-M} 180^{\circ}, \quad k=0,1,2, \ldots,(n-M-1)
$$

where $k$ is an integer index [3]. The usefulness of this rule is obvious for sketching the approximate form of a root locus. Equation (7.30) can be readily derived by considering a point on a root locus segment at a remote distance from the finite poles and zeros in the $s$-plane. The net phase angle at this remote point is $180^{\circ}$, because it is a point on a root locus segment. The finite poles and zeros of $P(s)$ are a great distance from the remote point, and so the angles from each pole and zero, $\phi$, are essentially equal, and therefore the net angle is simply $(n-M) \phi$, where $n$ and $M$ are the number of finite poles and zeros, respectively. Thus, we have

$$
(n-M) \phi=180^{\circ} \text {, }
$$

or, alternatively,

$$
\phi=\frac{180^{\circ}}{n-M}
$$

Accounting for all possible root locus segments at remote locations in the s-plane, we obtain Equation (7.30).

The center of the linear asymptotes, often called the asymptote centroid, is determined by considering the characteristic equation in Equation (7.24). For large values of $s$, only the higher-order terms need be considered, so that the characteristic equation reduces to

$$
1+\frac{K s^{M}}{s^{n}}=0
$$

However, this relation, which is an approximation, indicates that the centroid of $n-M$ asymptotes is at the origin, $s=0$. A better approximation is obtained if we consider a characteristic equation of the form

with a centroid at $\sigma_{A}$.

$$
1+\frac{K}{\left(s-\sigma_{A}\right)^{n-M}}=0
$$

The centroid is determined by considering the first two terms of Equation (7.24), which may be found from the relation

$$
1+\frac{K \prod_{i=1}^{M}\left(s+z_{i}\right)}{\prod_{j=1}^{n}\left(s+p_{j}\right)}=1+K \frac{s^{M}+b_{M-1} s^{M-1}+\cdots+b_{0}}{s^{n}+a_{n-1} s^{n-1}+\cdots+a_{0}} .
$$

We note that

$$
b_{M-1}=\sum_{i=1}^{M} z_{i} \quad \text { and } \quad a_{n-1}=\sum_{j=1}^{n} p_{j} .
$$

Considering only the first two terms of this expansion, we have

$$
1+\frac{K}{s^{n-M}+\left(a_{n-1}-b_{M-1}\right) s^{n-M-1}}=0 .
$$

The first two terms of

$$
1+\frac{K}{\left(s-\sigma_{A}\right)^{n-M}}=0
$$

are

$$
1+\frac{K}{s^{n-M}-(n-M) \sigma_{A} s^{n-M-1}}=0 .
$$

Equating the term for $s^{n-M-1}$, we obtain

$$
a_{n-1}-b_{M-1}=-(n-M) \sigma_{A},
$$

or

$$
\sigma_{A}=\frac{\sum_{i=1}^{n}\left(-p_{i}\right)-\sum_{i=1}^{M}\left(-z_{i}\right)}{n-M}
$$

which is Equation (7.29).

For example, reexamine the system shown in Figure 7.2 and discussed in Section 7.2. The characteristic equation is written as

$$
1+\frac{K}{s(s+2)}=0 .
$$

Because $n-M=2$, we expect two loci to end at zeros at infinity. The asymptotes of the loci are located at a center

$$
\sigma_{A}=\frac{-2}{2}=-1
$$

and at angles of

$$
\phi_{A}=90^{\circ}(\text { for } \mathrm{k}=0) \text { and } \phi_{A}=270^{\circ}(\text { for } \mathrm{k}=1) \text {. }
$$

The root locus is readily sketched, and the locus shown in Figure 7.3 is obtained. An example will further illustrate the process of using the asymptotes.

\section{EXAMPLE 7.2 Fourth-order system}

A unity negative feedback control system has a characteristic equation as follows:

$$
1+G_{c}(s) G(s)=1+\frac{K(s+1)}{s(s+2)(s+4)^{2}} .
$$

We wish to sketch the root locus in order to determine the effect of the gain $K$. The poles and zeros are located in the $s$-plane, as shown in Figure 7.7(a). The root loci on the real axis must be located to the left of an odd number of poles and zeros; they are shown as heavy lines in Figure 7.7(a). The intersection of the asymptotes is

$$
\sigma_{A}=\frac{(-2)+2(-4)-(-1)}{4-1}=\frac{-9}{3}=-3 \text {. }
$$

FIGURE 7.7 A fourth-order system with (a) a zero and (b) root locus.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0458.jpg?height=654&width=473&top_left_y=155&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0458.jpg?height=658&width=550&top_left_y=153&top_left_x=1049)

(b)
The angles of the asymptotes are

$$
\begin{array}{ll}
\phi_{A}=+60^{\circ} & (k=0), \\
\phi_{A}=180^{\circ} & (k=1), \text { and } \\
\phi_{A}=300^{\circ} & (k=2),
\end{array}
$$

where there are three asymptotes, since $n-M=3$. Also, we note that the root loci must begin at the poles; therefore, two loci must leave the double pole at $s=-4$. Then with the asymptotes sketched in Figure 7.7(b), we may sketch the form of the root locus as shown in Figure 7.7(b). The actual shape of the locus in the area near $\sigma_{A}$ would be graphically evaluated, if necessary.

We now proceed to develop more steps for the process of determining the root loci.

Step 4: Determine where the locus crosses the imaginary axis (if it does so), using the Routh-Hurwitz criterion. The actual point at which the root locus crosses the imaginary axis is readily evaluated by using the criterion.

Step 5: Determine the breakaway point on the real axis (if any). The root locus in Example 7.2 left the real axis at a breakaway point. The locus breakaway from the real axis occurs where the net change in angle caused by a small displacement is zero. The locus leaves the real axis where there is a multiplicity of roots (typically, two). The breakaway point for a simple second-order system is shown in Figure 7.8(a) and, for a special case of a fourth-order system, is shown in Figure 7.8(b). In general, due to the phase criterion, the tangents to the loci at the breakaway point are equally spaced over $360^{\circ}$. Therefore, in Figure 7.8(a), we find that the two loci at the breakaway point are spaced $180^{\circ}$ apart, whereas in Figure 7.8(b), the four loci are spaced $90^{\circ}$ apart.

The breakaway point on the real axis can be evaluated graphically or analytically. The most straightforward method of evaluating the breakaway point FIGURE 7.8

Illustration of the breakaway point (a) for a simple second-order system and (b) for a fourth-order system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0459.jpg?height=482&width=532&top_left_y=154&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0459.jpg?height=482&width=574&top_left_y=154&top_left_x=971)

(b)

involves the rearranging of the characteristic equation to isolate the multiplying factor $K$. Then the characteristic equation is written as

$$
p(s)=K .
$$

For example, consider a unity feedback closed-loop system with a loop transfer function

$$
L(s)=K G(s)=\frac{K}{(s+2)(s+4)},
$$

which has the characteristic equation

$$
1+K G(s)=1+\frac{K}{(s+2)(s+4)}=0 .
$$

Alternatively, the equation may be written as

$$
K=p(s)=-(s+2)(s+4) .
$$

The root loci for this system are shown in Figure 7.8(a). We expect the breakaway point to be near $s=\sigma=-3$ and plot $\left.p(s)\right|_{s=\sigma}$ near that point, as shown in Figure 7.9. In this case, $p(s)$ equals zero at the poles $s=-2$ and $s=-4$. The plot of $p(s)$ versus $s-\sigma$ is symmetrical, and the maximum point occurs at $s=\sigma=-3$, the breakaway point.

FIGURE 7.9

A graphical evaluation of the breakaway point.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0459.jpg?height=376&width=569&top_left_y=1731&top_left_x=372)

Analytically, the very same result may be obtained by determining the maximum of $K=p(s)$. To find the maximum analytically, we differentiate, set the differentiated polynomial equal to zero, and determine the roots of the polynomial. Therefore, we may evaluate

$$
\frac{d K}{d s}=\frac{d p(s)}{d s}=0
$$

in order to find the breakaway point. Equation (7.36) is an analytical expression of the graphical procedure outlined in Figure 7.9 and will result in an equation of only one degree less than the total number of poles and zeros $n+M-1$.

The proof of Equation (7.36) is obtained from a consideration of the characteristic equation

$$
1+F(s)=1+\frac{K Y(s)}{X(s)}=0
$$

which may be written as

$$
X(s)+K Y(s)=0 .
$$

For a small increment in $K$, we have

$$
X(s)+(K+\Delta K) Y(s)=0 .
$$

Dividing by $X(s)+K Y(s)$ yields

$$
1+\frac{\Delta K Y(s)}{X(s)+K Y(s)}=0 .
$$

Because the denominator is the original characteristic equation, a multiplicity $m$ of roots exists at a breakaway point, and

$$
\frac{Y(s)}{X(s)+K Y(s)}=\frac{C_{i}}{\left(s-s_{i}\right)^{m}}=\frac{C_{i}}{(\Delta s)^{m}} .
$$

Then we may write Equation (7.38) as

$$
1+\frac{\Delta K C_{i}}{(\Delta s)^{m}}=0
$$

or, alternatively,

$$
\frac{\Delta K}{\Delta s}=\frac{-(\Delta s)^{m-1}}{C_{i}}
$$

Therefore, as we let $\Delta s$ approach zero, we obtain

$$
\frac{d K}{d s}=0
$$

at the breakaway points. Now, considering again the specific case where

$$
L(s)=K G(s)=\frac{K}{(s+2)(s+4)},
$$

we obtain

$$
p(s)=K=-(s+2)(s+4)=-\left(s^{2}+6 s+8\right) .
$$

Then, when we differentiate, we have

$$
\frac{d p(s)}{d s}=-(2 s+6)=0,
$$

or the breakaway point occurs at $s=-3$. A more complicated example will illustrate the approach and demonstrate the use of the graphical technique to determine the breakaway point.

\section{EXAMPLE 7.3 Third-order system}

A feedback control system is shown in Figure 7.10. The characteristic equation is

$$
1+G(s) H(s)=1+\frac{K(s+1)}{s(s+2)(s+3)}=0 .
$$

The number of poles $n$ minus the number of zeros $M$ is equal to 2, and so we have two asymptotes at $\pm 90^{\circ}$ with a center at $\sigma_{A}=-2$. The asymptotes and the sections of loci on the real axis are shown in Figure 7.11(a). A breakaway point occurs between $s=-2$ and $s=-3$. To evaluate the breakaway point, we rewrite the characteristic equation so that $K$ is separated; thus,

$$
s(s+2)(s+3)+K(s+1)=0,
$$

or

$$
p(s)=\frac{-s(s+2)(s+3)}{s+1}=K .
$$

Then, evaluating $p(s)$ at various values of $s$ between $s=-2$ and $s=-3$, we obtain the results of Table 7.1, as shown in Figure 7.11(b). Alternatively, we differentiate

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0461.jpg?height=338&width=644&top_left_y=1776&top_left_x=374)



\section{Table 7.1}

\begin{tabular}{lllllll}
$p(s)$ & 0 & 0.411 & 0.419 & 0.417 & +0.390 & 0 \\
\hline$s$ & -2.00 & -2.40 & -2.46 & -2.50 & -2.60 & -3.0 \\
\hline
\end{tabular}

Equation (7.46) and set it equal to zero to obtain

$$
\begin{gathered}
\frac{d}{d s}\left(\frac{-s(s+2)(s+3)}{(s+1)}\right)= \\
=\frac{\left(s^{3}+5 s^{2}+6 s\right)-(s+1)\left(3 s^{2}+10 s+6\right)}{(s+1)^{2}}=0 \\
2 s^{3}+8 s^{2}+10 s+6=0 .
\end{gathered}
$$

Now to locate the maximum of $p(s)$, we locate the roots of Equation (7.47) to obtain $s=-2.46,-0.77 \pm 0.79 j$. The only value of $s$ on the real axis in the interval $s=-2$ to $s=-3$ is $s=-2.46$; hence this must be the breakaway point. It is evident from this one example that the numerical evaluation of $p(s)$ near the expected breakaway point provides an effective method of evaluating the breakaway point.

Step 6: Determine the angle of departure of the locus from a pole and the angle of arrival of the locus at a zero, using the phase angle criterion. The angle of locus departure from a pole is the difference between the net angle due to all other poles and zeros and the criterion angle of $\pm 180^{\circ}(2 k+1)$, and similarly for the locus angle of arrival at a zero. The angle of departure (or arrival) is particularly of interest for complex poles (and zeros) because the information is helpful in completing the root locus. For example, consider the third-order loop transfer function

$$
L(s)=G(s) H(s)=\frac{K}{\left(s+p_{3}\right)\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)} .
$$

The pole locations and the vector angles at one complex pole $-p_{1}$ are shown in Figure 7.12(a). The angles at a test point $s_{1}$, an infinitesimal distance from $-p_{1}$, must meet the angle criterion. Therefore, since $\theta_{2}=90^{\circ}$, we have

FIGURE 7.11

Evaluation of the (a) asymptotes and (b) breakaway point.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0462.jpg?height=544&width=529&top_left_y=1506&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0462.jpg?height=541&width=556&top_left_y=1508&top_left_x=1105)

(b) FIGURE 7.12

Illustration of the angle of departure. (a) Test point infinitesimal distance from $-p_{1}$. (b) Actual departure vector at $-p_{1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0463.jpg?height=675&width=512&top_left_y=152&top_left_x=412)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0463.jpg?height=668&width=524&top_left_y=158&top_left_x=980)

(b)

$$
\theta_{1}+\theta_{2}+\theta_{3}=\theta_{1}+90^{\circ}+\theta_{3}=+180^{\circ}
$$

or the angle of departure at pole $p_{1}$ is

$$
\theta_{1}=90^{\circ}-\theta_{3}
$$

as shown in Figure 7.12(b). The departure at pole $-p_{2}$ is the negative of that at $-p_{1}$, because $-p_{1}$ and $-p_{2}$ are complex conjugates. Another example of a departure angle is shown in Figure 7.13. In this case, the departure angle is found from

$$
\theta_{2}-\left(\theta_{1}+\theta_{3}+90^{\circ}\right)=180^{\circ}+k 360^{\circ} \text {. }
$$

Since $\theta_{2}-\theta_{3}=\gamma$ in the diagram, we find that the departure angle is $\theta_{1}=90^{\circ}+\gamma$.

Step 7: The final step in the root locus sketching procedure is to complete the sketch. This entails sketching in all sections of the locus not covered in the previous six steps.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0463.jpg?height=468&width=640&top_left_y=1641&top_left_x=376)

FIGURE 7.13

Evaluation of the angle of departure. In some situation, we may want to determine a root location $s_{x}$ and the value of the parameter $K_{x}$ at that root location. Determine the root locations that satisfy the phase criterion at the root $s_{x}, x=1,2, \ldots, n$, using the phase criterion. The phase criterion, given in Equation (7.17), is

$$
\angle P(s)=180^{\circ}+k 360^{\circ}, \quad \text { and } k=0, \pm 1, \pm 2, \ldots
$$

To determine the parameter value $K_{x}$ at a specific root $s_{x}$, we use the magnitude requirement (Equation 7.16). The magnitude requirement at $s_{x}$ is

$$
K_{x}=\left.\frac{\prod_{j=1}^{n}\left|s+p_{i}\right|}{\prod_{i=1}^{M}\left|s+z_{i}\right|}\right|_{s=s_{x}} .
$$

The seven steps utilized in the root locus method are summarized in Table 7.2.

\section{Table 7.2 Seven Steps for Sketching a Root Locus}

\section{Step}

1. Prepare the root locus sketch.

(a) Write the characteristic equation so that the parameter of interest, $K$, appears as a multiplier.

(b) Factor $P(s)$ in terms of $n$ poles and $M$ zeros.

(c) Locate the open-loop poles and zeros of $P(s)$ in the $s$-plane with selected symbols.

(d) Determine the number of separate loci, $S L$.

(e) The root loci are symmetrical with respect to the horizontal real axis.

2. Locate the segments of the real axis that are root loci.

3. The loci proceed to the zeros at infinity along asymptotes centered at $\sigma_{A}$ and with angles $\phi_{A}$.

4. Determine the points at which the locus crosses the imaginary axis (if it does so).

5. Determine the breakaway point on the real axis (if any).

6. Determine the angle of locus departure from complex poles and the angle of locus arrival at complex zeros, using the phase criterion.

7. Complete the root locus sketch.

\section{Related Equation or Rule}

$1+K P(s)=0$.

$\prod^{M}\left(s+z_{i}\right)$

$1+K \frac{\prod_{i=1}^{n}}{\prod_{j=1}^{n}\left(s+p_{j}\right)}=0$.

$\times=$ poles, $\mathrm{O}=$ zeros

Locus begins at a pole and ends at a zero.

$S L=n$ when $n \geq M ; n=$ number of finite poles, $M=$ of finite zeros.

Locus lies to the left of an odd number of poles and zeros.

$\sigma_{A}=\frac{\sum\left(-p_{j}\right)-\sum\left(-z_{i}\right)}{n-M}$.

$\phi_{A}=\frac{2 k+1}{n-M} 180^{\circ}, k=0,1,2, \ldots,(n-M-1)$.

Use Routh-Hurwitz criterion.

a) Set $K=p(s)$.

b) Determine roots of $d p(s) / d s=0$ or use graphical method to find maximum of $p(s)$. $\angle P(s)=180^{\circ}+k 360^{\circ}$ at $s=-p_{j}$ or $-z_{i}$. 

\section{EXAMPLE 7.4 Fourth-order system}

1. (a) Consider the root locus for the characteristic equation of a system as $K$ varies for $0 \leq K<\infty$ when

$$
1+\frac{K}{s^{4}+12 s^{3}+64 s^{2}+128 s}=0 .
$$

(b) Determining the poles, we have

$$
1+\frac{K}{s(s+4)(s+4+j 4)(s+4-j 4)}=0 .
$$

This system has no finite zeros.

(c) The poles are located on the $s$-plane as shown in Figure 7.14(a).

(d) Because the number of poles $n$ is equal to 4, we have four separate loci.

(e) The root loci are symmetrical with respect to the real axis.

2. A segment of the root locus exists on the real axis between $s=0$ and $s=-4$.

3. The angles of the asymptotes are

$$
\begin{aligned}
& \phi_{A}=\frac{(2 k+1)}{4} 180^{\circ}, \quad k=0,1,2,3 ; \\
& \phi_{A}=+45^{\circ}, 135^{\circ}, 225^{\circ}, 315^{\circ} .
\end{aligned}
$$

The center of the asymptotes is

$$
\sigma_{A}=\frac{-4-4-4 j-4+4 j}{4}=-3 .
$$

Then the asymptotes are drawn as shown in Figure 7.14(a).

FIGURE 7.14 The root locus for Example 7.4. Locating (a) the poles and (b) the asymptotes.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0465.jpg?height=770&width=538&top_left_y=1332&top_left_x=352)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0465.jpg?height=771&width=717&top_left_y=1334&top_left_x=902)

(b) 4. The characteristic equation is rewritten as

$$
s(s+4)\left(s^{2}+8 s+32\right)+K=s^{4}+12 s^{3}+64 s^{2}+128 s+K=0 .
$$

Therefore, the Routh array is

\begin{tabular}{c|ccc}
$s^{4}$ & 1 & 64 & $K$ \\
$s^{3}$ & 12 & 128 & \\
$s^{2}$ & $b_{1}$ & $K$ & \\
$s^{1}$ & $c_{1}$ & & \\
$s^{0}$ & $K$ & &
\end{tabular}

where

$$
b_{1}=\frac{12(64)-128}{12}=53.33 \text { and } \quad c_{1}=\frac{53.33(128)-12 K}{53.33} .
$$

Hence, the limiting value of gain for stability is $K=568.89$, and the roots of the auxiliary equation are

$$
53.33 s^{2}+568.89=53.33\left(s^{2}+10.67\right)=53.33(s+j 3.266)(s-j 3.266) .
$$

The points where the locus crosses the imaginary axis are shown in Figure 7.14(a). Therefore, when $K=568.89$, the root locus crosses the $j \omega$-axis at $s= \pm j 3.266$.

5. The breakaway point is estimated by evaluating

$$
K=p(s)=-s(s+4)(s+4+j 4)(s+4-j 4)
$$

between $s=-4$ and $s=0$. We expect the breakaway point to lie between $s=-3$ and $s=-1$, so we search for a maximum value of $p(s)$ in that region. The resulting values of $p(s)$ for several values of $s$ are given in Table 7.3. The maximum of $p(s)$ is found to lie at approximately $s=-1.577$, as indicated in the table. A more accurate estimate of the breakaway point is normally not necessary. The breakaway point is then indicated on Figure 7.14(a).

6. The angle of departure at the complex pole $p_{1}$ can be estimated by utilizing the angle criterion as follows:

$$
\theta_{1}+90^{\circ}+90^{\circ}+\theta_{3}=180^{\circ}+k 360^{\circ} .
$$

Here, $\theta_{3}$ is the angle subtended by the vector from pole $p_{3}$. The angles from the pole at $s=-4$ and $s=-4-j 4$ are each equal to $90^{\circ}$. Since $\theta_{3}=135^{\circ}$, we find that

$$
\theta_{1}=-135^{\circ} \equiv+225^{\circ}
$$

as shown in Figure 7.14(a).

7. Complete the sketch as shown in Figure 7.14(b).

Table 7.3
\begin{tabular}{llllllll}
$p(s)$ & 0 & 51.0 & 68.44 & 80.0 & 83.57 & 75.0 & 0 \\
\hline$s$ & -4.0 & -3.0 & -2.5 & -2.0 & -1.577 & -1.0 & 0 \\
\hline
\end{tabular}

Using the information derived from the seven steps of the root locus method, the complete root locus sketch is obtained by filling in the sketch as well as possible by visual inspection. The root locus for this system is shown in Figure 7.14(b). When the complex roots near the origin have a damping ratio of $\zeta=0.707$, the gain $K$ can be determined graphically as shown in Figure 7.14(b). The vector lengths to the root location $s_{1}$ from the open-loop poles are evaluated and result in a gain at $s_{1}$ of

$$
K=\left|s_{1}\right|\left|s_{1}+4\right|\left|s_{1}-p_{1}\right|\left|s_{1}-\hat{p}_{1}\right|=(1.9)(2.9)(3.8)(6.0)=126 .
$$

The remaining pair of complex roots occurs at $s_{2}$ and $\hat{s}_{2}$, when $K=126$. The effect of the complex roots at $s_{2}$ and $\hat{s}_{2}$ on the transient response will be negligible compared to the roots $s_{1}$ and $\hat{s}_{1}$. This fact can be ascertained by considering the damping of the response due to each pair of roots. The damping due to $s_{1}$ and $\hat{s}_{1}$ is

$$
e^{-\zeta_{1} \omega_{n 1} t}=e^{-\sigma_{1} t}
$$

and the damping factor due to $s_{2}$ and $\hat{s}_{2}$ is

$$
e^{-\zeta_{2} \omega_{n 2} t}=e^{-\sigma_{2} t}
$$

where $\sigma_{2}$ is approximately five times as large as $\sigma_{1}$. Therefore, the transient response term due to $s_{2}$ will decay much more rapidly than the transient response term due to $s_{1}$. Thus, the response to a unit step input may be written as

$$
\begin{aligned}
y(t) & =1+c_{1} e^{-\sigma_{1} t} \sin \left(\omega_{1} t+\theta_{1}\right)+c_{2} e^{-\sigma_{2} t} \sin \left(\omega_{2} t+\theta_{2}\right) \\
& \approx 1+c_{1} e^{-\sigma_{1} t} \sin \left(\omega_{1} t+\theta_{1}\right) .
\end{aligned}
$$

The complex conjugate roots near the origin of the $s$-plane relative to the other roots of the closed-loop system are labeled the dominant roots of the system because they represent or dominate the transient response. The relative dominance of the complex roots, in a third-order system with a pair of complex conjugate roots, is determined by the ratio of the real root to the real part of the complex roots and will result in approximate dominance for ratios exceeding 5.

The dominance of the second term of Equation (7.53) also depends upon the relative magnitudes of the coefficients $c_{1}$ and $c_{2}$. These coefficients, which are the residues evaluated at the complex roots, in turn depend upon the location of the zeros in the $s$-plane. Therefore, the concept of dominant roots is useful for estimating the response of a system, but must be used with caution and with a comprehension of the underlying assumptions.

\subsection{PARAMETER DESIGN BY THE ROOT LOCUS METHOD}

Originally, the root locus method was developed to determine the locus of roots of the characteristic equation as the system gain, $K$, is varied from zero to infinity. However, as we have seen, the effect of other system parameters may be readily investigated by using the root locus method. Fundamentally, the root locus method is concerned with a characteristic equation (Equation 7.22), which may be written as

$$
1+F(s)=0
$$

Then the standard root locus method we have studied may be applied. The question arises: How do we investigate the effect of two parameters, $\alpha$ and $\beta$ ? It appears that the root locus method is a single-parameter method; fortunately, it can be readily extended to the investigation of two or more parameters. This method of parameter design uses the root locus approach to select the values of the parameters.

The characteristic equation of a dynamic system may be written as

$$
a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots+a_{1} s+a_{0}=0 .
$$

Hence, the effect of varying $0 \leq a_{1}<\infty$ may be ascertained from the root locus equation

$$
1+\frac{a_{1} s}{a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots+a_{2} s^{2}+a_{0}}=0 .
$$

If the parameter of interest, $\alpha$, does not appear solely as a coefficient, the parameter may be isolated as

$$
a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots+\left(a_{n-q}-\alpha\right) s^{n-q}+\alpha s^{n-q}+\cdots+a_{1} s+a_{0}=0 .
$$

For example, a third-order equation of interest might be

$$
s^{3}+(3+\alpha) s^{2}+3 s+6=0 .
$$

To ascertain the effect of the parameter $\alpha$, we isolate the parameter and rewrite the equation in root locus form, as shown in the following steps:

$$
\begin{gathered}
s^{3}+3 s^{2}+\alpha s^{2}+3 s+6=0 \\
1+\frac{\alpha s^{2}}{s^{3}+3 s^{2}+3 s+6}=0 .
\end{gathered}
$$

Then, to determine the effect of two parameters, we must repeat the root locus approach twice. Thus, for a characteristic equation with two variable parameters, $\alpha$ and $\beta$, we have

$$
\begin{aligned}
a_{n} s^{n}+a_{n-1} s^{n-1}+\cdots & +\left(a_{n-q}-\alpha\right) s^{n-q}+\alpha s^{n-q}+\cdots \\
& +\left(a_{n-r}-\beta\right) s^{n-r}+\beta s^{n-r}+\cdots+a_{1} s+a_{0}=0 .
\end{aligned}
$$

The two variable parameters have been isolated, and the effect of $\alpha$ will be determined. Then, the effect of $\beta$ will be determined. For example, for a certain third-order characteristic equation with $\alpha$ and $\beta$ as parameters, we obtain

$$
s^{3}+s^{2}+\beta s+\alpha=0 .
$$

In this particular case, the parameters appear as the coefficients of the characteristic equation. The effect of varying $\beta$ from zero to infinity is determined from the root locus equation 

$$
1+\frac{\beta s}{s^{3}+s^{2}+\alpha}=0
$$

We note that the denominator of Equation (7.63) is the characteristic equation of the system with $\beta=0$. Therefore, we must first evaluate the effect of varying $\alpha$ from zero to infinity by using the equation

$$
s^{3}+s^{2}+\alpha=0
$$

rewritten as

$$
1+\frac{\alpha}{s^{2}(s+1)}=0
$$

where $\beta$ has been set equal to zero in Equation (7.62). Then, upon evaluating the effect of $\alpha$, a value of $\alpha$ is selected and used with Equation (7.63) to evaluate the effect of $\beta$. This two-step method of evaluating the effect of $\alpha$ and then $\beta$ may be carried out as two root locus procedures. First, we obtain a locus of roots as $\alpha$ varies, and we select a suitable value of $\alpha$; the results are satisfactory root locations. Then, we obtain the root locus for $\beta$ by noting that the poles of Equation (7.63) are the roots evaluated by the root locus of Equation (7.64). A limitation of this approach is that we will not always be able to obtain a characteristic equation that is linear in the parameter under consideration.

To illustrate this approach, let us obtain the root locus for $\alpha$ and then $\beta$ for Equation (7.62). A sketch of the root locus as $\alpha$ varies for Equation (7.64) is shown in Figure 7.15(a), where the roots for two values of gain $\alpha$ are shown. If the gain $\alpha$ is selected as $\alpha_{1}$, then the resultant roots of Equation (7.64) become the poles of Equation (7.63). The root locus of Equation (7.63) as $\beta$ varies is shown in Figure 7.15(b), and a suitable $\beta$ can be selected on the basis of the desired root locations.

Using the root locus method, we will further illustrate this parameter design approach by a specific design example.

FIGURE 7.15

Root loci as a function of $\alpha$ and $\beta$. (a) Loci as $\alpha$ varies. (b) Loci as $\beta$ varies for one value of $\alpha=\alpha_{1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0469.jpg?height=560&width=623&top_left_y=1505&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0469.jpg?height=565&width=588&top_left_y=1503&top_left_x=1051)

(b) 

\section{EXAMPLE 7.5 Welding head control}

A welding head for an auto body requires an accurate control system for positioning the welding head [4]. The feedback control system is to be designed to satisfy the following specifications:

1. Steady-state error for a ramp input is $e_{s s} \leq 35 \%$ of input slope

2. Damping ratio of dominant roots is $\zeta \geq 0.707$

3. Settling time to within $2 \%$ of the final value is $T_{s} \leq 3 \mathrm{~s}$.

The structure of the feedback control system is shown in Figure 7.16, where the amplifier gain $K_{1}$ and the derivative feedback gain $K_{2}$ are to be selected. The steadystate error specification can be written as

$$
e_{\mathrm{SS}}=\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} \frac{s\left(|R| / s^{2}\right)}{1+G_{2}(s)},
$$

where $G_{2}(s)=G(s) /(1+G(s) H(s))$. Therefore, the steady-state error requirement is

$$
\frac{e_{\mathrm{sS}}}{|R|}=\frac{2+K_{1} K_{2}}{K_{1}} \leq 0.35
$$

Thus, we will select a small value of $K_{2}$ to achieve a low value of steady-state error. The damping ratio specification requires that the roots of the closed-loop system be below the line at $45^{\circ}$ in the left-hand $s$-plane, as illustrated in Figure 7.17. The settling time specification can be rewritten in terms of the real part of the dominant roots as

$$
T_{s}=\frac{4}{\sigma} \leq 3 \mathrm{~s}
$$

Therefore, it is necessary that $\sigma \geq 4 / 3$; this area in the left-hand $s$-plane is indicated along with the $\zeta$ - requirement in Figure 7.17. Note that $\sigma \geq 4 / 3$ implies that we want the dominant roots to lie to the left of the line defined by $\sigma=-4 / 3$. To satisfy the specifications, all the roots must lie within the shaded area of the left-hand plane.

The parameters to be selected are $\alpha=K_{1}$ and $\beta=K_{2} K_{1}$. The characteristic equation is

$$
s^{2}+2 s+\beta s+\alpha=0 .
$$

FIGURE 7.16

Block diagram of welding head control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0470.jpg?height=403&width=774&top_left_y=1713&top_left_x=502)

FIGURE 7.17

A region in the $s$-plane for desired root location.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0471.jpg?height=598&width=473&top_left_y=155&top_left_x=375)

The locus of roots as $\alpha=K_{1}$ varies (set $\beta=0$ ) is determined from the equation

$$
1+\frac{\alpha}{s(s+2)}=0
$$

as shown in Figure 7.18(a). For a gain of $K_{1}=\alpha=20$, the roots are $s=-1 \pm j 4.36$ as indicated on the locus. Then the effect of varying $\beta=20 K_{2}$ is determined from the locus equation

$$
1+\frac{\beta s}{s^{2}+2 s+20}=0 .
$$

The root locus for Equation (7.70) is shown in Figure 7.18(b), and roots with $\zeta=0.707$ are obtained when $\beta=4.3=20 K_{2}$ or when $K_{2}=0.215$. The real part

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0471.jpg?height=656&width=529&top_left_y=1394&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0471.jpg?height=654&width=544&top_left_y=1395&top_left_x=958)

(b) tion of (a) $\alpha$ and (b) $\beta$.

FIGURE 7.18

Root loci as a func- of these roots is $\sigma=-3.15$; therefore, the time to settle (to within $2 \%$ of the final value) is $T_{s}=1.27 \mathrm{~s}$, which is considerably less than the specification of $T_{s} \leq 3 \mathrm{~s}$.

We can extend the root locus method to more than two parameters by extending the number of steps in the method outlined in this section. Furthermore, a family of root loci can be generated for two parameters in order to determine the total effect of varying two parameters. For example, let us determine the effect of varying $\alpha$ and $\beta$ of the following characteristic equation:

$$
s^{3}+3 s^{2}+2 s+\beta s+\alpha=0 .
$$

The root locus equation as a function of $\alpha$ is $(\operatorname{set} \beta=0)$

$$
1+\frac{\alpha}{s(s+1)(s+2)}=0
$$

The root locus as a function of $\beta$ is

$$
1+\frac{\beta s}{s^{3}+3 s^{2}+2 s+\alpha}=0 .
$$

The root locus for Equation (7.72) as a function of $\alpha$ is shown in Figure 7.19 (unbroken lines). The roots of this locus, indicated by slashes, become the poles for the locus of Equation (7.73). Then the locus of Equation (7.73) is continued on Figure 7.19 (dotted lines), where the locus for $\beta$ is shown for several selected values of $\alpha$. This family of loci, often called root contours, illustrates the effect of $\alpha$ and $\beta$ on the roots of the characteristic equation of a system [3].

FIGURE 7.19

Two-parameter root locus. The loci for $\alpha$ varying are solid; the loci for $\beta$ varying are dashed.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0472.jpg?height=849&width=647&top_left_y=1260&top_left_x=509)



\subsection{SENSITIVITY AND THE ROOT LOCUS}

One of the prime reasons for the use of negative feedback in control systems is the reduction of the effect of parameter variations. The effect of parameter variations can be described by a measure of the sensitivity of the system performance to specific parameter changes. We define the logarithmic sensitivity originally suggested by Bode as

$$
S_{K}^{T}=\frac{\partial \ln \mathrm{T}}{\partial \ln \mathrm{K}}=\frac{\partial T / T}{\partial K / K}
$$

where the system transfer function is $T(s)$ and the parameter of interest is $K$.

It is useful to define a sensitivity measure in terms of the positions of the roots of the characteristic equation [7-9]. Because these roots represent the dominant modes of transient response, the effect of parameter variations on the position of the roots is an important and useful measure of the sensitivity. The root sensitivity of a system $T(s)$ can be defined as

$$
S_{K}^{r_{i}}=\frac{\partial r_{i}}{\partial \ln \mathrm{K}}=\frac{\partial r_{i}}{\partial K / K},
$$

where $r_{i}$ equals the $i$ th root of the system, so that

$$
T(s)=\frac{K_{1} \prod_{j=1}^{M}\left(s+z_{j}\right)}{\prod_{i=1}^{n}\left(s+r_{i}\right)}
$$

and $K$ is a parameter affecting the roots. The root sensitivity relates the changes in the location of the root in the $s$-plane to the change in the parameter. The root sensitivity is related to the logarithmic sensitivity by the relation

$$
S_{K}^{T}=\frac{\partial \ln \mathrm{K}_{1}}{\partial \ln \mathrm{K}}-\sum_{i=1}^{n} \frac{\partial r_{i}}{\partial \ln \mathrm{K}} \cdot \frac{1}{s+r_{i}}
$$

when the zeros of $T(s)$ are independent of the parameter $K$, so that

$$
\frac{\partial z_{j}}{\partial \ln K}=0 .
$$

This logarithmic sensitivity can be readily obtained by determining the derivative of $T(s)$ in Equation (7.76) with respect to $K$. For this particular case, when the gain of the system is independent of the parameter $K$, we have

$$
S_{K}^{T}=-\sum_{i=1}^{n} S_{K}^{r_{i}} \cdot \frac{1}{s+r_{i}},
$$

and the two sensitivity measures are directly related. The evaluation of the root sensitivity for a control system can be readily accomplished by utilizing the root locus methods of the preceding section. The root sensitivity $S_{K}^{r_{i}}$ may be evaluated at root $-r_{i}$ by examining the root contours for the parameter $K$. We can change $K$ by a small finite amount $\Delta K$ and determine the modified root $-\left(r_{i}+\Delta r_{i}\right)$ at $K+\Delta K$. Then, using Equation (7.75), we have

$$
S_{K}^{r_{i}} \approx \frac{\Delta r_{i}}{\Delta K / K} .
$$

Equation (7.79) is an approximation that approaches the actual value of the sensitivity as $\Delta K \rightarrow 0$. An example will illustrate the process of evaluating the root sensitivity.

\section{EXAMPLE 7.6 Root sensitivity of a control system}

The characteristic equation of the feedback control system shown in Figure 7.20 is

$$
1+\frac{K}{s(s+\beta)}=0,
$$

or, alternatively,

$$
s^{2}+\beta s+K=0 .
$$

The gain $K$ will be considered to be the parameter $\alpha$. Then the effect of a change in each parameter can be determined by utilizing the relations

$$
\alpha=\alpha_{0} \pm \Delta \alpha \text { and } \beta=\beta_{0} \pm \Delta \beta,
$$

where $\alpha_{0}$ and $\beta_{0}$ are the nominal or desired values for the parameters $\alpha$ and $\beta$, respectively. We shall consider the case when the nominal value is $\beta_{0}=1$ and the desired gain is $\alpha_{0}=K=0.5$. Then the root locus can be obtained as a function of $\alpha=K$ by utilizing the root locus equation

$$
1+\frac{K}{s\left(s+\beta_{0}\right)}=1+\frac{K}{s(s+1)}=0,
$$

as shown in Figure 7.21. The nominal value of gain $K=\alpha_{0}=0.5$ results in two complex roots, $-r_{1}=-0.5+j 0.5$ and $-r_{2}=-\hat{r}_{1}$, as shown in Figure 7.21. To evaluate the effect of changes in the gain, the characteristic equation with $\alpha=\alpha_{0} \pm \Delta \alpha$ becomes

$$
s^{2}+s+\alpha_{0} \pm \Delta \alpha=s^{2}+s+0.5 \pm \Delta \alpha .
$$

Therefore, the effect of changes in the gain can be evaluated from the root locus of Figure 7.21. For a $20 \%$ change in $\alpha$, we have $\Delta \alpha= \pm 0.1$. The root locations for

FIGURE 7.20

A feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0474.jpg?height=235&width=682&top_left_y=1884&top_left_x=522)

FIGURE 7.21

The root locus for $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0475.jpg?height=527&width=532&top_left_y=167&top_left_x=374)

a gain $\alpha=0.4$ and $\alpha=0.6$ are readily determined by root locus methods, and the root locations for $\Delta \alpha= \pm 0.1$ are shown in Figure 7.21. When $\alpha=K=0.6$, the root in the second quadrant of the $s$-plane is

$$
\left(-r_{1}\right)+\Delta r_{1}=-0.5+j 0.59
$$

and the change in the root is $\Delta r_{1}=+j 0.09$. When $\alpha=K=0.4$, the root in the second quadrant is

$$
-\left(r_{1}\right)+\Delta r_{1}=-0.5+j 0.387
$$

and the change in the root is $-\Delta r_{1}=-j 0.11$. Thus, the root sensitivity for $r_{1}$ is

$$
S_{K+}^{r_{1}}=\frac{\Delta r_{1}}{\Delta K / K}=\frac{+j 0.09}{+0.2}=j 0.45=0.45 \not+90^{\circ}
$$

for positive changes of gain. For negative increments of gain, the sensitivity is

$$
S_{K-}^{r_{1}}=\frac{\Delta r_{1}}{\Delta K / K}=\frac{-j 0.11}{+0.2}=-j 0.55=0.55 \angle-90^{\circ} .
$$

For infinitesimally small changes in the parameter $K$, the sensitivity will be equal for negative or positive increments in $K$. The angle of the root sensitivity indicates the direction the root moves as the parameter varies. The angle of movement for $+\Delta \alpha$ is always $180^{\circ}$ from the angle of movement for $-\Delta \alpha$ at the point $\alpha=\alpha_{0}$.

The pole $\beta$ variation is represented by $\beta=\beta_{0}+\Delta \beta$, where $\beta_{0}=1$. Then the effect of variation of the poles is represented by the characteristic equation

$$
s^{2}+s+\Delta \beta s+K=0,
$$

or, in root locus form,

$$
1+\frac{\Delta \beta s}{s^{2}+s+K}=0
$$

The denominator of the second term is the unchanged characteristic equation when $\Delta \beta=0$. The root locus for the unchanged system $(\Delta \beta=0)$ is shown in Figure 7.21 as a function of $K$. For a design specification requiring $\zeta=0.707$, the complex roots lie at

$$
-r_{1}=-0.5+j 0.5 \text { and }-r_{2}=-\hat{r}_{1}=-0.5-j 0.5
$$

Then, because the roots are complex conjugates, the root sensitivity for $r_{1}$ is the conjugate of the root sensitivity for $\hat{r}_{1}=r_{2}$. Using the parameter root locus techniques discussed in the preceding section, we obtain the root locus for $\Delta \beta$ as shown in Figure 7.22. We are normally interested in the effect of a variation for the parameter so that $\beta=\beta_{0} \pm \Delta \beta$, for which the locus as $\beta$ decreases is obtained from the root locus equation

$$
1+\frac{-(\Delta \beta) s}{s^{2}+s+K}=0 .
$$

We note that the equation is of the form

$$
1-\Delta \beta P(s)=0 .
$$

Comparing this equation with Equation (7.23) in Section 7.3, we find that the sign preceding the gain $\Delta \beta$ is negative in this case. In a manner similar to the development of the root locus method in Section 7.3, we require that the root locus satisfy the equations

$$
|\Delta \beta P(s)|=1 \text { and } \angle P(s)=0^{\circ} \pm k 360^{\circ}
$$

FIGURE 7.22

The root locus for the parameter $\beta$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0476.jpg?height=791&width=539&top_left_y=1319&top_left_x=521)

where $k$ is an integer. The locus of roots follows a zero-degree locus in contrast with the $180^{\circ}$ locus considered previously. However, the root locus rules of Section 7.3 may be altered to account for the zero-degree phase angle requirement, and then the root locus may be obtained as in the preceding sections. Therefore, to obtain the effect of reducing $\beta$, we determine the zero-degree locus in contrast to the $180^{\circ}$ locus, as shown by a dotted locus in Figure 7.22. To find the effect of a $20 \%$ change of the parameter $\beta$, we evaluate the new roots for $\Delta \beta= \pm 0.20$, as shown in Figure 7.22. The root sensitivity is readily evaluated graphically and, for a positive change in $\beta$, is

$$
S_{\beta+}^{r_{1}}=\frac{\Delta r_{1}}{\Delta \beta / \beta}=\frac{0.16 \angle-128^{\circ}}{0.20}=0.80\left\lfloor-128^{\circ} .\right.
$$

The root sensitivity for a negative change in $\beta$ is

$$
S_{\beta-}^{r_{1}}=\frac{\Delta r_{1}}{\Delta \beta / \beta}=\frac{0.125 \angle 39^{\circ}}{0.20}=0.625 \angle+39^{\circ} .
$$

As the percentage change $\Delta \beta / \beta$ decreases, the sensitivity measures $S_{\beta+}^{n_{1}}$ and $S_{\beta-}^{\eta_{-}}$ will approach equality in magnitude and a difference in angle of $180^{\circ}$. Thus, for small changes when $\Delta \beta / \beta \leq 0.10$, the sensitivity measures are related as

$$
\left|S_{\beta+}^{r_{1}}\right|=\left|S_{\beta-}^{r_{1}}\right|
$$

and

$$
\angle S_{\beta+}^{r_{1}}=180^{\circ}+\angle S_{\beta-}^{r_{1}}
$$

Often, the desired root sensitivity measure is desired for small changes in the parameter. When the relative change in the parameter is of the order $\Delta \beta / \beta=0.10$, we can estimate the increment in the root change by approximating the root locus with the line at the angle of departure $\theta_{d}$. This approximation is shown in Figure 7.22 and is accurate for only relatively small changes in $\Delta \beta$. However, the use of this approximation allows the analyst to avoid sketching the complete root locus diagram. Therefore, for Figure 7.22, the root sensitivity may be evaluated for $\Delta \beta / \beta=0.10$ along the departure line, and we obtain

$$
S_{\beta+}^{r_{1}}=\frac{0.075 \angle-132^{\circ}}{0.10}=0.75 \angle-132^{\circ} .
$$

The root sensitivity measure for a parameter variation is useful for comparing the sensitivity for various design parameters and at different root locations. Comparing Equation (7.85) for $\beta$ with Equation (7.83) for $\alpha$, we find (a) that the sensitivity for $\beta$ is greater in magnitude by approximately $50 \%$ and (b) that the angle for $S_{\beta-}^{r_{1}}$ indicates that the approach of the root toward the $j \omega$-axis is more sensitive for changes in $\beta$. Therefore, the tolerance requirements for $\beta$ would be more stringent than for $\alpha$. This information provides the designer with a comparative measure of the required tolerances for each parameter. To utilize the root sensitivity measure for the analysis and design of control systems, a series of calculations must be performed; they will determine the various selections of possible root configurations and the zeros and poles of the loop transfer function. Therefore, the root sensitivity measure as a design technique is somewhat limited by the relatively large number of calculations required and the lack of an obvious direction for adjusting the parameters in order to provide a minimized or reduced sensitivity. However, the root sensitivity measure can be utilized as an analysis measure, which permits the designer to compare the sensitivity for several system designs based on a suitable method of design. The root sensitivity measure is a useful index of the system sensitivity to parameter variations expressed in the $s$-plane. The weakness of the sensitivity measure is that it relies on the ability of the root locations to represent the performance of the system. The root locations represent the performance quite adequately for many systems, but due consideration must be given to the location of the zeros of the closed-loop transfer function and the dominant roots. The root sensitivity measure is a suitable measure of system performance sensitivity and can be used reliably for system analysis and design.

\subsection{PID CONTROLLERS}

One form of controller widely used in industrial process control is the three-term, PID controller $[4,10]$. This controller has a transfer function

$$
G_{c}(s)=K_{p}+\frac{K_{I}}{s}+K_{D} s
$$

The equation for the output in the time domain is

$$
u(t)=K_{p} e(t)+K_{I} \int e(t) d t+K_{D} \frac{d e(t)}{d t} .
$$

The three-term controller is called a PID controller because it contains a proportional, an integral, and a derivative term represented by $K_{p}, K_{I}$, and $K_{D}$, respectively. The transfer function of the derivative term is actually

$$
G_{d}(s)=\frac{K_{D} s}{\tau_{d} s+1},
$$

but $\tau_{d}$ is usually much smaller than the time constants of the process itself, so it is neglected.

If we set $K_{D}=0$, then we have the proportional plus integral (PI) controller

$$
G_{c}(s)=K_{p}+\frac{K_{I}}{s}
$$

When $K_{I}=0$, we have

$$
G_{c}(s)=K_{p}+K_{D} s
$$

which is called a proportional plus derivative (PD) controller. The PID controller can also be viewed as a cascade of the PI and the PD controllers. Consider the PI controller

$$
G_{P I}(s)=\hat{K}_{P}+\frac{\hat{K}_{I}}{s}
$$

and the PD controller

$$
G_{P D}(s)=\bar{K}_{P}+\bar{K}_{D} s,
$$

where $\hat{K}_{P}$ and $\hat{K}_{I}$ are the PI controller gains and $\bar{K}_{P}$ and $\bar{K}_{D}$ are the PD controller gains. Cascading the two controllers (that is, placing them in series) yields

$$
\begin{aligned}
G_{c}(s) & =G_{P I}(s) G_{P D}(s) \\
& =\left(\hat{K}_{P}+\frac{\hat{K}_{I}}{s}\right)\left(\bar{K}_{P}+\bar{K}_{D} s\right) \\
& =\left(\bar{K}_{P} \hat{K}_{P}+\hat{K}_{I} \bar{K}_{D}\right)+\hat{K}_{P} \bar{K}_{D} s+\frac{\hat{K}_{I} \bar{K}_{D}}{s} \\
& =K_{P}+K_{D} s+\frac{K_{I}}{s},
\end{aligned}
$$

where we have the following relationships between the PI and PD controller gains and the PID controller gains

$$
\begin{aligned}
K_{P} & =\bar{K}_{P} \hat{K}_{P}+\hat{K}_{I} \bar{K}_{D} \\
K_{D} & =\hat{K}_{P} \bar{K}_{D} \\
K_{I} & =\hat{K}_{I} \bar{K}_{D} .
\end{aligned}
$$

Consider the PID controller

$$
\begin{aligned}
G_{c}(s) & =K_{P}+\frac{K_{I}}{s}+K_{D} s=\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s} \\
& =\frac{K_{D}\left(s^{2}+a s+b\right)}{s}=\frac{K_{D}\left(s+z_{1}\right)\left(s+z_{2}\right)}{s},
\end{aligned}
$$

where $a=K_{P} / K_{D}$ and $b=K_{I} / K_{D}$. A PID controller introduces a transfer function with one pole at the origin and two zeros that can be located anywhere in the $s$-plane.

Consider the system shown in Figure 7.23 where we use a PID controller with complex zeros $-z_{1}$ and $-z_{2}$, where $-z_{1}=-3+j 1$ and $-z_{2}=-\hat{z}_{1}$. We plot the root

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0479.jpg?height=214&width=1000&top_left_y=1902&top_left_x=370)

FIGURE 7.24

Root locus for plant with a PID controller with complex zeros.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0480.jpg?height=727&width=760&top_left_y=154&top_left_x=523)

locus as shown in Figure 7.24. As the gain, $K_{D}$, of the controller is increased, the complex roots approach the zeros. The closed-loop transfer function is

$$
T(s)=\frac{G(s) G_{c}(s)}{1+G(s) G_{c}(s)}=\frac{K_{D}\left(s+z_{1}\right)\left(s+\hat{z}_{1}\right)}{\left(s+r_{2}\right)\left(s+r_{1}\right)\left(s+\hat{r}_{1}\right)} .
$$

The percent overshoot to a step will be P.O. $\leq 2 \%$, and the steady-state error for a step input will be $e_{S S}=0$. The settling time will be approximately $T_{s}=1 \mathrm{~s}$. If a shorter settling time is desired, then we select $z_{1}$ and $z_{2}$ to lie further left in the left-hand $s$-plane and set $K_{D}$ to drive the roots near the complex zeros.

The popularity of PID controllers can be attributed partly to their good performance over a wide range of operating conditions and partly to their functional simplicity that allows engineers to operate them in a simple, straightforward manner. To implement the PID controller, three parameters must be determined, the proportional gain, denoted by $K_{P}$, integral gain, denoted by $K_{I}$, and derivative gain denoted by $K_{D}[10]$.

There are many methods available to determine acceptable values of the PID gains. The process of determining the gains is often called PID tuning. A common approach to tuning is to use manual PID tuning methods, whereby the PID control gains are obtained by trial-and-error with minimal analytic analysis using step responses obtained via simulation, or in some cases, actual testing on the system and deciding on the gains based on observations and experience. A more analytic method is known as the Ziegler-Nichols tuning method. The Ziegler-Nichols tuning method actually has several variations. We discuss in this section a Ziegler-Nichols tuning method based on open-loop responses to a step input and a related a Ziegler-Nichols tuning method based on closed-loop response to a step input. Table 7.4 Effect of Increasing the PID Gains $K_{p}, K_{D}$, and $K_{\text {I }}$ on the Step Response

\begin{tabular}{llll} 
PID Gain & Percent & & Steady-State \\
\hline Increasing $K_{P}$ & Overshoot & Settling Time & Error \\
Increasing $K_{I}$ & Increases & Minimal impact & Decreases \\
Increasing $K_{D}$ & Decreases & Increases & Zero steady-state error \\
\hline
\end{tabular}

One approach to manual tuning is to first set $K_{I}=0$ and $K_{D}=0$. This is followed by slowly increasing the gain $K_{P}$ until the output of the closed-loop system oscillates just on the edge of instability. This can be done either in simulation or on the actual system if it cannot be taken off-line. Once the value of $K_{P}$ (with $K_{I}=0$ and $K_{D}=0$ ) is found that brings the closed-loop system to the edge of stability, you reduce the value of gain $K_{P}$ to achieve what is known as the quarter amplitude decay. That is, the amplitude of the closed-loop response is reduced approximately to one-fourth of the maximum value in one oscillatory period. A rule-of-thumb is to start by reducing the proportional gain $K_{P}$ by onehalf. The next step of the design process is to increase $K_{I}$ and $K_{D}$ manually to achieve a desired step response. Table 7.4 describes in general terms the effect of increasing $K_{I}$ and $K_{D}$.

\section{EXAMPLE 7.7 Manual PID tuning}

Consider the closed-loop system in Figure 7.25, where $b=10, \zeta=0.707$, and $\omega_{n}=4$. To begin the manual tuning process, set $K_{I}=0$ and $K_{D}=0$ and increase $K_{P}$ until the closed-loop system has sustained oscillations. As can be seen in Figure 7.26(a), when $K_{P}=885.5$, we have a sustained oscillation of magnitude $A=1.9$ and period $P=0.83$ s. The root locus shown in Figure 7.26(b) corresponds to the characteristic equation

$$
1+K_{P}\left[\frac{1}{s(s+10)(s+5.66)}\right]=0 .
$$

The root locus shown in Figure 7.26(b) illustrates that when $K_{P}=885.5$, we have closed-loop poles at $s= \pm 7.5 \mathrm{j}$ leading to the oscillatory behavior in the step response in Figure 7.26(a).

FIGURE 7.25

Unity feedback control system with PID controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0481.jpg?height=247&width=1152&top_left_y=1763&top_left_x=374)

FIGURE 7.26

(a) Step response with $K_{P}=885.5$, $K_{D}=0$, and $K_{I}=0$. (b) Root locus showing $K_{P}=885.5$ results in marginal stability with $s= \pm 7.5 j$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0482.jpg?height=351&width=948&top_left_y=154&top_left_x=523)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0482.jpg?height=351&width=964&top_left_y=563&top_left_x=520)

(b)

Reduce $K_{P}=885.5$ by half as a first step to achieving a step response with approximately a quarter amplitude decay. You may have to iterate on the value $K_{P}=442.75$. The step response is shown in Figure 7.27 where we note that the peak amplitude is reduced to one-fourth of the maximum value in one period, as desired. To accomplish this reduction, we refined the value of $K_{P}$ by slowly reducing the value from $K_{P}=442.75$ to $K_{P}=370$.

The root locus for $K_{P}=370, K_{I}=0$, and $0 \leq K_{D}<\infty$ is shown in Figure 7.28. In this case, the characteristic equation is

$$
1+K_{D}\left[\frac{s}{(s+10)(s+5.66)+K_{P}}\right]=0 .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0482.jpg?height=630&width=802&top_left_y=1484&top_left_x=516)

FIGURE 7.27

Step response with $K_{P}=370$ showing the quarter amplitude decay. FIGURE 7.28

Root locus for $K_{P}=370$,

$K_{I}=0$, and $0 \leq K_{D}<\infty$.

FIGURE 7.29

Percent overshoot and settling time with $K_{P}=370$, $K_{I}=0$, and $5 \leq K_{D}<75$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0483.jpg?height=635&width=833&top_left_y=155&top_left_x=374)

We see in Figure 7.28 that as $K_{D}$ increases, the root locus shows that the closed-loop complex poles move left, and in doing so, increases the associated damping ratio and thereby decreases the percent overshoot. The movement of the complex poles to the left also increases the associated $\zeta \omega_{n}$, thereby reducing the settling time. These effects of varying $K_{D}$ are consistent with information provided in Table 7.4. As $K_{D}$ increases (when $K_{D}>75$ ), the real root begins to dominant the response and the trends described in Table 7.4 become less accurate. The percent overshoot and settling time as a function of $K_{D}$ are shown in Figure 7.29.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0483.jpg?height=792&width=996&top_left_y=1314&top_left_x=374)FIGURE 7.30

Root locus for $K_{P}=370$, $K_{D}=0$, and $0 \leq K_{l}<\infty$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0484.jpg?height=783&width=1000&top_left_y=152&top_left_x=521)

The root locus for $K_{P}=370, K_{D}=0$, and $0 \leq K_{I}<\infty$ is shown in Figure 7.30. The characteristic equation is

$$
1+K_{I}\left[\frac{1}{s\left(s(s+10)(s+5.66)+K_{P}\right)}\right]=0 .
$$

We see in Figure 7.30 that as $K_{I}$ increases, the root locus shows that the closedloop complex pair poles move right. This decreases the associated damping ratio and thereby increasing the percent overshoot. In fact, when $K_{I}=778.2$, the system is marginally stable with closed-loop poles at $s= \pm 4.86 j$. The movement of the complex poles to the right also decreases the associated $\zeta \omega_{n}$, thereby increasing the settling time. The percent overshoot and settling time as a function of $K_{I}$ are shown in Figure 7.31. The trends in Figure 7.31 are consistent with Table 7.4.

To meet the percent overshoot and settling time specifications, we can select $K_{P}=370, K_{D}=60$, and $K_{I}=100$. The step response shown in Figure 7.32 indicates a $T_{S}=2.4 \mathrm{~s}$ and P.O. $=12.8 \%$ meeting the specifications.

Two important PID controller gain tuning methods were published in 1942 by John G. Ziegler and Nathaniel B. Nichols intended to achieve a fast closed-loop step response without excessive oscillations and excellent disturbance rejection. The two approaches are classified under the general heading of Ziegler-Nichols tuning methods. The first approach is based on closed-loop concepts requiring the computation of the ultimate gain and ultimate period. The second approach is based on open-loop concepts relying on reaction curves. The Ziegler-Nichols tuning methods are based on assumed forms of the models of the process, but the models do not have to be precisely known. This makes the tuning approach very practical in FIGURE 7.31

Percent overshoot and settling time with $K_{P}=370$, $K_{D}=0$, and $50 \leq K_{l}<600$.

FIGURE 7.32

Percent overshoot and settling time with final design $K_{p}=370$,

$K_{D}=60$, and $K_{l}=100$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0485.jpg?height=1456&width=998&top_left_y=168&top_left_x=374)

process control applications. Our suggestion is to consider the Ziegler-Nichols rules to obtain initial controller designs followed by design iteration and refinement. Remember that the Ziegler-Nichols rules will not work with all plants or processes.

The closed-loop Ziegler-Nichols tuning method considers the closed-loop system response to a step input (or step disturbance) with the PID controller in the loop. Initially the derivative and integral gains, $K_{D}$ and $K_{I}$, respectively, are set to zero. The proportional gain $K_{P}$ is increased (in simulation or on the actual system) until the closed-loop system reaches the boundary of instability. The gain on the border of instability, denoted by $K_{U}$, is called the ultimate gain. The period of the sustained oscillations, denoted by $P_{U}$, is called the ultimate period. Once $K_{U}$ and Table 7.5 Ziegler-Nichols PID Tuning Using Ultimate Gain, $K_{U}$, and Oscillation Period, $P_{U}$

Ziegler-Nichols PID Controller Gain Tuning Using Closed-Loop Concepts

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0486.jpg?height=444&width=1531&top_left_y=272&top_left_x=220)

$P_{U}$ are determined, the PID gains are computed using the relationships in Table 7.5 according to the Ziegler-Nichols tuning method.

\section{EXAMPLE 7.8 Closed-loop Ziegler-Nichols PID tuning}

Re-consider the system in Example 7.7. The gains $K_{P}, K_{D}$, and $K_{I}$ are computed using the formulas in Table 7.5. We found in Example 7.7 that $K_{U}=885.5$ and $T_{U}=0.83 \mathrm{~s}$. By using the Ziegler-Nichols formulas we obtain

$$
K_{P}=0.6 K_{U}=531.3, \quad K_{I}=\frac{1.2 K_{U}}{T_{U}}=1280.2, \quad \text { and } \quad K_{D}=\frac{0.6 K_{U} T_{U}}{8}=55.1 .
$$

Comparing the step response in Figures 7.33 and 7.34 we note that the settling time is approximately the same for the manually tuned and the Ziegler-Nichols tuned PID controllers. However, the percent overshoot of the manually tuned controller is less than that of the Ziegler-Nichols tuning. This is due to the fact that the ZieglerNichols tuning is designed to provide the best disturbance rejection performance rather than the best input response performance.

FIGURE 7.33

Time response for the Ziegler-Nichols PID tuning with

$K_{P}=531.3$,

$K_{I}=1280.2$, and $K_{D}=55.1$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0486.jpg?height=640&width=830&top_left_y=1470&top_left_x=507)

FIGURE 7.34

Disturbance response for the Ziegler-Nichols PID tuning versus the manual tuning.
FIGURE 7.35

Reaction curve illustrating parameters $R$ and $\Delta T$ required for the Ziegler-Nichols open-loop tuning method.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0487.jpg?height=692&width=868&top_left_y=169&top_left_x=375)

In Figure 7.34, we see that the step disturbance performance of the ZieglerNichols PID controller is indeed better than the manually tuned controller. While Ziegler-Nichols approach provides a structured procedure for obtaining the PID controller gains, the appropriateness of the Ziegler-Nichols tuning depends on the requirements of the problem under investigation.

The open-loop Ziegler-Nichols tuning method utilizes a reaction curve obtained by taking the controller off-line (that is, out of the loop) and introducing a step input (or step disturbance). This approach is very commonly used in process control applications. The measured output is the reaction curve and is assumed to have the general shape shown in Figure 7.35. The response in Figure 7.35 implies that the process is a first-order system with a transport delay. If the actual system does not match the assumed form, then another approach to PID tuning should be

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0487.jpg?height=652&width=513&top_left_y=1457&top_left_x=376)

considered. However, if the underlying system is linear and lethargic (or sluggish and characterized by delay), the assumed model may suffice to obtain a reasonable PID gain selection using the open-loop Ziegler-Nichols tuning method.

The reaction curve is characterized by the transport delay, $\Delta T$, and the reaction rate, $R$. Generally, the reaction curve is recorded and numerical analysis is performed to obtain estimates of the parameters $\Delta T$ and $R$. A system possessing the reaction curve shown in Figure 7.35 can be approximated by a first-order system with a transport delay as

$$
G(s)=M\left[\frac{p}{s+p}\right] e^{-\Delta T s},
$$

where $M$ is the magnitude of the response at steady-state, $\Delta T$ is the transport delay, and $p$ is related to the slope of the reaction curve. The parameters $M, \tau$, and $\Delta T$ can be estimated from the open-loop step response and then utilized to compute $R=M / \tau$. Once that is accomplished, the PID gains are computed as shown in Table 7.6. You can also use the Ziegler-Nichols open-loop tuning method to design a proportional controller or a proportional-plus-integral controller.

\section{EXAMPLE 7.9 Open-loop Ziegler-Nichols PI controller tuning}

Consider the reaction curve shown in Figure 7.36. We estimate the transport lag to be $\Delta T=0.1 \mathrm{~s}$ and the reaction rate $R=0.8$.

Using the Ziegler-Nichols tuning for the PI controller gains we have

$$
K_{P}=\frac{0.9}{R \Delta T}=11.25 \quad \text { and } \quad K_{I}=\frac{0.27}{R \Delta T^{2}}=33.75 .
$$

The closed-loop system step response (assuming unity feedback) is shown in Figure 7.37. The settling time is $T_{S}=1.28 \mathrm{~s}$ and the percent overshoot is $P . O .=78 \%$. Since we are using a PI controller, the steady-state error is zero, as expected.

The manual tuning method and the two Ziegler-Nichols tuning approaches presented here will not always lead to the desired closed-loop performance. The three

\section{Table 7.6 Ziegler-Nichols PID Tuning Using Reaction Curve Characterized by Time Delay,} $\Delta T$, and Reaction Rate, $R$

\begin{tabular}{|c|c|c|c|}
\hline Controller Type & $K_{P}$ & $K_{l}$ & $K_{D}$ \\
\hline Proportional $(\mathrm{P})$ & 1 & & \\
\hline$G_{c}(s)=K_{P}$ & $R \Delta T$ & - & - \\
\hline \multicolumn{4}{|c|}{ Proportional-plus-integral (PI) } \\
\hline$G_{(\mathrm{c})} \quad K_{I}$ & 0.9 & 0.27 & - \\
\hline$G_{c}(s)=K_{P}+\frac{-1}{s}$ & $R \Delta T$ & $R \Delta T^{2}$ & \\
\hline \multicolumn{4}{|c|}{ Proportional-plus-integral-plus-derivative (PID) } \\
\hline$G_{(\mathrm{s})}-K_{\mathrm{D}}+K_{I}+K_{\mathrm{D}}$ & 1.2 & 0.6 & 0.6 \\
\hline$U_{c}(s)=\Lambda_{P}+\frac{\bar{s}}{s}+\Lambda_{D}$ & $R \Delta T$ & $\overline{R \Delta T^{2}}$ & $R$ \\
\hline
\end{tabular}

Ziegler-Nichols PID Controller Gain Tuning Using Open-Loop Concepts FIGURE 7.36

Reaction curve with $T_{d}=0.1 \mathrm{~s}$ and $R=0.8$.

FIGURE 7.37

Time response for the Ziegler-Nichols PI tuning with $K_{P}=11.25$ and $K_{I}=33.75$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0489.jpg?height=1390&width=890&top_left_y=152&top_left_x=374)

methods do provide structured design steps leading to candidate PID gains and should be viewed as first steps in the design iteration. Since the PID (and the related PD and PI) controllers are in wide use today in a variety of applications, it is important to become familiar with various design approaches. We will use the PD controller later in this chapter to control the hard disk drive sequential design problem (see Section 7.10).

\subsection{NEGATIVE GAIN ROOT LOCUS}

As discussed in Section 7.2, the dynamic performance of a closed-loop control system is described by the closed-loop transfer function, that is, by the poles and zeros of the closed-loop system. The root locus is a graphical illustration of the variation of the roots of the characteristic equation as a single parameter of interest varies. We know that the roots of the characteristic equation and the closed-loop poles are one in the same. In the case of the single-loop negative unity feedback system shown in Figure 7.1, the characteristic equation is

$$
1+K G(s)=0,
$$

where $K$ is the parameter of interest. The orderly seven-step procedure for sketching the root locus described in Section 7.3 and summarized in Table 7.2 is valid for the case where $0 \leq K<\infty$. Sometimes the situation arises where we are interested in the root locus for negative values of the parameter of interest where $-\infty<K \leq 0$. We refer to this as the negative gain root locus. Our objective here is to develop an orderly procedure for sketching the negative gain root locus using familiar concepts from root locus sketching as described in Section 7.2.

Rearranging Equation (7.86) yields

$$
G(s)=-\frac{1}{K}
$$

Since $K$ is negative, it follows that

$$
|K G(s)|=1 \text { and } K G(s)=0^{\circ}+k 360^{\circ}
$$

where $k=0, \pm 1, \pm 2, \pm 3, \ldots$. The magnitude and phase conditions in Equation (7.87) must both be satisfied for all points on the negative gain root locus. Note that the phase condition in Equation (7.87) is different from the phase condition in Equation (7.4). As we will show, the new phase condition leads to several key modifications in the root locus sketching steps from those summarized in Table 7.2.

\section{EXAMPLE 7.10 Negative gain root locus}

Consider the system shown in Figure 7.38. The loop transfer function is

$$
L(s)=K G(s)=K \frac{s-20}{s^{2}+5 s-50}
$$

and the characteristic equation is

$$
1+K \frac{s-20}{s^{2}+5 s-50}=0 .
$$

Sketching the root locus yields the plot shown in Figure 7.39(a) where it can be seen that the closed-loop system is not stable for any $0 \leq K<\infty$. The negative gain root locus is shown in Figure 7.39(b). Using the negative gain root locus in Figure 7.39(b) we find that the stability is $-5.0<K<-2.5$. The system in Figure 7.38 can thus be stabilized with only negative gain, $K$.

To locate the roots of the characteristic equation in a graphical manner on the $s$-plane for negative values of the parameter of interest, we will re-visit the seven steps summarized in Table 7.2 to obtain a similar orderly procedure to facilitate the rapid sketching of the locus. FIGURE 7.38

(a) Signal flow graph and (b) block diagram of unity feedback system with controller gain, $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0491.jpg?height=430&width=717&top_left_y=166&top_left_x=620)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0491.jpg?height=356&width=1226&top_left_y=711&top_left_x=375)

(b)

$$
1+K \frac{s-20}{s^{2}+5 s-50}=0
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0491.jpg?height=454&width=1076&top_left_y=1184&top_left_x=412)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0491.jpg?height=372&width=1072&top_left_y=1698&top_left_x=414)

(b)
FIGURE 7.39

(a) Root locus for $0 \leq K<\infty$

(b) Negative gain root locus for $-\infty<K \leq 0$. Step 1: Prepare the root locus sketch. As before, you begin by writing the characteristic equation and rearranging, if necessary, so that the parameter of interest, $K$, appears as the multiplying factor in the form,

$$
1+K P(s)=0 .
$$

For the negative gain root locus, we are interested in determining the locus of roots of the characteristic equation in Equation (7.88) for $-\infty<K \leq 0$. As in Equation (7.24), factor $P(s)$ in Equation (7.88) in the form of poles and zeros and locate the poles and zeros on the $s$-plane with "x" to denote poles and "o" to denote zeros.

When $K=0$, the roots of the characteristic equation are the poles of $P(s)$, and when $K \rightarrow-\infty$ the roots of the characteristic equation are the zeros of $P(s)$. Therefore, the locus of the roots of the characteristic equation begins at the poles of $P(s)$ when $K=0$ and ends at the zeros of $P(s)$ as $K \rightarrow-\infty$. If $P(s)$ has $n$ poles and $M$ zeros and $n>M$, we have $n-M$ branches of the root locus approaching the zeros at infinity and the number of separate loci is equal to the number of poles. The root loci are symmetrical with respect to the horizontal real axis because the complex roots must appear as pairs of complex conjugate roots.

Step 2: Locate the segments of the real axis that are root loci. The root locus on the real axis always lies in a section of the real axis to the left of an even number of poles and zeros. This follows from the angle criterion of Equation (7.87).

Step 3: When $n>M$, we have $n-M$ branches heading to the zeros at infinity as $K \rightarrow-\infty$ along asymptotes centered at $\sigma_{A}$ and with angles $\phi_{A}$. The linear asymptotes are centered at a point on the real axis given by

$$
\sigma_{A}=\frac{\sum \text { poles of } P(s)-\sum \text { zeros of } P(s)}{n-M}=\frac{\sum_{j=1}^{n}\left(-p_{j}\right)-\sum_{i=1}^{M}\left(-z_{i}\right)}{n-M} .
$$

The angle of the asymptotes with respect to the real axis is

$$
\phi_{A}=\frac{2 k+1}{n-M} 360^{\circ} \quad k=0,1,2, \ldots,(n-M-1),
$$

where $k$ is an integer index.

Step 4: Determine where the locus crosses the imaginary axis (if it does so), using the Routh-Hurwitz criterion.

Step 5: Determine the breakaway point on the real axis (if any). In general, due to the phase criterion, the tangents to the loci at the breakaway point are equally spaced over $360^{\circ}$. The breakaway point on the real axis can be evaluated graphically or analytically. The breakaway point can be computed by rearranging the characteristic equation

$$
1+K \frac{n(s)}{d(s)}=0
$$

as

$$
p(s)=K,
$$

where $p(s)=-d(s) / n(s)$ and finding the values of $s$ that maximize $p(s)$. This is accomplished by solving the equation

$$
n(s) \frac{\mathrm{d}[d(s)]}{\mathrm{d} s}-d(s) \frac{\mathrm{d}[n(s)]}{\mathrm{d} s}=0 .
$$

Equation (7.91) yields a polynomial equation in $s$ of degree $n+M-1$, where $n$ is the number of poles and $M$ is the number of zeros. Hence the number of solutions is $n+M-1$. The solutions that exist on the root locus are the breakaway points.

Step 6: Determine the angle of departure of the locus from a pole and the angle of arrival of the locus at a zero using the phase angle criterion. The angle of locus departure from a pole or angle of arrival at a zero is the difference between the net angle due to all other poles and zeros and the criterion angle of $\pm k 360^{\circ}$.

Step 7: The final step is to complete the sketch by drawing in all sections of the locus not covered in the previous six steps.

The seven steps for sketching a negative gain root locus are summarized in Table 7.7.

\section{Table 7.7 Seven Steps for Sketching a Negative Gain Root Locus (color text denotes changes from root locus steps in Table 7.2)}

1. Prepare the root locus sketch.

(a) Write the characteristic equation so that the parameter of interest, $K$, appears as a multiplier.

(b) Factor $P(s)$ in terms of $n$ poles and $M$ zeros

(c) Locate the open-loop poles and zeros of $P(s)$ in the s-plane with selected symbols.

(d) Determine the number of separate loci, $S L$.

(e) The root loci are symmetrical with respect to the horizontal real axis.

2. Locate the segments of the real axis that are root loci.

3. The loci proceed to the zeros at infinity along asymptotes centered at $\sigma_{A}$ and with angles $\phi_{A}$. (a) $1+K P(s)=0$

$\prod^{M}\left(s+z_{i}\right)$

(b) $1+K \frac{\prod_{i=1}^{n}\left(s+z_{i}\right)}{\prod_{j=1}^{n}\left(s+p_{j}\right)}=0$

(c) $\times=$ poles, $\mathrm{O}=$ zeros

(d) Locus begins at a pole and ends at a zero.

$S L=n$ when $n \geq M ; n=$ number of finite, $M=$ number of finite zeros .

Locus lies to the left of an even number of poles and zeros.

$$
\begin{aligned}
\sigma_{A}= & \frac{\sum_{j=1}^{n}\left(-p_{j}\right)-\sum_{i=1}^{M}\left(-z_{i}\right)}{n-M} . \\
\phi_{A}= & \frac{2 k+1}{n-M} 360^{\circ}, k=0,1,2, \ldots(n-M-1)
\end{aligned}
$$



\section{Table 7.7 (continued)}

Step

4. Determine the points at which the locus crosses the imaginary axis (if it does so).

5. Determine the breakaway point on the real axis (if any).

6. Determine the angle of locus departure from complex at or poles and the angle of locus arrival at complex zeros using the phase criterion.

\section{Related Equation or Rule}

Use Routh-Hurwitz criterion.

a) Set $K=p(s)$

b) Determine roots of $d p(s) / d s=0$ or use graphical method to find maximum of $p(s)$.

$\angle P(s)= \pm k 360^{\circ}$ at $s=-p_{j}$ or $-z_{i}$

7. Complete the negative gain root locus sketch.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. The first example is a wind turbine control system. The feedback control system uses a PI controller to achieve a fast settling time and rise time while limiting the percent overshoot to a step input. In the second example, the automatic control of the velocity of an automobile is considered. The root locus method is extended from one parameter to three parameters as the three gains of a PID controller are determined. The design process is emphasized, including considering the control goals and associated variables to be controlled, the design specifications, and the PID controller design using root locus methods.

\section{EXAMPLE 7.11 Wind turbine speed control}

Wind energy conversion to electric power is achieved by wind energy turbines connected to electric generators. Of particular interest are wind turbines, as shown in Figure 7.40, that are located offshore [33]. The new concept is to allow the wind turbine to float rather than positioning the structure on a tower tied deep into the

FIGURE 7.40

Wind turbine placed offshore can help alleviate energy needs. (IS-200501/ Cultura RM/Alamy Stock Photo)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0494.jpg?height=606&width=492&top_left_y=1501&top_left_x=521)

ocean floor. This allows the wind turbine structure to be placed in deeper waters up to 100 miles offshore far enough not to burden the landscape with unsightly structures [34]. Moreover, the wind is generally stronger on the open ocean, potentially leading to the production of $5 \mathrm{MW}$ versus the more typical $1.5 \mathrm{MW}$ for wind turbines onshore. However, the irregular character of wind direction and power results in the need for reliable, steady electric energy by using control systems for the wind turbines. The goal of these control devices is to reduce the effects of wind intermittency and of wind direction change. The rotor and generator speed control can be achieved by adjusting the pitch angle of the blades.

A basic model of the generator speed control system is shown in Figure 7.41 [35]. A linearized model from the collective pitch to the generator speed is given by ${ }^{1}$

$$
G(s)=\frac{4.2158(s-827.1)\left(s^{2}-5.489 s+194.4\right)}{(s+0.195)\left(s^{2}+0.101 s+482.6\right)} .
$$

The model corresponds to a $600 \mathrm{KW}$ turbine with hub height $=36.6 \mathrm{~m}$, rotor diameter $=40 \mathrm{~m}$, rated rotor speed $=41.7 \mathrm{rpm}$, rated generator speed $=1800 \mathrm{rpm}$, and maximum pitch rate $=18.7 \mathrm{deg} / \mathrm{s}$. Note that the linearized model in Equation (7.92) has zeros in the right half-plane at $s_{1}=827.1$ and $s_{2,3}=0.0274 \pm 0.1367 j$ making this a nonminimum phase system.

A simplified version of the model in Equation (7.92) is given by the transfer function

$$
G(s)=\frac{K}{\tau s+1}
$$

where $\tau=5$ s and $K=-7200$. We will design a PI controller to control the speed of the turbine generator using the simplified first-order model in Equation (7.93) and confirm that the design specifications are satisfied for both the first-order model and the third-order model in Equation (7.92). The PI controller, denoted by $G_{c}(s)$, is given by

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=K_{P}\left[\frac{s+\tau_{c}}{s}\right],
$$

where $\tau_{c}=K_{I} / K_{P}$ and the gains $K_{P}$ and $K_{I}$ are to be determined. A stability analysis indicates that negative gains $K_{I}<0$ and $K_{P}<0$ will stabilize the system.

FIGURE 7.41

Wind turbine generator speed control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0495.jpg?height=298&width=1209&top_left_y=1709&top_left_x=372)

${ }^{1}$ Provided by Dr. Lucy Pao and Jason Laks in private correspondence. FIGURE 7.42

Wind turbine generator speed control root locus with a PI controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0496.jpg?height=673&width=856&top_left_y=155&top_left_x=522)

The main design specification is to have a settling time $T_{S}<4$ s to a unit step input. We also desire a limited percent overshoot $($ P.O. $<25 \%)$ and a short rise time $\left(T_{r}<1 \mathrm{~s}\right)$ while meeting the settling time specification. To this end, we will target the damping ratio of the dominant roots to be $\zeta>0.4$ and the natural frequency $\omega_{n}>2.5 \mathrm{rad} / \mathrm{s}$.

The root locus is shown in Figure 7.42 for the characteristic equation

$$
1+\hat{K}_{P}\left[\frac{s+\tau_{c}}{s} \frac{7200}{5 s+1}\right]=0
$$

where $\tau_{c}=2$ and $\hat{K}_{P}=-K_{p}>0$. The placement of the controller zero at $s=-\tau_{c}=-2$ is a design parameter. We select the value of $\hat{K}_{P}$ such that the damping ratio of the closed-loop complex poles is $\zeta=0.707$. Selecting $\hat{K}_{P}=0.0025$ yields $K_{P}=-0.0025$ and $K_{I}=-0.005$. The PI controller is

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=-0.0025\left[\frac{s+2}{s}\right] .
$$

The step response is shown in Figure 7.43 using the simplified first-order model in Equation (7.93). The step response has $T_{s}=1.8 \mathrm{~s}, T_{r}=0.34 \mathrm{~s}$, and $\zeta=0.707$ which translates to P.O. $=19 \%$. The PI controller is able to meet all the control specifications. The step response using the third-order model in Equation (7.92) is shown in Figure 7.44 where we see the effect of the neglected components in the design as small oscillations in the speed response. The closed-loop impulse disturbance response in Figure 7.45 shows fast and accurate rejection of the disturbance in less than 3 seconds due to a $1^{\circ}$ pitch angle change. FIGURE 7.43

Step response of the wind turbine generator speed control system using the first-order model in Equation (7.93) with the designed PI controller showing all specifications are satisfied with P.O. $=19 \%$, $T_{\mathrm{s}}=1.8 \mathrm{~s}$, and $T_{r}=0.34 \mathrm{~s}$.

FIGURE 7.44

Step response of the third-order model in Equation (7.92) with the PI controller showing that all specifications are satisfied with P.O. $=25 \%$, $T_{\mathrm{s}}=1.7 \mathrm{~s}$, and $T_{r}=0.3 \mathrm{~s}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0497.jpg?height=1514&width=888&top_left_y=152&top_left_x=412)

\section{EXAMPLE 7.12 Automobile velocity control}

The automotive electronics market is expected to surpass $\$ 300$ billion. It is predicted that there will be an annual growth rate of over $7 \%$ in electronic braking, steering, and driver information. Much of the additional computing power will FIGURE 7.45

Disturbance response of the wind turbine generator speed control system with a PI controller shows excellent disturbance rejection characteristics.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0498.jpg?height=652&width=831&top_left_y=154&top_left_x=450)

be used for new technology for smart cars and smart roads, such as IVHS (intelligent vehicle/highway systems) $[14,30,31]$. New systems on-board the automobile will support semi-autonomous automobiles, safety enhancements, emission reduction, and other features including intelligent cruise control, and brake by wire systems eliminating the hydraulics [32].

The term IVHS refers to a varied assortment of electronics that provides real-time information on accidents, congestion, and roadside services to drivers and traffic controllers. IVHS also encompasses devices that make vehicles more autonomous: collision-avoidance systems and lane-tracking technology that alert drivers to impending disasters and allow a car to drive itself.

An example of an automated highway system is shown in Figure 7.46. A velocity control system for maintaining the velocity between vehicles is shown in Figure 7.47. The output $Y(s)$ is the relative velocity of the two automobiles; the input $R(s)$ is the desired relative velocity between the two vehicles. Our design goal is to develop a controller that can maintain the prescribed velocity between the vehicles and maneuver the active vehicle (in this case the rearward automobile) as commanded. The elements of the design process emphasized in this example are depicted in Figure 7.48.

The control goal is

\section{Control Goal}

Maintain the prescribed velocity between the two vehicles, and maneuver the active vehicle as commanded. FIGURE 7.46

Automated highway system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0499.jpg?height=624&width=1226&top_left_y=151&top_left_x=410)

FIGURE 7.47 Vehicle velocity control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0499.jpg?height=334&width=1118&top_left_y=887&top_left_x=410)

The variable to be controlled is the relative velocity between the two vehicles:

\section{Variable to Be Controlled}

The relative velocity between vehicles, denoted by $y(t)$.

The design specifications are

\section{Design Specifications}

DS1 Zero steady-state error to a step input.

DS2 Steady-state error due to a ramp input of $e_{s s} \leq 25 \%$ of the input magnitude.

DS3 Percent overshoot of P.O. $\leq 5 \%$ to a step input.

DS4 Settling time of $T_{s} \leq 1.5 \mathrm{~s}$ to a step input (using a $2 \%$ criterion to establish settling time).

From the design specifications and knowledge of the open-loop system, we find that we need a type 1 system to guarantee a zero steady-state error to a step input. The open-loop system transfer function is a type 0 system; therefore, the controller needs to increase the system type by at least 1 . A type 1 controller (that is, a controller 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0500.jpg?height=1011&width=1348&top_left_y=245&top_left_x=370)

FIGURE 7.48 Elements of the control system design process emphasized in the automobile velocity control example.

with one integrator) satisfies DS1. To meet DS2 we need to have the velocity error constant

$$
K_{v}=\lim _{s \rightarrow 0} s G_{c}(s) G(s) \geq \frac{1}{0.25}=4
$$

where

$$
G(s)=\frac{1}{(s+2)(s+8)}
$$

and $G_{c}(s)$ is the controller (yet to be specified).

The percent overshoot specification DS3 allows us to define a target damping ratio

$$
\text { P.O. } \leq 5 \% \text { implies } \zeta \geq 0.69 \text {. }
$$

Similarly from the settling time specification DS4 we have

$$
T_{s} \approx \frac{4}{\zeta \omega_{n}} \leq 1.5
$$

Solving for $\zeta \omega_{n}$ yields $\zeta \omega_{n} \geq 2.6$.

The desired region for the poles of the closed-loop transfer function is shown in Figure 7.49. Using a proportional controller $G_{c}(s)=K_{P}$, is not reasonable, because DS2 cannot be satisfied. We need at least one pole at the origin to track a ramp input. Consider the PI controller

$$
G_{c}(s)=\frac{K_{P} s+K_{I}}{s}=K_{P} \frac{s+\frac{K_{I}}{K_{P}}}{s} .
$$

The question is where to place the zero at $s=-K_{I} / K_{P}$.

We ask for what values of $K_{P}$ and $K_{I}$ is the system stable. The closed-loop transfer function is

$$
T(s)=\frac{K_{P} s+K_{I}}{s^{3}+10 s^{2}+\left(16+K_{P}\right) s+K_{I}} .
$$

The corresponding Routh array is

$$
\begin{array}{c|cc}
s^{3} & 1 & 16+K_{P} \\
s^{2} & 10 & K_{I} \\
s- & \frac{10\left(K_{P}+16\right)-K_{I}}{10} & 0 \\
1 & K_{I} &
\end{array}
$$

The first requirement for stability (from column one, row four) is

$$
K_{I}>0
$$

From the first column, third row, we have the inequality

$$
K_{P}>\frac{K_{I}}{10}-16
$$

FIGURE 7.49

Desired region in the complex plane for locating the dominant system poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0501.jpg?height=541&width=675&top_left_y=1571&top_left_x=394)

It follows from DS2 that

$$
K_{v}=\lim _{s \rightarrow 0} s G_{c}(s) G(s)=\lim _{s \rightarrow 0} s \frac{K_{P}\left(s+\frac{K_{I}}{K_{P}}\right)}{s} \frac{1}{(s+2)(s+8)}=\frac{K_{I}}{16}>4 .
$$

Therefore, the integral gain must satisfy

$$
K_{I}>64 .
$$

If we select $K_{I}>64$, then the inequality in Equation (7.97) is satisfied. The valid region for $K_{P}$ is then given by Equation (7.98), where $K_{I}>64$.

We need to consider DS4. Here we want to have the dominant poles to the left of the $s=-2.6$ line. We know from our experience sketching the root locus that since we have three poles (at $s=0,-2$, and -8 ) and one zero (at $s=-K_{I} / K_{P}$ ), we expect two branches of the loci to go to infinity along two asymptotes at $\phi=-90^{\circ}$ and $+90^{\circ}$ centered at

$$
\sigma_{A}=\frac{\sum\left(-p_{i}\right)-\sum\left(-z_{i}\right)}{n_{p}-n_{z}}
$$

where $n_{p}=3$ and $\mathrm{n}_{z}=1$. In our case

$$
\sigma_{A}=\frac{-2-8-\left(-\frac{K_{I}}{K_{P}}\right)}{2}=-5+\frac{1}{2} \frac{K_{I}}{K_{P}} .
$$

We want to have $\alpha<-2.6$ so that the two branches will bend into the desired regions. Therefore,

$$
-5+\frac{1}{2} \frac{K_{I}}{K_{P}}<-2.6
$$

or

$$
\frac{K_{I}}{K_{P}}<4.7
$$

So as a first design, we can select $K_{P}$ and $K_{I}$ such that

$$
K_{I}>64, K_{P}>\frac{K_{I}}{10}-16, \text { and } \frac{K_{I}}{K_{P}}<4.7 .
$$

Suppose we choose $K_{I} / K_{P}=2.5$. Then the closed-loop characteristic equation is

$$
1+K_{P} \frac{s+2.5}{s(s+2)(s+8)}=0 .
$$

The root locus is shown in Figure 7.50. To meet the $\zeta=0.69$ (which evolved from DS3), we need to select $K_{P}<30$. We selected the value at the boundary of the performance region (see Figure 7.50) as carefully as possible. FIGURE 7.50

Root locus for $K_{l} / K_{P}=2.5$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0503.jpg?height=861&width=1113&top_left_y=153&top_left_x=410)

Selecting $K_{P}=26$, we have $K_{I} / K_{P}=2.5$ which implies $K_{I}=65$. This satisfies the steady-state tracking error specification (DS2) since $K_{I}=65>64$.

The resulting PI controller is

$$
G_{c}(s)=26+\frac{65}{s}
$$

The step response is shown in Figure 7.51.

The percent overshoot is P.O. $=8 \%$, and the settling time is $T_{s}=1.45 \mathrm{~s}$. The percent overshoot specification is not precisely satisfied, but the controller in Equation (7.101) represents a very good first design. We can iteratively refine it. Even though the closed-loop poles lie in the desired region, the response does not exactly meet the specifications because the controller zero influences the response. The closed-loop system is a third-order system and does not have the performance of a second-order system. We might consider moving the zero to $s=-2$ (by choosing $K_{I} / K_{P}=2$ ) so that the pole at $s=-2$ is cancelled and the resulting system is a second-order system.

\subsection{THE ROOT LOCUS USING CONTROL DESIGN SOFTWARE}

An approximate root locus sketch can be obtained by applying the orderly procedure summarized in Table 7.2. Alternatively, we can use control design software to obtain an accurate root locus plot. However, we should not be tempted to rely solely on the computer for obtaining root locus plots while neglecting the manual steps in developing an approximate root locus. The fundamental concepts behind the root locus FIGURE 7.51

Automobile velocity control using the $\mathrm{PI}$ controller in Equation (7.101).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0504.jpg?height=859&width=1114&top_left_y=154&top_left_x=452)

method are embedded in the manual steps, and it is essential to understand their application fully.

The section begins with a discussion on obtaining a computer-generated root locus plot. This is followed by a discussion of the connections between the partial fraction expansion, dominant poles, and the closed-loop system response. Root sensitivity is covered in the final paragraphs.

The functions covered in this section are rlocus, rlocfind, and residue. The functions rlocus and rlocfind are used to obtain root locus plots, and the residue function is utilized for partial fraction expansions of rational functions.

Obtaining a Root Locus Plot. Consider the closed-loop control system in Figure 7.10. The closed-loop transfer function is

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{K(s+1)(s+3)}{s(s+2)(s+3)+K(s+1)} .
$$

The characteristic equation can be written as

$$
1+K \frac{s+1}{s(s+2)(s+3)}=0 .
$$

The form of the characteristic equation in Equation (7.102) is necessary to use the rlocus function for generating root locus plots. The general form of the characteristic equation necessary for application of the rlocus function is

$$
1+K G(s)=1+K \frac{p(s)}{q(s)}=0,
$$

FIGURE 7.52

The rlocus function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0505.jpg?height=301&width=646&top_left_y=165&top_left_x=411)

where $K$ is the parameter of interest to be varied from $0 \leq K<\infty$. The rlocus function is shown in Figure 7.52, where we define the transfer function object sys $=G(s)$. The steps to obtaining the root locus plot associated with Equation (7.102), along with the associated root locus plot, are shown in Figure 7.53. Invoking the rlocus function without left-hand arguments results in an automatic generation of the root locus plot. When invoked with left-hand arguments, the rlocus function returns a matrix of root locations and the associated gain vector.

The steps to obtain a computer-generated root locus plot are as follows:

1. Obtain the characteristic equation in the form given in Equation (7.103), where $K$ is the parameter of interest.

2. Use the rlocus function to generate the plots.

Referring to Figure 7.53, we can see that as $K$ increases, two branches of the root locus break away from the real axis. This means that, for some values of $K$, the closedloop system characteristic equation will have two complex roots. Suppose we want to find the value of $K$ corresponding to a pair of complex roots. We can use the rlocfind

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0505.jpg?height=618&width=778&top_left_y=1274&top_left_x=427)

$$
>p=\left[\begin{array}{lll}
1 & 1
\end{array}\right] ; q=\left[\begin{array}{llll}
1 & 5 & 6 & 0
\end{array}\right] ; \text { sys=tf(p,q); [r,K]=rlocus(sys); }
$$

Obtaining root locations $r$ associated with various values of the gain $K$. function to do this, but only after a root locus has been obtained with the rlocus function. Executing the rlocfind function will result in a cross-hair marker appearing on the root locus plot. We move the cross-hair marker to the location on the locus of interest and hit the enter key. The value of the parameter $K$ and the value of the selected point will then be displayed in the command display. The use of the rlocfind function is illustrated in Figure 7.54.

Control design software packages may respond differently when interacting with plots, such as with the rlocfind function on the root locus. The response of rlocfind in Figure 7.54 corresponds to MATLAB. Refer to the companion website for more information on other control design software applications.

Continuing our third-order root locus example, we find that when $K=20.5775$, the closed-loop transfer function has three poles and two zeros, at

$$
\text { poles : } s=\left(\begin{array}{c}
-2.0505+j 4.3227 \\
-2.0505-j 4.3227 \\
-0.8989
\end{array}\right) ; \quad \text { zeros }: s=\left(\begin{array}{c}
-1 \\
-3
\end{array}\right) \text {. }
$$

Considering the closed-loop pole locations only, we would expect that the real pole at $s=-0.8989$ would be the dominant pole. To verify this, we can study the closed-loop system response to a step input, $R(s)=1 / s$. For a step input, we have

$$
Y(s)=\frac{20.5775(s+1)(s+3)}{s(s+2)(s+3)+20.5775(s+1)} \cdot \frac{1}{s} .
$$

FIGURE 7.54 Using the rlocfind function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0506.jpg?height=433&width=812&top_left_y=1275&top_left_x=450)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0506.jpg?height=48&width=569&top_left_y=1773&top_left_x=506)

$$
\begin{aligned}
& >>\text { rlocfind(sys) rlocfind follows the rlocus function. } \\
& \text { Select a point in the graphics window } \\
& \text { selected_point }= \\
& -2.0509+4.3228 \mathrm{i} \\
& \text { ans }= \\
& \text { Value of } K \text { at selected point }
\end{aligned}
$$

FIGURE 7.55

Partial fraction expansion of Equation (7.104).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0507.jpg?height=1026&width=910&top_left_y=230&top_left_x=486)

Generally, the first step in computing $y(t)$ is to expand Equation (7.104) in a partial fraction expansion. The residue function can be used to expand Equation (7.104), as shown in Figure 7.55. The residue function is described in Figure 7.56.

The partial fraction expansion of Equation (7.104) is

$$
Y(s)=\frac{-1.3786+j 1.7010}{s+2.0505+j 4.3228}+\frac{-1.3786-j 1.7010}{s+2.0505-j 4.3228}+\frac{-0.2429}{s+0.8989}+\frac{3}{s} .
$$

Comparing the residues, we see that the coefficient of the term corresponding to the pole at $s=-0.8989$ is considerably smaller than the coefficient of the terms corresponding to the complex-conjugate poles at $s=-2.0505 \pm j 4.3227$. From this, we expect that the influence of the pole at $s=-0.8989$ on the output response $y(t)$ is not dominant. The settling time (to within $2 \%$ of the final value) is then predicted by considering the complex-conjugate poles. The poles at $s=-2.0505 \pm j 4.3227$ correspond to a damping of $\zeta=0.4286$ and a natural frequency of $\omega_{n}=4.7844$. Thus, the settling time is predicted to be

$$
T_{s} \simeq \frac{4}{\zeta \omega_{n}}=1.95 \mathrm{~s} .
$$

FIGURE 7.56 The residue function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0508.jpg?height=520&width=850&top_left_y=154&top_left_x=450)

Using the step function, as shown in Figure 7.57, we find that $T_{s}=1.6 \mathrm{~s}$. Hence, our approximation of settling time $T_{s} \simeq 1.95 \mathrm{~s}$ is a fairly good approximation. The percent overshoot is predicted (considering the zero of $T(s)$ at $s=-3$ ) to be P.O. $=60 \%$. As can be seen in Figure 7.57, the actual overshoot is P.O. $=50 \%$.

When using the step function, we can right-click on the figure to access the pulldown menu, which allows us to determine the step response settling time and peak response, as illustrated in Figure 7.57. On the pull-down menu select "Characteristics" and select "Settling Time." A dot will appear on the figure at the settling point. Place the cursor over the dot to determine the settling time.

In this example, the role of the system zeros on the transient response is illustrated. The proximity of the zero at $s=-1$ to the pole at $s=-0.8989$ reduces the impact of that pole on the transient response. The main contributors to the transient

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0508.jpg?height=826&width=1281&top_left_y=1304&top_left_x=465)
for the closedloop system in Figure 7.10 with $K=20.5775$. FIGURE 7.58

Converting a partial fraction expansion back to a rational function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0509.jpg?height=261&width=715&top_left_y=166&top_left_x=412)

response are the complex-conjugate poles at $s=-2.0505 \pm j 4.3228$ and the zero at $s=-3$.

There is one final point regarding the residue function: We can convert the partial fraction expansion back to the polynomials num/den, given the residues $r$, the pole locations $p$, and the direct terms $k$, with the command shown in Figure 7.58.

Sensitivity and the Root Locus. The roots of the characteristic equation play an important role in defining the closed-loop system transient response. The effect of parameter variations on the roots of the characteristic equation is a useful measure of sensitivity. The root sensitivity is defined in Equation (7.75). We can use Equation (7.75) to investigate the sensitivity of the roots of the characteristic equation to variations in the parameter $K$. If we change $K$ by a small finite amount $\Delta K$, and evaluate the modified root $r_{i}+\Delta r_{i}$, it follows that $S_{K}^{r_{i}}$ is given in Equation (7.79).

The quantity $S_{K}^{r_{i}}$ is a complex number. Referring back to the third-order example of Figure 7.10 (Equation 7.102), if we change $K$ by a factor of $5 \%$, we find that the dominant complex-conjugate pole at $s=-2.0505+j 4.3228$ changes by

$$
\Delta r_{i}=-0.0025-j 0.1168
$$

when $K$ changes from $K=20.5775$ to $K=21.6064$. From Equation (7.79), it follows that

$$
S_{K}^{r_{i}}=\frac{-0.0025-j 0.1168}{1.0289 / 20.5775}=-0.0494-j 2.3355 .
$$

The sensitivity $S_{K}^{r_{i}}$ can also be written in the form

$$
S_{K}^{r_{i}}=2.34 / 268.79^{\circ} \text {. }
$$

The magnitude and direction of $S_{K}^{r_{i}}$ provides a measure of the root sensitivity. The script used to perform these sensitivity calculations is shown in Figure 7.59.

The root sensitivity measure may be useful for comparing the sensitivity for various system parameters at different root locations.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this chapter, we will use the PID controller to obtain a desirable response using velocity feedback. We will proceed with our model and then select a controller. Finally, we will optimize the parameters and analyze the performance. In this chapter, we will use the root locus method in the selection of the controller parameters. FIGURE 7.59

Sensitivity calculations for the root locus for a $5 \%$ change in $K=20.5775$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0510.jpg?height=405&width=654&top_left_y=179&top_left_x=578)

We use the root locus to select the controller gains. The PID controller introduced in this chapter is

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s
$$

Since the process model $G_{1}(s)$ already possesses an integration, we set $K_{I}=0$. Then we have the PD controller

$$
G_{c}(s)=K_{P}+K_{D} s,
$$

and our goal is to select $K_{P}$ and $K_{D}$ in order to meet the specifications. The system is shown in Figure 7.60. The closed-loop transfer function of the system is

$$
\frac{Y(s)}{R(s)}=T(s)=\frac{G_{c}(s) G_{1}(s) G_{2}(s)}{1+G_{c}(s) G_{1}(s) G_{2}(s)} .
$$

In order to obtain the root locus as a function of a parameter, we write $G_{c}(s) G_{1}(s) G_{2}(s)$ as

$$
G_{c}(s) G_{1}(s) G_{2}(s)=\frac{5000\left(K_{P}+K_{D} s\right)}{s(s+20)(s+1000)}=\frac{5000 K_{D}(s+z)}{s(s+20)(s+1000)}
$$

where $z=K_{P} / K_{D}$. We use $K_{P}$ to select the location of the zero $z$ and then sketch the locus as a function of $K_{D}$. We select $z=1$ so that

$$
G_{c}(s) G_{1}(s) G_{2}(s)=\frac{5000 K_{D}(s+1)}{s(s+20)(s+1000)} .
$$

FIGURE 7.60

Disk drive control system with a PD controller.
Disturbance

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0510.jpg?height=270&width=1263&top_left_y=1843&top_left_x=488)

FIGURE 7.61

Sketch of the root locus.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0511.jpg?height=508&width=830&top_left_y=162&top_left_x=413)

Table 7.8 Disk Drive Control System Specifications and Actual Design Performance

\begin{tabular}{lll} 
Performance Measure & Desired Value & Actual Response \\
\hline Percent overshoot & Less than $5 \%$ & $0 \%$ \\
Settling time & Less than $250 \mathrm{~ms}$ & $20 \mathrm{~ms}$ \\
Maximum response to a unit disturbance & Less than $5 \times 10^{-3}$ & $2 \times 10^{-3}$
\end{tabular}

The number of poles minus the number of zeros is 2 , and we expect asymptotes at $\phi_{A}= \pm 90^{\circ}$ with a centroid

$$
\sigma_{A}=\frac{-1020+1}{2}=-509.5,
$$

as shown in Figure 7.61. We can quickly sketch the root locus, as shown in Figure 7.61. We use the computer-generated root locus to determine the root values for various values of $K_{D}$. When $K_{D}=91.3$, we obtain the roots shown in Figure 7.61. Then, obtaining the system response, we achieve the actual response measures as listed in Table 7.8. As designed, the system meets all the specifications. It takes the system a settling time of $20 \mathrm{~ms}$ to "practically" reach the final value. In reality, the system drifts very slowly toward the final value after quickly achieving $97 \%$ of the final value.

\subsection{SUMMARY}

The relative stability and the transient response performance of a closed-loop control system are directly related to the location of the closed-loop roots of the characteristic equation. We investigated the movement of the characteristic roots on the $s$-plane as key system parameters (such as controller gains) are varied. The root locus and the negative gain root locus are graphical representations of the variation of the system closedloop poles as one parameter varies. The plots can be sketched using a given set of rules in order to analyze the initial design of a system and determine suitable alterations of the system structure and the parameter values. A computer is then commonly used to obtain the accurate root locus for use in the final design and analysis. A summary of fifteen typical root locus diagrams is shown in Table 7.9. Section 7.11 Summary $\mathbf{5 1 1}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0512.jpg?height=1968&width=1513&top_left_y=150&top_left_x=222)

512 Chapter 7 The Root Locus Method

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0513.jpg?height=1976&width=1437&top_left_y=146&top_left_x=185)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0514.jpg?height=1967&width=941&top_left_y=155&top_left_x=470)

Furthermore, we extended the root locus method for the design of several parameters for a closed-loop control system. Then the sensitivity of the characteristic roots was investigated for undesired parameter variations by defining a root sensitivity measure. It is clear that the root locus method is a powerful and useful approach for the analysis and design of modern control systems and will continue to be one of the most important procedures of control engineering.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 7.62 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0515.jpg?height=240&width=871&top_left_y=689&top_left_x=583)

FIGURE 7.62 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. The root locus is the path the roots of the characteristic equation (given by $1+K G(s)=0)$ trace out on the $s$-plane as the system parameter $0 \leq K<\infty$ varies.

True or False

2. On the root locus plot, the number of separate loci is equal to the number of poles of $G(s)$.

True or False

3. The root locus always starts at the zeros and ends at the poles of $G(s)$.

True or False

4. The root locus provides the control system designer with a measure of the sensitivity of the poles of the system to variations of a parameter of interest.

True or False

5. The root locus provides valuable insight into the response of a system to various test inputs.

True or False

6. Consider the control system in Figure 7.62, where the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+5 s+9\right)}{s^{2}(s+3)} .
$$

Using the root locus method, determine the value of $K$ such that the dominant roots have a damping ratio $\zeta=0.5$.
a. $K=1.2$
b. $K=4.5$
c. $K=9.7$
d. $K=37.4$ In Problems 7 and 8, consider the unity feedback system in Figure 7.62 with

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1)}{s^{2}+5 s+17.33} .
$$

7. The approximate angles of departure of the root locus from the complex poles are
a. $\phi_{d}= \pm 180^{\circ}$
b. $\phi_{d}= \pm 115^{\circ}$
c. $\phi_{d}= \pm 205^{\circ}$
d. None of the above

8. The root locus of this system is given by which of the following:

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0516.jpg?height=428&width=532&top_left_y=659&top_left_x=562)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0516.jpg?height=431&width=530&top_left_y=1144&top_left_x=563)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0516.jpg?height=430&width=545&top_left_y=660&top_left_x=1108)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0516.jpg?height=431&width=529&top_left_y=1144&top_left_x=1109)

(d)

9. A unity feedback system has the closed-loop transfer function given by

$$
T(s)=\frac{K}{(s+45)^{2}+K} .
$$

Using the root locus method, determine the value of the gain $K$ so that the closed-loop system has a damping ratio $\zeta=\sqrt{2} / 2$.
a. $K=25$
b. $K=1250$
c. $K=2025$
d. $K=10500$ 10. Consider the unity feedback control system in Figure 7.62 where

$$
L(s)=G_{c}(s) G(s)=\frac{10(s+z)}{s\left(s^{2}+4 s+8\right)} .
$$

Using the root locus method, determine that maximum value of $z$ for closed-loop stability.

a. $z=7.2$

b. $z=12.8$

c. Unstable for all $z>0$

d. Stable for all $z>0$

In Problems 11 and 12, consider the control system in Figure 7.62 where the model of the process is

$$
G(s)=\frac{7500}{(s+1)(s+10)(s+50)} .
$$

11. Suppose that the controller is

$$
G_{c}(s)=\frac{K(1+0.2 s)}{1+0.025 s} .
$$

Using the root locus method, determine the maximum value of the gain $K$ for closedloop stability.
a. $K=2.13$
b. $K=3.88$
c. $K=14.49$
d. Stable for all $K>0$

12. Suppose that a simple proportional controller is utilized, that is, $G_{c}(s)=K$. Using the root locus method, determine the maximum controller gain $K$ for closed-loop stability.
a. $K=0.50$
b. $K=1.49$
c. $K=4.48$
d. Unstable for $K>0$

13. Consider the unity feedback system in Figure 7.62 where

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+5)\left(s^{2}+6 s+17.76\right)} .
$$

Determine the breakaway point on the real axis and the respective gain, $K$.
a. $s=-1.8, K=58.75$
b. $s=-2.5, K=4.59$
c. $s=1.4, K=58.75$
d. None of the above

In Problems 14 and 15, consider the feedback system in Figure 7.62, where

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1+j)(s+1-j)}{s(s+2 j)(s-2 j)} .
$$

14. Which of the following is the associated root locus?

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0518.jpg?height=503&width=569&top_left_y=245&top_left_x=525)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0518.jpg?height=503&width=569&top_left_y=795&top_left_x=525)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0518.jpg?height=503&width=586&top_left_y=245&top_left_x=1123)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0518.jpg?height=508&width=590&top_left_y=795&top_left_x=1121)

(d)

15. The departure angles from the complex poles and the arrival angles at the complex zeros are:
a. $\phi_{D}= \pm 180^{\circ}, \phi_{A}=0^{\circ}$
b. $\phi_{D}= \pm 116.6^{\circ}, \phi_{A}= \pm 198.4^{\circ}$
c. $\phi_{D}= \pm 45.8^{\circ}, \phi_{A}= \pm 116.6^{\circ}$
d. None of the above

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.
a. Parameter design
The amplitude of the closed-loop response is reduced approximately to one-fourth of the maximum value in one oscillatory period.

b. Root sensitivity The path the root locus follows as the parameter becomes very large and approaches $\infty$.

c. Root locus The center of the linear asymptotes, $\sigma_{A}$.

d. Root locus segments The process of determining the PID controller gains on the real axis using one of several analytic methods based on openloop and closed-loop responses to step inputs. e. Root locus method A method of selecting one or two parameters using the root locus method.

f. Asymptote centroid The root locus lying in a section of the real axis to the left of an odd number of poles and zeros.

g. Breakaway point The root locus for negative values of the parameter of interest where $-\infty<K \leq 0$.

h. Locus

The angle at which a locus leaves a complex pole in the $s$-plane.

i. Angle of departure A path or trajectory that is traced out as a parameter is changed.

j. Number of separate The locus or path of the roots traced out on the loci $s$-plane as a parameter is changed.

k. Asymptote

The sensitivity of the roots as a parameter changes from its normal value.

l. Negative gain root locus

The method for determining the locus of roots of the characteristic equation $1+K G(s)=0$ as $0 \leq K<\infty$.

m. PID tuning The process of determining the PID controller gains.

n. Quarter amplitude decay

The point on the real axis where the locus departs from the real axis of the $s$-plane.

o. Ziegler-Nichols PID Equal to the number of poles of the transfer function, tuning method assuming that the number of poles is greater than or equal to the number of zeros of the transfer function.

\section{EXERCISES}

E7.1 Consider a device that consists of a ball rolling on the inside rim of a hoop [11]. This model is similar to the problem of liquid fuel sloshing in a rocket. The hoop is free to rotate about its horizontal principal axis as shown in Figure E7.1. The angular position of the hoop may be controlled via the torque $T(t)$ applied to the hoop from a torque motor attached to the hoop drive shaft. If negative feedback is used, the system characteristic equation is

$$
1+\frac{K s(s+4)}{s^{2}+2 s+2}=0
$$

(a) Sketch the root locus. (b) Find the gain when the roots are both equal. (c) Find these two equal roots.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0519.jpg?height=316&width=327&top_left_y=1766&top_left_x=241)

FIGURE E7.1 Hoop rotated by motor. (d) Find the settling time of the system when the roots are equal.

E7.2 A tape recorder with a unity feedback speed control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+1)\left(s^{2}+10 s+24\right)} .
$$

a. Sketch a root locus for $K$, and show that the dominant roots are $s=-0.41 \pm j 0.384$, when $K=8$.

b. For the dominant roots of part (a), calculate the settling time and overshoot for a step input.

E7.3 A unity feedback control system for an automobile suspension tester has the loop transfer function [12]

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+3)^{2}}{s^{2}(s+10)} .
$$

We desire the dominant roots to have the maximum imaginary part value. Using the root locus, show that $K=8.67$ is required, and the dominant roots are $s=-1.5 \pm j 1.65$.

E7.4 Consider a unity feedback system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+5)}{s^{2}+2 s+8} .
$$

(a) Find the angle of departure of the root locus from the complex poles. (b) Find the entry point for the root locus as it enters the real axis.

Answers: $123.5^{\circ},-9.8$

E7.5 Consider a unity feedback system with a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+4}{s^{3}+10 s^{2}+25 s+85} .
$$

(a) Find the breakaway point on the real axis. (b) Find the asymptote centroid. (c) Find the value of $K$ at the breakaway point.

E7.6 One version of a space station is shown in Figure E7.6 [28]. It is critical to keep this station in the proper orientation toward the Sun and the Earth for generating power and communications. The orientation controller may be represented by a unity feedback system with an actuator and controller, such as

$$
L(s)=G_{c}(s) G(s)=\frac{20 K}{s\left(s^{2}+10 s+80\right)} .
$$

Sketch the root locus of the system as $K$ increases. Find the value of $K$ that results in an unstable system.

Answers: $K=40$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0520.jpg?height=510&width=755&top_left_y=1128&top_left_x=225)

FIGURE E7.6 Space station.

E7.7 The elevator in a modern office building can travel at a speed of 25 feet per second and still stop within one-eighth of an inch of the floor outside. The loop transfer function of the unity feedback elevator position control is

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+3)}{s(s+1)(s+5)(s+10)} .
$$

Determine the gain $K$ when the complex roots have an $\zeta$ equal to 0.7 .
E7.8 Sketch the root locus for a unity feedback system with

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+3)}{(s+1)^{2}(s+19)} .
$$

(a) Find the gain when all three roots are real and equal. (b) Find the roots when all the roots are equal as in part (a).

Answers: $K=108 ; s=-7$

E7.9 The primary mirror of a large telescope can have a diameter of $10 \mathrm{~m}$ and a mosaic of 36 hexagonal segments with the orientation of each segment actively controlled. Suppose this unity feedback system for the mirror segments has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s\left(s^{2}+2 s+5\right)} .
$$

a. Find the asymptotes and sketch them in the $s$-plane.

b. Find the angle of departure from the complex poles.

c. Determine the gain when two roots lie on the imaginary axis.

d. Sketch the root locus.

E7.10 A unity feedback system has the loop transfer function

$$
L(s)=K G(s)=\frac{K(s+6)}{s(s+4)} .
$$

a. Find the breakaway and entry points on the real axis.

b. Find the gain and the roots when the real part of the complex roots is located at -3 .

c. Sketch the root locus.

Answers: (a) $-0.59,-3.41$; (b) $K=3, s=-2 \pm j \sqrt{2}$

E7.11 A robot force control system with unity feedback has a loop transfer function [6]

$$
L(s)=K G(s)=\frac{K(s+1)}{s\left(s^{2}+6 s+18\right)} .
$$

a. Find the gain $K$ that results in dominant roots with a damping ratio of 0.707 . Sketch the root locus.

b. Find the actual percent overshoot and peak time for the gain $K$ of part (a).

E7.12 A unity feedback system has a loop transfer function

$$
L(s)=K G(s)=\frac{K(s+1)}{s\left(s^{2}+6 s+18\right)} .
$$

(a) Sketch the root locus for $K>0$. (b) Find the roots when $K=10$ and 20. (c) Compute the rise time, percent overshoot, and settling time (with a $2 \%$ criterion) of the system for a unit step input when $K=10$ and 20 . E7.13 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{(s+4)}{s(s+2)(s+z)} .
$$

(a) Draw the root locus as $z$ varies from 0 to 100 .

(b) Using the root locus, estimate the percent overshoot and settling time (with a $2 \%$ criterion) of the system at $z=1,2$, and 3 for a step input. (c) Determine the actual overshoot and settling time at $z=1,2$, and 3 .

E7.14 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+15)}{s(s+3)} .
$$

(a) Determine the breakaway and entry points of the root locus, and sketch the root locus for $K>0$.

(b) Determine the gain $K$ when the two characteristic roots have a $\zeta$ of $1 / \sqrt{2}$. (c) Calculate the roots.

E7.15 (a) Plot the root locus for a unity feedback system with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+10)(s+2)}{s^{3}} .
$$

(b) Calculate the range of $K$ for which the system is stable. (c) Predict the steady-state error of the system for a ramp input.

Answers: (a) $K>1.67$; (b) $e_{s s}=0$

E7.16 A negative unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K e^{-s T}}{s+1},
$$

where $T=0.1 \mathrm{~s}$. Show that an approximation for the time delay is

$$
e^{-s T} \approx \frac{\frac{2}{T}-s}{\frac{2}{T}+s} .
$$

Using

$$
e^{-0.1 s}=\frac{20-s}{20+s},
$$

obtain the root locus for the system for $K>0$. Determine the range of $K$ for which the system is stable.

E7.17 A control system, as shown in Figure E7.17, has a process

$$
G(s)=\frac{1}{s(s-1)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0521.jpg?height=153&width=697&top_left_y=163&top_left_x=978)

FIGURE E7.17 Feedback system.

(a) When $G_{c}(s)=K$, show that the system is always unstable by sketching the root locus. (b) When

$$
G_{c}(s)=\frac{K(s+2)}{s+20},
$$

sketch the root locus, and determine the range of $K$ for which the system is stable. Determine the value of $K$ and the complex roots when two roots lie on the $j \omega$-axis.

E7.18 A closed-loop negative unity feedback system is used to control the yaw of an aircraft. When the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+3)\left(s^{2}+2 s+2\right)},
$$

determine (a) the root locus breakaway point and (b) the value of the roots on the $j \omega$-axis and the gain required for those roots. Sketch the root locus.

Answers: (a) Breakaway: $s=-2.29$; (b) $j \omega$-axis: $s= \pm j 1.09, K=8$

E7.19 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+3)\left(s^{2}+6 s+64\right)} .
$$

(a) Determine the angle of departure of the root locus at the complex poles. (b) Sketch the root locus.

(c) Determine the gain $K$ when the roots are on the $j \omega$-axis and determine the location of these roots.

E7.20 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1)}{s(s-2)(s+6)} .
$$

(a) Determine the range of $K$ for stability. (b) Sketch the root locus. (c) Determine the maximum $\zeta$ of the stable complex roots.

Answers: (a) $K>16$; (b) $\zeta=0.25$

E7.21 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K s}{s^{3}+5 s^{2}+10} .
$$

Sketch the root locus. Determine the gain $K$ when the complex roots of the characteristic equation have a damping ratio $\zeta$ approximately equal to 0.66 . E7.22 A high-performance missile for launching a satel- E7.25 A closed-loop feedback system is shown in Figure

lite has a unity feedback system with a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+18\right)(s+2)}{\left(s^{2}-2\right)(s+12)} .
$$

Sketch the root locus as $K$ varies from $0<K<\infty$.

E7.23 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{10(s+5)}{s^{2}(s+a)} .
$$

Sketch the root locus for $0 \leq a<\infty$.

E7.24 Consider the system represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{gathered}
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-k & -1
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \\
\mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right], \mathbf{D}=[0] .
\end{gathered}
$$

Determine the characteristic equation and then sketch the root locus as $0<k<\infty$.
E7.25. For what range of $K$ is the system stable? Sketch the root locus as $0<K<\infty$.

E7.26 Consider the single-input, single-output system is described by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A} \mathbf{x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
3-K & -2-K
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & -1
\end{array}\right]
$$

Compute the characteristic polynomial and plot the root locus as $0 \leq K<\infty$. For what values of $K$ is the system stable?

E7.27 Consider the unity feedback system in Figure E7.27. Sketch the root locus as $0 \leq p<\infty$. For what values of $p$ is the closed loop system stable?

E7.28 Consider the feedback system in Figure E7.28. Obtain the negative gain root locus as $-\infty<K \leq 0$. For what values of $K$ is the system stable?
FIGURE E7.25

Nonunity feedback system with parameter $K$.

FIGURE E7.27 Unity feedback system with parameter $p$.

FIGURE E7.28 Feedback system for negative gain root locus.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0522.jpg?height=1018&width=1000&top_left_y=1091&top_left_x=544)

\section{PROBLEMS}

P7.1 Sketch the root locus for the following loop transfer functions of the system shown in Figure P7.1 when $0 \leq K<\infty$ :
a. $L(s)=G_{c}(s) G(s)=\frac{K}{s(s+5)(s+20)}$
b. $L(s)=G_{c}(s) G(s)=\frac{K}{\left(s^{2}+2 s+2\right)(s+2)}$
c. $\quad L(s)=G_{c}(s) G(s)=\frac{K(s+10)}{s(s+1)(s+20)}$
d. $L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+4 s+8\right)}{s^{2}(s+1)}$

P7.2 Consider the loop transfer function of a phase-lock loop system

$$
L(s)=G_{c}(s) G(s)=K_{a} K \frac{10(s+10)}{s(s+1)(s+100)} .
$$

Sketch the root locus as a function of the gain $K_{v}=K_{a} K$. Determine the value of $K_{v}$ attained if the complex roots have a damping ratio equal to 0.60 [13].

P7.3 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+2)(s+4)(s+6)} .
$$

Find (a) the breakaway point on the real axis and the gain $K$ for this point, (b) the gain and the roots when two roots lie on the imaginary axis, and (c) the roots when $K=10$. (d) Sketch the root locus.
P7.4 Suppose that the loop transfer function of a large antenna is given by

$$
L(s)=G_{c}(s) G(s)=\frac{k_{a}}{\tau s+1} \frac{\omega_{n}^{2}}{s\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)},
$$

where $\tau=0.2, \zeta=0.707$, and $\omega_{\mathrm{n}}=1 \mathrm{rad} / \mathrm{s}$. Sketch the root locus of the system as $0 \leq k_{a}<\infty$. Determine the maximum allowable gain of $k_{a}$ for a stable system.

P7.5 Automatic control of helicopters is necessary because, unlike fixed-wing aircraft which possess a fair degree of inherent stability, the helicopter is quite unstable. A helicopter control system that utilizes an automatic control loop plus a pilot stick control is shown in Figure P7.5. When the pilot is not using the control stick, the switch may be considered to be open. The dynamics of the helicopter are represented by the transfer function

$$
G(s)=\frac{25(s+0.03)}{(s+0.4)\left(s^{2}-0.36 s+0.16\right)} .
$$

(a) With the pilot control loop open (hands-off control), sketch the root locus for the automatic stabilization loop. Determine the gain $K_{2}$ that results in a damping for the complex roots equal to $\zeta=0.707$. (b) For the gain $K_{2}$ obtained in part (a), determine the steady-state error due to a wind gust $T_{d}(s)=1 / s$. (c) With the pilot loop added, draw the root locus as $K_{1}$ varies from zero to $\infty$ when $K_{2}$ is set at the value calculated in part (a). (d) Recalculate the steady-state

FIGURE P7.1

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0523.jpg?height=254&width=870&top_left_y=1395&top_left_x=372)

FIGURE P7.5

Helicopter control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0523.jpg?height=419&width=1264&top_left_y=1691&top_left_x=370)

FIGURE P7.6

Satellite attitude control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0524.jpg?height=280&width=1172&top_left_y=152&top_left_x=543)

error of part (b) when $K_{1}$ is equal to a suitable value based on the root locus.

P7.6 An attitude control system for a satellite vehicle within the earth's atmosphere is shown in Figure P7.6.

(a) Draw the root locus of the system as $K$ varies from $0 \leq K<\infty$. (b) Determine the range of $K$ for closedloop stability. (c) Determine the gain $K$ that results in a system with a settling time (with a $2 \%$ criterion) of $T_{s} \leq 12 \mathrm{~s}$ and a percent overshoot P.O. $\leq 25 \%$.

P7.7 The speed control system for an isolated power system is shown in Figure P7.7. The valve controls the steam flow input to the turbine in order to account for load changes $\Delta L(s)$ within the power distribution network. The equilibrium speed desired results in a generator frequency equal to $60 \mathrm{cps}$. The effective rotary inertia $J$ is equal to 4000 and the friction constant $b$ is equal to 0.75 . The steady-state speed regulation factor $R$ is represented by the equation $R \approx\left(\omega_{0}-\omega_{r}\right) / \Delta L$, where $\omega_{r}$ equals the speed at rated load and $\omega_{0}$ equals the speed at no load. We want to obtain a very small $R$, usually less than 0.10 . (a) Using root locus techniques, determine the regulation $R$ attainable when the damping ratio of the roots of the system must be greater than 0.60. (b) Verify that the steady-state speed deviation for a load torque change $\Delta L(s)=\Delta L / s$ is, in fact, approximately equal to $R \Delta L$ when $R \leq 0.1$.

P7.8 Consider again the power control system of Problem P7.7 when the steam turbine is replaced by a hydroturbine. For hydroturbines, the large inertia of the water used as a source of energy causes a considerably larger time constant. The transfer function of a hydroturbine may be approximated by

$$
G_{t}(s)=\frac{-\tau s+1}{(\tau / 2) s+1},
$$

where $\tau=1 \mathrm{~s}$. With the rest of the system remaining as given in Problem P7.7, repeat parts (a) and (b) of Problem P7.7.

P7.9 The achievement of safe, efficient control of the spacing of automatically controlled guided vehicles is an important part of the future use of the vehicles in a manufacturing plant $[14,15]$. It is important that the system eliminates the effects of disturbances (such as oil on the floor) as well as maintains accurate spacing between vehicles on a guide way. The system can be
FIGURE P7.7 Power system control.

FIGURE P7.9 Guided vehicle control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0524.jpg?height=786&width=1262&top_left_y=1336&top_left_x=488)represented by the block diagram of Figure P7.9. The vehicle dynamics can be represented by

$$
G(s)=\frac{(s+0.3)\left(s^{2}+5 s+162\right)}{s(s-2)(s+1.2)\left(s^{2}+4 s+230\right)} .
$$

(a) Sketch the root locus of the system. (b) Determine all the roots when the loop gain $K=K_{1} K_{2}$ is equal to 2500 .

P7.10 New concepts in passenger airliner design will have the range to cross the Pacific in a single flight and the efficiency to make it economical $[16,29]$. These new designs will require the use of temperature-resistant, lightweight materials and advanced control systems. Noise control is an important issue in modern aircraft designs since most airports have strict noise level requirements. An advanced airliner is depicted in Figure P7.10(a). It would seat 200 passengers and cruise at just below the speed of sound. The flight control system must provide good handling characteristics and comfortable flying conditions. An automatic control system can be designed for the next generation passenger aircraft.
The desired characteristics of the dominant roots of the control system shown in Figure P7.10(b) have a $\zeta=0.707$. The characteristics of the aircraft are $\omega_{n}=2.5, \zeta=0.30$, and $\tau=0.1$. The gain factor $K_{1}$, however, will vary over the range 0.02 at medium-weight cruise conditions to 0.20 at lightweight descent conditions. (a) Sketch the root locus as a function of the loop gain $K_{1} K_{2}$. (b) Determine the gain $K_{2}$ necessary to yield roots with $\zeta=0.707$ when the aircraft is in the medium-cruise condition. (c) With the gain $K_{2}$ as found in part (b), determine the $\zeta$ of the roots when the gain $K_{1}$ results from the condition of light descent.

P7.11 A computer system requires a high-performance magnetic tape transport system [17]. The environmental conditions imposed on the system result in a severe test of control engineering design. A direct-drive DC motor system for the magnetic tape reel system is shown in Figure P7.11, where $r$ equals the reel radius, and $J$ equals the reel and rotor inertia. A complete reversal of the tape reel direction is required in $6 \mathrm{~ms}$, and the tape reel must follow a step command in $3 \mathrm{~ms}$ or less. The tape is normally operating at a speed of $100 \mathrm{in} / \mathrm{s}$.
FIGURE P7.10

(a) A passenger jet aircraft of the future. (Muratart/ Shutterstock.)

(b) Control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0525.jpg?height=604&width=907&top_left_y=1015&top_left_x=579)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0525.jpg?height=339&width=1231&top_left_y=1724&top_left_x=410)

(b) FIGURE P7.11

(a) Tape control system. (b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0526.jpg?height=517&width=475&top_left_y=153&top_left_x=880)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0526.jpg?height=470&width=1268&top_left_y=762&top_left_x=481)

(b)
The motor and components selected for this system possess the following characteristics:

$$
\begin{aligned}
& K_{b}=0.40 \\
& K_{p}=1 \\
& \tau_{1}=\tau_{a}=1 \mathrm{~ms} \\
& K_{T} /(L J)=2.0
\end{aligned}
$$

$$
\begin{aligned}
r & =0.2 \\
K_{1} & =2.0
\end{aligned}
$$

$K_{2}$ is adjustable.

The inertia of the reel and motor rotor is $2.5 \times 10^{-3}$ when the reel is empty, and $5.0 \times 10^{-3}$ when the reel is full. A series of photocells is used as an error-sensing device. The time constant of the motor is $L / R=0.5 \mathrm{~ms}$. (a) Sketch the root locus for the system when $K_{2}=10$ and $J=5.0 \times 10^{-3}, 0<K_{a}<\infty$. (b) Determine the gain $K_{a}$ that results in a welldamped system so that the $\zeta$ of all the roots is greater than or equal to 0.60 . (c) With the $K_{a}$ determined from part (b), sketch a root locus for $0<K_{2}<\infty$.

P7.12 A precision speed control system (Figure P7.12) is required for a platform used in gyroscope and inertial system testing where a variety of closely controlled speeds is necessary. A direct-drive DC torque motor system was utilized to provide (1) a speed range of $0.01 \%$ s to $600 \%$, and (2) $0.1 \%$ steady-state error maximum for a step input. The direct-drive DC torque motor avoids the use of a gear train with its attendant backlash and friction. Also, the direct-drive motor has a high-torque capability, high efficiency, and low motor time constants. The motor gain constant is nominally $K_{m}=1.8$, but is subject to variations up to $50 \%$. The amplifier gain $K_{a}$ is normally greater than 10 and subject to a variation of $10 \%$. (a) Determine the minimum loop gain necessary to satisfy the steady-state error requirement. (b) Determine the limiting value of gain for stability. (c) Sketch the root locus as $K_{a}$ varies from 0 to $\infty$. (d) Determine the roots when $K_{a}=40$, and estimate the response to a step input.

P7.13 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+1)\left(s^{2}+3 s+12\right)} .
$$

FIGURE P7.12

Speed control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0527.jpg?height=412&width=1261&top_left_y=161&top_left_x=395)

(a) Find the breakaway point on the real axis and the gain for this point. (b) Find the gain to provide two complex roots nearest the $j \omega$-axis with a damping ratio $\zeta=0.6$. (c) Are the two roots of part (b) dominant? (d) Determine the settling time (with a $2 \%$ criterion) of the system when the gain of part (b) is used.

P7.14 The loop transfer function of a unity feedback system is

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}-2 s+4\right)}{s(s+4)(s+6)} .
$$

This system is called conditionally stable because it is stable only for a range of the gain $K$ such that $k_{1}<K<k_{2}$. Using the Routh-Hurwitz criteria and the root locus method, determine the range of the gain for which the system is stable. Sketch the root locus for $0<K<\infty$.
P7.15 Suppose that the dynamics of a transport vehicle can be represented by the loop transfer function

$G_{c}(s) G(s)=\frac{K\left(s^{2}+40 s+800\right)(s+40)}{s\left(s^{2}+100 s+1000\right)\left(s^{2}+250 s+4500\right)}$.

Sketch the root locus for the system. Determine the damping ratio of the dominant roots when $K=1000$.

P7.16 Control systems for maintaining constant tension on strip steel in a hot strip finishing mill are called "loopers." A typical system is shown in Figure P7.16. The looper is an arm 2 to 3 feet long with a roller on the end; it is raised and pressed against the strip by a motor [18]. The typical speed of the strip passing the looper is $2000 \mathrm{ft} / \mathrm{min}$. A voltage proportional to the looper position is compared with a reference voltage and integrated where it is assumed that a change in looper position is proportional to a change in the steel

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0527.jpg?height=315&width=927&top_left_y=1383&top_left_x=557)

(a)

FIGURE P7.16

Steel mill control system. (b) strip tension. The time constant $\tau$ of the filter is negligible relative to the other time constants in the system. (a) Sketch the root locus of the control system for $0<K_{a}<\infty$. (b) Determine the gain $K_{a}$ that results in a system whose roots have a damping ratio of $\zeta=0.707$ or greater. (c) Determine the effect of $\tau$ as $\tau$ increases from a negligible quantity.

P7.17 Consider the vibration absorber in Figure P7.17. Using the root locus method, determine the effect of the parameters $M_{2}$ and $k_{12}$. Determine the specific values of the parameters $M_{2}$ and $k_{12}$ so that the mass $M_{1}$ does not vibrate when $F(t)=a \sin \left(\omega_{0} t\right)$. Assume that $M_{1}=1, k_{1}=1$, and $b=1$. Also assume that $k_{12}<1$ and that the term $k_{12}{ }^{1}$ may be neglected.

P7.18 A feedback control system is shown in Figure P7.18. The filter $G_{c}(s)$ is often called a compensator, and the design problem involves selecting the parameters $\alpha$ and $\beta$. Using the root locus method, determine the effect of varying the parameters. Select a suitable filter so that the time to settle (to within $2 \%$ of the final value) is $T_{s} \leq 4 \mathrm{~s}$, and the damping ratio of the dominant roots is $\zeta>0.6$.

P7.19 In recent years, many automatic control systems for guided vehicles in factories have been installed. One system uses a magnetic tape applied to the floor to guide the vehicle along the desired lane $[10,15]$. Using transponder tags on the floor, the automatically
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0528.jpg?height=702&width=754&top_left_y=167&top_left_x=1010)

FIGURE P7.18 Filter design.

guided vehicles can be tasked (for example, to speed up or slow down) at key locations. An example of a guided vehicle in a factory is shown in Figure P7.19(a).

FIGURE P7.17

Vibration absorber.
FIGURE P7.19

(a) An automatically guided vehicle. (Photo courtesy of the Vanit Janthra/ Shutterstock.)

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0528.jpg?height=513&width=906&top_left_y=1192&top_left_x=582)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0528.jpg?height=277&width=1096&top_left_y=1783&top_left_x=508)

(b) Sketch a root locus and determine a suitable gain P7.23 Repeat Problem P7.22 for the loop transfer func$K_{a}$ so that the damping ratio of the complex roots is $\zeta>0.707$.

P7.20 Determine the root sensitivity for the dominant roots of the design for Problem P7.18 for the gain $K=4 \alpha / \beta$ and the pole $s=-2$.

P7.21 Determine the root sensitivity of the dominant roots of the power system of Problem P7.7. Evaluate the sensitivity for variations of (a) the poles at $s=-4$, and (b) the feedback gain, $1 / R$.

P7.22 Determine the root sensitivity of the dominant roots of Problem P7.1(a) when $K$ is set so that the damping ratio of the unperturbed roots is $\zeta=0.707$. Evaluate and compare the sensitivity as a function of the poles and zeros of the loop transfer function $L(s)=G_{c}(s) G(s)$. tion $L(s)=G_{c}(s) G(s)$ of Problem P7.1(c).

P7.24 For systems of relatively high degree, the form of the root locus can often assume an unexpected pattern. The root loci of four different feedback systems of third order or higher are shown in Figure P7.24. The open-loop poles and zeros of $K G(s)$ are shown, and the form of the root loci as $K$ varies from zero to infinity is presented. Verify the diagrams of Figure P7.24 by constructing the root loci.

P7.25 Solid-state integrated electronic circuits are composed of distributed $R$ and $C$ elements. Therefore, feedback electronic circuits in integrated circuit form must be investigated by obtaining the transfer function of the distributed $R C$ networks. It has been shown that the slope of the attenuation curve of a distributed $R C$ network is $10 n \mathrm{~dB} /$ decade, where $n$ is the order of

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0529.jpg?height=357&width=397&top_left_y=821&top_left_x=601)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0529.jpg?height=355&width=741&top_left_y=1262&top_left_x=427)

(b)

FIGURE P7.24

Root loci of four systems.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0529.jpg?height=357&width=426&top_left_y=1710&top_left_x=363)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0529.jpg?height=353&width=379&top_left_y=1712&top_left_x=843)

(d) the $R C$ filter [13]. This attenuation is in contrast with the normal $20 n \mathrm{~dB} /$ decade for the lumped parameter circuits. An interesting case arises when the distributed $R C$ network occurs in a series-to-shunt feedback path of a transistor amplifier. Then the loop transfer function may be written as

$$
L(s)=G_{c}(s) G(s)=\frac{K(s-1)(s+3)^{1 / 2}}{(s+1)(s+2)^{1 / 2}} .
$$

(a) Using the root locus method, determine the locus of roots as $K$ varies from zero to infinity. (b) Calculate the gain at borderline stability and the frequency of oscillation for this gain.

P7.26 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+2)^{2}}{s\left(s^{2}+4\right)(s+5)} .
$$

(a) Sketch the root locus for $0 \leq K<\infty$. (b) Determine the range of the gain $K$ for which the system is stable. (c) For what value of $K$ in the range $K \geq 0$ do purely imaginary roots exist? What are the values of these roots? (d) Would the use of the dominant roots approximation for an estimate of settling time be justified in this case for a large magnitude of gain $(K=100)$ ?

P7.27 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+0.05\right)}{s\left(s^{2}+2\right)} .
$$

Sketch the root locus as a function of $K$. Determine the values of $K$ where the root locus enters and leaves the real axis.

P7.28 To meet current U.S. emissions standards for automobiles, hydrocarbon (HC) and carbon monoxide (CO) emissions are usually controlled by a catalytic converter in the automobile exhaust. Federal standards for nitrogen oxides $\left(\mathrm{NO}_{x}\right)$ emissions are met mainly by exhaust-gas recirculation (EGR) techniques.

Although many schemes are under investigation for meeting the emissions standards for all three emissions, one of the most promising employs a three- way catalyst - for $\mathrm{HC}, \mathrm{CO}$, and $\mathrm{NO}_{x}$ emissions in conjunction with a closed-loop engine-control system. The approach is to use a closed-loop engine control, as shown in Figure P7.28 [19, 23]. The exhaust-gas sensor gives an indication of a rich or lean exhaust and compares it to a reference. The difference signal is processed by the controller, and the output of the controller modulates the vacuum level in the carburetor to achieve the best air-fuel ratio for proper operation of the catalytic converter. The loop transfer function is represented by

$$
L(s)=\frac{K s^{2}+12 s+20}{s^{3}+10 s^{2}+25 s} .
$$

Calculate the root locus as a function of $K$. Calculate where the segments of the locus enter and leave the real axis. Determine the roots when $K=2$. Predict the step response of the system when $K=2$.

P7.29 A unity feedback control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+6 s+10\right)}{s\left(s^{2}+2 s+10\right)} .
$$

We desire the dominant roots to have a damping ratio $\zeta=0.707$. Find the gain $K$ when this condition is satisfied. Show that the complex roots area $s=-11.1 \pm j 11.1$ at this gain.

P7.30 An $R L C$ network is shown in Figure P7.30. The nominal values (normalized) of the network elements are $L-C=1$ and $R=2.5$. Show that the root sensitivity of the two roots of the input impedance $Z(s)$ to a change in $R$ is different by a factor of 4 .

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0530.jpg?height=177&width=501&top_left_y=1445&top_left_x=1142)

FIGURE P7.30 RLC network.

FIGURE P7.28

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0530.jpg?height=240&width=1263&top_left_y=1795&top_left_x=488)

Auto engine control. P7.31 The development of high-speed aircraft and missiles requires information about aerodynamic parameters prevailing at very high speeds. Wind tunnels are used to test these parameters. These wind tunnels are constructed by compressing air to very high pressures and releasing it through a valve to create a wind. Since the air pressure drops as the air escapes, it is necessary to open the valve wider to maintain a constant wind speed. Thus, a control system is needed to adjust the valve to maintain a constant wind speed. The loop transfer function for a unity feedback system is

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+4)}{s(s+0.2)\left(s^{2}+15 s+150\right)} .
$$

Sketch the root locus and show the location of the roots for $K=1391$.

P7.32 A mobile robot suitable for nighttime guard duty is available. This guard never sleeps and can tirelessly patrol large warehouses and outdoor yards. The steering control system for the mobile robot has a unity feedback with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1)(s+5)}{s(s+1.5)(s+2)} .
$$

(a) Find $K$ for all breakaway and entry points on the real axis. (b) Find $K$ when the damping ratio of the complex roots is 0.707 . (c) Find the minimum value of the damping ratio for the complex roots and the associated gain $K$. (d) Find the overshoot and the time to settle (to within $2 \%$ of the final value) for a unit step input for the gain, $K$, determined in parts (b) and (c).

P7.33 The Bell-Boeing V-22 Osprey Tiltrotor is both an airplane and a helicopter. Its advantage is the ability to rotate its engines to $90^{\circ}$ from a vertical position for takeoffs and landings as shown in Figure P7.33(a), and then to switch the engines to a horizontal position for cruising as an airplane [20]. The altitude control system in the helicopter mode is shown in Figure P7.33(b). (a) Determine the root locus as $K$ varies and determine the range of $K$ for a stable system. (b) For $K=280$, find the actual $y(t)$ for a unit step input $r(t)$ and the percentage overshoot and settling time (with a $2 \%$ criterion). (c) When $K=280$ and $r(t)=0$, find $y(t)$ for a unit step disturbance, $T_{d}(s)=1 / s$.

P7.34 The fuel control for an automobile uses a diesel pump that is subject to parameter variations. A unity negative feedback has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+2)}{(s+1)(s+2.5)(s+4)(s+10)} .
$$

(a) Sketch the root locus as $K$ varies from 0 to 2000 . (b) Find the roots for $K$ equal to 400, 500, and 600 . (c) Predict how the percent overshoot to a step will vary for the gain $K$, assuming dominant roots. (d) Find the actual time response for a step input for all three gains and compare the actual overshoot with the predicted overshoot.

P7.35 A powerful electrohydraulic forklift can be used to lift pallets weighing several tons on top of 35-foot scaffolds at a construction site. The unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+5)^{2}}{s\left(s^{2}+4 s+13\right)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0531.jpg?height=339&width=555&top_left_y=1390&top_left_x=692)

(a)

FIGURE P7.33

(a) Osprey Tiltrotor aircraft. (b) Its control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0531.jpg?height=249&width=1193&top_left_y=1823&top_left_x=370)

(b) (a) Sketch the root locus for $K>0$. (b) Find the gain $K$ when two complex roots have a $\zeta=0.707$, and calculate all three roots. (c) Find the entry point of the root locus at the real axis. (d) Estimate the expected percent overshoot to a step input, and compare it with the actual percent overshoot.

P7.36 A microrobot with a high-performance manipulator has been designed for testing very small particles, such as simple living cells [6]. The unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+5)(s+10)}{s^{2}(s+2)(s-8)} .
$$

(a) Sketch the root locus for $K>0$. (b) Find the gain and roots when the characteristic equation has two imaginary roots. (c) Determine the characteristic roots when $K=50$ and $K=100$. (d) For $K=50$, estimate the percent overshoot to a step input, and compare the estimate to the actual percent overshoot.

P7.37 Identify the parameters $K, a$, and $b$ of the system shown in Figure P7.37. The system is subject to a unit step input, and the output response has a percent overshoot but ultimately attains the final value of 1 . When the closed-loop system is subjected to a ramp input, the output response follows the ramp input with a finite steady-state error. When the gain is doubled to $2 K$, the output response to an impulse input is a pure sinusoid with a period of 0.314 second. Determine $K$, $a$, and $b$.

P7.38 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+2)(s+8)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0532.jpg?height=188&width=732&top_left_y=153&top_left_x=1017)

FIGURE P7.37 Feedback system.

(a) Determine the range of $K$ so that the closedloop system is stable. (b) Sketch the root locus. (c) Determine the roots for $K=100$. (d) For $K=100$, predict the percent overshoot for a step input. (e) Determine the actual percent overshoot.

P7.39 High-speed trains for U.S. railroad tracks must traverse twists and turns. In conventional trains, the axles are fixed in steel frames called trucks. The trucks pivot as the train goes into a curve, but the fixed axles stay parallel to each other, even though the front axle tends to go in a different direction from the rear axle [24]. If the train is going fast, it may jump the tracks. One solution uses axles that pivot independently. To counterbalance the strong centrifugal forces in a curve, the train also has a computerized hydraulic system that tilts each car as it rounds a turn. On-board sensors calculate the train's speed and the sharpness of the curve and feed this information to hydraulic pumps under the floor of each car. The pumps tilt the car up to eight degrees, causing it to lean into the curve like a race car on a banked track.

The tilt control system is shown in Figure P7.39. Sketch the root locus, and determine the value of $K$ when the complex roots have maximum damping. Predict the response of this system to a step input $R(s)$.
FIGURE P7.39

Tilt control for a high-speed train.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0532.jpg?height=228&width=1206&top_left_y=1429&top_left_x=507)

\section{ADVANCED PROBLEMS}

AP7.1 The top view of a high-performance jet aircraft is shown in Figure AP7.1(a) [20]. Using the block diagram in Figure AP7.1(b), sketch the root locus and determine the gain $K$ so that the damping ratio of the complex poles near the $j \omega$-axis is the maximum achievable. Evaluate the roots at this $K$, and predict the response to a step input. Determine the actual response, and compare it to the predicted response.
AP7.2 A magnetically levitated high-speed train "flies" on an air gap above its rail system, as shown in Figure AP7.2(a) [24]. The air gap control system has a unity feedback system with a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+1)(s+2)}{s(s-0.5)(s+5)(s+10)} .
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0533.jpg?height=385&width=682&top_left_y=158&top_left_x=433)

FIGURE AP7.1

(a) Highperformance aircraft. (b) Pitch control system. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0533.jpg?height=226&width=799&top_left_y=628&top_left_x=372)

(b)
The feedback control system is illustrated in Figure AP7.2(b). The goal is to select $K$ so that the response for a unit step input is reasonably damped. Sketch the root locus, and select $K$ so that the $T_{s} \leq 3 \mathrm{~s}$ and P.O. $\leq 20 \%$. Determine the actual response for the selected $K$ and the percent overshoot.
AP7.3 A compact disc player for portable use requires a good rejection of disturbances and an accurate position of the optical reader sensor. The position control system uses unity feedback and a loop transfer function

$$
\begin{aligned}
L(s) & =G_{c}(s) G(s) \\
& =1+p \frac{\left(s^{3}+20 s^{2}+150 s+100\right)}{\left(s^{4}+20 s^{3}+150 s^{2}+10 s+5\right)} \\
& =0 .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0533.jpg?height=371&width=911&top_left_y=1282&top_left_x=537)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0533.jpg?height=339&width=1232&top_left_y=1710&top_left_x=372)

(b)

(b)
FIGURE AP7.2

(a) Magnetically levitated highspeed train.

(b) Feedback control system. The parameter $p$ can be chosen by selecting the appropriate DC motor. Sketch the root locus as a function of $p$. Select $p$ so that the damping ratio of the complex roots of the characteristic equation is approximately $\zeta=1 / \sqrt{2}$.

AP7.4 A remote manipulator control system has unity feedback and a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+1+\alpha}{s^{3}+3 \alpha s^{2}+2 s} .
$$

We want the percent overshoot for a step input to be less than or equal to $30 \%$. Sketch the root locus as a function of the parameter $\alpha$. Determine the range of $\alpha$ required for the desired percent overshoot. Locate the roots for the allowable value of $\alpha$ to achieve the required maximum overshoot. Check the actual step responses of the system for various $\alpha$ values.

AP7.5 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s^{3}+10 s^{2}+8 s-15} .
$$

a. Sketch the root locus and determine $K$ for a stable system with complex roots with $\zeta=1 / \sqrt{2}$.

b. Determine the root sensitivity of the complex roots of part (a).

c. Determine the percent change in $K$ (increase or decrease) so that the roots lie on the $j \omega$-axis.

AP7.6 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+5 s+10\right)}{s^{3}+6 s^{2}+12 s} .
$$

Sketch the root locus for $K>0$, and select a value for $K$ that will maximize the damping ratio of the complex roots.

AP7.7 A feedback system with positive feedback is shown in Figure AP7.7. The root locus for $K>0$ must meet the condition

$$
\begin{aligned}
K G(s) & =1 \pm \angle k 360^{\circ} \\
\text { for } \mathrm{k} & =0,1,2, \ldots .
\end{aligned}
$$

Sketch the root locus for $0<K<\infty$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0534.jpg?height=230&width=744&top_left_y=579&top_left_x=1009)

FIGURE AP7.7 A closed-loop system with positive feedback.

AP7.8 A position control system for a DC motor is shown in Figure AP7.8. Obtain the root locus for the velocity feedback constant $K$, and select $K$ so that all the roots of the characteristic equation are real (two are equal and real). Estimate the step response of the system for the $K$ selected. Compare the estimate with the actual response.

AP7.9 A control system is shown in Figure AP7.9. Sketch the root loci for the following transfer functions $G_{c}(s)$ :

a. $G_{c}(s)=K$

b. $G_{c}(s)=K(s+3)$
FIGURE AP7.8

A position control system with velocity feedback.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0534.jpg?height=622&width=1048&top_left_y=1485&top_left_x=550)

FIGURE AP7.9

A unity feedback control system. 
c. $G_{c}(s)=\frac{K(s+1)}{s+20}$
d. $G_{c}(s)=\frac{K(s+1)(s+4)}{s+10}$

AP7.10 A feedback system is shown in Figure AP7.10. Sketch the root locus as $K$ varies when $K \geq 0$. Determine a value for $K$ that will provide a step response with a percent overshoot of P.O. $\leq 5 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 2.5 \mathrm{~s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0535.jpg?height=252&width=722&top_left_y=542&top_left_x=86)

AP7.11 A control system is shown in Figure AP7.11. Sketch the root locus, and select a gain $K$ so that the step response of the system has a percent overshoot of P.O. $\leq 5 \%$, and the settling time (with a $2 \%$ criterion) is $T_{s} \leq 10 \mathrm{~s}$.

AP7.12 A control system with PI control is shown in Figure AP7.12. (a) Let $K_{I} / K_{P}=0.2$ and determine $K_{P}$ so that the complex roots have maximum damping ratio. (b) Predict the step response of the system with $K_{P}$ set to the value determined in part (a).

AP7.13 The feedback system shown in Figure AP7.13 has two unknown parameters $K_{1}$ and $K_{2}$. The process transfer function is unstable. Sketch the root locus for $0 \leq K_{1}, K_{2}<\infty$. What is the fastest settling time that you would expect of the closed-loop system in response to a unit step input $R(s)=1 / s$ ? Explain.

FIGURE AP7.10

A nonunity feedback control system.

FIGURE AP7.11

A control system with parameter $K$.

FIGURE AP7.12 A control system with a PI controller.

FIGURE AP7.13

An unstable plant with two parameters $K_{1}$ and $K_{2}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0535.jpg?height=770&width=1020&top_left_y=938&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0535.jpg?height=240&width=791&top_left_y=1823&top_left_x=376)

(b) AP7.14 Consider the unity feedback control system shown in Figure AP7.14. Design a PID controller using Ziegler-Nichols methods. Determine the unit step response and the unit disturbance response. What is the maximum percent overshoot and settling time for the unit step input?
FIGURE AP7.14

Unity feedback loop with PID controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0536.jpg?height=261&width=1061&top_left_y=340&top_left_x=448)

\section{DESIGN PROBLEMS}

CDP7.1 The drive motor and slide system uses the output of a tachometer mounted on the shaft of the motor as shown in Figure CDP4.1 (switch-closed option). The output voltage of the tachometer is $v_{T}=K_{1} \theta$. Use the velocity feedback with the adjustable gain $K_{1}$. Select the best values for the gain $K_{1}$ and the amplifier gain $K_{a}$ so that the transient response to a step input has a percent overshoot of P.O. $\leq 5 \%$ and a settling time (to within $2 \%$ of the final value) of $T_{s} \leq 300 \mathrm{~ms}$.

DP7.1 A high-performance aircraft, shown in Figure DP7.1(a), uses the ailerons, rudder, and elevator to steer through a three-dimensional flight path [20]. The pitch rate control system for a fighter aircraft at 10,000 $\mathrm{m}$ and Mach 0.9 can be represented by the system in Figure DP7.1(b). (a) Sketch the root locus when the controller is a gain, so that $G_{c}(s)=K$, and determine $K$ when $\zeta$ for the roots with $\omega_{n}>2$ is $\zeta \geq 0.15$ (seek a maximum $\zeta$ ). (b) Plot the response $q(t)$ for a step input $r(t)$ with $K$ as in (a). (c) A designer suggests an anticipatory controller with $G_{c}(s)=K_{1}+K_{2} s=K(s+2)$. Sketch the root locus for this system as $K$ varies and determine a $K$ so that the damping ratio of all the closedloop roots is $\zeta>0.8$. (d) Plot the response $q(t)$ for a step input $r(t)$ with $K$ as in (c).

DP7.2 A large helicopter uses two tandem rotors rotating in opposite directions, as shown in Figure P7.33(a). The controller adjusts the tilt angle of the main rotor and thus the forward motion as shown in Figure DP7.2.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0536.jpg?height=226&width=664&top_left_y=1385&top_left_x=677)

(a)

\section{FIGURE DP7.1}

(a) Highperformance aircraft. (b) Pitch rate control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0536.jpg?height=245&width=1117&top_left_y=1710&top_left_x=448)

(b) FIGURE DP7.2

Two-rotor helicopter velocity control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0537.jpg?height=282&width=946&top_left_y=153&top_left_x=409)

(a) Sketch the root locus of the system, and determine $K$ when $\zeta$ of the complex roots is equal to 0.707. (b) Plot the response of the system to a step input $r(t)$, and find the settling time (with a $2 \%$ criterion) and percent overshoot for the system of part (a). (c) Repeat parts (a) and (b) when the damping ratio of the complex roots is $\zeta=0.3$. Compare the results with those obtained in parts (a) and (b).

DP7.3 A rover vehicle has been designed for maneuvering at $0.25 \mathrm{mph}$ over Martian terrain. Because Mars is 189 million miles from Earth, and it would take up to 40 minutes each way to communicate with Earth $[22,27]$, the rover must act independently and reliably. Resembling a cross between a small flatbed truck and an elevated jeep, the rover is constructed of three articulated sections, each with its own two independent, axle-bearing, one-meter conical wheels. A pair of sampling arms - one for chipping and drilling, the other for manipulating fine objects-extend from its front end like pincers. The control of the arms can be represented by the system shown in Figure DP7.3. (a) Sketch the root locus for $K$, and identify the roots for $K=2$ and 25. (b) Determine the gain $K$ that results in a percent overshoot to a step of $P . O .=1 \%$. (c) Determine the gain that minimizes the settling time (with a $2 \%$ criterion) while maintaining a percent overshoot of P.O. $\leq 1 \%$.

DP7.4 A welding torch is remotely controlled to achieve high accuracy while operating in changing and hazardous environments [21]. A model of the welding arm position control is shown in Figure DP7.4, with the disturbance representing the environmental changes. (a) With $T_{d}(s)=0$, select $K_{1}$ and $K$ to provide highquality performance of the position control system. Select a set of performance criteria, and examine the results of your design. (b) For the system in part (a), let $R(s)=0$ and determine the effect of a unit step $T_{d}(s)=1 / s$ by obtaining $y(t)$.

DP7.5 A high-performance jet aircraft with an autopilot control system has a unity feedback and control system, as shown in Figure DP7.5. Sketch the root locus and select a gain $K$ that leads to dominant poles. With this gain $K$, predict the step response of the system. Determine the actual response of the system, and compare it to the predicted response.
FIGURE DP7.3

Mars vehicle robot control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0537.jpg?height=656&width=1042&top_left_y=1371&top_left_x=410)

FIGURE DP7.4 Remotely controlled welder. FIGURE DP7.5

High-performance jet aircraft.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0538.jpg?height=240&width=925&top_left_y=153&top_left_x=450)

FIGURE DP7.6

Automatic control of walking motion.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0538.jpg?height=230&width=945&top_left_y=487&top_left_x=447)

DP7.6 A system to aid and control the walk of a partially disabled person could use automatic control of the walking motion [25]. One model of a system is shown in Figure DP7.6. Using the root locus, select $K$ for the maximum achievable damping ratio of the complex roots. Predict the step response of the system, and compare it with the actual step response.

DP7.7 A mobile robot using a vision system as the measurement device is shown in Figure DP7.7(a) [36]. The control system is shown in Figure DP7.7(b). Design the controller so that (a) the percent overshoot for a step input is $P . O . \leq 5 \%$; (b) the settling time (with a $2 \%$ criterion) is $T_{s} \leq 6 \mathrm{~s}$; (c) the system velocity error constant $K_{v}>0.9$; and (d) the peak time, $T_{P}$, for a step input is minimized.

DP7.8 Most commercial op-amps are designed to be unity-gain stable [26]. That is, they are stable when used in a unity-gain configuration. To achieve higher bandwidth, some op-amps relax the requirement to be unity-gain stable. One such amplifier has a DC gain of $10^{5}$ and a
FIGURE DP7.7

(a) A robot and vision system.

(b) Feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0538.jpg?height=526&width=738&top_left_y=1207&top_left_x=638)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0538.jpg?height=237&width=1132&top_left_y=1815&top_left_x=450)

(b) FIGURE DP7.8

(a) Op-amp circuit.

(b) Control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0539.jpg?height=351&width=491&top_left_y=154&top_left_x=413)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0539.jpg?height=259&width=718&top_left_y=242&top_left_x=958)

(b) bandwidth of $10 \mathrm{kHz}$. The amplifier, $G(s)$, is connected in the feedback circuit shown in Figure DP7.8(a). The amplifier is represented by the model shown in Figure DP7.8(b), where $K_{a}=10^{5}$. Sketch the root locus of the system for $K$. Determine the minimum value of the DC gain of the closed-loop amplifier for stability. Select a DC gain and the resistors $R_{1}$ and $R_{2}$.

DP7.9 A robotic arm actuated at the elbow joint is shown in Figure DP7.9(a), and the control system for the actuator is shown in Figure DP7.9(b). Plot the root locus for $K \geq 0$. Select $G_{p}(s)$ so that the steady-state error for a step input is equal to zero. Using the $G_{p}(s)$ selected, plot $y(t)$ for $K$ equal to 1,1.75, and 3.0. Record the rise time, settling time (with a $2 \%$ criterion), and percent overshoot for the three gains. We wish to limit the overshoot to P.O. $\leq 6 \%$ while achieving the shortest rise time possible. Select the best system for $1 \leq K \leq 3.0$.

DP7.10 The four-wheel-steering automobile has several benefits. The system gives the driver a greater degree of control over the automobile. The driver gets a more forgiving vehicle over a wide variety of conditions. The system enables the driver to make sharp, smooth

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0539.jpg?height=543&width=1265&top_left_y=1107&top_left_x=414)

(a)

FIGURE DP7.9

(a) A robotic arm actuated at the joint elbow. (b) Its control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0539.jpg?height=301&width=1251&top_left_y=1750&top_left_x=426)

(b) lane transitions. It also prevents yaw, which is the swaying of the rear end during sudden movements. Furthermore, the four-wheel-steering system gives a car increased maneuverability. This enables the driver to park the car in extremely tight quarters. With additional closed-loop computer operating systems, a car could be prevented from sliding out of control in abnormal icy or wet road conditions.

The system works by moving the rear wheels relative to the front-wheel-steering angle. The control system takes information about the front wheels' steering angle and passes it to the actuator in the back. This actuator then moves the rear wheels appropriately.

When the rear wheels are given a steering angle relative to the front ones, the vehicle can vary its lateral acceleration response according to the loop transfer function

$L(s)=G_{c}(s) G(s)=K \frac{1+(1+\lambda) T_{1} s+(1+\lambda) T_{2} s^{2}}{s\left[1+\left(2 \zeta / \omega_{n}\right) s+\left(1 / \omega_{n}{ }^{1}\right) s^{2}\right]}$,

where $\lambda=2 q /(1-q)$, and $q$ is the ratio of rear wheel angle to front wheel steering angle [14]. We will assume that $T_{1}=T_{2}=1$ second and $\omega_{n}=4$. Design a unity feedback system, selecting an appropriate set of parameters $(\lambda, K, \zeta)$ so that the steering control response is rapid and yet will yield modest overshoot characteristics. In addition, $q$ must be between 0 and 1 .

DP7.11 A pilot crane control is shown in Figure DP7.11(a). The trolley is moved by an input $F(t)$ in order to control $x(t)$ and $\phi(t)$ [13]. The model of the pilot crane control is shown in Figure DP7.11(b). Design a controller that will achieve zero steady-state error for ramp inputs, and maximize the closed-loop system damping when $G_{c}(s)=K\left(1+\frac{0.25}{s}\right)$.

DP7.12 A rover vehicle designed for use on other planets and moons is shown in Figure DP7.12(a) [21]. The block diagram of the steering control is shown in Figure DP7.12(b). (a) Sketch the root locus as $K$ varies from 0 to 10000 . Find the roots for $K$ equal to 1000 , 1500, and 2500. Predict the overshoot, settling time (with a $2 \%$ criterion), and steady-state error for a step input, assuming dominant roots. (c) Determine the actual time response for a step input for the three values of the gain $K$, and compare the actual results with the predicted results.

DP7.13 The automatic control of an airplane is one example that requires multiple-variable feedback methods. In this system, the attitude of an aircraft is controlled by three sets of surfaces: elevators, a rudder, and ailerons, as shown in Figure DP7.13(a). By manipulating these surfaces, a pilot can set the aircraft on a desired flight path [20].

An autopilot, which will be considered here, is an automatic control system that controls the roll angle $\phi(t)$ by adjusting aileron surfaces. The deflection of the aileron surfaces by an angle $\theta(t)$ generates a torque due to air pressure on these surfaces. This causes a rolling motion of the aircraft. The aileron surfaces are controlled by a hydraulic actuator with a transfer function $1 / s$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0540.jpg?height=337&width=625&top_left_y=1278&top_left_x=767)

(a)

FIGURE DP7.11

(a) Pilot crane control system.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0540.jpg?height=337&width=1247&top_left_y=1713&top_left_x=449)

(b) FIGURE DP7.12

(a) Planetary rover vehicle. (b) Steering control system.
FIGURE DP7.13

(a) An airplane with a set of ailerons.

(b) The block diagram for controlling the roll rate of the airplane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0541.jpg?height=352&width=572&top_left_y=151&top_left_x=636)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0541.jpg?height=175&width=1005&top_left_y=604&top_left_x=410)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0541.jpg?height=398&width=1113&top_left_y=876&top_left_x=410)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0541.jpg?height=430&width=1040&top_left_y=1403&top_left_x=562)

(b)
The actual roll angle $\phi(t)$ is measured and compared with the input. The difference between the desired roll angle $\phi_{d}(t)$ and the actual angle $\phi(t)$ will drive the hydraulic actuator, which in turn adjusts the deflection of the aileron surface.
A simplified model where the rolling motion can be considered independent of other motions is assumed, and its block diagram is shown in Figure DP7.13(b). Assume that the roll rate $\dot{\phi}(t)$ is fed back using a rate gyro. We desire a zero steady-state tracking error to a unit step. The step response desired has a percent overshoot P.O. $\leq 15 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 25 \mathrm{~s}$. Select the parameters $K_{1}$ and $K_{2}$.

DP7.14 Consider the feedback system shown in Figure DP7.14. The process transfer function is marginally stable. The controller is the proportional-derivative (PD) controller.

a. Determine the characteristic equation of the closed-loop system.

b. Let $\tau=K_{P} / K_{D}$. Write the characteristic equation in the form

$$
\Delta(s)=1+K_{D} \frac{n(s)}{d(s)} \text {. }
$$

c. Plot the root locus for $0 \leq K_{D}<\propto$ when $\tau=6$.

d. What is the effect on the root locus when $0<\tau<\sqrt{10}$ ?

e. Design the PD controller to meet the following specifications:

(i) $P . O . \leq 5 \%$

(ii) $T_{\mathrm{s}} \leq 1 \mathrm{~s}$
FIGURE DP7.14

A marginally stable plant with a PD controller in the loop.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0542.jpg?height=264&width=871&top_left_y=618&top_left_x=449)

\section{COMPUTER PROBLEMS}

CP7.1 Using the rlocus function, obtain the root locus for the following transfer functions of the system shown in Figure CP7.1 when $0 \leq K<\infty$ :
a. $G(s)=\frac{25}{s^{3}+10 s^{2}+40 s+25}$
b. $G(s)=\frac{s+10}{s^{2}+2 s+10}$
c. $G(s)=\frac{s^{2}+2 s+4}{s\left(s^{2}+5 s+10\right)}$
c. $G(s)=\frac{s^{5}+6 s^{4}+6 s^{3}+12 s^{2}+6 s+4}{s^{6}+4 s^{5}+5 s^{4}+s^{3}+s^{2}+12 s+1}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0542.jpg?height=153&width=570&top_left_y=1537&top_left_x=263)

\section{FIGURE CP7.1}

A single-loop feedback system with parameter $K$.

CP7.2 A unity negative feedback system has the loop transfer function

$$
K G(s)=K \frac{s+4}{s(s+2)\left(s^{2}+6 s+27\right)} .
$$

Develop an m-file to plot the root locus, and show with the rlocfind function that the maximum value of $K$ for a stable system is $K=92.7$.
CP7.3 Compute the partial fraction expansion of

$$
Y(s)=\frac{s+6}{s\left(s^{2}+6 s+5\right)}
$$

and verify the result using the residue function.

CP7.4 A unity negative feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{p(s-1)}{s^{3}+4 s^{2}+5 s+4} .
$$

Develop an m-file to obtain the root locus as $p$ varies; $0<p<\infty$. For what values of $p$ is the closed-loop stable?

CP7.5 Consider the unity feedback system with the loop transfer function

$$
L(s)=\frac{K}{s(s+10)} .
$$

For what value of $K$ is the step response to a unit step such that the percent overshoot, P.O. $<5 \%$ ? Show the step response and confirm the perfomance specification is satisfied.

CP7.6 A large antenna, as shown in Figure CP7.6(a), is used to receive satellite signals and must accurately track the satellite as it moves across the sky. The control system uses an armature-controlled motor and a controller to be selected, as shown in Figure CP7.6(b). The system specifications require a zero steady-state error for a ramp input. We also seek a FIGURE CP7.6

Antenna position control.

FIGURE CP7.7

A single-loop feedback control system with controller $G_{c}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0543.jpg?height=572&width=717&top_left_y=149&top_left_x=580)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0543.jpg?height=271&width=1134&top_left_y=817&top_left_x=376)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0543.jpg?height=226&width=906&top_left_y=1181&top_left_x=370)

percent overshoot to a step input of P.O. $\leq 3 \%$ with a settling time (with a $2 \%$ criterion) of $T_{s} \leq 1 \mathrm{~s}$. Using root locus methods, create an m-file to assist in designing the controller. Plot the resulting unit step response and compute the percent overshoot and the settling time and label the plot accordingly. Determine the effect of the disturbance $T_{d}(s)=Q / \mathrm{s}$ (where $Q$ is a constant) on the output $Y(s)$. Draw the system output $y(t)$ when $Q=1$.

CP7.7 Consider the feedback control system in Figure CP7.7. We have three potential controllers for our system:

1. $G_{c}(s)=K$ (proportional controller)

2. $G_{c}(s)=K / s$ (integral controller)

3. $G_{c}(s)=K(1+1 / s)$ (proportional, integral (PI) controller).

The design specifications are $T_{s} \leq 10 \mathrm{~s}$ and P.O. $\leq 10 \%$ for a unit step input. a. For the proportional controller, develop an m-file to sketch the root locus for $0<K<\infty$, and determine the value of $K$ so that the design specifications are satisfied.

b. Repeat part (a) for the integral controller.

c. Repeat part (a) for the PI controller.

d. Co-plot the unit step responses for the closedloop systems with each controller designed in parts (a)-(c).

e. Compare and contrast the three controllers obtained in parts (a)-(c), concentrating on the steady-state errors and transient performance.

CP7.8 Consider the spacecraft single-axis attitude control system shown in Figure CP7.8. The controller is known as a proportional-derivative (PD) controller. Suppose that we require the ratio of $K_{p} / K_{D}=12$. Then, develop an m-file using root locus methods find the values of $K_{D} / J$ and $K_{p} / J$ so that the settling time $T_{s}$ is $T_{s} \leq 2 \mathrm{~s}$, and the peak overshoot is FIGURE CP7.8

A spacecraft attitude control system with a proportionalderivative controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0544.jpg?height=277&width=1059&top_left_y=151&top_left_x=449)

$\leq 5 \%$ for a unit step input. Use a $2 \%$ criterion to determine the settling time.

CP7.9 Consider the feedback control system in Figure CP7.9. Develop an $m$-file to plot the root locus for $0<K<\infty$. Find the value of $K$ resulting in a damping ratio of the closed-loop poles equal to $\zeta=0.707$.

CP7.10 Consider the system represented in state variable form

$$
\begin{aligned}
& \mathbf{x}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
& y(t)=\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-1 & -8 & -3-k
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
1 \\
5 \\
0
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{lll}
3 & 1 & -15
\end{array}\right], \text { and } \mathbf{D}=[0]
\end{aligned}
$$

(a) Determine the characteristic equation. (b) Using the Routh-Hurwitz criterion, determine the values of $k$ for which the system is stable. (c) Develop an m-file to plot the root locus, and compare the results to those obtained in (b).

FIGURE CP7.9

Unity feedback

system with

parameter $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0544.jpg?height=191&width=774&top_left_y=1029&top_left_x=450)

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) True; (5) True

Multiple Choice: (6) b; (7) c; (8) a; (9) c; (10) a; (11) b; (12) c; (13) a; (14) c; (15) b
Word Match (in order, top to bottom): n, k, f, o, a, d, l, $\mathrm{i}, \mathrm{h}, \mathrm{c}, \mathrm{b}, \mathrm{e}, \mathrm{m}, \mathrm{g}, \mathrm{j}$

\section{TERMS AND CONCEPTS}

Angle of departure The angle at which a locus leaves a complex pole in the $s$-plane.

Angle of the asymptotes The angle $\phi_{A}$ that the asymptote makes with respect to the real axis.

Asymptote The path the root locus follows as the parameter becomes very large and approaches infinity. The number of asymptotes is equal to the number of poles minus the number of zeros.

Asymptote centroid The center $\sigma_{A}$ of the linear asymptotes.
Breakaway point The point on the real axis where the locus departs from the real axis of the $s$-plane.

Dominant roots The roots of the characteristic equation that represent or dominate the closed-loop transient response.

Locus A path or trajectory that is traced out as a parameter is changed.

Logarithmic sensitivity A measure of the sensitivity of the system performance to specific parameter changes, given by $S_{K}^{T}(s)=\frac{\partial T(s) / T(s)}{\partial K / K}$, where $T(s)$ is the system transfer function and $K$ is the parameter of interest.

Manual PID tuning methods The process of determining the PID controller gains by trial-and-error with minimal analytic analysis.

Negative gain root locus The root locus for negative values of the parameter of interest, where $-\infty<K \leq 0$.

Number of separate loci Equal to the number of poles of the transfer function, assuming that the number of poles is greater than or equal to the number of zeros of the transfer function.

Parameter design A method of selecting one or two parameters using the root locus method.

PID controller A widely used controller used in industry of the form $G_{c}(s)=K_{p}+\frac{K_{I}}{s}+K_{D} s$, where $K_{p}$ is the proportional gain, $K_{I}$ is the integral gain, and $K_{D}$ is the derivative gain.

PID tuning The process of determining the PID controller gains.

Proportional plus derivative (PD) controller A twoterm controller of the form $G_{c}(s)=K_{p}+K_{D} s$, where $K_{p}$ is the proportional gain and $K_{D}$ is the derivative gain.

Proportional plus integral (PI) controller A two-term controller of the form $G_{c}(s)=K_{p}+\frac{K_{I}}{s}$, where $K_{p}$ is the proportional gain and $K_{I}$ is the integral gain.
Quarter amplitude decay The amplitude of the closedloop response is reduced approximately to onefourth of the maximum value in one oscillatory period.

Reaction curve The response obtained by taking the controller off-line and introducing a step input. The underlying process is assumed to be a first-order system with a transport delay.

Root contours The family of loci that depict the effect of varying two parameters on the roots of the characteristic equation.

Root locus The locus or path of the roots traced out on the $s$-plane as a parameter is changed.

Root locus method The method for determining the locus of roots of the characteristic equation $1+K P(s)=0$ as $K$ varies from 0 to infinity.

Root locus segments on the real axis The root locus lying in a section of the real axis to the left of an odd number of poles and zeros.

Root sensitivity The sensitivity of the roots as a parameter changes from its normal value. The root sensitivity is given by $S_{K}^{r}=\frac{\partial r}{\partial K / K}$, the incremental change in the root divided by the proportional change of the parameter.

Ultimate gain The $\mathrm{PD}$ controller proportional gain, $K_{p}$, on the border of instability when $K_{D}=0$ and $K_{I}=0$.

Ultimate period The period of the sustained oscillations when $K_{p}$ is the ultimate gain and $K_{D}=0$ and $K_{I}=0$.

Ziegler-Nichols PID tuning method The process of determining the PID controller gains using one of several analytic methods based on open-loop and closedloop responses to step inputs. 

\title{
Frequency Response Methods
}

\author{
8.1 Introduction 546 \\ 8.2 Frequency Response Plots 548 \\ 8.3 Frequency Response Measurements 569 \\ 8.4 Performance Specifications in the Frequency Domain 571 \\ 8.5 Log-Magnitude and Phase Diagrams 574 \\ 8.6 Design Examples 575 \\ 8.7 Frequency Response Methods Using Control Design Software 584 \\ 8.8 Sequential Design Example: Disk Drive Read System 589 \\ 8.9 Summary 591
}

\section{PREVIEW}

In this chapter, we consider the steady-state response of a system to a sinusoidal input test signal. We will see that the response of a linear constant coefficient system to a sinusoidal input signal is an output sinusoidal signal at the same frequency as the input. However, the magnitude and phase of the output signal differ from those of the input sinusoidal signal, and the amount of difference is a function of the input frequency. Thus, we will be investigating the steady-state response of the system to a sinusoidal input as the frequency varies.

We will examine the transfer function $G(s)$ when $s=j \omega$ and develop methods for graphically displaying the complex number $G(j \omega)$ as $\omega$ varies. The Bode plot is one of the most powerful graphical tools for analyzing and designing control systems, and we will cover that subject in this chapter. We will also consider polar plots and log-magnitude and phase diagrams. We will develop several time-domain performance measures in terms of the frequency response of the system, as well as introduce the concept of system bandwidth. The chapter concludes with a frequency response analysis of the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 8, students should be able to:

$\square \quad$ Explain the concept of frequency response and its role in control system design.

$\square \quad$ Sketch a Bode plot and also how to obtain a computer-generated Bode plot.

$\square \quad$ Describe log-magnitude and phase diagrams.

$\square \quad$ Identify performance specifications in the frequency domain and relative stability based on gain and phase margins.

$\square \quad$ Design a controller to meet desired specifications using frequency response methods. 

\subsection{INTRODUCTION}

A very practical and important approach to the analysis and design of a system is the frequency response method.

The frequency response of a system is defined as the steady-state response of the system to a sinusoidal input signal. The sinusoid is a unique input signal, and the resulting output signal for a linear system is sinusoidal in the steady state; it differs from the input only in amplitude and phase angle.

For example, consider the system $Y(s)=T(s) R(s)$ with $r(t)=A \sin \omega t$. We have

$$
R(s)=\frac{A \omega}{s^{2}+\omega^{2}}
$$

and

$$
T(s)=\frac{m(s)}{q(s)}=\frac{m(s)}{\prod_{i=1}^{n}\left(s+p_{i}\right)},
$$

where $-p_{i}$ are assumed to be distinct poles. Then, in partial fraction form, we have

$$
Y(s)=\frac{k_{1}}{s+p_{1}}+\cdots+\frac{k_{n}}{s+p_{n}}+\frac{\alpha s+\beta}{s^{2}+\omega^{2}} .
$$

Taking the inverse Laplace transform yields

$$
y(t)=k_{1} e^{-p_{1} t}+\cdots+k_{n} e^{-p_{n} t}+\mathscr{L}^{-1}\left\{\frac{\alpha s+\beta}{s^{2}+\omega^{2}}\right\},
$$

where $\alpha$ and $\beta$ are constants which are problem dependent. If the system is stable, then all $p_{i}$ have positive real parts and

$$
\lim _{t \rightarrow \infty} y(t)=\lim _{t \rightarrow \infty} \mathscr{L}^{-1}\left\{\frac{\alpha s+\beta}{s^{2}+\omega^{2}}\right\},
$$

since each exponential term $k_{i} e^{-p_{i} t}$ decays to zero as $t \rightarrow \infty$.

In the limit for $y(t)$, it can be shown, for $t \rightarrow \infty$ (the steady state),

$$
\begin{aligned}
y(t) & =\mathscr{L}^{-1}\left[\frac{\alpha s+\beta}{s^{2}+\omega^{2}}\right]=\frac{1}{\omega}|A \omega T(j \omega)| \sin (\omega t+\phi) \\
& =A|T(j \omega)| \sin (\omega t+\phi),
\end{aligned}
$$

where $\phi=/ \mathrm{T}(j \omega)$.

Thus, the steady-state output signal depends only on the magnitude and phase of $T(j \omega)$ at a specific frequency $\omega$. The steady-state response, as described in Equation (8.1), is true only for stable systems, $T(s)$. One advantage of the frequency response method is the ready availability of sinusoid test signals for various ranges of frequencies and amplitudes. Thus, the experimental determination of the system frequency response is easily accomplished. The unknown transfer function of a system can often be deduced from the experimentally determined frequency response of a system [1,2]. Furthermore, the design of a system in the frequency domain provides the designer with control of the bandwidth of a system, as well as some measure of the response of the system to undesired noise and disturbances.

A second advantage of the frequency response method is that the transfer function describing the sinusoidal steady-state behavior of a system can be obtained by replacing $s$ with $j \omega$ in the system transfer function $T(s)$. The transfer function representing the sinusoidal steady-state behavior of a system is then a function of the complex variable $j \omega$ and is itself a complex function $T(j \omega)$ that possesses a magnitude and phase angle. The magnitude and phase angle of $T(j \omega)$ are readily represented by graphical plots that provide significant insight into the analysis and design of control systems.

The basic disadvantage of the frequency response method for analysis and design is the indirect link between the frequency and the time domain. Direct correlations between the frequency response and the corresponding transient response characteristics are somewhat tenuous, and in practice the frequency response characteristic is adjusted by using various design criteria that will normally result in a satisfactory transient response.

The Laplace transform pair is

$$
F(s)=\mathscr{L}\{f(t)\}=\int_{0}^{\infty} f(t) e^{-s t} d t
$$

and

$$
f(t)=\mathscr{L}^{-1}\{F(s)\}=\frac{1}{2 \pi j} \int_{\sigma-j \infty}^{\sigma+j \infty} F(s) e^{s t} d s,
$$

where the complex variable $s=\sigma+j \omega$. Similarly, the Fourier transform pair is

$$
F(\omega)=\mathscr{F}\{f(t)\}=\int_{-\infty}^{\infty} f(t) e^{-j \omega t} d t
$$

and

$$
f(t)=\mathscr{F}^{-1}\{F(\omega)\}=\frac{1}{2 \pi} \int_{-\infty}^{\infty} F(\omega) e^{j \omega t} d \omega .
$$

The Fourier transform exists for $f(t)$ when

$$
\int_{-\infty}^{\infty}|f(t)| d t<\infty
$$

The Fourier and Laplace transforms are closely related, as we can see by examining Equations (8.2) and (8.4). When the function $f(t)$ is defined only for $t \geq 0$, as is often the case, the lower limits on the integrals are the same. Then we note that the two equations differ only in the complex variable. Thus, if the Laplace transform of a function $f_{1}(t)$ is known to be $F_{1}(s)$, we can obtain the Fourier transform of this same time function by setting $s=j \omega$ in $F_{1}(s)$ [3].

Again we might ask, Since the Fourier and Laplace transforms are so closely related, why not use the Laplace transform? Why use the Fourier transform at all? The Laplace transform enables us to investigate the $s$-plane location of the poles and zeros of a transfer function $T(s)$. However, the frequency response method allows us to consider the transfer function $T(j \omega)$ and to concern ourselves with the amplitude and phase characteristics of the system. This ability to investigate and represent the character of a system by amplitude, phase equations, and curves is an advantage for the analysis and design of control systems.

If we consider the frequency response of the closed-loop system, we might have an input that $r(t)$ has a Fourier transform in the frequency domain as follows:

$$
R(j \omega)=\int_{-\infty}^{\infty} r(t) e^{-j \omega t} d t
$$

Then the output frequency response of a unity feedback control system can be obtained by substituting $s=j \omega$ in the closed-loop system relationship, $Y(s)=T(s) R(s)$, so that we have

$$
Y(j \omega)=T(j \omega) R(j \omega)=\frac{G_{c}(j \omega) G(j \omega)}{1+G_{c}(j \omega) G(j \omega)} R(j \omega) .
$$

Using the inverse Fourier transform, the output transient response would be

$$
y(t)=\mathscr{F}^{-1}\{Y(j \omega)\}=\frac{1}{2 \pi} \int_{-\infty}^{\infty} Y(j \omega) e^{j \omega t} d \omega .
$$

However, it is usually difficult to evaluate this inverse transform integral for all but the simplest systems, and a graphical integration may be used. Alternatively, as we will note in succeeding sections, several measures of the transient response can be related to the frequency characteristics and utilized for design purposes.

\subsection{FREQUENCY RESPONSE PLOTS}

The transfer function of a system $G(s)$ can be described in the frequency domain by the relation

$$
G(j \omega)=\left.G(s)\right|_{s=j \omega}=R(\omega)+j X(\omega)
$$

FIGURE 8.1

The polar plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0550.jpg?height=277&width=604&top_left_y=153&top_left_x=505)

where

$$
R(\omega)=\operatorname{Re}[G(j \omega)] \text { and } X(\omega)=\operatorname{Im}[G(j \omega)] .
$$

See the MCS website for a review of complex numbers.

Alternatively, the transfer function can be represented by a magnitude $|G(j \omega)|$ and a phase $\phi(j \omega)$ as

$$
G(j \omega)=|G(j \omega)| e^{j \phi(\omega)}=|G(j \omega)| \angle \phi(\omega),
$$

where

$$
\phi(\omega)=\tan ^{-1} \frac{X(\omega)}{R(\omega)} \text { and }|G(j \omega)|^{2}=[R(\omega)]^{2}+[X(\omega)]^{2} .
$$

The graphical representation of the frequency response of the system $G(j \omega)$ can utilize either Equation (8.8) or Equation (8.9). The polar plot representation of the frequency response is obtained by using Equation (8.8). The coordinates of the polar plot are the real and imaginary parts of $G(j \omega)$, as shown in Figure 8.1. An example of a polar plot will illustrate this approach.

\section{EXAMPLE 8.1 Frequency response of an $\boldsymbol{R} C$ filter}

A simple $R C$ filter is shown in Figure 8.2. The transfer function of this filter is

$$
G(s)=\frac{V_{2}(s)}{V_{1}(s)}=\frac{1}{R C s+1}
$$

and the sinusoidal steady-state transfer function is

$$
G(j \omega)=\frac{1}{j \omega(R C)+1}=\frac{1}{j\left(\omega / \omega_{1}\right)+1},
$$

where

$$
\omega_{1}=\frac{1}{R C}
$$

FIGURE 8.2 An $R C$ filter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0550.jpg?height=224&width=564&top_left_y=1892&top_left_x=506)

FIGURE 8.3 Polar plot for $R C$ filter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0551.jpg?height=506&width=668&top_left_y=166&top_left_x=374)

Then the polar plot is obtained from the relation

$$
\begin{aligned}
G(j \omega) & =R(\omega)+j X(\omega)=\frac{1-j\left(\omega / \omega_{1}\right)}{\left(\omega / \omega_{1}\right)^{2}+1} \\
& =\frac{1}{1+\left(\omega / \omega_{1}\right)^{2}}-\frac{j\left(\omega / \omega_{1}\right)}{1+\left(\omega / \omega_{1}\right)^{2}} .
\end{aligned}
$$

The first step is to determine $R(\omega)$ and $X(\omega)$ at the two frequencies, $\omega=0$ and $\omega=\infty$. At $\omega=0$, we have $R(\omega)=1$ and $X(\omega)=0$. At $\omega=\infty$, we have $R(\omega)=0$ and $X(\omega)=0$. These two points are shown in Figure 8.3. The locus of the real and imaginary parts is also shown in Figure 8.3 and is easily shown to be a circle with the center at $\left(\frac{1}{2}, 0\right)$. When $\omega=\omega_{1}$, the real and imaginary parts are equal in magnitude, and the angle $\phi(\omega)=-45^{\circ}$. The polar plot can also be readily obtained from Equation (8.9) as

$$
G(j \omega)=|G(j \omega)| \angle \phi(\omega),
$$

where

$$
|G(j \omega)|=\frac{1}{\left[1+\left(\omega / \omega_{1}\right)^{2}\right]^{1 / 2}} \text { and } \phi(\omega)=-\tan ^{-1}\left(\omega / \omega_{1}\right) .
$$

Hence, when $\omega=\omega_{1}$, the magnitude is $\left|G\left(j \omega_{1}\right)\right|=1 / \sqrt{2}$ and the phase $\phi\left(\omega_{1}\right)=-45^{\circ}$. Also, when $\omega$ approaches $+\infty$, we have $|G(j \omega)| \rightarrow 0$ and $\phi(\omega)=-90^{\circ}$. Similarly, when $\omega=0$, we have $|G(j \omega)|=1$ and $\phi(\omega)=0$.

\section{EXAMPLE 8.2 Polar plot of a transfer function}

The polar plot of a transfer function is useful for investigating system stability. Consider a transfer function

$$
\left.G(s)\right|_{s=j \omega}=G(j \omega)=\frac{K}{j \omega(j \omega \tau+1)}=\frac{K}{j \omega-\omega^{2} \tau} .
$$

FIGURE 8.4

Polar plot for $G(j \omega)=$ $K /(j \omega(j \omega \tau+1))$.

Note that $\omega=\infty$ is at the origin.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0552.jpg?height=691&width=665&top_left_y=151&top_left_x=505)

Then the magnitude and phase angle are written as

$$
|G(j \omega)|=\frac{K}{\left(\omega^{2}+\omega^{4} \tau^{2}\right)^{1 / 2}} \text { and } \phi(\omega)=-\tan ^{-1} \frac{1}{-\omega \tau} .
$$

The phase angle and the magnitude are readily calculated at the frequencies $\omega=0, \omega=1 / \tau$, and $\omega=+\infty$. The polar plot of $G(j \omega)$ is shown in Figure 8.4.

An alternative solution uses the real and imaginary parts of $G(j \omega)$ as

$$
G(j \omega)=\frac{K}{j \omega-\omega^{2} \tau}=\frac{K\left(-j \omega-\omega^{2} \tau\right)}{\omega^{2}+\omega^{4} \tau^{2}}=R(\omega)+j X(\omega),
$$

where $R(\omega)=-K \omega^{2} \tau / M(\omega)$ and $X(\omega)=-\omega K / M(\omega)$, and where $M(\omega)=\omega^{2}+$ $\omega^{4} \tau^{2}$. Then when $\omega=\infty$, we have $R(\omega)=0$ and $X(\omega)=0$. When $\omega=0$, we have $R(\omega)=-K \tau$ and $X(\omega)=-\infty$. When $\omega=1 / \tau$, we have $R(\omega)=-K \tau / 2$ and $X(\omega)=-K \tau / 2$, as shown in Figure 8.4.

Another method of obtaining the polar plot is to evaluate the vector $G(j \omega)$ graphically at specific frequencies, $\omega$, along the $s=j \omega$ axis on the $s$-plane. We consider

$$
G(s)=\frac{K / \tau}{s(s+1 / \tau)}
$$

with the two poles shown on the $s$-plane in Figure 8.5.

When $s=j \omega$, we have

$$
G(j \omega)=\frac{K / \tau}{j \omega(j \omega+p)},
$$

FIGURE 8.5

Two vectors on the $s$-plane to evaluate $G\left(j \omega_{1}\right)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0553.jpg?height=508&width=644&top_left_y=167&top_left_x=372)

where $p=1 / \tau$. The magnitude and phase of $G(j \omega)$ can be evaluated at a specific frequency, $\omega_{1}$, on the $j \omega$-axis, as shown in Figure 8.5 . The magnitude and the phase are, respectively,

$$
\left|G\left(j \omega_{1}\right)\right|=\frac{K / \tau}{\left|j \omega_{1}\right|\left|j \omega_{1}+p\right|}
$$

and

$$
\phi(\omega)=-\left\lfloor\left(j \omega_{1}\right)-\left\lfloor\left(j \omega_{1}+p\right)=-90^{\circ}-\tan ^{-1}\left(\omega_{1} / p\right) .\right.\right.
$$

There are several possibilities for coordinates of a graph portraying the frequency response of a system. As we have seen, we may use a polar plot to represent the frequency response (Equation 8.8) of a system. However, the limitations of polar plots are readily apparent. The addition of poles or zeros to an existing system requires the recalculation of the frequency response, as outlined in Examples 8.1 and 8.2. Furthermore, calculating the frequency response in this manner is tedious and does not indicate the effect of the individual poles or zeros.

The introduction of logarithmic plots, often called Bode plots, simplifies the determination of the graphical portrayal of the frequency response. The logarithmic plots are called Bode plots in honor of H. W. Bode, who used them extensively in his studies of feedback amplifiers $[4,5]$. The transfer function in the frequency domain is

$$
G(j \omega)=|G(j \omega)| e^{j \phi(\omega)} .
$$

The logarithm of the magnitude is normally expressed in terms of the logarithm to the base 10 , so we use

$$
\text { Logarithmic gain }=20 \log _{10}|G(j \omega)|
$$

where the units are decibels (dB). A decibel conversion table is given on the MCS website. The logarithmic gain in $\mathrm{dB}$ and the angle $\phi(\omega)$ can be plotted versus the frequency $\omega$ by utilizing several different arrangements. For a Bode diagram, the FIGURE 8.6

Bode plot for $G(j \omega)=1 /(j \omega \tau+1)$ :

(a) magnitude plot and (b) phase plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0554.jpg?height=327&width=1080&top_left_y=156&top_left_x=523)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0554.jpg?height=428&width=1098&top_left_y=562&top_left_x=519)

(b)

plot of logarithmic gain in $\mathrm{dB}$ versus $\omega$ is normally plotted on one set of axes, and the phase $\phi(\omega)$ versus $\omega$ on another set of axes, as shown in Figure 8.6. For example, the Bode plot of the transfer function of Example 8.1 can be readily obtained, as we will find in the following example.

\section{EXAMPLE 8.3 Bode plot of an $\boldsymbol{R} C$ filter}

The transfer function of Example 8.1 is

$$
G(j \omega)=\frac{1}{j \omega(R C)+1}=\frac{1}{j \omega \tau+1},
$$

where

$$
\tau=R C,
$$

the time constant of the network. The logarithmic gain is

$$
20 \log |G(j \omega)|=20 \log \left(\frac{1}{1+(\omega \tau)^{2}}\right)^{1 / 2}=-10 \log \left(1+(\omega \tau)^{2}\right) .
$$

For small frequencies - that is, $\omega \ll 1 / \tau$ - the logarithmic gain is

$$
20 \log |G(j \omega)|=-10 \log (1)=0 \mathrm{~dB}, \quad \omega \ll 1 / \tau .
$$

For large frequencies - that is, $\omega \gg 1 / \tau$ - the logarithmic gain is

$$
20 \log G(j \omega)=-20 \log (\omega \tau) \quad \omega \gg 1 / \tau,
$$

and at $\omega=1 / \tau$, we have

$$
20 \log |G(j \omega)|=-10 \log 2=-3.01 \mathrm{~dB} .
$$

The magnitude plot for this network is shown in Figure 8.6(a). The phase angle of the network is

$$
\phi(\omega)=-\tan ^{-1}(\omega \tau) .
$$

The phase plot is shown in Figure 8.6(b). The frequency $\omega=1 / \tau$ is often called the break frequency or corner frequency.

A linear scale of frequency is not the most convenient or judicious choice, and we consider the use of a logarithmic scale of frequency. The convenience of a logarithmic scale of frequency can be seen by considering Equation (8.21) for large frequencies $\omega \gg 1 / \tau$, as follows:

$$
20 \log |G(j \omega)|=-20 \log (\omega \tau)=-20 \log \tau-20 \log \omega .
$$

Then, on a set of axes where the horizontal axis is $\log \omega$, the asymptotic curve for $\omega \gg 1 / \tau$ is a straight line, as shown in Figure 8.7. The slope of the straight line can be ascertained from Equation (8.21). An interval of two frequencies with a ratio equal to 10 is called a decade, so that the range of frequencies from $\omega_{1}$ to $\omega_{2}$, where $\omega_{2}=10 \omega_{1}$, is called a decade. The difference between the logarithmic gains, for $\omega \gg 1 / \tau$, over a decade of frequency is

$$
\begin{aligned}
20 \log \left|G\left(j \omega_{1}\right)\right|-20 \log \left|G\left(j \omega_{2}\right)\right| & =-20 \log \left(\omega_{1} \tau\right)-\left(-20 \log \left(\omega_{2} \tau\right)\right) \\
& =-20 \log \frac{\omega_{1} \tau}{\omega_{2} \tau} \\
& =-20 \log \frac{1}{10}=+20 \mathrm{~dB} ;
\end{aligned}
$$

that is, the slope of the asymptotic line for this first-order transfer function is $-20 \mathrm{~dB} /$ decade, and the slope is shown for this transfer function in Figure 8.7. Instead of using a horizontal axis of $\log \omega$ and linear rectangular coordinates, it is easier to use semilog axes with a linear rectangular coordinate for $\mathrm{dB}$ and a logarithmic coordinate for $\omega$. Alternatively, we could use a logarithmic coordinate for the magnitude as well as for frequency and avoid the necessity of calculating the logarithm of the magnitude.

FIGURE 8.7

Asymptotic curve for $(j \omega \tau+1)^{-1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0555.jpg?height=355&width=605&top_left_y=1765&top_left_x=375)

The frequency interval $\omega_{2}=2 \omega_{1}$ is often used and is called an octave of frequencies. The difference between the logarithmic gains for $\omega \gg 1 / \tau$, for an octave, is

$$
\begin{aligned}
20 \log \left|G\left(j \omega_{1}\right)\right|-20 \log \left|G\left(j \omega_{2}\right)\right| & =-20 \log \frac{\omega_{1} \tau}{\omega_{2} \tau} \\
& =-20 \log \frac{1}{2}=6.02 \mathrm{~dB} .
\end{aligned}
$$

Therefore, the slope of the asymptotic line is $-6 \mathrm{~dB} /$ octave.

The primary advantage of the logarithmic plot is the conversion of multiplicative factors, such as $(j \omega \tau+1)$, into additive factors, $20 \log (j \omega \tau+1)$, by virtue of the definition of logarithmic gain. This can be readily ascertained by considering the transfer function

$$
G(j \omega)=\frac{K_{b} \prod_{i=1}^{Q}\left(1+j \omega \tau_{i}\right) \prod_{l=1}^{P}\left[\left(1+\left(2 \zeta_{l} / \omega_{n_{l}}\right) j \omega+\left(j \omega / \omega_{n_{l}}\right)^{2}\right)\right]}{(j \omega)^{N} \prod_{m=1}^{M}\left(1+j \omega \tau_{m}\right) \prod_{k=1}^{R}\left[\left(1+\left(2 \zeta_{k} / \omega_{n_{k}}\right) j \omega+\left(j \omega / \omega_{n_{k}}\right)^{2}\right)\right]} .
$$

This transfer function includes $Q$ zeros, $N$ poles at the origin, $M$ poles on the real axis, $P$ pairs of complex conjugate zeros, and $R$ pairs of complex conjugate poles. The logarithmic magnitude of $G(j \omega)$ is

$$
\begin{array}{r}
20 \log |G(j \omega)|=20 \log K_{b}+20 \sum_{i=1}^{Q} \log \left|1+j \omega \tau_{i}\right| \\
-20 \log \left|(j \omega)^{N}\right|-20 \sum_{m=1}^{M} \log \left|1+j \omega \tau_{m}\right| \\
+20 \sum_{l=1}^{P} \log \left|1+\frac{2 \zeta_{l}}{\omega_{n_{l}}} j \omega+\left(\frac{j \omega}{\omega_{n l}}\right)^{2}\right|-20 \sum_{k=1}^{R} \log \left|1+\frac{2 \zeta_{k}}{\omega_{n_{k}}} j \omega+\left(\frac{j \omega}{\omega_{n_{k}}}\right)^{2}\right|,
\end{array}
$$

and the Bode plot can be obtained by adding the contribution of each individual factor. Furthermore, the separate phase angle plot is obtained as

$$
\begin{aligned}
\phi(\omega)= & +\sum_{i=1}^{Q} \tan ^{-1}\left(\omega \tau_{i}\right)-N\left(90^{\circ}\right)-\sum_{m=1}^{M} \tan ^{-1}\left(\omega \tau_{m}\right) \\
& -\sum_{k=1}^{R} \tan ^{-1} \frac{2 \zeta_{k} \omega_{n_{k}} \omega}{\omega_{n_{k}}^{2}-\omega^{2}}+\sum_{l=1}^{P} \tan ^{-1} \frac{2 \zeta_{l} \omega_{n_{l}} \omega}{\omega_{n_{l}}^{2}-\omega^{2}},
\end{aligned}
$$

which is the summation of the phase angles due to each individual factor of the transfer function.

Therefore, the four different kinds of factors that may occur in a transfer function are as follows:

1. Constant gain $K_{b}$

2. Poles (or zeros) at the origin $(j \omega)$

3. Poles (or zeros) on the real axis $(j \omega \tau+1)$

4. Complex conjugate poles (or zeros) $\left[1+\left(2 \zeta / \omega_{n}\right) j \omega+\left(j \omega / \omega_{n}\right)^{2}\right]$. We can determine the logarithmic magnitude plot and phase angle for these four factors and then use them to obtain a Bode plot for any general form of a transfer function. Typically, the curves for each factor are obtained and then added together graphically to obtain the curves for the complete transfer function. Furthermore, this procedure can be simplified by using the asymptotic approximations to these curves and obtaining the actual curves only at specific important frequencies.

Constant Gain $K_{b}$. The logarithmic gain for the constant $K_{b}$ is

$$
20 \log K_{b}=\text { constant in } \mathrm{dB} \text {, }
$$

and the phase angle is

$$
\phi(\omega)=0
$$

The gain curve is a horizontal line on the Bode plot.

If the gain is a negative value, $-K_{b}$, the logarithmic gain remains $20 \log K_{b}$. The negative sign is accounted for by the phase angle, $-180^{\circ}$.

Poles (or Zeros) at the Origin $(j \omega)$. A pole at the origin has a logarithmic magnitude

$$
20 \log \left|\frac{1}{j \omega}\right|=-20 \log \omega \mathrm{dB}
$$

and a phase angle

$$
\phi(\omega)=-90^{\circ} .
$$

The slope of the magnitude curve is $-20 \mathrm{~dB} / \mathrm{decade}$ for a pole. Similarly, for a multiple pole at the origin, we have

$$
20 \log \left|\frac{1}{(j \omega)^{N}}\right|=-20 N \log \omega,
$$

and the phase is

$$
\phi(\omega)=-90^{\circ} N
$$

In this case, the slope due to the multiple pole is $-20 \mathrm{~N} \mathrm{~dB} /$ decade. For a zero at the origin, we have a logarithmic magnitude

$$
20 \log |j \omega|=+20 \log \omega
$$

FIGURE 8.8

Bode plot for $(j \omega)^{ \pm N}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0558.jpg?height=424&width=1228&top_left_y=164&top_left_x=522)

where the slope is $+20 \mathrm{~dB} /$ decade and the phase angle is

$$
\phi(\omega)=+90^{\circ} \text {. }
$$

The Bode plot of the magnitude and phase angle of $(j \omega)^{ \pm N}$ is shown in Figure 8.8 for $N=1$ and $N=2$.

Poles or Zeros on the Real Axis. For a pole on the real axis,

$$
20 \log \left|\frac{1}{1+j \omega \tau}\right|=-10 \log \left(1+\omega^{2} \tau^{2}\right) \text {. }
$$

The asymptotic curve for $\omega \ll 1 / \tau$ is $20 \log 1=0 \mathrm{~dB}$, and the asymptotic curve for $\omega \gg 1 / \tau$ is $-20 \log (\omega \tau)$, which has a slope of $-20 \mathrm{~dB} /$ decade. The intersection of the two asymptotes occurs when

$$
20 \log 1=0 \mathrm{~dB}=-20 \log (\omega \tau),
$$

or when $\omega=1 / \tau$, the break frequency. The actual logarithmic gain when $\omega=1 / \tau$ is $-3 \mathrm{~dB}$. The phase angle is $\phi(\omega)=-\tan ^{-1}(\omega \tau)$ for the denominator factor. The Bode plot of a pole factor $(1+j \omega \tau)^{-1}$ is shown in Figure 8.9.

The Bode plot of a zero factor $1+j \omega \tau$ is obtained in the same manner as that of the pole. However, the slope is positive at $+20 \mathrm{~dB} /$ decade, and the phase angle is $\phi(\omega)=+\tan ^{-1}(\omega \tau)$.

A piecewise linear approximation to the phase angle curve can be obtained as shown in Figure 8.9. This linear approximation, which passes through the correct phase at the break frequency, is within $6^{\circ}$ of the actual phase curve for all frequencies. This approximation will provide a useful means for readily determining the form of the phase angle curves of a transfer function $G(s)$. However, often the accurate phase angle curves are required, and the actual phase curve for the first-order factor must be obtained via a computer program.

Complex Conjugate Poles or Zeros $\left[1+\left(2 \zeta / \omega_{n}\right) j \omega+\left(j \omega / \omega_{n}\right)^{2}\right]$. The quadratic factor for a pair of complex conjugate poles can be written in normalized form as

$$
\left[1+j 2 \zeta u-u^{2}\right]^{-1}
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0559.jpg?height=419&width=1226&top_left_y=162&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0559.jpg?height=400&width=1247&top_left_y=670&top_left_x=376)

Frequency (rad/s)

Bode diagram for $(1+j \omega \tau)^{-1}$.

(b)

where $u=\omega / \omega_{n}$. Then the logarithmic magnitude for a pair of complex conjugate poles is

$$
20 \log |G(j \omega)|=-10 \log \left(\left(1-u^{2}\right)^{2}+4 \zeta^{2} u^{2}\right),
$$

and the phase angle is

$$
\phi(\omega)=-\tan ^{-1} \frac{2 \zeta u}{1-u^{2}} .
$$

When $u \ll 1$, the magnitude is

$$
20 \log |G(j \omega)|=-10 \log 1=0 \mathrm{~dB},
$$

and the phase angle approaches $0^{\circ}$. When $u \gg 1$, the logarithmic magnitude approaches

$$
20 \log |G(j \omega)|=-10 \log u^{4}=-40 \log u,
$$

which results in a curve with a slope of $-40 \mathrm{~dB} /$ decade. The phase angle, when $u \gg 1$, approaches $-180^{\circ}$. The magnitude asymptotes meet at the $0 \mathrm{~dB}$ line when $u=\omega / \omega_{n}=1$. However, the difference between the actual magnitude curve and the asymptotic approximation is a function of the damping ratio and must be FIGURE 8.10

Bode diagram for $G(j \omega)=\left[1+\left(2 \zeta / \omega_{n}\right)\right.$ $\left.j \omega+\left(j \omega / \omega_{n}\right)\right]^{-1}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0560.jpg?height=750&width=1228&top_left_y=152&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0560.jpg?height=621&width=1232&top_left_y=1000&top_left_x=520)

(b)

accounted for when $\zeta<0.707$. The Bode plot of a quadratic factor due to a pair of complex conjugate poles is shown in Figure 8.10. The maximum value $M_{p \omega}$ of the frequency response occurs at the resonant frequency $\omega_{r}$. When the damping ratio approaches zero, then $\omega_{r}$ approaches $\omega_{n}$, the natural frequency. The resonant frequency is determined by taking the derivative of the magnitude of Equation (8.33) with respect to the normalized frequency, $u$, and setting it equal to zero. The resonant frequency is given by the relation

$$
\omega_{r}=\omega_{n} \sqrt{1-2 \zeta^{2}}, \quad \zeta<0.707
$$

FIGURE 8.11

The maximum $M_{p w}$ of the frequency response and the resonant frequency $\omega_{r}$ versus $\zeta$ for a pair of complex conjugate poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0561.jpg?height=1296&width=979&top_left_y=152&top_left_x=395)

and the maximum value of the magnitude $|G(j \omega)|$ is

$$
M_{p \omega}=\left|G\left(j \omega_{r}\right)\right|=\left(2 \zeta \sqrt{1-\zeta^{2}}\right)^{-1}, \quad \zeta<0.707,
$$

for a pair of complex poles. The maximum value of the frequency response, $M_{p \omega}$, and the resonant frequency $\omega_{r}$ are shown as a function of the damping ratio $\zeta$ for a pair of complex poles in Figure 8.11. Assuming the dominance of a pair of complex conjugate closed-loop poles, we find that these curves are useful for estimating the damping ratio of a system from an experimentally determined frequency response.

The frequency response curves can be evaluated on the $s$-plane by determining the vector lengths and angles at various frequencies $\omega$ along the $s=+j \omega$-axis. For example, considering the second-order factor with complex conjugate poles, we have

$$
G(s)=\frac{1}{\left(s / \omega_{n}\right)^{2}+2 \zeta s / \omega_{n}+1}=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

FIGURE 8.12

Vector evaluation of the frequency response for selected values of $\omega$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0562.jpg?height=320&width=381&top_left_y=167&top_left_x=506)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0562.jpg?height=424&width=357&top_left_y=583&top_left_x=506)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0562.jpg?height=317&width=386&top_left_y=166&top_left_x=917)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0562.jpg?height=421&width=357&top_left_y=584&top_left_x=920)

(d)
The poles for varying $\zeta$ lie on a circle of radius $\omega_{n}$ and are shown for a particular $\zeta$ in Figure 8.12(a). The transfer function evaluated for real frequency $s=j \omega$ is written as

$$
G(j \omega)=\left.\frac{\omega_{n}^{2}}{\left(s-s_{1}\right)\left(s-\hat{s}_{1}\right)}\right|_{s=j \omega}=\frac{\omega_{n}^{2}}{\left(j \omega-s_{1}\right)\left(j \omega-\hat{s}_{1}\right)},
$$

where $s_{1}$ and $\hat{s}_{1}$ are the complex conjugate poles. The vectors $j \omega-s_{1}$ and $j \omega-\hat{s}_{1}$ are the vectors from the poles to the frequency $j \omega$, as shown in Figure 8.12(a). Then the magnitude and phase may be evaluated for various specific frequencies. The magnitude is

$$
|G(j \omega)|=\frac{\omega_{n}^{2}}{\left|j \omega-s_{1}\right|\left|j \omega-\hat{s}_{1}\right|},
$$

and the phase is

$$
\phi(\omega)=-\left\lfloor\left(j \omega-s_{1}\right)-\left\lfloor\left(j \omega-\hat{s}_{1}\right) .\right.\right.
$$

The magnitude and phase may be evaluated for three specific frequencies, namely,

$$
\omega=0, \quad \omega=\omega_{r}, \quad \text { and } \quad \omega=\omega_{d},
$$

as shown in Figure 8.12 in parts (b), (c), and (d), respectively. The magnitude and phase corresponding to these frequencies are shown in Figure 8.13. FIGURE 8.13

Bode diagram for complex conjugate poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0563.jpg?height=574&width=910&top_left_y=153&top_left_x=373)

\section{EXAMPLE 8.4 Bode diagram of a twin-T network}

As an example of the determination of the frequency response using the pole-zero diagram and the vectors to $j \omega$, consider the twin-T network shown in Figure 8.14 [6]. The transfer function of this network is

$$
G(s)=\frac{V_{\mathrm{o}}(s)}{V_{\mathrm{in}}(s)}=\frac{(s \tau)^{2}+1}{(s \tau)^{2}+4 s \tau+1},
$$

where $\tau=R C$. The zeros are at $s= \pm j 1 / \tau$, and the poles are at $s=(-2 \pm \sqrt{3}) / \tau$, in the $s$-plane, as shown in Figure 8.15(a). At $\omega=0$, we have $|G(j \omega)|=1$ and $\phi(\omega)=0^{\circ}$. At $\omega=1 / \tau,|G(j \omega)|=0$ and the phase angle of the vector from the zero at $s=j 1 / \tau$ passes through a transition of $180^{\circ}$. When $\omega$ approaches $\infty,|G(j \omega)|=1$ and $\phi(\omega)=0$ again. The frequency response is shown in Figure 8.15(b).

A summary of the asymptotic curves for basic terms of a transfer function is provided in Table 8.1 .

In the previous examples, the poles and zeros of $G(s)$ have been restricted to the left-hand plane. However, a system may have zeros located in the right-hand $s$ plane and may still be stable. Transfer functions with zeros in the right-hand $s$-plane are classified as nonminimum phase transfer functions. If the zeros of a transfer function are all reflected about the $j \omega$-axis, there is no change in the magnitude of the transfer function, and the only difference is in the phase-shift characteristics. If the phase characteristics of the two system functions are compared, it can be

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0563.jpg?height=313&width=684&top_left_y=1800&top_left_x=373)

FIGURE 8.14 Twin-T network. Table 8.1 Asymptotic Curves for Basic Terms of a Transfer Function

Term

1. Gain,

$G(j \omega)=K$

2. Zero,

$G(j \omega)=$

$1+j \omega / \omega_{1}$

3. Pole,

$G(j \omega)=$

$\left(1+j \omega / \omega_{1}\right)^{-1}$

4. Pole at

the origin,

$G(j \omega)=1 / j \omega$
Magnitude $20 \log _{10}|G(j \omega)|$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0564.jpg?height=1338&width=566&top_left_y=319&top_left_x=582)

5. Two complex poles,

$0.1<\zeta<1$,

$G(j \omega)=(1+$

$\left.j 2 \zeta u-u^{2}\right)^{-1}$

$u=\omega / \omega_{n}$
Phase $\phi(\omega)$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0564.jpg?height=626&width=536&top_left_y=320&top_left_x=1178)

Frequency $(\mathrm{rad} / \mathrm{s})$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0564.jpg?height=1020&width=1166&top_left_y=978&top_left_x=580)FIGURE 8.15

Twin-T network.

(a) Pole-zero

pattern.

(b) Frequency response.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0565.jpg?height=588&width=1248&top_left_y=169&top_left_x=374)

(a)

readily shown that the net phase shift over the frequency range from zero to infinity is less for the system with all its zeros in the left-hand $s$-plane. Thus, the transfer function $G_{1}(s)$, with all its zeros in the left-hand $s$-plane, is called a minimum phase transfer function. The transfer function $G_{2}(s)$, with $\left|G_{2}(j \omega)\right|=\left|G_{1}(j \omega)\right|$ and all the zeros of $G_{1}(s)$ reflected about the $j \omega$-axis into the right-hand $s$-plane, is called a nonminimum phase transfer function. Reflection of any zero or pair of zeros into the right half-plane results in a nonminimum phase transfer function.

\section{A transfer function is called a minimum phase transfer function if all its zeros lie in the left-hand $s$-plane. It is called a nonminimum phase transfer function if it has zeros in the right-hand $s$-plane.}

The two pole-zero patterns shown in Figures 8.16(a) and (b) have the same amplitude characteristics as can be deduced from the vector lengths. However, the phase characteristics are different for Figures 8.16(a) and (b). The minimum phase characteristic of Figure 8.16(a) and the nonminimum phase characteristic of Figure 8.16(b) are shown in Figure 8.17. Clearly, the phase shift of

$$
G_{1}(s)=\frac{s+z}{s+p}
$$

ranges over less than $80^{\circ}$, whereas the phase shift of

$$
G_{2}(s)=\frac{s-z}{s+p}
$$

ranges over $180^{\circ}$. The meaning of the term minimum phase is illustrated by Figure 8.17 . The range of phase shift of a minimum phase transfer function is the least possible or minimum corresponding to a given amplitude curve, whereas the range of the nonminimum phase curve is the greatest possible for the given amplitude curve. FIGURE 8.16

Pole-zero patterns giving the same amplitude response and different phase characteristics.

FIGURE 8.17

The phase characteristics for the minimum phase and nonminimum phase transfer function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=313&width=531&top_left_y=152&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=301&width=638&top_left_y=165&top_left_x=1092)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=396&width=595&top_left_y=564&top_left_x=521)

Frequency $(\mathrm{rad} / \mathrm{s})$

A particularly interesting nonminimum phase network is the all-pass network, which can be realized with a symmetrical lattice network [8]. A symmetrical pattern of poles and zeros is obtained as shown in Figure 8.18(a). Again, the magnitude $|G(j \omega)|$ remains constant; in this case, it is equal to unity. However, the angle varies

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=431&width=360&top_left_y=1257&top_left_x=582)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=212&width=508&top_left_y=1797&top_left_x=527)

(c)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0566.jpg?height=784&width=600&top_left_y=1244&top_left_x=1149)

Frequency (rad/s)

(b)

response, and

(c) a lattice network. from $0^{\circ}$ to $-360^{\circ}$. Because $\theta_{2}=180^{\circ}-\theta_{1}$ and $\hat{\theta}_{2}=180^{\circ}-\hat{\theta}_{1}$, the phase is given by $\left.\phi(\omega)=-2\left(\theta_{1}+\hat{\theta}_{1}\right\}\right)$. The magnitude and phase characteristic of the all-pass network is shown in Figure 8.18(b). A nonminimum phase lattice network is shown in Figure 8.18(c).

\section{EXAMPLE 8.5 Sketching a Bode plot}

The Bode plot of a transfer function $G(s)$, which contains several zeros and poles, is obtained by adding the plot due to each individual pole and zero. The simplicity of this method is illustrated by considering the transfer function

$$
G(j \omega)=\frac{5(1+j 0.1 \omega)}{j \omega(1+j 0.5 \omega)\left(1+j 0.6(\omega / 50)+(j \omega / 50)^{2}\right)} .
$$

The factors, in order of their occurrence as frequency increases, are:

1. A constant gain $K=5$

2. A pole at the origin

3. A pole at $\omega=2$

4. A zero at $\omega=10$

5. A pair of complex poles at $\omega=\omega_{n}=50$.

First, we plot the magnitude characteristic for each individual pole and zero factor and the constant gain:

1. The constant gain is $20 \log 5=14 \mathrm{~dB}$, as shown in Figure 8.19.

2. The magnitude of the pole at the origin extends from zero frequency to infinite frequencies and has a slope of $-20 \mathrm{~dB} /$ decade intersecting the 0 - $\mathrm{dB}$ line at $\omega=1$, as shown in Figure 8.19.

3. The asymptotic approximation of the magnitude of the pole at $\omega=2$ has a slope of $-20 \mathrm{~dB} /$ decade beyond the break frequency at $\omega=2$. The asymptotic magnitude below the break frequency is $0 \mathrm{~dB}$, as shown in Figure 8.19.

4. The asymptotic magnitude for the zero at $\omega=+10$ has a slope of $+20 \mathrm{~dB} /$ decade beyond the break frequency at $\omega=10$, as shown in Figure 8.19.

FIGURE 8.19 Magnitude asymptotes of poles and zeros used in the example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0567.jpg?height=545&width=1267&top_left_y=1574&top_left_x=352)

5. The magnitude for the complex poles is $-40 \mathrm{~dB} /$ decade. The break frequency is $\omega=\omega_{n}=50$, as shown in Figure 8.19. This approximation must be corrected to the actual magnitude because the damping ratio is $\zeta=0.3$, and the magnitude differs appreciably from the approximation, as shown in Figure 8.20.

Therefore, the total asymptotic magnitude can be plotted by adding the asymptotes due to each factor, as shown by the solid line in Figure 8.20. Examining the asymptotic curve of Figure 8.20, we note that the curve can be obtained directly by plotting each asymptote in order as frequency increases. Thus, the slope is $-20 \mathrm{~dB} /$ decade due to $K(j \omega)^{-1}$ intersecting $14 \mathrm{~dB}$ at $\omega=1$. Then, at $\omega=2$, the slope becomes $-40 \mathrm{~dB} /$ decade due to the pole at $\omega=2$. The slope changes to $-20 \mathrm{~dB} /$ decade due to the zero at $\omega=10$. Finally, the slope becomes $-60 \mathrm{~dB} /$ decade at $\omega=50$ due to the pair of complex poles at $\omega_{n}=50$.

The exact magnitude curve is then obtained by using Figure 8.9, which provides the difference between the actual and asymptotic curves for a single pole. The single zero follows a similar pattern, but with actual curve $+3 \mathrm{~dB}$ at the break frequency. The exact magnitude curve for the pair of complex poles is obtained by utilizing Figure 8.10(a) for the quadratic factor. The exact magnitude curve for $G(j \omega)$ is shown by a dashed line in Figure 8.20.

The phase characteristic can be obtained by adding the phase due to each individual factor. Usually, the linear approximation of the phase characteristic for a single pole or zero is suitable for the initial analysis. Thus, the individual phase characteristics for the poles and zeros are shown in Figure 8.21 and are:

1. The phase of the constant gain is $0^{\circ}$.

2. The phase of the pole at the origin is a constant $-90^{\circ}$.

3. The linear approximation of the phase characteristic for the pole at $\omega=2$ is shown in Figure 8.21 , where the phase shift is $-45^{\circ}$ at $\omega=2$.

4. The linear approximation of the phase characteristic for the zero at $\omega=10$ is also shown in Figure 8.21, where the phase shift is $+45^{\circ}$ at $\omega=10$.

FIGURE 8.20 Magnitude characteristic.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0568.jpg?height=705&width=1025&top_left_y=1407&top_left_x=520)

FIGURE 8.21

Phase characteristic.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0569.jpg?height=734&width=1317&top_left_y=148&top_left_x=299)

5. The actual phase characteristic for the pair of complex poles is obtained from Figure 8.10 and is shown in Figure 8.21.

Therefore, the total phase characteristic, $\phi(\omega)$, is obtained by adding the phase due to each factor as shown in Figure 8.21. While this curve is an approximation, its usefulness merits consideration as a first attempt to determine the phase characteristic. Thus, a frequency of interest is the frequency for which $\phi(\omega)=-180^{\circ}$. The approximate curve indicates that a phase shift of $-180^{\circ}$ occurs at $\omega=46$. The actual phase shift at $\omega=46$ can be readily calculated as

$$
\phi(\omega)=-90^{\circ}-\tan ^{-1} \omega \tau_{1}+\tan ^{-1} \omega \tau_{2}-\tan ^{-1} \frac{2 \zeta u}{1-u^{2}},
$$

where

$$
\tau_{1}=0.5, \quad \tau_{2}=0.1, \quad 2 \zeta=0.6, \quad \text { and } \quad u=\omega / \omega_{n}=\omega / 50 .
$$

Then we find that

$$
\phi(46)=-90^{\circ}-\tan ^{-1} 23+\tan ^{-1} 4.6-\tan ^{-1} 3.55=-175^{\circ},
$$

and the approximate curve has an error of $5^{\circ}$ at $\omega=46$. However, once the approximate frequency of interest is ascertained from the approximate phase curve, the accurate phase shift for the neighboring frequencies is readily determined by using the exact phase shift relation (Equation 8.43). This approach is usually preferable to the calculation of the exact phase shift for all frequencies over several decades. In summary, we may obtain approximate curves for the magnitude and phase shift of a transfer function $G(j \omega)$ in order to determine the important frequency ranges. Then, within the relatively small important frequency ranges, the exact magnitude and phase shift can be readily evaluated by using the exact equations, such as Equation (8.43). FIGURE 8.22 The Bode plot of the $G(j \omega)$ of Equation (8.42).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0570.jpg?height=428&width=1174&top_left_y=153&top_left_x=523)

The Bode plot for the transfer function in Equation 8.42 is shown in Figure 8.22. The plot is generated for four decades, and the $0-\mathrm{dB}$ line is indicated, as well as the $-180^{\circ}$ line. The plot indicates that the magnitude is $34 \mathrm{~dB}$ and that the phase is $-92.36^{\circ}$ at $\omega=0.1$. Similarly, the plot indicates that the magnitude is $-43 \mathrm{~dB}$ and that the phase is $-243^{\circ}$ at $\omega=100$. Examining the plot, we find that the magnitude is $0 \mathrm{~dB}$ at $\omega=3.0$ and the phase is $-180^{\circ}$ at $\omega=50$.

\subsection{FREQUENCY RESPONSE MEASUREMENTS}

A sine wave can be used to measure the open-loop frequency response of a system. In practice, a plot of amplitude versus frequency and phase versus frequency will be obtained $[1,3,6]$. From these two plots, the loop transfer function $G_{c}(j \omega) G(j \omega)$ can be deduced. Similarly, the closed-loop frequency response of a control system, $T(j \omega)$, may be obtained and the actual transfer function deduced.

A device called a wave analyzer can be used to measure the amplitude and phase variations as the frequency of the input sine wave is altered. Also, a device called a transfer function analyzer can be used to measure the loop transfer function and closed-loop transfer functions [6].

A typical signal analyzer instrument can perform frequency response measurements from DC to $100 \mathrm{kHz}$. Built-in analysis and modeling capabilities can derive poles and zeros from measured frequency responses or construct phase and magnitude responses from user-supplied models. This device can also synthesize the frequency response of a model of a system, allowing a comparison with an actual response.

As an example of determining the transfer function from the Bode plot, consider Figure 8.23. The system is a stable circuit consisting of resistors and capacitors. Because the magnitude declines at about $-20 \mathrm{~dB} /$ decade as $\omega$ increases between 100 and 1,000, and because the phase is $-45^{\circ}$ and the magnitude is $-3 \mathrm{~dB}$ at $300 \mathrm{rad} / \mathrm{s}$, we can deduce that one factor is a pole at $p_{1}=300$. Next, we deduce that a pair of quadratic zeros exist at $\omega_{n}=2450$. This is inferred by noting that the phase changes abruptly by nearly $+180^{\circ}$, passing through $0^{\circ}$ at $\omega_{n}=2,450$. Also, the slope of the magnitude changes from $-20 \mathrm{~dB} /$ decade to $+20 \mathrm{~dB} /$ decade at $\omega_{n}=2,450$. Because the slope of the magnitude returns to $0 \mathrm{~dB} /$ decade as $\omega$ exceeds 50,000 , we determine that there is a second pole as well as two zeros. This second pole is at FIGURE 8.23

A Bode plot for a system with an unidentified transfer function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0571.jpg?height=586&width=943&top_left_y=168&top_left_x=375)

Frequency $(\mathrm{rad} / \mathrm{s})$

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0571.jpg?height=630&width=965&top_left_y=842&top_left_x=376)

(b)

$p_{2}=20,000$, because the magnitude is $-3 \mathrm{~dB}$ from the asymptote and the phase is $+45^{\circ}$ at this point $\left(-90^{\circ}\right.$ for the first pole, $+180^{\circ}$ for the pair of quadratic zeros, and $-45^{\circ}$ for the second pole). We sketch the asymptotes for the poles and the numerator of the proposed transfer function $T(s)$ of Equation (8.45), as shown in Figure 8.23(a). The equation is

$$
T(s)=\frac{\left(s / \omega_{n}\right)^{2}+\left(2 \zeta / \omega_{n}\right) s+1}{\left(s / p_{1}+1\right)\left(s / p_{2}+1\right)} .
$$

The difference in magnitude from the corner frequency $\left(\omega_{n}=2,450\right)$ of the asymptotes to the minimum response is $10 \mathrm{~dB}$, which, from Equation (8.37), indicates that $\zeta=0.16$. (Compare the plot of the quadratic zeros to the plot of the quadratic poles in Figure 8.10. Note that the plots need to be turned "upside down" for the quadratic zeros and that the phase goes from $0^{\circ}$ to $+180^{\circ}$ instead of $-180^{\circ}$.) Therefore, the transfer function is

$$
T(s)=\frac{(s / 2450)^{2}+(0.32 / 2450) s+1}{(s / 300+1)(s / 20000+1)} .
$$

This frequency response is actually obtained from a bridged-T network.

\subsection{PERFORMANCE SPECIFICATIONS IN THE FREQUENCY DOMAIN}

We must ask the question: how does the frequency response of a system relate to the expected transient response of the system? In other words, given a set of timedomain (transient performance) specifications, how do we specify the frequency response? For a simple second-order system, we have already answered this question by considering the time-domain performance in terms of overshoot, settling time, and other performance criteria, such as integral squared error. For the second-order system shown in Figure 8.24, the closed-loop transfer function is

$$
T(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}} .
$$

The frequency response of the closed-loop system is shown in Figure 8.25. Because this is a second-order system, the damping ratio of the system is related to the maximum magnitude $M_{p \omega}$, which occurs at the frequency $\omega_{r}$ as shown in Figure 8.25.

\section{At the resonant frequency $\omega_{r}$ a maximum value $M_{p \omega}$ of the frequency response is attained.}

FIGURE 8.24

A second-order closed-loop system.

FIGURE 8.25

Magnitude characteristic of the second-order system closed-loop transfer function, $T(s)$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0572.jpg?height=582&width=664&top_left_y=1534&top_left_x=486)FIGURE 8.26

Normalized bandwidth, $\omega_{B} / \omega_{n}$, versus $\zeta$ for a second-order system (Equation 8.46). The linear approximation $\omega_{B} / \omega_{n}=-1.19 \zeta+1.85$ is accurate for $0.3 \leq \zeta \leq 0.8$.
The bandwidth is the frequency $\omega_{B}$ at which the frequency response has declined $3 \mathrm{~dB}$ from its low-frequency value. This corresponds to approximately half an octave, or about $1 / \sqrt{2}$ of the low-frequency value.

The resonant frequency $\omega_{r}$ and the $-3 \mathrm{~dB}$ bandwidth can be related to the speed of the transient response. Thus, as the bandwidth $\omega_{B}$ increases, the rise time of the step response of the system will decrease. Furthermore, the overshoot to a step input can be related to $M_{p \omega}$ through the damping ratio $\zeta$. The curves of Figure 8.11 relate the resonance magnitude and frequency to the damping ratio of the second-order system. With the damping ratio, the percent overshoot to a unit step can be computed. Thus, we find as the resonant peak $M_{p \omega}$ increases in magnitude, the percent overshoot to a step input increases. In general, the magnitude $M_{p \omega}$ indicates the relative stability of a system.

The bandwidth of a system $\omega_{B}$, as indicated on the frequency response, can be approximately related to the natural frequency of the system. Figure 8.26 shows the normalized bandwidth $\omega_{B} / \omega_{n}$ versus $\zeta$ for the second-order system of Equation (8.46). The response of the second-order system to a unit step input is of the form

$$
y(t)=1+B e^{-\zeta \omega_{n} t} \cos \left(\omega_{1} t+\theta\right) .
$$

The greater the magnitude of $\omega_{n}$ when $\zeta$ is constant, the more rapidly the response approaches the desired steady-state value. Thus, desirable frequency-domain specifications are as follows:

1. Relatively small resonant magnitudes: $M_{p \omega}<1.5$, for example.

2. Relatively large bandwidths so that the system time constant $\tau=1 /\left(\zeta \omega_{n}\right)$ is sufficiently small.

The usefulness of the frequency response specifications and their relation to the actual transient performance depend upon the approximation of the system by a second-order pair of complex poles, called the dominant roots. If the frequency

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0573.jpg?height=602&width=759&top_left_y=1508&top_left_x=446)

response is dominated by a pair of complex poles, the relationships between the frequency response and the time response discussed in this section will be valid. Fortunately, a large proportion of control systems satisfy this dominant second-order approximation in practice.

The steady-state error specification can also be related to the frequency response of a closed-loop system. The steady-state error for a specific test input signal is related to the gain and number of integrations (poles at the origin) of the loop transfer function. Therefore, for the system shown in Figure 8.24, the steady-state error for a ramp input is specified in terms of $K_{v}$, the velocity constant. The steadystate error for the system is

$$
\lim _{t \rightarrow \infty} e(t)=\frac{A}{K_{v}}
$$

where $A$ is the magnitude of the ramp input. The velocity constant for the system of Figure 8.24 without feedback is

$$
K_{v}=\lim _{s \rightarrow 0} s G(s)=\lim _{s \rightarrow 0} s\left(\frac{\omega_{n}^{2}}{s\left(s+2 \zeta \omega_{n}\right)}\right)=\frac{\omega_{n}}{2 \zeta} .
$$

The transfer function can be written as

$$
G(s)=\frac{\omega_{n} /(2 \zeta)}{s\left(s /\left(2 \zeta \omega_{n}\right)+1\right)}=\frac{K_{v}}{s(\tau s+1)},
$$

and the gain constant is $K_{v}$ for this type-one system. For example, reexamining Example 8.5, we had a type-one system with a loop transfer function

$$
G(j \omega)=\frac{5\left(1+j \omega \tau_{2}\right)}{j \omega\left(1+j \omega \tau_{1}\right)\left(1+j 0.6 u-u^{2}\right)},
$$

where $u=\omega / \omega_{n}$. Therefore, in this case, we have $K_{v}=5$. In general, if the loop transfer function of a feedback system is written as

$$
G(j \omega)=\frac{K \prod_{i=1}^{M}\left(1+j \omega \tau_{i}\right)}{(j \omega)^{N} \prod_{k=1}^{Q}\left(1+j \omega \tau_{k}\right)},
$$

then the system is type $N$ and the gain $K$ is the gain constant for the steady-state error. Thus, for a type-zero system that has two poles, we have

$$
G(j \omega)=\frac{K}{\left(1+j \omega \tau_{1}\right)\left(1+j \omega \tau_{2}\right)} .
$$

In this equation, $K=K_{p}$ (the position error constant) that appears as the low-frequency gain on the Bode plot. Furthermore, the gain constant $K=K_{v}$ for the type-one system appears as the gain of the low-frequency section of the magnitude characteristic. Considering only the pole at the origin and gain of the type-one system of Equation (8.50), we have

$$
G(j \omega)=\frac{5}{j \omega}=\frac{K_{v}}{j \omega}, \quad \omega<1 / \tau_{1},
$$

and the $K_{v}$ is equal to the magnitude when this portion of the magnitude characteristic intersects the 0 -dB line. For example, the low-frequency intersection of $K_{v} / j \omega$ in Figure 8.20 is equal to $\omega=5$, as we expect.

Therefore, the frequency response characteristics represent the performance of a system quite adequately, and with some experience, they are quite useful for the analysis and design of feedback control systems.

\subsection{LOG-MAGNITUDE AND PHASE DIAGRAMS}

There are several alternative methods for presenting the frequency response of a function $G(j \omega)$. We have seen that suitable graphical presentations of the frequency response are (1) the polar plot and (2) the Bode plot. An alternative approach to portraying the frequency response graphically is to plot the logarithmic magnitude in $\mathrm{dB}$ versus the phase angle for a range of frequencies. Consider the log-magnitude-phase plot for the transfer function

$$
G_{1}(j \omega)=\frac{5}{j \omega(0.5 j \omega+1)(j \omega / 6+1)}
$$

shown in Figure 8.27. The numbers indicated along the curve are for values of frequency $\omega$.

The log-magnitude-phase curve for the transfer function

$$
G_{2}(j \omega)=\frac{5(0.1 j \omega+1)}{j \omega(0.5 j \omega+1)\left(1+j 0.6(\omega / 50)+(j \omega / 50)^{2}\right)}
$$

is shown in Figure 8.28. This curve can be obtained by utilizing the Bode plots of Figures 8.20 and 8.21 to transfer the frequency response information to the log-magnitude and phase coordinates. The shape of the locus of the frequency response on a log-magnitude-phase diagram is particularly important as the phase approaches $-180^{\circ}$ and the magnitude approaches $0 \mathrm{~dB}$. The locus of Equation (8.54) and Figure 8.27 differs substantially from the locus of Equation (8.55) and Figure 8.28. Therefore, as the correlation between the shape of the locus and the transient response of a system is established, we will obtain another useful portrayal of the frequency response of a system. We can establish a stability criterion in the frequency domain for which it will be useful to utilize the log-magnitudephase diagram to investigate the relative stability of closed-loop feedback control systems. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0576.jpg?height=1032&width=621&top_left_y=166&top_left_x=223)

FIGURE 8.27 Log-magnitude-phase curve for $G_{1}(j \omega)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0576.jpg?height=1051&width=609&top_left_y=152&top_left_x=1144)

FIGURE 8.28 Log-magnitude-phase curve for $G_{2}(j \omega)$.

\subsection{DESIGN EXAMPLES}

In this section, we present two illustrative examples using frequency response methods to design controllers. The first example describes the control of a photovoltaic generator to achieve maximum power delivery as the sunlight varies over time. The second example considers the control of one leg of a six-legged robotic device. In this example, the specifications that must be satisfied include a mix of time-domain specifications (percent overshoot and settling time) and frequency-domain specifications (bandwidth). The design process leads to a viable PID controller meeting all the specifications.

\section{EXAMPLE 8.6 Maximum power pointing tracking for photovoltaic generators}

One goal of green engineering is to design products that minimize pollution and improve the environment. Using solar energy is one way to provide clean energy using photovoltaic generators converting sunlight to electricity directly. However, the output of a photovoltaic generator is variable and depends on the available sunlight, the temperature, and the attached loads. In this example, we provide a FIGURE 8.29

Photovoltaic generator feedback control system to a track reference input voltage.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0577.jpg?height=311&width=1024&top_left_y=155&top_left_x=370)

discussion on regulating the voltage provided by a photovoltaic generator system using feedback control [24]. We will design a controller to achieve the desired specifications.

Consider the feedback control system in Figure 8.29. The plant transfer function is

$$
G(s)=\frac{K}{s(s+p)}
$$

where $K=300,000$ and $p=360$. This model is consistent with a photovoltaic generator with 182 cells generating over $1,100 \mathrm{~W}$ [24]. Assume a controller of the form

$$
G_{c}(s)=K_{c}\left[\frac{\tau_{1} s+1}{\tau_{2} s+1}\right],
$$

where $K_{c}, \tau_{1}$, and $\tau_{2}$ are to be determined. The controller in Equation (8.56) is a lead or lag compensator depending on $\tau_{1}$ and $\tau_{2}$. The controller should minimize the effects of disturbances and plant changes by providing a high gain at low frequencies while minimizing the measurement noise by providing a low gain at high frequencies [24]. To accomplish these goals, the design specifications are:

1. $\left|G_{c}(j \omega) G(j \omega)\right| \geq 20 \mathrm{~dB}$ at $\omega \leq 10 \mathrm{rad} / \mathrm{s}$

2. $\left|G_{c}(j \omega) G(j \omega)\right| \leq-20 \mathrm{~dB}$ at $\omega \geq 1,000 \mathrm{rad} / \mathrm{s}$

3. Phase margin P.M. $\geq 60^{\circ}$

The phase margin of the uncompensated system is $P . M .=36.3^{\circ}$ implying that the compensated system needs to add approximately P.M. $=25^{\circ}$, hence the use of the compensator to add the required phase lead. Also, the magnitude of the uncompensated frequency response at $\omega=1000 \mathrm{rad} / \mathrm{s}$ is $-11 \mathrm{~dB}$ indicating that the gain needs to be further reduced at high frequencies to meet the specifications.

One possible controller is

$$
G_{c}(s)=250\left[\frac{0.04 s+1}{100 s+1}\right] .
$$

The compensated phase margin is P.M. $=60.4^{\circ}$. As can be seen in Figure 8.30, the low-frequency, high-gain specification is satisfied, as well as the high-frequency, low-gain specification. The closed-loop step response is shown in Figure 8.31. The settling time is $T_{s}=0.11 \mathrm{~s}$ and the percent overshoot is $P . O .=19.4 \%$, both very acceptable for the control of the photovoltaic generator voltage. FIGURE 8.30

Bode plot of compensated system with $G_{c}(s)=$ $250\left[\frac{0.04 s+1}{100 s+1}\right]$.

FIGURE 8.31

Step response of the closed-loop system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0578.jpg?height=1492&width=944&top_left_y=154&top_left_x=486)

\section{EXAMPLE 8.7 Control of one leg of a six-legged robot}

The Ambler is a six-legged walking machine being developed at Carnegie-Mellon University [23]. An artist's conception of the Ambler is shown in Figure 8.32.

In this example we consider the control system design for position control of one leg. The elements of the design process emphasized in this example are highlighted in Figure 8.33. The mathematical model of the actuator and leg is provided. The transfer function is

$$
G(s)=\frac{1}{s\left(s^{2}+2 s+10\right)} .
$$

FIGURE 8.32

An artist's

conception of the six-legged Ambler.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0579.jpg?height=541&width=534&top_left_y=151&top_left_x=352)

Topics emphasized in this example
FIGURE 8.33

Elements of the control system design process emphasized in this six-legged robot example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0579.jpg?height=1049&width=1082&top_left_y=771&top_left_x=482)

The input is a voltage command to the actuator, and the output is the leg position (vertical position only). A block diagram of the control system is shown in Figure 8.34. The control goal is

\section{Control Goal}

Control the robot leg position and maintain the position in the presence of unwanted measurement noise. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0580.jpg?height=425&width=1402&top_left_y=159&top_left_x=353)

FIGURE 8.34 Control system for one leg.

The variable to be controlled is

\section{Variable to Be Controlled}

Leg position, $Y(s)$.

We want the leg to move to the commanded position as fast as possible but with minimal overshoot. As a practical first step, the design goal will be to produce a system that moves, albeit slowly. In other words, the control system bandwidth will initially be low.

The control design specifications are

\section{Control Design Specifications}

DS1 Closed-loop bandwidth is $\omega_{B} \geq 1 \mathrm{~Hz}$.

DS2 Percent overshoot is P.O. $\leq 15 \%$ to a step input.

DS3 Zero steady-state tracking error to a step input.

Specifications DS1 and DS2 are intended to ensure acceptable tracking performance. Design specification DS3 is actually a nonissue in our design: the actuator/ leg transfer function is a type-one system so a zero steady-state tracking error to a step input is guaranteed. We need to ensure that $G_{c}(s) G(s)$ remains at least a typeone system.

Consider the controller

$$
G_{c}(s)=\frac{K\left(s^{2}+a s+b\right)}{s+c} .
$$

As $c \rightarrow 0$, a PID controller is obtained with $K_{P}=K_{a}, K_{D}=K$, and $K_{I}=K b$. We can let $c$ be a parameter at this point and see if the additional freedom in selecting $c \neq 0$ is useful. It may be that we can simply set $c=0$ and use the PID form. The key tuning parameters are

\section{Select Key Tuning Parameters}

$K, a, b$, and $c$. The controller in Equation (8.58) is not the only controller that we can consider. For example, we might consider

$$
G_{c}(s)=K \frac{s+z}{s+p}
$$

where $K, z$, and $p$ are the key tuning parameters. The design of the type of controller given in Equation (8.59) will be left as a design problem at the end of the chapter.

The response of a closed-loop control system is determined predominantly by the location of the dominant poles. Our approach to the design is to determine appropriate locations for the dominant poles of the closed-loop system. We can determine the locations from the performance specifications by using second-order system approximation formulas. Once the controller parameters are obtained so that the closed-loop system has the desired dominant poles, the remaining poles are located so that their contribution to the overall response is negligible.

Per specification DS1, we want

$$
\omega_{B}=1 \mathrm{~Hz}=6.28 \mathrm{rad} / \mathrm{s} .
$$

From the percent overshoot specification, we can determine the minimum value of $\zeta$. Thus for P.O. $\leq 15 \%$, we require $\zeta \geq 0.52$; therefore, we will design with $\zeta=0.52$. Even though settling time is not a design specification for this problem, we usually attempt to make the system response as fast as possible while still meeting all the design specifications. From Figure 8.26 and Equation (8.60) it follows that

$$
\omega_{n}=\frac{\omega_{B}}{-1.1961 \zeta+1.8508}=5.11 \mathrm{rad} / \mathrm{s}
$$

Then with $\omega_{n}=5.11 \mathrm{rad} / \mathrm{s}$ and $\zeta=0.52$ and using Equation (8.36) we compute $\omega_{r}=3.46 \mathrm{rad} / \mathrm{s}$.

So, if we had a second-order system, we would want to determine values of the control gains such that $\omega_{n}=5.11 \mathrm{rad} / \mathrm{s}$ and $\zeta=0.52$, which yields $M_{p \omega}=1.125$ and $\omega_{r}=3.46 \mathrm{rad} / \mathrm{s}$.

Our closed-loop system is a fourth-order system and not a second-order system. So, a valid design approach would be to select $K, a, b$, and $c$ so that two poles are dominant and located appropriately to meet the design specifications. This will be the approach followed here.

Another valid approach is to develop a second-order approximation of the fourth-order system. In the approximate transfer function, the parameters $K, a, b$, and $c$ are left as variables. The objective would be to obtain an approximate transfer function $T_{L}(s)$ in such a way that the frequency response of $T_{L}(s)$ is very close to that of the original system.

The loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+a s+b\right)}{s\left(s^{2}+2 s+10\right)(s+c)},
$$

and the closed-loop transfer function is

$$
T(s)=\frac{K\left(s^{2}+a s+b\right)}{s^{4}+(2+c) s^{3}+(10+2 c+K) s^{2}+(10 c+K a) s+K b} .
$$

The associated characteristic equation is

$$
s^{4}+(2+c) s^{3}+(10+2 c+K) s^{2}+(10 c+K a) s+K b=0 .
$$

The desired characteristic polynomial must also be fourth-order, but we want it to be composed of multiple factors, as follows:

$$
P_{d}(s)=\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)\left(s^{2}+d_{1} s+d_{0}\right),
$$

where $\zeta$ and $\omega_{n}$ are selected to meet the design specifications, and the roots of $s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=0$ are the dominant roots. Conversely we want the roots of $s^{2}+d_{1} s+d_{0}=0$ to be the nondominant roots. The dominant roots should lie on a vertical line in the complex plane defined by the distance $s=-\zeta \omega_{n}$ away from the imaginary axis. Let

$$
d_{1}=2 \alpha \zeta \omega_{n} .
$$

Then the roots of $s^{2}+d_{1} s+d_{0}=0$, when complex or equal, lie on a vertical line in the complex plane defined by $s=-\alpha \zeta \omega_{n}$. By choosing $\alpha>1$, we effectively move the roots to the left of the dominant roots. The larger we select $\alpha$, the further the nondominant roots lie to the left of the dominant roots. A reasonable value of $\alpha$ is $\alpha=12$. Also, if we select

$$
d_{0}=\alpha^{2} \zeta^{2} \omega_{n}^{2}
$$

then we obtain two real roots

$$
s^{2}+d_{1} s+d_{0}=\left(s+\alpha \zeta \omega_{n}\right)^{2}=0 .
$$

Choosing $d_{0}=\alpha^{2} \zeta^{2} \omega_{n}^{2}$ is not required, but this seems to be a reasonable choice since we would like the contribution of the nondominant roots to the overall response to be quickly fading and nonoscillatory.

The desired characteristic polynomial is then

$$
\begin{gathered}
s^{4}+2 \zeta \omega_{n}(1+\alpha) s^{3}+\omega_{n}^{2}\left(1+\alpha \zeta^{2}(\alpha+4)\right) s^{2} \\
+2 \alpha \zeta \omega_{n}^{3}\left(1+\zeta^{2} \alpha\right) s+\alpha^{2} \zeta^{2} \omega_{n}^{4}=0 .
\end{gathered}
$$

Equating the coefficients of Equations (8.63) and (8.64) yields four relationships involving $K, a, b, c$, and $\alpha$ :

$$
\begin{aligned}
2 \zeta \omega_{n}(1+\alpha) & =2+c, \\
\omega_{n}^{2}\left(1+\alpha \zeta^{2}(4+\alpha)\right) & =10+2 c+K, \\
2 \alpha \zeta \omega_{n}^{3}\left(1+\zeta^{2} \alpha\right) & =10 c+K a, \\
\alpha^{2} \zeta^{2} \omega_{n}^{4} & =K b .
\end{aligned}
$$

FIGURE 8.35

Step response using the controller in Equation (8.65).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0583.jpg?height=746&width=981&top_left_y=154&top_left_x=370)

In our case $\zeta=0.52, \omega_{n}=5.11$, and $\alpha=12$. Thus we obtain

$$
\begin{aligned}
c & =67.13 \\
K & =1239.2 \\
a & =5.17 \\
b & =21.48
\end{aligned}
$$

and the resulting controller is

$$
G_{c}(s)=1239 \frac{s^{2}+5.17 s+21.48}{s+67.13} .
$$

The step response of the closed-loop system using the controller in Equation (8.65) is shown in Figure 8.35. The percent overshoot is P.O. $=14 \%$, and the settling time is $T_{s}=0.96 \mathrm{~s}$.

The magnitude plot of the closed-loop system is shown in Figure 8.36. The bandwidth is $\omega_{B}=27.2 \mathrm{rad} / \mathrm{s}=4.33 \mathrm{~Hz}$. This satisfies DS1 but is larger than the $\omega_{B}=1 \mathrm{~Hz}$ used in the design (due to the fact that our system is not a second-order system). The higher bandwidth leads us to expect a faster settling time. The peak magnitude is $M_{p \omega}=1.21$. We were expecting $M_{p \omega}=1.125$.

What is the steady-state response of the closed-loop system if the input is a sinusoidal input? From our previous discussions we expect that as the input frequency increases, the magnitude of the output will decrease. Two cases are presented here. In Figure 8.37 the input frequency is $\omega=1 \mathrm{rad} / \mathrm{s}$. The output magnitude is approximately equal to 1 in the steady state. In Figure 8.38 the input frequency is $\omega=500 \mathrm{rad} / \mathrm{s}$. The output magnitude is less than 0.005 in the steady state. FIGURE 8.36

Magnitude plot of the closedloop system with the controller in Equation (8.65).
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0584.jpg?height=1592&width=1000&top_left_y=150&top_left_x=506)

Time (s)
FIGURE 8.37

Output response of the closed-loop system when the input is a sinusoidal signal of frequency $\omega=1 \mathrm{rad} / \mathrm{s}$.

This verifies our intuition that the system response decreases as the input sinusoidal frequency increases.

Using simple analytic methods, we obtained an initial set of controller parameters for the mobile robot. The controller thus designed proved to satisfy the design requirements. Some fine-tuning would be necessary to meet the design specifications exactly. FIGURE 8.38

Output response of the closed-loop system when the input is a sinusoidal signal of frequency $\omega=500 \mathrm{rad} / \mathrm{s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0585.jpg?height=746&width=985&top_left_y=154&top_left_x=373)

\subsection{FREQUENCY RESPONSE METHODS USING CONTROL DESIGN SOFTWARE}

In this section, we cover the functions bode and logspace. The bode function is used to generate a Bode plot, and the logspace function generates a logarithmically spaced vector of frequencies utilized by the bode function.

Consider the transfer function

$$
G(s)=\frac{5(1+0.1 s)}{s(1+0.5 s)\left(1+(0.6 / 50) s+\left(1 / 50^{2}\right) s^{2}\right)} .
$$

The Bode plot corresponding to Equation (8.66) is shown in Figure 8.39. The plot consists of the logarithmic gain in $\mathrm{dB}$ versus $\omega$ in one plot and the phase $\phi(\omega)$ in degrees versus $\omega$ in $\mathrm{rad} / \mathrm{s}$ in a second plot. As with the root locus plots, it will be tempting to rely exclusively on control design software to obtain the Bode plots. The software should be treated as one tool in a tool kit that can be used to design and analyze control systems. It is essential to develop the capability to obtain approximate Bode plots manually. There is no substitute for a clear understanding of the underlying theory.

A Bode plot is obtained with the bode function shown in Figure 8.40. The Bode plot is automatically generated if the bode function is invoked without lefthand arguments. Otherwise, the magnitude and phase characteristics are placed in the workspace through the variables mag and phase. A Bode plot can then be obtained with the plot or semilogx function using mag, phase, and $\omega$. The vector $\omega$ contains the values of the frequency in $\mathrm{rad} / \mathrm{s}$ at which the Bode plot will be calculated. If $\omega$ is not specified, the bode function will automatically choose the frequency values by placing more points in regions where the frequency response is changing quickly. If the frequencies are specified explicitly, it is desirable to generate the vector $\omega$ using the logspace function. The logspace function is shown in Figure 8.41. FIGURE 8.39

The Bode plot associated with Equation (8.66).
FIGURE 8.40

The bode function, given $G(s)$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0586.jpg?height=1700&width=996&top_left_y=166&top_left_x=507)

The Bode plot in Figure 8.39 is generated using the script shown in Figure 8.42. The bode function automatically selected the frequency range. This range is user selectable using the logspace function. The bode function can be used with a state variable model, as shown in Figure 8.43. The use of the bode function is exactly the same as with transfer functions, except that the input is a state-space object instead of a transfer function object. FIGURE 8.41 The logspace function.

FIGURE 8.42 The script for the Bode plot in Figure 8.39.

FIGURE 8.43

The bode function with a state variable model.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0587.jpg?height=1190&width=1002&top_left_y=163&top_left_x=376)

$\%$ Bode plot script for Figure 8.39

$\%$

num $=5^{*}[0.11]$

$f 1=[10] ; f 2=[0.51] ; f 3=[1 / 2500.6 / 50$ 1];

den $=\operatorname{conv}(\mathrm{f} 1, \operatorname{conv}(\mathrm{f} 2, \mathrm{f} 3))$;

$\%$

sys=tf(num,den);

bode(sys)

$$
s(1+0.5 s)\left(1+\frac{0.6}{50} s+\frac{1}{50^{2}} s^{2}\right)
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0587.jpg?height=341&width=567&top_left_y=1768&top_left_x=389)

FIGURE 8.44

(a) The relationship between $\left(M_{p \omega}, \omega_{r}\right)$ and $\left(\zeta, \omega_{n}\right)$ for a second-order system. (b) m-file script.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0588.jpg?height=250&width=790&top_left_y=164&top_left_x=618)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0588.jpg?height=295&width=930&top_left_y=535&top_left_x=538)

Keep in mind that our goal is to design control systems that satisfy certain performance specifications given in the time domain. Thus, we must establish a connection between the frequency response and the transient time response of a system. The relationship between specifications given in the time domain to those given in the frequency domain depends upon approximation of the system by a second-order system with the poles being the system dominant roots.

Consider the second-order system shown in Figure 8.24. The Bode plot magnitude characteristic associated with the closed-loop transfer function in Equation (8.46) is shown in Figure 8.25. The relationship between the resonant frequency, $\omega_{r}$, the maximum of the frequency response, $M_{p \omega}$, and the damping ratio, $\zeta$, and the natural frequency, $\omega_{n}$, is shown in Figure 8.44 (and in Figure 8.11). The information in Figure 8.44 will be quite helpful in designing control systems in the frequency domain while satisfying time-domain specifications.

\section{EXAMPLE 8.8 Engraving machine system}

Engraving machines employ two drive motors and associated lead screws to position the engraving scribe in the desired direction [7]. The block diagram model for the position control system is shown in Figure 8.45. Our objective is to select $K$ so that the closed-loop system has an acceptable time response to a step command. A functional block diagram describing the frequency-domain design process is shown in Figure 8.46. First, we choose $K=2$ and then iterate $K$ if the performance is unacceptable. The script shown in Figure 8.47 is used in the design. The value of $K$ is defined at the command level. Then the script is executed and the closed-loop Bode plot is generated. The values of $M_{p \omega}$ and $\omega_{r}$ are determined by inspection from the Bode plot. Those values are used in conjunction with Figure 8.44 to determine the corresponding values of $\zeta$ and $\omega_{n}$. FIGURE 8.45

Engraving machine block diagram model.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0589.jpg?height=1444&width=1074&top_left_y=154&top_left_x=370)

Establish relationship between frequency domain specs and time domain specs.

$$
M_{p \omega}=\left(2 \zeta \sqrt{1-\zeta^{2}}\right)^{-1}, \zeta<0.707
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0589.jpg?height=318&width=456&top_left_y=1732&top_left_x=445)

Determine $\omega_{n}$ and $\zeta$.$$
\omega_{r} / \omega_{n}=\sqrt{1-2 \zeta^{2}}, \zeta<0.707
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0589.jpg?height=376&width=489&top_left_y=1675&top_left_x=922)

FIGURE 8.46

Frequency design functional block diagram for the engraving machine. FIGURE 8.47

Script for the design of an engraving machine. engrave.m

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0590.jpg?height=54&width=299&top_left_y=222&top_left_x=697)
sys=tf(num, den); $\mathrm{w}=$ logspace $(-1,1,400)$; [mag,phase,w]=bode(sys,w); $[\mathrm{mp}, \mathrm{l}]=\max (\mathrm{mag}) ; \mathrm{wr}=\mathrm{w}(\mathrm{l})$;

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0590.jpg?height=66&width=537&top_left_y=221&top_left_x=1011)

Closed-loop transfer function. Closed-loop Bode plot. zeta $=\operatorname{sqrt}\left(0.5^{\star}\left(1-\operatorname{sqrt}\left(1-1 / \mathrm{mp}^{\wedge} 2\right)\right)\right)$; $w n=w r / s q r t\left(1-2^{\star} z^{2} a^{\wedge} 2\right)$;

Solving Equations (8.36) ts $=4 /$ zeta/wn po $=100^{*} \exp \left(-\right.$ zeta $^{*}$ pi/sqrt $\left(1-\right.$ zeta^$\left.\left.^{\wedge} 2\right)\right)$

$>\mathrm{K}=2$; engrave

ts $=$

15.7962

$\mathrm{po}=$

39.4570

Check specifications and iterate, if necessary.

Given the damping ratio, $\zeta$, and the natural frequency, $\omega_{n}$, the settling time and percent overshoot can be estimated. If the time-domain specifications are not satisfied, then we adjust $K$ and iterate.

The values for $\zeta$ and $\omega_{n}$ corresponding to $K=2$ are $\zeta=0.29$ and $\omega_{n}=0.88$. This leads to a prediction of P.O. $=37 \%$ and $T_{s}=15.7 \mathrm{~s}$. The step response, shown in Figure 8.48, is a verification that the performance predictions are quite accurate and that the closed-loop system performs adequately.

In this example, the second-order system approximation is reasonable and leads to an acceptable design. However, the second-order approximation may not always lead directly to a good design. Fortunately, the control design software allows us to construct an interactive design facility to assist in the design process by reducing the manual computational loads while providing easy access to a host of classical and modern control tools.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

The disk drive uses a flexure suspension to hold the reader head mount. This flexure may be modeled by a spring and mass. In this chapter, we will include the effect of the flexure within the model of the motor-load system [22].

We model the flexure with the mounted head as a mass $M$, a spring $k$, and a sliding friction $b$, as shown in Figure 8.49. Here, we assume that the force $u(t)$ is exerted on the flexure by the arm. The transfer function of a spring-massdamper is

$$
\frac{Y(s)}{U(s)}=G_{3}(s)=\frac{\omega_{n}^{2}}{s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}}=\frac{1}{1+\left(2 \zeta s / \omega_{n}\right)+\left(s / \omega_{n}\right)^{2}} .
$$

FIGURE 8.48

(a) Engraving machine step response for $K=2$. (b) m-file script.
FIGURE 8.49

Spring, mass, friction model of flexure and head.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0591.jpg?height=637&width=859&top_left_y=152&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0591.jpg?height=38&width=574&top_left_y=950&top_left_x=557)
$\mathrm{t}=[0: 0.01: 20] ;$

$\mathrm{y}=\operatorname{step}(\mathrm{sys}, \mathrm{t}) ; \operatorname{plot}(\mathrm{t}, \mathrm{y}) ;$ grid

xlabel('Time (s)'), ylabel('y(t)')

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0591.jpg?height=254&width=590&top_left_y=1287&top_left_x=373)

A typical flexure and head has $\zeta=0.3$ and a natural resonance at $f_{n}=3000 \mathrm{~Hz}$. Therefore, $\omega_{n}=18.85 \times 10^{3}$ as shown in the model of the system (see Figure 8.50).

First, we sketch the magnitude characteristics for the open-loop Bode diagram. The Bode plot of the loop transfer function with $K=400$ is shown in Figure 8.51. Note that the actual plot has a $10-\mathrm{dB}$ gain (over the asymptotic plot) at the resonance $\omega=\omega_{n}$, as shown in the sketch. Note the resonance at $\omega_{n}$. Clearly, we wish to avoid exciting this resonance.

Plots of the magnitude of the loop transfer function and the closed-loop transfer function are shown in Figure 8.52. The bandwidth of the closed-loop system 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0592.jpg?height=240&width=1564&top_left_y=155&top_left_x=220)

FIGURE 8.50 Disk drive head position control, including effect of flexure head mount.

FIGURE 8.51

Sketch of the Bode diagram magnitude for the system of Figure 8.50.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0592.jpg?height=680&width=1138&top_left_y=580&top_left_x=520)

Frequency (rad/s)

is $\omega_{B}=2000 \mathrm{rad} / \mathrm{s}$. We can estimate the settling time (with a $2 \%$ criterion) of this system where $\zeta \simeq 0.8$ and $\omega_{n} \simeq \omega_{B}=2000 \mathrm{rad} / \mathrm{s}$. Therefore, we expect $T_{s}=2.5 \mathrm{~ms}$ for the system of Figure 8.50. As long as $K \leq 400$, the resonance is outside the bandwidth of the system.

\subsection{SUMMARY}

In this chapter, we considered the representation of a feedback control system by its frequency response characteristics. The frequency response of a system was defined as the steady-state response of the system to a sinusoidal input signal. Several alternative forms of frequency response plots were considered. They included the polar plot of the frequency response and logarithmic plots, often called Bode plots. The value of the logarithmic measure was also illustrated. The ease of obtaining a Bode 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0593.jpg?height=576&width=809&top_left_y=159&top_left_x=412)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0593.jpg?height=571&width=809&top_left_y=839&top_left_x=412)

Frequency $(\mathrm{rad} / \mathrm{s})$

(b)

FIGURE 8.52 The magnitude Bode plot for (a) the loop transfer function and (b) the closed-loop system.

plot for the various factors of $G(j \omega)$ was noted. The asymptotic approximation for sketching the Bode plot simplifies the computation considerably. A summary of fifteen typical Bode plots is shown in Table 8.2. Several performance specifications in the frequency domain were discussed; among them were the maximum magnitude $M_{p \omega}$ and the resonant frequency $\omega_{r}$. The relationship between the Bode plot and the system error constants $\left(K_{p}\right.$ and $\left.K_{v}\right)$ was noted. Finally, the log-magnitude versus phase diagram was considered for graphically representing the frequency response of a system. Section 8.9 Summary

593

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0594.jpg?height=1957&width=1538&top_left_y=155&top_left_x=226)

594 Chapter 8 Frequency Response Methods

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0595.jpg?height=1964&width=1534&top_left_y=156&top_left_x=87)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0596.jpg?height=2018&width=1216&top_left_y=113&top_left_x=220)



\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 8.53 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0597.jpg?height=259&width=868&top_left_y=414&top_left_x=488)

FIGURE 8.53 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. The frequency response represents the steady-state response of a stable system to a sinusoidal input signal at various frequencies.

True or False

2. A plot of the real part of $G(j \omega)$ versus the imaginary part of $G(j \omega)$ is called a Bode plot.

True or False

3. A transfer function is termed minimum phase if all its zeros lie in the right-hand s-plane.

True or False

4. The resonant frequency and bandwidth can be related to the speed of the transient response.

True or False

5. One advantage of frequency response methods is the ready availability of sinusoidal test signals for various ranges of frequencies and amplitudes. True or False

6. Consider the stable system represented by the differential equation

$$
\dot{x}(t)+3 x(t)=u(t) .
$$

Determine the phase of this system at the frequency $\omega=3 \mathrm{rad} / \mathrm{s}$.
a. $\phi=0^{\circ}$
b. $\phi=-45^{\circ}$
c. $\phi=-60^{\circ}$
d. $\phi=-180^{\circ}$

In Problems 7 and 8, consider the feedback system in Figure 8.53 with the loop transfer function

$$
L(s)=G(s) G_{c}(s)=\frac{8(s+1)}{s(2+s)(2+3 s)} .
$$

7. The Bode plot of this system corresponds to which plot in Figure 8.54?

8. Determine the frequency at which the gain has unit magnitude and compute the phase angle at that frequency:
a. $\omega=1 \mathrm{rad} / \mathrm{s}, \phi=-82^{\circ}$
b. $\omega=1.26 \mathrm{rad} / \mathrm{s}, \phi=-133^{\circ}$
c. $\omega=1.26 \mathrm{rad} / \mathrm{s}, \phi=133^{\circ}$
d. $\omega=4.2 \mathrm{rad} / \mathrm{s}, \phi=-160^{\circ}$ 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0598.jpg?height=196&width=1468&top_left_y=172&top_left_x=246)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0598.jpg?height=226&width=708&top_left_y=395&top_left_x=253)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0598.jpg?height=448&width=710&top_left_y=695&top_left_x=254)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0598.jpg?height=228&width=715&top_left_y=394&top_left_x=1014)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0598.jpg?height=448&width=716&top_left_y=699&top_left_x=1015)

(d)

FIGURE 8.54 Bode plot selections.

In Problems 9 and 10, consider the feedback system in Figure 8.53 with the loop transfer function

$$
L(s)=G(s) G_{c}(s)=\frac{50}{s^{2}+12 s+20} .
$$

9. The break frequency on the Bode plot is
a. $\omega=1 \mathrm{rad} / \mathrm{s}$
b. $\omega=4.47 \mathrm{rad} / \mathrm{s}$
c. $\omega=8.94 \mathrm{rad} / \mathrm{s}$
d. $\omega=10 \mathrm{rad} / \mathrm{s}$

10. The slope of the asymptotic plot at very low $(\omega \ll 1)$ and high $(\omega \gg 10)$ frequencies are, respectively:

a. At low frequency: slope $=20 \mathrm{~dB} /$ decade and at high frequency: slope $=20 \mathrm{~dB} /$ decade

b. At low frequency: slope $=0 \mathrm{~dB} /$ decade and at high frequency: slope $=-20 \mathrm{~dB} /$ decade

c. At low frequency: slope $=0 \mathrm{~dB} /$ decade and at high frequency: slope $=-40 \mathrm{~dB} /$ decade

d. At low frequency: slope $=-20 \mathrm{~dB} /$ decade and at high frequency: slope $=-20 \mathrm{~dB} /$ decade 11. Consider the Bode plot in Figure 8.55.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0599.jpg?height=830&width=1404&top_left_y=248&top_left_x=145)

FIGURE 8.55 Bode plot for unknown system.

Which loop transfer function $L(s)=G_{c}(s) G(s)$ corresponds to the Bode plot in Figure 8.55?
a. $L(s)=G_{c}(s) G(s)=\frac{100}{s(s+5)(s+6)}$
b. $L(s)=G_{c}(s) G(s)=\frac{24}{s(s+2)(s+6)}$
c. $L(s)=G_{c}(s) G(s)=\frac{24}{s^{2}(s+6)}$
d. $L(s)=G_{c}(s) G(s)=\frac{10}{s^{2}+0.5 s+10}$

12. Suppose that one design specification for a feedback control system requires that the percent overshoot to a step input be $P . O . \leq 10 \%$. The corresponding specification in the frequency domain is
a. $M_{p \omega} \leq 0.55$
b. $M_{p \omega} \leq 0.59$
c. $M_{p \omega} \leq 1.05$
d. $M_{p \omega} \leq 1.27$

13. Consider the feedback control system in Figure 8.53 with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{100}{s(s+11.8)} .
$$

The resonant frequency, $\omega_{r}$, and the bandwidth, $\omega_{b}$, are:
a. $\omega_{r}=1.59 \mathrm{rad} / \mathrm{s}, \omega_{b}=1.86 \mathrm{rad} / \mathrm{s}$
b. $\omega_{r}=3.26 \mathrm{rad} / \mathrm{s}, \omega_{b}=16.64 \mathrm{rad} / \mathrm{s}$
c. $\omega_{r}=12.52 \mathrm{rad} / \mathrm{s}, \omega_{b}=3.25 \mathrm{rad} / \mathrm{s}$
d. $\omega_{r}=5.51 \mathrm{rad} / \mathrm{s}, \omega_{b}=11.6 \mathrm{rad} / \mathrm{s}$

For Problems 14 and 15, consider the frequency response of a process $G(j \omega)$ depicted in Figure 8.56.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0600.jpg?height=818&width=1372&top_left_y=528&top_left_x=358)

FIGURE 8.56 Bode plot for $G(j \omega)$.

14. Determine the system type (that is, the number of integrators, $N$ ):
a. $N=0$
b. $N=1$
c. $N=2$
d. $N>2$

15. The transfer function corresponding to the Bode plot in Figure 8.56 is:
a. $G(s)=\frac{100(s+10)(s+5000)}{s(s+5)(s+6)}$
b. $G(s)=\frac{100}{(s+1)(s+20)}$
c. $G(s)=\frac{100}{(s+1)(s+50)(s+200)}$
d. $G(s)=\frac{100(s+20)(s+5000)}{(s+1)(s+50)(s+200)}$ In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Laplace transform pair

b. Decibel (dB)

c. Fourier transform

d. Bode plot

e. Transfer function in the frequency domain

f. Decade

g. Dominant roots

h. All-pass network

i. Logarithmic magnitude

j. Natural frequency

k. Fourier transform pair

l. Minimum phase

m. Bandwidth

n. Frequency response

o. Resonant frequency

p. Break frequency

q. Polar plot

r. Maximum value of the frequency response

s. Nonminimum phase
The logarithm of the magnitude of the transfer function and the phase are plotted versus the logarithm of $\omega$, the frequency.

The logarithm of the magnitude of the transfer function, $20 \log _{10}|G(j \omega)|$.

A plot of the real part of $G(j \omega)$ versus the imaginary part of $G(j \omega)$.

The steady-state response of a system to a sinusoidal input signal.

All the zeros of a transfer function lie in the left-hand side of the $s$-plane.

The frequency at which the frequency response has declined $3 \mathrm{~dB}$ from its low-frequency value.

The frequency at which the maximum value of the frequency response of a complex pair of poles is attained.

The frequency of natural oscillation that would occur for two complex poles if the damping were equal to zero.

Transfer functions with zeros in the right-hand $s$-plane.

The frequency at which the asymptotic approximation of the frequency response for a pole (or zero) changes slope.

The transformation of a function of time into the frequency domain.

The ratio of the output to the input signal where the input is a sinusoid.

The units of the logarithmic gain.

A pair of complex poles will result in a maximum value for the frequency response occurring at the resonant frequency.

A nonminimum phase system that passes all frequencies with equal gain.

A factor of ten in frequency.

The roots of the characteristic equation that represent or dominate the closed-loop transient response.

A pair of functions, one in the time domain, and the other in the frequency domain, and both related by the Fourier transform.

A pair of functions, one in the time domain, and the other in the frequency domain, and both related by the Laplace transform. 

\section{EXERCISES}

E8.1 Increased track densities for computer disk drives necessitate careful design of the head positioning control [1]. The loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+1)^{2}} .
$$

Plot the frequency response for this system when $K=10$. Calculate the phase and magnitude at $\omega=0,0.5,1,2,4$, and $\infty$.

Answer: $|L(j 0.5)|=8$ and $/ L(j 0.5)=-53.13^{\circ}$

E8.2 A tendon-operated robotic hand can be implemented using a pneumatic actuator [8]. The actuator can be represented by

$$
G(s)=\frac{5000}{(s+70)(s+500)} .
$$

Plot the frequency response of $G(j \omega)$. Show that the magnitude of $G(j \omega)$ is $-17 \mathrm{~dB}$ at $\omega=10$ and $-27.1 \mathrm{~dB}$ at $\omega=200$. Show also that the phase is $-138.7^{\circ}$ at $\omega=700$.

E8.3 A robotic arm has a joint-control loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{100(s+0.1)}{s(s+1)(s+10)} .
$$

Show that the frequency equals $\omega=11.7 \mathrm{rad} / \mathrm{s}$ when the phase angle of $L(j \omega)$ is $-135^{\circ}$. Find the magnitude of $L(j \omega)$ at $\omega=11.7 \mathrm{rad} / \mathrm{s}$.

Answer: $|L(j 11.7)|=-5.1 \mathrm{~dB}$

E8.4 The frequency response for the system

$$
G(s)=\frac{K s}{(s+a)\left(s^{2}+5 s+6.25\right)}
$$

is shown in Figure E8.4. Estimate $K$ and $a$ by examining the frequency response curves.

E8.5 The magnitude plot of a transfer function

$$
G(s)=\frac{K^{\prime}(1+0.125 s)(1+a s)(1+b s)}{s(s+c)(1+s / 16)}
$$

is shown in Figure E8.5. Estimate $K^{\prime}, a, b$, and $c$ from the plot.

Answer: $K=6, a=1 / 3, b=1 / 12, c=1 / 6$

E8.6 Several studies have proposed an extravehicular robot that could move around in a NASA space station and perform physical tasks at various worksites [9]. The arm is controlled by a unity feedback control with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s / 8+1)(s / 100+1)} .
$$

Sketch the Bode plot for $K=30$, and determine the frequency when $20 \log |L(j \omega)|$ is $0 \mathrm{~dB}$.

E8.7 Consider a system with a closed-loop transfer function

$$
G(s)=\frac{100}{\left(s^{2}+2 s+16\right)\left(s^{2}+s+64\right)} .
$$

This system will have a steady-state error for a step input. (a) Plot the frequency response, noting the two peaks in the magnitude response. (b) Predict the time response to a step input, noting that the system has four poles and cannot be represented as a dominant second-order system. (c) Plot the step response.

E8.8 Two feedback systems with their respective loop transfer function are represented as:

(i) $T(s)=\frac{100(s-1)}{\left(s^{2}+25 s+100\right)}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0602.jpg?height=290&width=965&top_left_y=1558&top_left_x=470)

FIGURE E8.4

Bode plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0602.jpg?height=310&width=964&top_left_y=1849&top_left_x=485)

FIGURE E8.5

Bode plot.

FIGURE E8.9

Bode plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0603.jpg?height=520&width=1099&top_left_y=152&top_left_x=370)

Frequency $(\mathrm{rad} / \mathrm{s})$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0603.jpg?height=475&width=755&top_left_y=809&top_left_x=356)

(ii) $T_{1}(s)=\frac{100(s+1)}{\left(s^{2}+25 s+100\right)}$

For each transfer function, (a) determine the break frequencies for the Bode plot. (b) Determine the slope of the asymptotic plot at very low frequencies and at high frequencies. (c) Sketch the Bode magnitude plot and compare them.

E8.9 The Bode plot of a system is shown in Figure E8.9. Estimate the transfer function $G(s)$.

E8.10 The dynamic analyzer shown in Figure E8.10(a) can be used to display the frequency response of a system. Figure E8.10(b) shows the actual frequency response of a system. Estimate the poles and zeros of the device. Note $X=1.37 \mathrm{kHz}$ at the first cursor, and $\Delta X=1.257 \mathrm{kHz}$ to the second cursor.

E8.11 Consider the feedback control system in Figure E8.11. Sketch the Bode plot of $G(s)$, and determine the crossover frequency, that is, the frequency when $20 \log _{10}|G(j \omega)|=0 \mathrm{~dB}$.
E8.12 Consider the system represented in state variable form

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
3 & 1 \\
-1 & 2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
2
\end{array}\right] u(t) \\
y(t)=\left[\begin{array}{ll}
1 & -2
\end{array}\right] \mathbf{x}(t)
\end{gathered}
$$

(a) Determine the transfer function representation of the system. (b) Sketch the Bode plot.

E8.13 Determine the bandwidth of the feedback control system in Figure E8.13.

E8.14 Consider the nonunity feedback system in Figure E8.14, where the controller gain is $K=2$. Sketch the Bode plot of the loop transfer function. Determine the phase of the loop transfer function when the magnitude $20 \log |L(j \omega)|=0 \mathrm{~dB}$. Recall that the loop transfer function is $L(s)=G_{c}(s) G(s) H(s)$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0604.jpg?height=616&width=814&top_left_y=155&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0604.jpg?height=546&width=805&top_left_y=903&top_left_x=517)

(b)

FIGURE E8.10 (a) Photo showing a typical signal analyzer. (b) Frequency response. (Courtesy of the Syafiq Adnan/Shutterstock.)

FIGURE E8.11

Unity feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0604.jpg?height=233&width=880&top_left_y=1784&top_left_x=517)

FIGURE E8.13

Third-order

feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0605.jpg?height=238&width=909&top_left_y=154&top_left_x=371)

FIGURE E8.14

Nonunity feedback system with controller gain $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0605.jpg?height=359&width=929&top_left_y=559&top_left_x=373)

E8.15 Consider the single-input, single-output system described by

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t)
\end{gathered}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-5 & -K-1
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}
2 & 4
\end{array}\right] .
$$

Compute the bandwidth of the system for $K=1,2$, and 10 . As $K$ increases, does the bandwidth increase or decrease?

\section{PROBLEMS}

P8.1 Sketch the polar plot for the following loop transfer functions:
(a) $L(s)=G_{c}(s) G(s)=\frac{1}{(1+0.5 s)(1+2 s)}$
(b) $L(s)=G_{c}(s) G(s)=\frac{3\left(s^{2}+1.5 s+1\right)}{(s-2)^{2}}$
(c) $L(s)=G_{c}(s) G(s)=\frac{s-6}{s^{2}+5 s+6}$
(d) $L(s)=G_{c}(s) G(s)=\frac{10(s+6)}{s(s+1)(s+3)}$

P8.2 Sketch the Bode plot representation of the frequency response for the transfer functions given in Problem P8.1.

P8.3 A rejection network is the bridged-T network shown in Figure P8.3. The transfer function of this network is

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0605.jpg?height=315&width=722&top_left_y=1468&top_left_x=881)

FIGURE P8.3 Bridged-T network.

$$
G(s)=\frac{s^{2}+\omega_{n}^{2}}{s^{2}+2\left(\omega_{n} / Q\right) s+\omega_{n}^{2}}
$$

where $\omega_{n}^{2}=2 / L C, Q=\omega_{n} L / R_{1}$, and $R_{2}$ is adjusted so that $R_{2}=\left(\omega_{n} L\right)^{2} / 4 R_{1}$ [3]. (a) Determine the poles and zeros. (b) Sketch the Bode plot. FIGURE P8.4

(a) Pressure controller. (b) Block diagram model.

P8.4 A control system for controlling the pressure in a closed chamber is shown in Figure P8.4. Sketch the Bode plot of the loop transfer function.

P8.5 The global robot industry is growing rapidly [8]. A typical industrial robot has multiple degrees of freedom. A unity feedback position control system for a force-sensing joint has a loop transfer function.

$G_{c}(s) G(s)=\frac{K}{(1+s / 4)(1+s / 8)(1+s / 16)(1+s / 32)}$,

where $K=20$. Sketch the Bode plot of this system.

P8.6 The asymptotic log-magnitude curves for two loop transfer functions are given in Figure P8.6. Sketch the corresponding asymptotic phase shift curves for each system. Estimate the transfer function for each system. Assume that the systems have minimum phase transfer functions.

P8.7 Driverless vehicles can be used in warehouses, airports, and many other applications. These vehicles follow a wire embedded in the floor and adjust the steerable front wheels in order to maintain proper direction, as shown in Figure P8.7(a) [10]. The sensing coils, mounted on the front wheel assembly, detect an error in the direction of travel and adjust the steering. The overall control system is shown in Figure P8.7(b). The loop transfer function is

$$
L(s)=\frac{K}{s(s+\pi)^{2}}=\frac{K_{v}}{s(s / \pi+1)^{2}} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0606.jpg?height=341&width=694&top_left_y=1034&top_left_x=998)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0606.jpg?height=348&width=757&top_left_y=1428&top_left_x=995)

(b)

FIGURE P8.6 Log-magnitude curves.

(a) Set $K_{v}=\pi$ and sketch the Bode plot. (b) Using the Bode plot, determine the phase at the crossover frequency. FIGURE P8.7

Steerable wheel control.

FIGURE P8.8

Second-order unity feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0607.jpg?height=298&width=548&top_left_y=152&top_left_x=728)

Energized guidepath wire

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0607.jpg?height=251&width=1249&top_left_y=580&top_left_x=373)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0607.jpg?height=233&width=851&top_left_y=923&top_left_x=372)

P8.8 A feedback control system is shown in Figure P8.8. The specification for the closed-loop system requires that the percent overshoot to a step input be P.O. $\leq 10 \%$. (a) Determine the corresponding specification $M_{p \omega}$ in the frequency domain for the closed-loop transfer function. (b) Determine the resonant frequency $\omega_{r}$. (c) Determine the bandwidth of the closed-loop system $\omega_{n}$.

P8.9 Sketch the logarithmic-magnitude versus phase angle curve for the transfer functions (a) and (b) of Problem P8.1.
FIGURE P8.10

Linear actuator control.
P8.10 A linear actuator is used in the system shown in Figure P8.10 to position a mass $M$. The actual position of the mass is measured by a slide wire resistor, and thus $H(s)=1.0$. The amplifier gain is selected so that the steady-state error of the system is less than $1 \%$ of the magnitude of the position reference $R(s)$. The actuator has a field coil with a resistance $R_{f}=0.1 \Omega$ and $L_{f}=0.2 \mathrm{H}$. The mass of the load is $M=0.1 \mathrm{~kg}$, and the friction is $b=0.2 \mathrm{~N} \mathrm{~s} / \mathrm{m}$. The

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0607.jpg?height=418&width=1423&top_left_y=1708&top_left_x=69)

FIGURE P8.11

Frequency response of ship control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0608.jpg?height=637&width=1023&top_left_y=152&top_left_x=523)

spring constant is $k=0.4 \mathrm{~N} / \mathrm{m}$. (a) Determine the gain $K$ necessary to maintain a steady-state error for a step input less than 1\%. (b) Sketch the Bode plot of the loop transfer function. (c) Sketch the Bode plot for the closed-loop transfer function. Determine $M_{p \omega}, \omega_{r}$, and the bandwidth.

P8.11 Automatic steering of a ship is a particularly useful application of feedback control theory [20]. In the case of heavily traveled seas, it is important to maintain the motion of the ship along an accurate track. An automatic system is more likely to maintain a smaller error from the desired heading than a helmsman who recorrects at infrequent intervals. A mathematical model of the steering system has been developed for a ship moving at a constant velocity and for small deviations from the desired track. For a large tanker, the transfer function of the ship is

$$
G(s)=\frac{E(s)}{\delta(s)}=\frac{0.164(s+0.2)(-s+0.32)}{s^{2}(s+0.25)(s-0.009)},
$$

where $E(s)$ is the Laplace transform of the deviation of the ship from the desired heading and $\delta(s)$ is the Laplace transform of the angle of deflection of the steering rudder. Verify that the Bode plot of $G(j \omega)$ is that shown in Figure P8.11.

P8.12 The block diagram of a feedback control system is shown in Figure P8.12(a). The transfer functions of the blocks are represented by the frequency response curves shown in Figure P8.12(b). (a) When $G_{3}$ is disconnected from the system, determine the damping ratio $\zeta$ of the system. (b) Connect $G_{3}$ and determine the damping ratio $\zeta$. Assume that the systems have minimum phase transfer functions.
P8.13 A position control system may be constructed by using an AC motor and AC components, as shown in Figure P8.13. The syncro and control transformer may be considered to be a transformer with a rotating winding. The syncro position detector rotor turns with the load through an angle $\theta_{0}$. The syncro motor is energized with an AC reference voltage, for example, 115 volts, $60 \mathrm{~Hz}$. The input signal or command is $R(s)=\theta_{\text {in }}(s)$ and is applied by turning the rotor of the control transformer. The AC two-phase motor operates as a result of the amplified error signal. The advantages of an AC control system are (1) freedom from DC drift effects and (2) the simplicity and accuracy of AC components. To measure the open-loop frequency response, we simply disconnect $X$ from $Y$ and $X^{\prime}$ from $Y^{\prime}$ and then apply a sinusoidal modulation signal generator to the $Y-Y^{\prime}$ terminals and measure the response at $X-X^{\prime}$. (The error $\left(\theta_{0}-\theta_{i}\right)$ will be adjusted to zero before applying the AC generator.) The resulting frequency response of the loop transfer function $L(j \omega)$ is shown in Figure P8.13(b). Determine the loop transfer function. Assume that the system has a minimum phase transfer function.

P8.14 A bandpass amplifier may be represented by the circuit model shown in Figure P8.14 [3]. When $R_{1}=R_{2}=10 \mathrm{k}, C_{1}=1 \mu \mathrm{F}, C_{2}=10 \mu \mathrm{F}$, and $K=100$, show that

$$
G(s)=\frac{10^{7} s}{\left(s+10^{5}\right)(s+100)} .
$$

(a) Sketch the Bode plot of $G(j \omega)$. (b) Find the mid band gain (in $d B$ ). (c) Find the high and low frequency $-3 \mathrm{~dB}$ points. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0609.jpg?height=242&width=976&top_left_y=161&top_left_x=509)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0609.jpg?height=766&width=1248&top_left_y=496&top_left_x=372)

FIGURE P8.12

Feedback system.

P8.15 To determine the transfer function of a process $G(s)$, the frequency response may be measured using a sinusoidal input. One system yields the data in the following table:

\begin{tabular}{ccc}
\hline$\omega$, rad/s & $|G(j \omega)|$ & Phase, degrees \\
\hline 0.1 & 50 & -90 \\
1 & 5.02 & -92.4 \\
2 & 2.57 & -96.4 \\
4 & 1.36 & -100 \\
5 & 1.17 & -104 \\
6.3 & 1.03 & -110 \\
8 & 0.97 & -120 \\
10 & 0.97 & -143 \\
12.5 & 0.74 & -169 \\
20 & 0.13 & -145 \\
31 & 0.026 & -158 \\
\hline
\end{tabular}

Determine the transfer function $G(s)$.
P8.16 A space shuttle was used to repair satellites. Figure P8.16 illustrates how a crew member, with her feet strapped to the platform on the end of the shuttle's robotic arm, used her arms to stop the satellite's spin. The control system of the robotic arm has a closed-loop transfer function

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{87}{s^{2}+15.9 s+87} .
$$

(a) Determine the response $y(t)$ to a unit step input, $R(s)=1 / s$. (b) Determine the bandwidth of the system.

P8.17 The experimental Oblique Wing Aircraft (OWA) has a wing that pivots, as shown in Figure P8.17. The wing is in the normal unskewed position for low speeds and can move to a skewed position for improved supersonic flight [11]. The aircraft control system loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{0.1(s+3)}{s(s+4)\left(s^{2}+3.2 s+64\right)} .
$$

FIGURE P8.13

(a) AC motor control. (b) Bode plot of the loop transfer function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0610.jpg?height=626&width=1223&top_left_y=167&top_left_x=508)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0610.jpg?height=418&width=1176&top_left_y=901&top_left_x=536)

(b)

rich sensory information acquired by the robot to the operator with a sensation of presence. This concept is called tele-existence or telepresence [9].

The tele-existence system consists of a system with a visual and auditory sensation of presence, a computer control system, and an anthropomorphic robot mechanism with an arm having seven degrees of freedom and a locomotion mechanism. The operator's head movement, right arm movement, right hand movement, and other auxiliary motion are measured. A specially designed stereo visual and auditory input system mounted on the neck mechanism of the robot gathers visual and auditory information from the remote environment. These pieces of information are fed back and are applied to the specially designed stereo display system to evoke the sensation of presence of the operator. The locomotion control system has the loop transfer function (a) Sketch the Bode plot. (b) Find the crossover frequency. Find the frequency when the phase is $\phi(\omega)=-180^{\circ}$.

P8.18 Remote operation plays an important role in hostile environments. Research engineers have been trying to improve teleoperations by feeding back 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0611.jpg?height=487&width=755&top_left_y=260&top_left_x=74)

FIGURE P8.16 Satellite repair.

$$
L(s)=G_{c}(s) G(s)=\frac{40(s+1)}{s^{2}+10 s+25} .
$$

Obtain the Bode plot for the loop transfer function, and determine the crossover frequency.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0611.jpg?height=560&width=536&top_left_y=153&top_left_x=861)

FIGURE P8.17 The Oblique Wing Aircraft, top and side views.

P8.19 A DC motor controller used extensively in automobiles is shown in Figure P8.19(a). The measured plot of $\Theta(s) / I(s)$ is shown in Figure P8.19(b). Determine the transfer function of $\Theta(s) / I(s)$.

P8.20 For the successful development of space projects, robotics and automation will be a key technology. Autonomous and dexterous space robots can reduce

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0611.jpg?height=251&width=891&top_left_y=1121&top_left_x=378)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0611.jpg?height=616&width=776&top_left_y=1458&top_left_x=412)

(b)
FIGURE P8.19

(a) Motor controller.

(b) Bode plot. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0612.jpg?height=416&width=736&top_left_y=168&top_left_x=225)

FIGURE P8.20 A space robot with three arms, shown capturing a satellite.

the workload of astronauts and increase operational efficiency in many missions. Figure P8.20 shows a concept called a free-flying robot $[9,13]$. A major characteristic of space robots, which clearly distinguishes them from robots operated on earth, is the lack of a fixed base. Any motion of the manipulator arm will induce reaction forces and moments in the base, which disturb its position and attitude.

The control of one of the joints of the robot can be represented by the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{823(s+9.8)}{s^{2}+22 s+471} .
$$

(a) Sketch the Bode plot of $L(j \omega)$. (b) Determine the maximum value of $L(j \omega)$, the frequency at which it occurs, and the phase at that frequency.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0612.jpg?height=544&width=739&top_left_y=1511&top_left_x=223)

P8.21 Low-altitude wind shear is a major cause of air carrier accidents in the United States. Most of these accidents have been caused by either microbursts (small-scale, low-altitude, intense thunderstorm downdrafts that impact the surface and cause strong divergent outflows of wind) or by the gust front at the leading edge of expanding thunderstorm outflows. A microburst encounter is a serious problem for either landing or departing aircraft, because the aircraft is at low altitudes and is traveling at just over $25 \%$ above its stall speed [12].

The design of the control of an aircraft encountering wind shear after takeoff may be treated as a problem of stabilizing the climb rate about a desired value of the climb rate. The resulting controller uses only climb rate information.

The standard negative unity feedback system of Figure 8.24 has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{-200 s^{2}}{s^{3}+14 s^{2}+44 s+40} .
$$

Note the negative gain in loop transfer function. This system represents the control system for the climb rate. Sketch the Bode plot and determine gain (in $\mathrm{dB}$ ) when the phase is $\phi(\omega)=-180^{\circ}$.

P8.22 The frequency response of a process $G(j \omega)$ is shown in Figure P8.22. Determine $G(s)$.

P8.23 The frequency response of a process $G(j \omega)$ is shown in Figure P8.23. Deduce the type number (number of integrations) for the system. Determine the transfer function of the system, $G(s)$. Calculate the error to a unit step input.

P8.24 The Bode plot of a closed-loop film transport system is shown in Figure P8.24 [17]. Assume that the system transfer function $T(s)$ has two dominant complex

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0612.jpg?height=541&width=752&top_left_y=1512&top_left_x=1014)

FIGURE P8.22 Bode plot of $G(s)$. 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0613.jpg?height=498&width=1548&top_left_y=162&top_left_x=87)

FIGURE P8.23 Frequency response of $G(j \omega)$.

FIGURE P8.24

Bode plot of a closed-film transport system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0613.jpg?height=590&width=760&top_left_y=828&top_left_x=389)

conjugate poles. (a) Determine the best secondorder model for the system. (b) Determine the system bandwidth. (c) Predict the percent overshoot and settling time (with a $2 \%$ criterion) for a step input.

P8.25 A unity feedback closed-loop system has a steady-state error equal to $A / 10$, where the input is $r(t)=A t^{2} / 2$. The Bode plot is shown in Figure P8.25 for $G(j \omega)$. Determine the transfer function $G(s)$.

P8.26 Determine the transfer function of the opamp circuit shown in Figure P8.26. Assume an ideal op-amp. Plot the frequency response when $R=10 \mathrm{k} \Omega, R_{1}=9 \mathrm{k} \Omega, R_{2}=1 \mathrm{k} \Omega$, and $C=1 \mu \mathrm{F}$.
P8.27 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+30)}{s^{2}+16 s+256} .
$$

Sketch the Bode plot of the loop transfer function, and indicate how the magnitude $20 \log |L(j \omega)|$ plot varies as $K$ varies. Develop a table for $K=10,20$, and 30 , and for each $K$ determine the crossover frequency ( $\omega_{c}$ for $20 \log |L(j \omega)|=0 \mathrm{~dB}$ ), the magnitude at low frequency $(20 \log |L(j \omega)|$ for $\omega \ll 1)$, and for the closed-loop system determine the bandwidth for each $K$. 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0614.jpg?height=564&width=1544&top_left_y=160&top_left_x=222)

FIGURE P8.25 Bode plot of a unity feedback system.

FIGURE P8.26

An op-amp circuit.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0614.jpg?height=324&width=633&top_left_y=826&top_left_x=521)

\section{ADVANCED PROBLEMS}

AP8.1 A high pass amplifier may be represented by the circuit model shown in Figure AP8.1. When $R_{1}=100 \Omega, R_{2}=100 \mathrm{k} \Omega, C_{1}=100 \mu \mathrm{F}, C_{2}=10 \mu \mathrm{F}$, and $K=1000$, show that

$$
G(s)=\frac{10 s^{2}}{(s+1)(s+100)} .
$$

FIGURE AP8.1

A high pass amplifier

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0614.jpg?height=231&width=311&top_left_y=1651&top_left_x=522)

(a) Sketch the Bode plot of $G(j \omega)$. (b) Find the pass band gain (in $\mathrm{dB}$ ). (c) Find the low frequency $-3 \mathrm{~dB}$ points.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0614.jpg?height=245&width=292&top_left_y=1637&top_left_x=844)

FIGURE AP8.2 System with parameter $b$ and controller gain $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0615.jpg?height=242&width=1037&top_left_y=152&top_left_x=375)

AP8.2 A system is shown in Figure AP8.2. The nominal value of the parameter $b$ is 4.0 and $K=5.0$. Determine the sensitivity $S_{b}^{T}$, and plot $20 \log \left|S_{b}^{T}(j \omega)\right|$.

AP8.3 As an automobile moves along the road, the vertical displacements at the tires act as the motion excitation to the automobile suspension system [16].

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0615.jpg?height=437&width=524&top_left_y=781&top_left_x=206)

FIGURE AP8.3 Auto suspension system model.
Figure AP8.3 is a schematic diagram of a simplified automobile suspension system, for which we assume the input is sinusoidal. Determine the transfer function $X(s) / R(s)$, and sketch the Bode plot when $M=1 \mathrm{~kg}, b=4 \mathrm{~N} \mathrm{~s} / \mathrm{m}$, and $k=18 \mathrm{~N} / \mathrm{m}$.

AP8.4 A helicopter with a load on the end of a cable is shown in Figure AP8.4(a). The position control system is shown in Figure AP8.4(b), where the visual feedback is represented by $H(s)$. Sketch the Bode plot of the loop transfer function. Determine the crossover frequency, that is, where $20 \log _{10}|H(j \omega) G(j \omega)|=0 \mathrm{~dB}$.

AP8.5 A closed-loop system with unity feedback has a transfer function

$$
T(s)=\frac{20(s+2)}{s^{2}+18 s+40} .
$$

(a) Determine the loop transfer function. (b) Plot the logarithmic-magnitude versus phase curve, and identify the frequency points for $\omega$ equal to $1,10,50,110$, and 500 . (c) Is the open-loop system stable? Is the closed-loop system stable?

AP8.6 Consider the spring-mass system depicted in Figure AP8.6. Develop a transfer function model
FIGURE AP8.4

A helicopter feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0615.jpg?height=732&width=1265&top_left_y=1337&top_left_x=353)

(a) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0616.jpg?height=471&width=355&top_left_y=169&top_left_x=434)

FIGURE AP8.6 Suspended spring-mass system with parameters $k$ and $b$.

to describe the motion of the mass $M=2 \mathrm{~kg}$, when the input is $u(t)$ and the output is $x(t)$. Assume that the initial conditions are $x(0)=0$ and $x(0)=0$. Determine values of $k$ and $b$ such that the maximum

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0616.jpg?height=284&width=604&top_left_y=166&top_left_x=1128)

FIGURE AP8.7 Op-amp lead compensator circuit.

steady-state response of the system to a sinusoidal input $u(t)=\sin (\omega t)$ is less than 1 for all $\omega$. For the values you selected for $k$ and $b$, what is the frequency at which the peak response occurs?

AP8.7 An op-amp circuit is shown in Figure AP8.7. The circuit represents a lead compensator.

(a) Determine the transfer function of this circuit.

(b) Sketch the Bode plot of the circuit when $R_{1}=$ $10 \mathrm{k} \Omega, R_{2}=10 \Omega, C_{1}=0.1 \mu \mathrm{F}$, and $C_{2}=1 \mathrm{mF}$.

\section{DESIGN PROBLEMS}

CDP8.1 In this chapter, we wish to use a PD controller such that

$$
G_{c}(s)=K(s+2) .
$$

The tachometer is not used (see Figure CDP4.1). Obtain the Bode plot for the system when $M_{p w}$ Determine the step response of this system and estimate the overshoot and settling time (with a $2 \%$ criterion).

DP8.1 Understanding the behavior of a human steering an automobile remains an interesting subject $[14,15$, 16, 21]. The design and development of systems for four-wheel steering, active suspensions, active, independent braking, and "drive-by-wire" steering provide the engineer with considerably more freedom in altering vehicle-handling qualities than existed in the past.

The vehicle and the driver are represented by the model in Figure DP8.1, where the driver develops anticipation of the vehicle deviation from the center line. For $K=1$, obtain the Bode plot of (a) the loop transfer function $L(s)=G_{c}(s) G(s)$ and (b) the closed-loop transfer function $T(s)$. (c) Repeat parts (a) and (b) when $K=50$. (d) A driver can select the gain $K$. Determine the appropriate gain so that $M_{p \omega} \leq 2$, and the bandwidth is the maximum attainable for the closed-loop system. (e) Determine the steady-state error of the system for a ramp input $r(t)=t$.

DP8.2 The unmanned exploration of planets requires a high level of autonomy because of the communication delays between robots in space and their Earthbased stations. This affects all the components of the system: planning, sensing, and mechanism. In particular, such a level of autonomy can be achieved only if each robot has a perception system that can reliably build and maintain models of the environment. The perception system is a major part of the development
FIGURE DP8.1

Human steering control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0616.jpg?height=278&width=1112&top_left_y=1844&top_left_x=507)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0617.jpg?height=414&width=609&top_left_y=158&top_left_x=566)

(a)

FIGURE DP8.2

(a) The Mars-bound Spider-bot. (Photo courtesy of NASA.) (b) Block diagram of the control system for one leg.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0617.jpg?height=256&width=994&top_left_y=639&top_left_x=378)

(b) of a complete system that includes planning and mechanism design. The target vehicle is the Spiderbot, a four-legged walking robot shown in Figure DP8.2(a), being developed at NASA Jet Propulsion Laboratory [18]. The control system of one leg is shown in Figure DP8.2(b).

(a) Sketch the Bode plot for the loop transfer function when $K=20$. Determine (1) the frequency when the phase is $\phi(\omega)=-180^{\circ}$ and (2) the crossover frequency. (b) Obtain the Bode plot for the closed-loop transfer function $T(s)$ when $K=20$. (c) Determine $M_{p \omega}, \omega_{r}$, and $\omega_{B}$ for the closed-loop system when $K=22$ and $K=25$. (d) Select the best gain of the two specified in part (c) when it is desired that the percent overshoot of the system to a step input $r(t)$ be P.O. $\leq 5 \%$ and the settling time be as short as possible.

DP8.3 A table is used to position vials under a dispenser head, as shown in Figure DP8.3(a). The objective is speed, accuracy, and smooth motion in order to eliminate spilling. The position control system is shown in Figure DP8.3(b). Determine a $K$ such that the bandwidth is maximized while keeping P.O. $\leq 20 \%$ to a unit step input. What is the maximum bandwidth, $\omega_{\mathrm{b}}$, when $P . O$. $\leq 20$ ? Determine the range of $K$ such that the closed-loop system is stable.

DP8.4 Anesthesia can be administered automatically by a control system. To ensure adequate operating conditions for the surgeon, muscle relaxant drugs, which block involuntary muscle movements, are administered.

A conventional method used by anesthesiologists for muscle relaxant administration is to inject a bolus dose whose size is determined by experience and to inject supplements as required. Significant improvements may be achieved by introducing the concept of automatic control, which results in a considerable reduction in the total relaxant drug consumed [19].

A model of the anesthesia process is shown in Figure DP8.4. Select a gain $K$ so that the bandwidth of the closed-loop system is maximized while $M_{p \omega} \leq 1.5$. Determine the bandwidth attained for your design.

DP8.5 Consider the control system depicted in Figure DP8.5(a) where the plant is a "black box" for which little is known in the way of mathematical models. The only information available on the plant is the frequency response shown in Figure DP8.5(b). Design a controller $G_{c}(s)$ to meet the following specifications: (i) the crossover frequency is between $10 \mathrm{rad} / \mathrm{s}$ and $50 \mathrm{rad} / \mathrm{s}$; (ii) the magnitude of the loop transfer function is greater than $20 \mathrm{~dB}$ for $\omega<0.1 \mathrm{rad} / \mathrm{s}$.

DP8.6 A single-input, single-output system is described by

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-1 & -p
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
K \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{lll}
0 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

FIGURE DP8.3

Automatic table and dispenser.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0618.jpg?height=677&width=1244&top_left_y=151&top_left_x=507)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0618.jpg?height=303&width=809&top_left_y=921&top_left_x=734)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0618.jpg?height=238&width=1112&top_left_y=1377&top_left_x=507)

FIGURE DP8.4 Model of an anesthesia control system.
DP8.7 Consider the system of Figure DP8.7. Consider the controller to be similar to a proportional plus derivative $(\mathrm{PD})$ given by

$$
G_{c}(s)=K_{P}+\frac{K_{D} s}{0.1 s+1} .
$$

Design the PD controller gains to achieve (a) a velocity constant $K v \geq 1$, (b) a phase margin of P.M. $\geq 60^{\circ}$, and (c) a bandwidth $\omega_{b} \geq 2.0$. Plot the response of the closed-loop system to a unit step input. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0619.jpg?height=221&width=758&top_left_y=162&top_left_x=376)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0619.jpg?height=640&width=770&top_left_y=518&top_left_x=374)

FIGURE DP8.5

(a) Feedback system with

"black box" plant.

(b) Frequency response plot of the "black box" represented by $G(s)$.

(b)

FIGURE DP8.7

Closed-loop

feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0619.jpg?height=230&width=880&top_left_y=1275&top_left_x=383)

\section{COMPUTER PROBLEMS}

CP8.1 Consider the closed-loop transfer function

$$
T(s)=\frac{25}{s^{2}+s+25} .
$$

Develop an m-file to obtain the Bode plot, and verify that the resonant frequency is $5 \mathrm{rad} / \mathrm{s}$ and that the peak magnitude $M_{p \omega}$ is $14 \mathrm{~dB}$.

CP8.2 For the following transfer functions, sketch the Bode plots, then verify with the bode function:

(a) $G(s)=\frac{1000}{(s+10)(s+100)}$ (b) $G(s)=\frac{s+100}{(s+2)(s+25)}$

(c) $G(s)=\frac{100}{s^{2}+2 s+50}$

(d) $G(s)=\frac{s-6}{(s+3)\left(s^{2}+12 s+50\right)}$

CP8.3 For each of the following transfer functions, sketch the Bode plot and determine the crossover frequency:

(a) $G(s)=\frac{2500}{(s+10)(s+100)}$ (b) $G(s)=\frac{50}{(s+1)\left(s^{2}+10 s+2\right)}$

(c) $G(s)=\frac{30(s+100)}{(s+1)(s+30)}$

(d) $G(s)=\frac{100\left(s^{2}+14 s+50\right)}{(s+1)(s+2)(s+200)}$

CP8.4 A unity negative feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{150}{s(s+10)} .
$$

Determine the closed-loop system bandwidth. Using the bode function, obtain the Bode plot and label the plot with the bandwidth.

CP8.5 A block plot of a second-order system is shown in Figure CP8.5.

(a) Determine the resonant peak $M_{p \omega}$ the resonant frequency $\omega_{r}$, and the bandwidth $\omega_{B}$, of the system from the closed-loop Bode plot. Generate the Bode plot with an m-file for $\omega=0.1$ to $\omega=1,000$ $\mathrm{rad} / \mathrm{s}$ using the logspace function. (b) Estimate the system damping ratio, $\zeta$, and natural frequency $\omega$. (c) From the closed-loop transfer function, compute the actual $\zeta$ and $\omega_{n}$ and compare with your results in part (b).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0620.jpg?height=188&width=736&top_left_y=1150&top_left_x=239)

FIGURE CP8.5 A second-order feedback control system.

CP8.6 Consider the feedback system in Figure CP8.6. Obtain the Bode plots of the loop transfer function and the closed-loop transfer function using an $\mathrm{m}$-file.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0620.jpg?height=191&width=760&top_left_y=1617&top_left_x=222)

FIGURE CP8.6 Closed-loop feedback system.
CP8.7 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{p}{s^{2}(s+p)} .
$$

Generate a plot of the bandwidth versus the parameter $p$ as $0.1<p<5$.

CP8.8 Consider the problem of controlling an inverted pendulum on a moving base, as shown in Figure CP8.8(a). The transfer function of the system is

$$
G(s)=\frac{-1 /\left(M_{b} L\right)}{s^{2}-\left(M_{b}+M_{s}\right) g /\left(M_{b} L\right)} .
$$

The design objective is to balance the pendulum (i.e., $\theta(t) \approx 0$ ) in the presence of disturbance inputs. A block diagram representation of the system is depicted in Figure CP8.8(b). Let $M_{s}=10 \mathrm{~kg}, M_{b}=$ $100 \mathrm{~kg}, L=1 \mathrm{~m}, g=9.81 \mathrm{~m} / \mathrm{s}^{2}, a=5$, and $b=10$. The design specifications, based on a unit step disturbance, are as follows:

1. settling time (with a $2 \%$ criterion) of $T_{s} \leq 10 \mathrm{~s}$,

2. percent overshoot of P.O. $\leq 40 \%$, and

3. steady-state tracking error less than $0.1^{\circ}$ in the presence of the disturbance.

Develop a set of interactive $\mathrm{m}$-file scripts to aid in the control system design. The first script should accomplish at least the following:

1. Compute the closed-loop transfer function from the disturbance to the output with $K$ as an adjustable parameter.

2. Draw the Bode plot of the closed-loop system.

3. Automatically compute and output $M_{p \omega}$ and $\omega_{r}$.

As an intermediate step, use $M_{p \omega}$ and $\omega_{r}$ and Equations (8.36) and (8.37) in Section 8.2 to estimate $\zeta$ and $\omega_{n}$. The second script should at least estimate the settling time and percent overshoot using $\zeta$ and $\omega_{n}$ as input variables.

If the performance specifications are not satisfied, change $K$ and iterate on the design using the first two scripts. After completion of the first two steps, the final step is to test the design by simulation. The functions of the third script are as follows:

1. plot the response, $\theta(t)$, to a unit step disturbance with $K$ as an adjustable parameter, and

2. label the plot appropriately. FIGURE CP8.8

(a) An inverted pendulum on a moving base.

(b) A block diagram representation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0621.jpg?height=363&width=1119&top_left_y=155&top_left_x=372)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0621.jpg?height=346&width=1132&top_left_y=615&top_left_x=370)

(b)
Utilizing the interactive scripts, design the controller to meet the specifications using frequency response Bode methods. To start the design process, use analytic methods to compute the minimum value of $K$ to meet the steady-state tracking error specification. Use the minimum $K$ as the first guess in the design iteration.

CP8.9 Design a filter, $G(s)$, with the following frequency response:
1. For $\omega<1 \mathrm{rad} / \mathrm{s}$, the magnitude $20 \log _{10}|G(j \omega)|$ $<0 \mathrm{~dB}$

2. For $1<\omega<1000 \mathrm{rad} / \mathrm{s}$, the magnitude $20 \log _{10}$ $|G(j \omega)| \geq 0 \mathrm{~dB}$

3. For $\omega>1000 \mathrm{rad} / \mathrm{s}$, the magnitude $20 \log _{10}$ $|G(j \omega)|<0 \mathrm{~dB}$

Try to maximize the peak magnitude as close to $\omega=40 \mathrm{rad} / \mathrm{s}$ as possible.

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) False; (3) False; (4) True; (5) True

Multiple Choice: (6) b; (7) a; (8) b; (9) b; (10) c; (11) b; (12) c; (13) d; (14) a; (15) d
Word Match (in order, top to bottom): d, i, q, n, l, m, o, j, s, p, c, e, b, r, h, f, g, k, a

\section{TERMS AND CONCEPTS}

All-pass network A nonminimum phase system that passes all frequencies with equal gain.

Bandwidth The frequency at which the frequency response has declined $3 \mathrm{~dB}$ from its low-frequency value.

Bode plot The logarithm of the magnitude of the transfer function is plotted versus the logarithm of $\omega$, the frequency. The phase $\phi$ of the transfer function is separately plotted versus the logarithm of the frequency.

Break frequency The frequency at which the asymptotic approximation of the frequency response for a pole (or zero) changes slope.

Corner frequency See Break frequency. Decade A factor of 10 in frequency (e.g., the range of frequencies from $1 \mathrm{rad} / \mathrm{s}$ to $10 \mathrm{rad} / \mathrm{s}$ is one decade).

Decibel (dB) The units of the logarithmic gain.

Dominant roots The roots of the characteristic equation that represent or dominate the closed-loop transient response.

Fourier transform The transformation of a function of time $f(t)$ into the frequency domain.

Fourier transform pair A pair of functions, one in the time domain, denoted by $f(t)$, and the other in the frequency domain, denoted by $F(\omega)$, related by the Fourier transform as $F(\omega)=\mathscr{F}\{f(t)\}$, where $\mathscr{F}$ denotes the Fourier transform.

Frequency response The steady-state response of a system to a sinusoidal input signal.

Laplace transform pair A pair of functions, one in the time domain, denoted by $f(\mathrm{t})$, and the other in the frequency domain, denoted by $F(\mathrm{~s})$, related by the Laplace transform as $F(s)=\mathscr{L}\{f(t)\}$, where $\mathscr{L}$ denotes the Laplace transform.

Logarithmic magnitude The logarithm of the magnitude of the transfer function, usually expressed in units of $20 \mathrm{~dB}$, thus $20 \log _{10}|G|$.

Logarithmic plot See Bode plot.
Maximum value of the frequency response $A$ pair of complex poles will result in a maximum value for the frequency response occurring at the resonant frequency.

Minimum phase transfer function All the zeros of a transfer function lie in the left-hand side of the $s$-plane.

Natural frequency The frequency of natural oscillation that would occur for two complex poles if the damping were equal to zero.

Nonminimum phase transfer function Transfer functions with zeros in the right-hand $s$-plane.

Octave The frequency interval $\omega_{2}=2 \omega_{1}$ is an octave of frequencies (e.g., the range of frequencies from $\omega_{1}=100 \mathrm{rad} / \mathrm{s}$ to $\omega_{2}=200 \mathrm{rad} / \mathrm{s}$ is one octave).

Polar plot A plot of the real part of $G(j \omega)$ versus the imaginary part of $G(j \omega)$.

Resonant frequency The frequency $\omega_{r}$ at which the maximum value of the frequency response of a complex pair of poles is attained.

Transfer function in the frequency domain The ratio of the output to the input signal where the input is a sinusoid. It is expressed as $G(j \omega)$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0623.jpg?height=294&width=308&top_left_y=98&top_left_x=86)

\title{
Stability in the Frequency
} Domain

\author{
9.1 Introduction 623 \\ 9.2 Mapping Contours in the s-Plane 624 \\ 9.3 The Nyquist Criterion 630 \\ 9.4 Relative Stability and the Nyquist Criterion 641 \\ 9.5 Time-Domain Performance Criteria in the Frequency Domain 648 \\ 9.6 System Bandwidth 655 \\ 9.7 The Stability of Control Systems with Time Delays 655 \\ 9.8 Design Examples 659 \\ 9.9 PID Controllers in the Frequency Domain 677 \\ 9.10 Stability in the Frequency Domain Using Control Design Software 678 \\ 9.11 Sequential Design Example: Disk Drive Read System 686 \\ 9.12 Summary 689
}

\section{PREVIEW}

In previous chapters, we discussed stability and developed various tools to determine stability and to assess relative stability. We continue that discussion in this chapter by showing how frequency response methods can be used to investigate stability. The important concepts of gain margin, phase margin, and bandwidth are developed in the context of Bode plots, Nyquist plots, and Nichols charts. A frequency response stability result - known as the Nyquist stability criterion - is presented and its use illustrated through several interesting examples. The implications of having pure time delays in the system on both stability and performance are discussed. We will see that the phase lag introduced by the time delay can destabilize an otherwise stable system. The chapter concludes with a frequency response analysis of the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 9, students should be able to:

$\square$ Explain the Nyquist stability criterion and the role of the Nyquist plot.

$\square$ Identify time-domain performance specifications in the frequency domain.

$\square$ Describe the importance of considering time delays in feedback control systems.

$\square \quad$ Analyze the relative stability and performance of feedback control systems using frequency response methods considering phase and gain margin, and system bandwidth with Bode plots, Nyquist plots, and Nichols charts. 

\subsection{INTRODUCTION}

Stability is a key characteristic of a feedback control system. Furthermore, if the system is stable, it is possible to investigate the relative stability. There are several methods of determining the absolute and relative stability of a system. The Routh-Hurwitz method is useful for investigating the characteristic equation expressed in terms of the complex variable $s=\sigma+j \omega$. The relative stability of a system can be investigated utilizing the root locus method, which is also expressed in terms of the complex variable $s$. In this chapter, we are concerned with investigating the stability of a system in the frequency domain, that is, in terms of the frequency response.

The frequency response of a system represents the sinusoidal steady-state response of a system and provides sufficient information for the determination of the relative stability of the system. The frequency response of a system can readily be obtained experimentally by exciting the system with sinusoidal input signals; therefore, it can be utilized to investigate the relative stability of a system when the system parameter values have not been determined. Furthermore, a frequency-domain stability criterion would be useful for determining suitable approaches to adjusting the parameters of a system in order to increase its relative stability.

A frequency domain stability criterion was developed by H. Nyquist in 1932, and it remains a fundamental approach to the investigation of the stability of linear control systems $[1,2]$. The Nyquist stability criterion is based on a theorem in the theory of the function of a complex variable due to Cauchy. Cauchy's theorem is concerned with mapping contours in the complex s-plane, and fortunately the theorem can be understood without a formal proof requiring complex variable theory.

To determine the relative stability of a closed-loop system, we must investigate the characteristic equation of the system:

$$
F(s)=1+L(s)=0
$$

For the unity feedback control system of Figure 9.1, the loop transfer function is $L(s)=G_{c}(s) G(s)$. For a multiloop system, in terms of signal-flow graphs, the characteristic equation is

$$
F(s)=\Delta(s)=1-\Sigma L_{n}+\Sigma L_{m} L_{q} \cdots=0
$$

where $\Delta(s)$ is the graph determinant. Therefore, we can represent the characteristic equation of single-loop or multiple-loop systems by Equation (9.1), where $L(s)$ is a rational function of $s$. To ensure stability, we must ascertain that all the zeros of $F(s)$ lie in the left-hand $s$-plane. Nyquist thus proposed a mapping of the right-hand $s$-plane into the $F(s)$-plane. Therefore, to use and understand Nyquist's criterion, we shall first consider briefly the mapping of contours in the complex plane. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0625.jpg?height=276&width=612&top_left_y=163&top_left_x=649)

(a)

FIGURE 9.1

Unity feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0625.jpg?height=303&width=1205&top_left_y=601&top_left_x=376)

(b)

\subsection{MAPPING CONTOURS IN THE s-PLANE}

Consider the mapping of contours in the $s$-plane by a function $F(s)$. A contour map is a contour or trajectory in one plane mapped or translated into another plane by a relation. Since $s$ is a complex variable, $s=\sigma+j \omega$, the function $F(s)$ is itself complex; it can be defined as $F(s)=u+j v$ and can be represented on a complex $F(s)$-plane with coordinates $u$ and $v$. As an example, let us consider a function $F(s)=2 s+1$ and a contour in the $s$-plane, as shown in Figure 9.2(a).

FIGURE 9.2

Mapping a square contour by $F(s)=2 s+1=$ $2(s+1 / 2)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0625.jpg?height=553&width=553&top_left_y=1462&top_left_x=354)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0625.jpg?height=551&width=628&top_left_y=1465&top_left_x=989)

(b) The mapping of the $s$-plane unit square contour to the $F(s)$-plane is accomplished through the relation $F(s)$, and so

$$
u+j v=F(s)=2 s+1=2(\sigma+j \omega)+1 .
$$

Therefore, in this case, we have

$$
u=2 \sigma+1
$$

and

$$
v=2 \omega .
$$

Thus, the contour has been mapped by $F(s)$ into a contour of an identical form, a square, with the center shifted by one unit and the magnitude of a side multiplied by two. This type of mapping, which retains the angles of the $s$-plane contour on the $F(s)$-plane, is called a conformal mapping. We also note that a closed contour in the $s$-plane results in a closed contour in the $F(s)$-plane.

The points $A, B, C$, and $D$, as shown in the $s$-plane contour, map into the points $A, B, C$, and $D$ shown in the $F(s)$-plane. Furthermore, a direction of traversal of the $s$-plane contour can be indicated by the direction $A B C D$ and the arrows shown on the contour. Then a similar traversal occurs on the $F(s)$-plane contour as we pass $A B C D$ in order, as shown by the arrows. By convention, the area within a contour to the right of the traversal of the contour is considered to be the area enclosed by the contour. Therefore, we will assume clockwise traversal of a contour to be positive and the area enclosed within the contour to be on the right. This convention is opposite to that usually employed in complex variable theory, but is equally applicable and is generally used in control system theory. We might consider the area on the right as we walk along the contour in a clockwise direction and call this rule "clockwise and eyes right."

Typically, we are concerned with an $F(s)$ that is a rational function of $s$. Therefore, it will be worthwhile to consider another example of a mapping of a contour. Let us again consider the unit square contour for the function

$$
F(s)=\frac{s}{s+2}
$$

Several values of $F(s)$ as $s$ traverses the square contour are given in Table 9.1, and the resulting contour in the $F(s)$-plane is shown in Figure 9.3(b). The contour in the $F(s)$-plane encloses the origin of the $F(s)$-plane because the origin lies within the enclosed area of the contour in the $F(s)$-plane.

\section{Table 9.1 Values of $F(s)$}

\begin{tabular}{lcccccccc} 
& Point $\boldsymbol{A}$ & & Point $\boldsymbol{B}$ & \multicolumn{3}{c}{ Point $\boldsymbol{C}$} & \multicolumn{2}{c}{ Point $\boldsymbol{D}$} \\
\hline$s=\sigma+j \omega$ & $1+j 1$ & 1 & $1-j 1$ & $-j 1$ & $-1-j 1$ & -1 & $-1+j 1$ & $j 1$ \\
$F(s)=u+j v$ & $\frac{4+2 j}{10}$ & $\frac{1}{3}$ & $\frac{4-2 j}{10}$ & $\frac{1-2 j}{5}$ & $-j$ & -1 & $+j$ & $\frac{1+2 j}{5}$
\end{tabular}

FIGURE 9.3

Mapping for

$F(s)=s /(s+2)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0627.jpg?height=562&width=680&top_left_y=166&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0627.jpg?height=562&width=525&top_left_y=166&top_left_x=1111)

(b)

Cauchy's theorem is concerned with mapping a function $F(s)$ that has a finite number of poles and zeros within the contour, so that we may express $F(s)$ as

$$
F(s)=\frac{K \prod_{i=1}^{n}\left(s+z_{i}\right)}{\prod_{k=1}^{M}\left(s+p_{k}\right)}
$$

where $-z_{i}$ are the zeros of the function $F(s)$ and $-p_{k}$ are the poles of $F(s)$. The function $F(s)$ is the characteristic equation, and so

$$
F(s)=1+L(s),
$$

where

$$
L(s)=\frac{N(s)}{D(s)}
$$

Therefore, we have

$$
F(s)=1+L(s)=1+\frac{N(s)}{D(s)}=\frac{D(s)+N(s)}{D(s)}=\frac{K \prod_{i=1}^{n}\left(s+z_{i}\right)}{\prod_{k=1}^{M}\left(s+p_{k}\right)},
$$

and the poles of $L(s)$ are the poles of $F(s)$. However, it is the zeros of $F(s)$ that are the characteristic roots of the system and that indicate its response. This is clear if we recall that the output of the system is

$$
Y(s)=T(s) R(s)=\frac{\sum P_{k} \Delta_{k}}{\Delta(s)} R(s)=\frac{\sum P_{k} \Delta_{k}}{F(s)} R(s),
$$

where $P_{k}$ and $\Delta_{k}$ are the path factors and cofactors as defined in Section 2.7. Reexamining the example when $F(s)=2(s+1 / 2)$, we have one zero of $F(s)$ at $s=-1 / 2$, as shown in Figure 9.2. The contour that we chose (that is, the unit square) enclosed and encircled the zero once within the area of the contour. Similarly, for the function $F(s)=s /(s+2)$, the unit square encircled the zero at the origin but did not encircle the pole at $s=-2$. The encirclement of the poles and zeros of $F(s)$ can be related to the encirclement of the origin in the $F(s)$-plane by Cauchy's theorem, commonly known as the principle of the argument, which states [3, 4]:

If a contour $\Gamma_{s}$ in the $s$-plane encircles $Z$ zeros and $P$ poles of $F(s)$ and does not pass through any poles or zeros of $F(s)$ and the traversal is in the clockwise direction along the contour, the corresponding contour $\Gamma_{F}$ in the $F(s)$-plane encircles the origin of the $F(s)$-plane $N=Z-P$ times in the clockwise direction.

Thus, for the examples shown in Figures 9.2 and 9.3, the contour in the $F(s)$ plane encircles the origin once, because $N=Z-P=1$, as we expect. As another example, consider the function $F(s)=s /(s+1 / 2)$. For the unit square contour shown in Figure 9.4(a), the resulting contour in the $F(s)$ plane is shown in Figure 9.4(b). In this case, $N=Z-P=0$, as is the case in Figure 9.4(b), since the contour $\Gamma_{F}$ does not encircle the origin.

Cauchy's theorem can be best comprehended by considering $F(s)$ in terms of the angle due to each pole and zero as the contour $\Gamma_{s}$ is traversed in a clockwise direction. Thus, let us consider the function

$$
F(s)=\frac{\left(s+z_{1}\right)\left(s+z_{2}\right)}{\left(s+p_{1}\right)\left(s+p_{2}\right)},
$$

where $-z_{i}$ is a zero of $F(s)$, and $-p_{k}$ is a pole of $F(s)$. Equation (9.10) can be written as

$$
\begin{aligned}
F(s) & =|F(s)| \not F(s) \\
& =\frac{\left|s+z_{1}\right|\left|s+z_{2}\right|}{\left|s+p_{1}\right|\left|s+p_{2}\right|}\left(\underline{s+z_{1}}+\underline{L s+z_{2}}-\underline{L s+p_{1}}-\not s+p_{2}\right) \\
& =|F(s)|\left(\phi_{z_{1}}+\phi_{z_{2}}-\phi_{p_{1}}-\phi_{p_{2}}\right) .
\end{aligned}
$$

Now, considering the vectors as shown for a specific contour $\Gamma_{s}$ (Figure 9.5a), we can determine the angles as $s$ traverses the contour. Clearly, the net angle change as $s$ traverses along $\Gamma_{s}$ (a full rotation of $360^{\circ}$ for $\phi_{p_{1}}, \phi_{p_{2}}$, and $\phi_{z_{2}}$ ) is zero degrees. However, for $\phi_{z_{1}}$ as $s$ traverses $360^{\circ}$ around $\Gamma_{s}$, the angle $\phi_{z_{1}}$ traverses a full $360^{\circ}$ clockwise. Thus, as $\Gamma_{s}$ is completely traversed, the net angle increase of $F(s)$ is equal to $360^{\circ}$, since only one zero is enclosed. If $Z$ zeros were enclosed within $\Gamma_{s}$, then the net angle increase would be equal to $\phi_{z}=2 \pi Z$ rad. Following this reasoning, if $Z$ zeros and $P$ poles are encircled as $\Gamma_{S}$ is traversed, then $2 \pi Z-2 \pi P$ is the net resultant angle increase of $F(s)$. Thus, the net angle increase of $\Gamma_{F}$ of the contour in the $F(s)$-plane is simply FIGURE 9.4

Mapping for

$F(s)=s /(s+1 / 2)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0629.jpg?height=560&width=605&top_left_y=167&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0629.jpg?height=560&width=585&top_left_y=167&top_left_x=1048)

(b)

$$
\phi_{F}=\phi_{Z}-\phi_{P},
$$

or

$$
2 \pi N=2 \pi Z-2 \pi P
$$

and the net number of encirclements of the origin of the $F(s)$-plane is $N=Z-P$. Thus, for the contour shown in Figure 9.5(a), which encircles one zero, the contour $\Gamma_{F}$ shown in Figure 9.5(b) encircles the origin once in the clockwise direction.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0629.jpg?height=555&width=562&top_left_y=1475&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0629.jpg?height=557&width=548&top_left_y=1469&top_left_x=991)

(b)
Evaluation of the net angle of $\Gamma_{F}$. FIGURE 9.6

Example of Cauchy's theorem with three zeros and one pole within $\Gamma_{s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0630.jpg?height=553&width=630&top_left_y=163&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0630.jpg?height=546&width=592&top_left_y=167&top_left_x=1181)

(b)

As an example of the use of Cauchy's theorem, consider the pole-zero pattern shown in Figure 9.6(a) with the contour $\Gamma_{s}$ to be considered. The contour encloses and encircles three zeros and one pole. Therefore, we obtain

$$
N=3-1=+2,
$$

and $\Gamma_{F}$ completes two clockwise encirclements of the origin in the $F(s)$-plane, as shown in Figure 9.6(b).

For the pole and zero pattern shown and the contour $\Gamma_{s}$ as shown in Figure 9.7(a), one pole is encircled and no zeros are encircled. Therefore, we have

$$
N=Z-P=-1,
$$

and we expect one encirclement of the origin by the contour $\Gamma_{F}$ in the $F(s)$-plane. However, since the sign of $N$ is negative, we find that the encirclement moves in the counterclockwise direction, as shown in Figure 9.7(b).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0630.jpg?height=470&width=644&top_left_y=1581&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0630.jpg?height=473&width=564&top_left_y=1579&top_left_x=1202)

(b)
FIGURE 9.7

Example of Cauchy's theorem $\Gamma_{S}$. Now that we have developed and illustrated the concept of mapping of contours through a function $F(s)$, we are ready to consider the stability criterion proposed by Nyquist.

\subsection{THE NYQUIST CRITERION}

To investigate the stability of a control system, we consider the characteristic equation

$$
F(s)=1+L(s)=\frac{K \prod_{i=1}^{n}\left(s+z_{i}\right)}{\prod_{k=1}^{M}\left(s+p_{k}\right)}=0 .
$$

For a system to be stable, all the zeros of $F(s)$ must lie in the left-hand $s$-plane. Thus, we find that the roots of a stable system (the zeros of $F(s)$ ) must lie to the left of the $j \omega$-axis in the $s$-plane. Therefore, we choose a contour $\Gamma_{s}$ in the $s$-plane that encloses the entire right-hand $s$-plane, and we determine whether any zeros of $F(s)$ lie within $\Gamma_{s}$ by utilizing Cauchy's theorem. That is, we plot $\Gamma_{F}$ in the $F(s)$-plane and determine the number of encirclements of the origin $N$. Then the number of zeros of $F(s)$ within the $\Gamma_{s}$ contour (and therefore, the unstable zeros of $F(s)$ ) is

$$
Z=N+P .
$$

Thus, if $P=0$, as is usually the case, we find that the number of unstable roots of the system is equal to $N$, the number of encirclements of the origin of the $F(s)$-plane.

The Nyquist contour that encloses the entire right-hand $s$-plane is shown in Figure 9.8. The contour $\Gamma_{s}$ passes along the $j \omega$-axis from $-j \infty$ to $+j \infty$, and this part of the contour provides the familiar $F(j \omega)$. The contour is completed by a

FIGURE 9.8

Nyquist contour is shown as the heavy line.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0631.jpg?height=605&width=569&top_left_y=1410&top_left_x=372)

semicircular path of radius $r$, where $r$ approaches infinity so this part of the contour typically maps to a point. This contour $\Gamma_{F}$ is known as the Nyquist plot.

The Nyquist criterion is concerned with the mapping of the function

$$
F(s)=1+L(s)
$$

and the number of encirclements of the origin of the $F(s)$-plane. Alternatively, we may define the function

$$
F^{\prime}(s)=F(s)-1=L(s)
$$

The change of functions represented by Equation (9.16) is very convenient because the loop transfer function $L(s)$ is typically available in factored form, while $1+L(s)$ is not. Then, the mapping of $\Gamma_{s}$ in the $s$-plane will be through the function $F^{\prime}(s)=L(s)$ into the $L(s)$-plane. In this case, the number of clockwise encirclements of the origin of the $F(s)$-plane becomes the number of clockwise encirclements of the -1 point in the $F^{\prime}(s)=L(s)$-plane because $F^{\prime}(s)=F(s)-1$. Therefore, the Nyquist stability criterion can be stated as follows:

\section{A feedback system is stable if and only if the contour $\Gamma_{L}$ in the $L(s)$-plane does not encircle the $(-1,0)$ point when the number of poles of in the right-hand $s$-plane is zero $(P=0)$.}

When the number of poles of $L(s)$ in the right-hand $s$-plane is other than zero, the Nyquist criterion is stated as follows:

A feedback control system is stable if and only if, for the contour $\Gamma_{L}$, the number of counterclockwise encirclements of the $(-1,0)$ point is equal to the number of poles of with positive real parts.

The basis for the two statements is the fact that, for the $F^{\prime}(s)=L(s)$ mapping, the number of roots (or zeros) of $1+L(s)$ in the right-hand $s$-plane is represented by the expression

$$
Z=N+P
$$

Clearly, if the number of poles of $L(s)$ in the right-hand $s$-plane is zero $(P=0)$, we require for a stable system that $N=0$, and the contour $\Gamma_{p}$ must not encircle the -1 point. Also, if $P$ is other than zero and we require for a stable system that $Z=0$, then we must have $N=-P$, or $P$ counterclockwise encirclements. 

\section{EXAMPLE 9.1 System with two real poles}

A unity feedback control system is shown in Figure 9.1, where

$$
L(s)=\frac{K}{\left(\tau_{1} s+1\right)\left(\tau_{2} s+1\right)} .
$$

In this case, $L(s)=G_{c}(s) G(s)$, and we use a contour $\Gamma_{L}$ in the $L(s)$-plane. The contour $\Gamma_{s}$ in the $s$-plane is shown in Figure 9.9(a), and the contour $\Gamma_{L}$ is shown in Figure 9.9(b) for $\tau_{1}=1, \tau_{2}=1 / 10$, and $K=100$.

The $+j \omega$-axis is mapped into the solid line, as shown in Figure 9.9. The $-j \omega$-axis is mapped into the dashed line, as shown in Figure 9.9. The semicircle with $r \rightarrow \infty$ in the $s$-plane is mapped into the origin of the $L(s)$-plane.

We note that the number of poles of $L(s)$ in the right-hand $s$-plane is zero, and thus $P=0$. Therefore, for this system to be stable, we require $N=Z=0$, and the contour must not encircle the -1 point in the $L(s)$-plane. Examining Figure 9.9(b) and Equation (9.17), we find that, irrespective of the value of $K$, the contour does not encircle the -1 point, and the system is always stable for all $K$ greater than zero.

\section{EXAMPLE 9.2 System with a pole at the origin}

A unity feedback control system is shown in Figure 9.1, where

$$
L(s)=\frac{K}{s(\tau s+1)} .
$$

In this single-loop case, $L(s)=G_{c}(s) G(s)$, and we determine the contour $\Gamma_{L}$ in the $L(s)$-plane. The contour $\Gamma_{s}$ in the $s$-plane is shown in Figure 9.10(a), where an infinitesimal detour around the pole at the origin is effected by a small semicircle of radius $\varepsilon$, where $\varepsilon \rightarrow 0$. This detour is a consequence of the condition of Cauchy's

FIGURE 9.9

Nyquist contour and mapping for $L(s)=$ $\frac{100}{(s+1)(s / 10+1)}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0633.jpg?height=565&width=605&top_left_y=1505&top_left_x=375)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0633.jpg?height=560&width=611&top_left_y=1505&top_left_x=1028)

(b) FIGURE 9.10

Nyquist contour and mapping for $L(s)=$ $K /(s(\tau s+1))$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0634.jpg?height=562&width=572&top_left_y=166&top_left_x=523)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0634.jpg?height=548&width=609&top_left_y=166&top_left_x=1163)

(b)

theorem, which requires that the contour cannot pass through the pole at the origin. A sketch of the contour $\Gamma_{L}$ is shown in Figure 9.10(b). Clearly, the portion of the contour $\Gamma_{L}$ from $\omega=0^{+}$to $\omega=+\infty$ is a plot of the real and imaginary components of $L(j \omega)=u(\omega)+j v(\omega)$. Let us consider each portion of the Nyquist contour $\Gamma_{s}$ in detail and determine the corresponding portions of the $L(s)$-plane contour $\Gamma_{L}$.

(a) The Origin of the s-Plane. The small semicircular detour around the pole at the origin can be represented by setting $s=\varepsilon e^{j \phi}$ and allowing $\phi$ to vary from $-90^{\circ}$ at $\omega=0^{-}$to $+90^{\circ}$ at $\omega=0^{+}$. Because $\varepsilon$ approaches zero, the mapping for $L(s)$ is

$$
\lim _{\varepsilon \rightarrow 0} L(s)=\lim _{\varepsilon \rightarrow 0} \frac{K}{\varepsilon e^{j \phi}}=\lim _{\varepsilon \rightarrow 0} \frac{K}{\varepsilon} e^{-j \phi} .
$$

Therefore, the angle of the contour in the $L(s)$-plane changes from $90^{\circ}$ at $\omega=0_{-}$ to $-90^{\circ}$ at $\omega=0_{+}$, passing through $0^{\circ}$ at $\omega=0$. The radius of the contour in the $L(s)$-plane for this portion of the contour is infinite, and this portion of the contour is shown in Figure 9.10(b). The points denoted by $A, B$, and $C$ in Figure 9.10(a) map to $A, B$, and $C$, respectively, in Figure 9.10(b).

(b) The Portion from $\omega=\mathbf{0}_{+}$to $\omega=+\infty$. The portion of the contour $\Gamma_{s}$ from $\omega=0_{+}$to $\omega=+\infty$ is mapped by the function $L(j \omega)$ where

$$
L(j \omega)=\left.L(s)\right|_{s=j \omega}
$$

for this part of the contour. This results in the plot with $\omega=0_{+}$to $\omega=+\infty$ shown in Figure 9.10(b). When $\omega$ approaches $+\infty$, we have

$$
\begin{aligned}
\lim _{\omega \rightarrow+\infty} L(j \omega) & =\lim _{\omega \rightarrow+\infty} \frac{K}{+j \omega(j \omega \tau+1)} \\
& =\lim _{\omega \rightarrow \infty}\left|\frac{K}{\tau \omega^{2}}\right| /-(\pi / 2)-\tan ^{-1}(\omega \tau) .
\end{aligned}
$$

Therefore, the magnitude approaches zero at an angle of $-180^{\circ}$. (c) The Portion from $\omega=+\infty$ to $\omega=-\infty$. The portion of $\Gamma_{s}$ from $\omega=+\infty$ to $\omega=-\infty$ is mapped into the point zero at the origin of the $L(s)$-plane by the function $L(s)$. The mapping is represented by

$$
\left.\lim _{r \rightarrow \infty} L(s)\right|_{s=r e^{j \phi}}=\lim _{r \rightarrow \infty}\left|\frac{K}{\tau r^{2}}\right| e^{-2 j \phi}
$$

as $\phi$ changes from $\phi=+90^{\circ}$ at $\omega=+\infty$ to $\phi=-90^{\circ}$ at $\omega=-\infty$. Thus, the contour moves from an angle of $-180^{\circ}$ at $\omega=+\infty$ to an angle of $+180^{\circ}$ at $\omega=-\infty$. The magnitude of the $L(s)$ contour when $r$ is infinite is always zero or a constant.

(d) The Portion from $\omega=-\infty$ to $\omega=\mathbf{0}_{-}$. The portion of the contour $\Gamma_{s}$ from $\omega=-\infty$ to $\omega=0_{-}$is mapped by the function $L(-j \omega)$ where

$$
L(-j \omega)=\left.L(s)\right|_{s=-j \omega}
$$

Thus, we obtain the complex conjugate of $L(j \omega)$, and the plot for the portion of the plot from $\omega=-\infty$ to $\omega=0_{-}$is symmetrical to the plot from $\omega=+\infty$ to $\omega=0_{+}$. This symmetrical plot is shown on the $L(s)$-plane in Figure 9.10(b).

To investigate the stability of this second-order system, we first note that the number of poles, $P$, within the right-hand $s$-plane is zero. Therefore, for this system to be stable, we require $N=Z=0$, and the contour $\Gamma_{L}$ must not encircle the -1 point in the $L(s)$-plane. Examining Figure 9.10(b), we find that irrespective of the value of the gain $K$ and the time constant $\tau$, the contour does not encircle the -1 point, and the system is always stable. We are considering positive values of gain $K$. If negative values of gain are to be considered, we should use $-K$, where $K \geq 0$.

We may draw two general conclusions from this example:

1. The plot of the contour $\Gamma_{L}$ for the range $-\infty<\omega<0$ - will be the complex conjugate of the plot for the range $0_{+}<\omega<+\infty$, and the Nyquist plot of $L(s)=G_{c}(s) G(s)$ will be symmetrical in the $L(s)$-plane about the $u$-axis. Therefore, it is sufficient to construct the contour $\boldsymbol{\Gamma}_{\boldsymbol{L}}$ for the frequency range $\mathbf{0}_{+}<\omega<+\infty$ in order to investigate the stability (keeping in mind the detour around the origin).

2. The magnitude of $L(s)=G_{c}(s) G(s)$ as $s=r e^{j \phi}$ and $r \rightarrow \infty$ will normally approach zero or a constant.

\section{EXAMPLE 9.3 System with three poles}

Consider the unity feedback system shown in Figure 9.1 with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s\left(\tau_{1} s+1\right)\left(\tau_{2} s+1\right)} .
$$

The Nyquist contour $\Gamma_{S}$ is shown in Figure 9.10(a). This mapping is symmetrical for $L(j \omega)$ and $L(-j \omega)$ so it is sufficient to investigate the $L(j \omega)$-locus. The small semicircle around the origin of the $s$-plane maps into a semicircle of infinite radius, as in Example 9.2. Also, the semicircle $r e^{j \phi}$ in the $s$-plane as $r \rightarrow \infty$ maps into the point $L(j \omega)=0$, as we expect. Therefore, to investigate the stability of the system, it is sufficient to plot the portion of the contour $\Gamma_{L}$ that is the magnitude and phase of $L(j \omega)$ for $0_{+}<\omega<+\infty$. Thus, when $s=+j \omega$, we have

$$
\begin{aligned}
L(j \omega) & =\frac{K}{j \omega\left(j \omega \tau_{1}+1\right)\left(j \omega \tau_{2}+1\right)}=\frac{-K\left(\tau_{1}+\tau_{2}\right)-j K(1 / \omega)\left(1-\omega^{2} \tau_{1} \tau_{2}\right)}{1+\omega^{2}\left(\tau_{1}^{2}+\tau_{2}^{2}\right)+\omega^{4} \tau_{1}^{2} \tau_{2}^{2}} \\
& =\frac{K}{\left[\omega^{4}\left(\tau_{1}+\tau_{2}\right)^{2}+\omega^{2}\left(1-\omega^{2} \tau_{1} \tau_{2}\right)^{2}\right]^{1 / 2}} /-\tan ^{-1}\left(\omega \tau_{1}\right)-\tan ^{-1}\left(\omega \tau_{2}\right)-(\pi / 2)
\end{aligned}
$$

When $\omega=0_{+}$, the magnitude of the locus is infinite at an angle of $-90^{\circ}$ in the $L(s)$ plane. When $\omega$ approaches $+\infty$, we have

$$
\begin{aligned}
\lim _{\omega \rightarrow \infty} L(j \omega) & =\lim _{\omega \rightarrow \infty}\left|\frac{1}{\omega^{3} \tau_{1} \tau_{2}}\right| L-(\pi / 2)-\tan ^{-1}\left(\omega \tau_{1}\right)-\tan ^{-1}\left(\omega \tau_{2}\right) \\
& =\lim _{\omega \rightarrow \infty}\left|\frac{1}{\omega^{3} \tau_{1} \tau_{2}}\right| /-3 \pi / 2 .
\end{aligned}
$$

Therefore, $L(j \omega)$ approaches a magnitude of zero at an angle of $-270^{\circ}$ [29]. To approach at an angle of $-270^{\circ}$, the locus must cross the $u$-axis in the $L(s)$-plane, as shown in Figure 9.11. Thus, it is possible to encircle the -1 point. The number of encirclements when the -1 point lies within the locus, as shown in Figure 9.11, is equal to two, and the system is unstable with two roots in the right-hand $s$-plane. The

FIGURE 9.11 Nyquist plot for $L(s)=$ $K /\left(s\left(\tau_{1} s+1\right)\right.$ $\left.\left(\tau_{2} s+1\right)\right)$. The tic mark shown to the left of the origin is the -1 point.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0636.jpg?height=564&width=736&top_left_y=1522&top_left_x=507)

point where the $L(s)$-locus intersects the real axis can be found by setting the imaginary part of $L(j \omega)=u+j v$ equal to zero. We then have, from Equation (9.24),

$$
v=\frac{-K(1 / \omega)\left(1-\omega^{2} \tau_{1} \tau_{2}\right)}{1+\omega^{2}\left(\tau_{1}^{2}+\tau_{2}^{2}\right)+\omega^{4} \tau_{1}^{2} \tau_{2}^{2}}=0 .
$$

Thus, $v=0$ when $1-\omega^{2} \tau_{1} \tau_{2}=0$ or $\omega=1 / \sqrt{\tau_{1} \tau_{2}}$. The magnitude of the real part of $L(j \omega)$ at this frequency is

$$
u=\left.\frac{-K\left(\tau_{1}+\tau_{2}\right)}{1+\omega^{2}\left(\tau_{1}^{2}+\tau_{2}^{2}\right)+\omega^{4} \tau_{1}^{2} \tau_{2}^{2}}\right|_{\omega^{2}=1 / \tau_{1} \tau_{2}}=\frac{-K \tau_{1} \tau_{2}}{\tau_{1}+\tau_{2}} .
$$

Therefore, the system is stable when

$$
\frac{-K \tau_{1} \tau_{2}}{\tau_{1}+\tau_{2}} \geq-1
$$

or

$$
K \leq \frac{\tau_{1}+\tau_{2}}{\tau_{1} \tau_{2}}
$$

Consider the case where $\tau_{1}=\tau_{2}=1$, so that

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+1)^{2}} .
$$

Using Equation (9.28), we expect stability when

$$
K \leq 2
$$

The Nyquist plots for three values of $K$ are shown in Figure 9.12.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0637.jpg?height=531&width=494&top_left_y=1449&top_left_x=89)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0637.jpg?height=531&width=501&top_left_y=1447&top_left_x=610)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0637.jpg?height=529&width=499&top_left_y=1448&top_left_x=1138)

(c)

FIGURE 9.12 Nyquist plot for $L(s)=G_{c}(s) G(s)=\frac{K}{s(s+1)^{2}}$ when (a) $K=1$, (b) $K=2$, and (c) $K=3$. 

\section{EXAMPLE 9.4 System with two poles at the origin}

Consider the unity feedback system shown in Figure 9.1 when

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s^{2}(\tau s+1)} .
$$

When $s=j \omega$, we have

$$
L(j \omega)=\frac{K}{-\omega^{2}(j \omega \tau+1)}=\frac{K}{\left[\omega^{4}+\tau^{2} \omega^{6}\right]^{1 / 2}} /-\pi-\tan ^{-1}(\omega \tau) .
$$

We note that the angle of $L(j \omega)$ is always $-180^{\circ}$ or less, and the locus of $L(j \omega)$ is above the $u$-axis for all values of $\omega$. As $\omega$ approaches $0_{+}$, we have

$$
\lim _{\omega \rightarrow 0+} L(j \omega)=\lim _{\omega \rightarrow 0+}\left|\frac{K}{\omega^{2}}\right| /-\pi .
$$

As $\omega$ approaches $+\infty$, we have

$$
\lim _{\omega \rightarrow+\infty} L(j \omega)=\lim _{\omega \rightarrow+\infty} \frac{K}{\omega^{3}} L-3 \pi / 2 .
$$

At the small semicircular detour at the origin of the $s$-plane where $s=\epsilon e^{j \phi}$, we have

$$
\lim _{\epsilon \rightarrow 0} L(s)=\lim _{\epsilon \rightarrow 0} \frac{K}{\epsilon^{2}} e^{-2 j \phi}
$$

where $-\pi / 2 \leq \phi \leq \pi / 2$. Thus, the contour $\Gamma_{L}$ ranges from an angle of $+\pi \omega=0_{-}$to $-\pi$ at $\omega=0_{+}$and passes through a full circle of $2 \pi$ rad as $\omega$ changes from $\omega=0_{-}$ to $\omega=0_{+}$. The complete contour plot of $\Gamma_{L}$ is shown in Figure 9.13. Because the contour encircles the -1 point twice, there are two roots of the closed-loop system in the right-hand plane, and the system, irrespective of the gain $K$, is unstable.

\section{EXAMPLE 9.5 System with a pole in the right-hand s-plane}

Consider the control system shown in Figure 9.14 and determine the stability of the system. First, consider the system without derivative feedback, so that $K_{2}=0$. We then have the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K_{1}}{s(s-1)} .
$$

Thus, the loop transfer function has one pole in the right-hand $s$-plane, and therefore $P=1$. For this system to be stable, we require $N=-P=-1$, one counterclockwise encirclement of the -1 point. At the semicircular detour at the origin of the $s$-plane, we let $s=\epsilon e^{j \phi}$ when $-\pi / 2 \leq \phi \leq \pi / 2$. Then, when $s=\epsilon e^{j \phi}$, we have FIGURE 9.13

Nyquist contour plot for $L(s)=$ $K /\left(s^{2}(\tau s+1)\right)$.

FIGURE 9.14

Second-order feedback control system. (a) Signalflow graph.

(b) Block diagram.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0639.jpg?height=862&width=848&top_left_y=166&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0639.jpg?height=266&width=835&top_left_y=1142&top_left_x=373)

(b)

$$
\lim _{\epsilon \rightarrow 0} L(s)=\lim _{\epsilon \rightarrow 0} \frac{K_{1}}{-\epsilon e^{j \phi}}=\lim _{\epsilon \rightarrow 0}\left|\frac{K_{1}}{\epsilon}\right| \angle-180^{\circ}-\phi .
$$

Therefore, this portion of the contour $\Gamma_{L}$ is a semicircle of infinite magnitude in the left-hand $L(s)$-plane, as shown in Figure 9.15. When $s=j \omega$, we have

$$
\begin{aligned}
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{K_{1}}{j \omega(j \omega-1)} & =\frac{K_{1}}{\left(\omega^{2}+\omega^{4}\right)^{1 / 2}} /(-\pi / 2)-\tan ^{-1}(-\omega) \\
& =\frac{K_{1}}{\left(\omega^{2}+\omega^{4}\right)^{1 / 2}} \frac{L}{+\pi / 2+\tan ^{-1} \omega .}
\end{aligned}
$$

FIGURE 9.15

Nyquist plot for

$L(s)=K_{1} /(s(s-1))$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0640.jpg?height=583&width=623&top_left_y=165&top_left_x=507)

Finally, for the semicircle of radius $r$ as $r$ approaches infinity, we have

$$
\left.\lim _{r \rightarrow \infty} L(s)\right|_{s=r e^{j \phi}}=\lim _{r \rightarrow \infty}\left|\frac{K_{1}}{r^{2}}\right| e^{-2 j \phi},
$$

where $\phi$ varies from $\pi / 2$ to $-\pi / 2$ in a clockwise direction. Therefore, the contour $\Gamma_{L}$, at the origin of the $L(s)$-plane, varies $2 \pi \mathrm{rad}$ in a counterclockwise direction. The contour $\Gamma_{L}$ in the $L(s)$-plane encircles the -1 point once in the clockwise direction so $N=+1$, and there is one pole $s=1$ in the right-hand plane so $P=1$. Hence,

$$
Z=N+P=2,
$$

and the system is unstable because two roots of the characteristic equation, irrespective of the value of the gain $K_{1}$, lie in the right half of the s-plane.

Let us now consider again the system when the derivative feedback is included in the system shown in Figure $9.14\left(K_{2}>0\right)$. Then the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K_{1}\left(1+K_{2} s\right)}{s(s-1)} .
$$

The portion of the contour $\Gamma_{L}$ when $s=\varepsilon e^{j \phi}$ is the same as the system without derivative feedback, as shown in Figure 9.16. However, when $s=r e^{j \phi}$ as $r$ approaches infinity, we have

$$
\left.\lim _{r \rightarrow \infty} L(s)\right|_{s=r e^{j \phi}}=\lim _{r \rightarrow \infty}\left|\frac{K_{1} K_{2}}{r}\right| e^{-j \phi},
$$

FIGURE 9.16

Nyquist plot

for $L(s)=$

$K_{1}\left(1+K_{2} s\right) /$

$(s(s-1))$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0641.jpg?height=562&width=724&top_left_y=166&top_left_x=374)

and the $\Gamma_{L}$-contour at the origin of the $L(s)$-plane varies $\pi$ rad in a counterclockwise direction. The locus $L(j \omega)$ crosses the $u$-axis at a point determined by considering

$$
\begin{aligned}
L(j \omega)=G_{c}(j \omega) G(j \omega) & =\frac{K_{1}\left(1+K_{2} j \omega\right)}{-\omega^{2}-j \omega} \\
& =\frac{-K_{1}\left(\omega^{2}+\omega^{2} K_{2}\right)+j\left(\omega-K_{2} \omega^{3}\right) K_{1}}{\omega^{2}+\omega^{4}} .
\end{aligned}
$$

The $L(j \omega)$-locus intersects the $u$-axis at a point where the imaginary part of $L(j \omega)$ is zero. Therefore,

$$
\omega-K_{2} \omega^{3}=0
$$

at this point, or $\omega^{2}=1 / K_{2}$. The value of the real part of $L(j \omega)$ at the intersection is then

$$
\left.u\right|_{\omega^{2}=1 / K_{2}}=\left.\frac{-\omega^{2} K_{1}\left(1+K_{2}\right)}{\omega^{2}+\omega^{4}}\right|_{\omega^{2}=1 / K_{2}}=-K_{1} K_{2} .
$$

Therefore, when $-K_{1} K_{2}<-1$ or $K_{1} K_{2}>1$, the contour $\Gamma_{L}$ encircles the -1 point once in a counterclockwise direction, and therefore $N=-1$. Then the number of zeros of the system in the right-hand plane is

$$
Z=N+P=-1+1=0 .
$$

Thus, the system is stable when $K_{1} K_{2}>1$. Often, it may be useful to utilize a computer to plot the Nyquist plot [5].

\section{EXAMPLE 9.6 System with a zero in the right-hand $s$-plane}

Consider the feedback control system shown in Figure 9.1 when

$$
L(s)=G_{c}(s) G(s)=\frac{K(s-2)}{(s+1)^{2}} .
$$

FIGURE 9.17 Nyquist plot for Example 9.6 for $L(j \omega) / K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0642.jpg?height=821&width=1164&top_left_y=154&top_left_x=514)

We have

$$
L(j \omega)=\frac{K(j \omega-2)}{(j \omega+1)^{2}}=\frac{K(j \omega-2)}{\left(1-\omega^{2}\right)+j 2 \omega} .
$$

As $\omega$ approaches $+\infty$ on the $+j \omega$ axis, we have

$$
\lim _{\omega \rightarrow+\infty} L(j \omega)=\lim _{\omega \rightarrow+\infty} \frac{K}{\omega} /-\pi / 2 .
$$

When $\omega=\sqrt{5}$, we have $L(j \omega)=K / 2$. At $\omega=0_{+}$, we have $L(j \omega)=-2 K$. The Nyquist plot for $L(j \omega) / K$ is shown in Figure 9.17. $L(j \omega)$ intersects the $-1+j 0$ point when $K=1 / 2$. Thus, the system is stable for the limited range of gain $0<K \leq 1 / 2$. When $K>1 / 2$, the number of encirclements of the -1 point is $N=1$. The number of poles of $L(s)$ in the right half $s$-plane is $P=0$. Therefore, we have

$$
Z=N+P=1
$$

and the system is unstable. Examining the Nyquist plot of Figure 9.17 we conclude that the system is unstable for all $K>1 / 2$.

\subsection{RELATIVE STABILITY AND THE NYQUIST CRITERION}

For the $s$-plane, we defined the relative stability of a system as the property measured by the relative settling time of each root or pair of roots. Therefore, a system with a shorter settling time is considered relatively more stable. We would like to determine a similar measure of relative stability useful for the frequency response method. The Nyquist criterion provides us with suitable information concerning the absolute stability and, furthermore, can be utilized to define and ascertain the relative stability of a system.

The Nyquist stability criterion is defined in terms of the $(-1,0)$ point on the Nyquist plot or the $0-\mathrm{dB},-180^{\circ}$ point on the Bode plot. The proximity of the $L(j \omega)$-locus to this stability point is a measure of the relative stability of a system. The critical section of the Nyquist plot for the loop transfer function for several values of $K$ with

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{K}{j \omega\left(j \omega \tau_{1}+1\right)\left(j \omega \tau_{2}+1\right)}
$$

is shown in Figure 9.18. As $K$ increases, the Nyquist plot approaches the -1 point and eventually encircles the -1 point for a gain $K=K_{3}$. We determined in Section 9.3 that the locus intersects the $u$-axis at a point

$$
u=\frac{-K \tau_{1} \tau_{2}}{\tau_{1}+\tau_{2}} .
$$

Therefore, the system has roots on the $j \omega$-axis when

$$
u=-1 \quad \text { or } \quad K=\frac{\tau_{1}+\tau_{2}}{\tau_{1} \tau_{2}}
$$

As $K$ is decreased below this marginal value, the stability is increased, and the margin between the critical gain $K=\left(\tau_{1}+\tau_{2}\right) / \tau_{1} \tau_{2}$ and a gain $K=K_{2}$ is a measure of the relative stability. This measure of relative stability is called the gain margin and is defined as the reciprocal of the gain $|L(j \omega)|$ at the frequency at which the phase angle reaches $-\mathbf{1 8 0}^{\circ}$ (that is, $v=0$ ). The gain margin is a measure of the factor by which the system gain would have to be increased for the $L(j \omega)$ locus to pass through the $u=-1$ point. Thus, for a gain $K=K_{2}$ in Figure 9.18, the gain margin

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0643.jpg?height=602&width=720&top_left_y=1508&top_left_x=376)

is equal to the reciprocal of $L(j \omega)$ when $v=0$. Because $\omega=1 / \sqrt{\tau_{1} \tau_{2}}$ when the phase shift is $-180^{\circ}$, we have a gain margin equal to

$$
\frac{1}{|L(j \omega)|}=\left[\frac{K_{2} \tau_{1} \tau_{2}}{\tau_{1}+\tau_{2}}\right]^{-1}=\frac{1}{d} .
$$

The gain margin can be defined in terms of a logarithmic (decibel) measure as

$$
20 \log \frac{1}{d}=-20 \log d \mathrm{~dB}
$$

For example, when $\tau_{1}=\tau_{2}=1$, the system is stable when $K \leq 2$. Thus, when $K=K_{2}=0.5$, the gain margin is equal to

$$
\frac{1}{d}=\left[\frac{K_{2} \tau_{1} \tau_{2}}{\tau_{1}+\tau_{2}}\right]^{-1}=4,
$$

or, in logarithmic measure,

$$
20 \log 4=12 \mathrm{~dB} .
$$

Therefore, the gain margin indicates that the system gain can be increased by a factor of four $(12 \mathrm{~dB})$ before the stability boundary is reached.

The gain margin is the increase in the system gain when phase $=-180^{\circ}$ that will result in a marginally stable system with intersection of the $-1+j 0$ point on the Nyquist plot.

An alternative measure of relative stability can be defind in terms of the phase margin between a specific and a system that is marginally stable. The phase margin is defined as the phase angle through which the $\boldsymbol{L}(\boldsymbol{j} \omega)$ locus must be rotated so that the unity magnitude $|L(j \omega)|=1$ point will pass through the $(-1,0)$ point in the $\boldsymbol{L}(\boldsymbol{j} \boldsymbol{\omega})$ plane. This measure of relative stability is equal to the additional phase lag required before the system becomes unstable. This information can be determined from the Nyquist plot shown in Figure 9.18. For a gain $K=K_{2}$, an additional phase angle, $\phi_{2}$, may be added to the system before the system becomes unstable. Similarly, for the gain $K_{1}$, the phase margin is equal to $\phi_{1}$, as shown in Figure 9.18.

The phase margin is the amount of phase shift of the $L(j \omega)$ at unity magnitude that will result in a marginally stable system with intersection of the $-1+j 0$ point on the Nyquist plot.

The gain phase margins are easily evaluated from the Bode plot. The critical point for stability is $u=-1, v=0$ in the $L(j \omega)$ - plane, which is equivalent to a logarithmic magnitude of $0 \mathrm{~dB}$ and a phase angle of $180^{\circ}$ (or $-180^{\circ}$ ) on the Bode plot. FIGURE 9.19

Bode plot for

$L(j \omega)=$

$1 /(j \omega(j \omega+1)$

$(0.2 j \omega+1))$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0645.jpg?height=731&width=911&top_left_y=152&top_left_x=370)

It is relatively straightforward to examine the Nyquist plot of a minimum-phase system. Special care is required with a nonminimum-phase system, however, and the complete Nyquist plot should be studied to determine stability.

The Bode plot associated with the loop transfer function

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{1}{j \omega(j \omega+1)(0.2 j \omega+1)}
$$

is shown in Figure 9.19. The phase angle when the logarithmic magnitude is $0 \mathrm{~dB}$ is equal to $-137^{\circ}$. Thus, the phase margin is $180^{\circ}-137^{\circ}=43^{\circ}$. The logarithmic magnitude when the phase angle is $-180^{\circ}$ is $-15 \mathrm{~dB}$, and therefore the gain margin is $G \cdot M .=15 \mathrm{~dB}$.

The frequency response of a system can be graphically portrayed on the logarithmic-magnitude-phase-angle diagram. For the log-magnitude-phase diagram, the critical stability point is the $0-\mathrm{dB},-180^{\circ}$ point, and the gain margin and phase margin can be easily determined and indicated on the diagram. The log-magnitude-phase locus of the loop transfer function, $L(j \omega)$, in Equation (9.50) is shown in Figure 9.20. The indicated phase margin is $P . M .=43^{\circ}$, and the gain margin is G.M. $=15 \mathrm{~dB}$. For comparison, the locus for

$$
L_{2}(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{1}{j \omega(j \omega+1)^{2}}
$$

is also shown in Figure 9.20. The gain margin for $L_{2}(j \omega)$ is $G . M .=5.7 \mathrm{~dB}$, and the phase margin for $L_{2}$ is $P . M .=20^{\circ}$. Clearly, the feedback system $L_{2}(j \omega)$ is relatively less stable than the system $L_{1}(j \omega)$. However, the question still remains: How much less stable is the system $L_{2}(j \omega)$ in comparison to the system $L_{1}(j \omega)$ ? In the following, we answer this question for a second-order system, and the general usefulness of the relation that we develop will depend on the presence of dominant roots. FIGURE 9.20

Log-magnitudephase curves for $L_{1}$ and $L_{2}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0646.jpg?height=1084&width=985&top_left_y=154&top_left_x=519)

Let us now determine the phase margin of a second-order system and relate the phase margin to the damping ratio $\zeta$ of an underdamped system. Consider the loop-transfer function of the system shown in Figure 9.1, where

$$
L(s)=G_{c}(s) G(s)=\frac{\omega_{n}^{2}}{s\left(s+2 \zeta \omega_{n}\right)} .
$$

The characteristic equation for the closed-loop second-order system is

$$
s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=0 .
$$

Therefore, the closed-loop roots are

$$
s=-\zeta \omega_{n} \pm j \omega_{n} \sqrt{1-\zeta^{2}} .
$$

The frequency domain form of Equation (9.52) is

$$
L(j \omega)=\frac{\omega_{n}^{2}}{j \omega\left(j \omega+2 \zeta \omega_{n}\right)} .
$$

The magnitude of the frequency response is equal to 1 at the crossover frequency $\omega_{c}$; thus,

$$
\frac{\omega_{n}^{2}}{\omega_{c}\left(\omega_{c}^{2}+4 \zeta^{2} \omega_{n}^{2}\right)^{1 / 2}}=1 .
$$

Rearranging Equation (9.55), we obtain

$$
\left(\omega_{c}^{2}\right)^{2}+4 \zeta^{2} \omega_{n}^{2}\left(\omega_{c}^{2}\right)-\omega_{n}^{4}=0 .
$$

Solving for $\omega_{c}$ yields

$$
\frac{\omega_{c}^{2}}{\omega_{n}^{2}}=\left(4 \zeta^{4}+1\right)^{1 / 2}-2 \zeta^{2} .
$$

The phase margin for this system is

$$
\begin{aligned}
\phi_{\mathrm{pm}} & =180^{\circ}-90^{\circ}-\tan ^{-1} \frac{\omega_{c}}{2 \zeta \omega_{n}} \\
& =90^{\circ}-\tan ^{-1}\left(\frac{1}{2 \zeta}\left[\left(4 \zeta^{4}+1\right)^{1 / 2}-2 \zeta^{2}\right]^{1 / 2}\right) \\
& =\tan ^{-1} \frac{2}{\left[\left(4+1 / \zeta^{4}\right)^{1 / 2}-2\right]^{1 / 2}} .
\end{aligned}
$$

Equation (9.57) is the relationship between the damping ratio $\zeta$ and the phase margin $\phi_{\mathrm{pm}}$, which provides a correlation between the frequency response and the time response. A plot of $\zeta$ versus $\phi_{\mathrm{pm}}$ is shown in Figure 9.21. The actual curve of $\zeta$ versus $\phi_{\text {pm }}$ can be approximated by the dashed line shown in Figure 9.21. The slope of the linear approximation is equal to 0.01 , and therefore an approximate linear relationship between the damping ratio and the phase margin is

$$
\zeta=0.01 \phi_{\mathrm{pm}}
$$

where the phase margin is measured in degrees. This approximation is reasonably accurate for $\zeta \leq 0.7$ and is a useful index for correlating the frequency response with the transient performance of a system. Equation (9.58) is a suitable approximation for a second-order system and may be used for higher-order systems if we can assume that the transient response of the system is primarily due to a pair of dominant underdamped roots. The approximation of a higher-order system by a dominant second-order system is a useful approximation. Although it must be used

FIGURE 9.21

Damping ratio versus phase margin for a second-order system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0647.jpg?height=563&width=947&top_left_y=1600&top_left_x=376)

with care, control engineers find this approach to be a simple, yet fairly accurate, technique of setting the specifications of a control system.

Therefore, for the system with a loop transfer function, $L(j \omega)$, in Equation (9.50) we found the phase margin $P . M .=43^{\circ}$. Thus, the damping ratio is approximately

$$
\zeta \simeq 0.01 \phi_{\mathrm{pm}}=0.43 \text {. }
$$

Then the percent overshoot to a step input for this system is approximately

$$
\text { P.O. }=22 \% \text {. }
$$

It is possible to calculate and plot the phase margin and gain margin versus the gain $K$ for a specified $L(j \omega)$. Consider the system of Figure 9.1 with the loop transfer function

$$
L(s)=G_{c}(s) G(s) H(s)=\frac{K}{s(s+4)^{2}} .
$$

The gain for which the system is marginally stable is $K=K^{*}=128$. The gain margin and the phase margin plotted versus $K$ are shown in Figures 9.22(a) and (b), respectively. The gain margin is plotted versus the phase margin, as shown in Figure 9.22(c). The phase margin and the gain margin are suitable measures of the performance of the system. We will normally emphasize phase margin as a frequency-domain specification.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0648.jpg?height=433&width=640&top_left_y=1091&top_left_x=508)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0648.jpg?height=444&width=642&top_left_y=1650&top_left_x=507)

(b)

b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0648.jpg?height=444&width=609&top_left_y=1655&top_left_x=1163)

(c) (a) Gain margin versus gain $K$. (b) Phase margin versus gain $K$. (c) Gain margin versus phase margin. The phase margin is a frequency response measure for indicating the expected transient performance of a system. Another useful index of performance in the frequency domain is $M_{p \omega}$, the maximum magnitude of the closed-loop frequency response, and we shall now consider this practical index.

\subsection{TIME-DOMAIN PERFORMANCE CRITERIA IN THE FREQUENCY DOMAIN}

The transient performance of a feedback system can be estimated from the closedloop frequency response. The closed-loop frequency response is the frequency response of the closed-loop transfer function $T(j \omega)$. The open- and closed-loop frequency responses for a single-loop system are related. Consider the closed-loop system:

$$
\frac{Y(j \omega)}{R(j \omega)}=T(j \omega)=M(\omega) e^{j \phi(\omega)}=\frac{G_{c}(j \omega) G(j \omega)}{1+G_{c}(j \omega) G(j \omega)}
$$

The Nyquist criterion and the phase margin index are defined for the loop transfer function $L(j \omega)=G_{c}(j \omega) G(j \omega)$. However, as we found in Section 8.2, the maximum magnitude of the closed-loop frequency response can be related to the damping ratio of a second-order system of

$$
M_{p \omega}=\left|T\left(\omega_{r}\right)\right|=\left(2 \zeta \sqrt{1-\zeta^{2}}\right)^{-1}, \quad \zeta<0.707 .
$$

Because this relationship between the closed-loop frequency response and the transient response is a useful one, we would like to be able to determine $M_{p \omega}$ from the plots completed for the investigation of the Nyquist criterion. That is, we want to be able to obtain the closed-loop frequency response from the open-loop frequency response. Of course, we could determine the closed-loop roots of $1+L(s)$ and plot the closed-loop frequency response. However, once we have invested all the effort necessary to find the closed-loop roots of a characteristic equation, then a closedloop frequency response is not necessary.

The relation between the closed-loop and open-loop frequency response is illuminated on the magnitude-phase plot when considering unity feedback systems. In the unity feedback case, key performance indicators such as $M_{p \omega}$ and $\omega_{r}$ can be determined from the magnitude-phase plot using circles of constant magnitude of the closed-loop transfer function. These circles are known as constant $M$-circles.

The relationship between $T(j \omega)$ and $L(j \omega)$ is readily obtained in terms of complex variables in the $L(s)$-plane. The coordinates of the $L(s)$-plane are $u$ and $v$, and we have

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=u+j v .
$$

Therefore, the magnitude of the closed-loop transfer function is

$$
M(\omega)=\left|\frac{G_{c}(j \omega) G(j \omega)}{1+G_{c}(j \omega) G(j \omega)}\right|=\left|\frac{u+j v}{1+u+j v}\right|=\frac{\left(u^{2}+v^{2}\right)^{1 / 2}}{\left[(1+u)^{2}+v^{2}\right]^{1 / 2}} .
$$

Squaring Equation (9.65) and rearranging, we obtain

$$
\left(1-M^{2}\right) u^{2}+\left(1-M^{2}\right) v^{2}-2 M^{2} u=M^{2} .
$$

Dividing Equation (9.66) by $1-M^{2}$ and adding the term $\left[M^{2} /\left(1-M^{2}\right)\right]^{2}$ to both sides, we have

$$
u^{2}+v^{2}-\frac{2 M^{2} u}{1-M^{2}}+\left(\frac{M^{2}}{1-M^{2}}\right)^{2}=\left(\frac{M^{2}}{1-M^{2}}\right)+\left(\frac{M^{2}}{1-M^{2}}\right)^{2} .
$$

Rearranging, we obtain

$$
\left(u-\frac{M^{2}}{1-M^{2}}\right)^{2}+v^{2}=\left(\frac{M}{1-M^{2}}\right)^{2},
$$

which is the equation of a circle on the $(u, v)$-plane with the center at

$$
u=\frac{M^{2}}{1-M^{2}}, \quad v=0 .
$$

The radius of the circle is equal to $\left|M /\left(1-M^{2}\right)\right|$. Therefore, we can plot several circles of constant magnitude $M$ in the $L(s)$-plane. Several constant $M$ circles are shown in Figure 9.23. The circles to the left of $u=-1 / 2$ are for $M>1$, and the circles to the right of $u=-1 / 2$ are for $M<1$. When $M=1$, the circle becomes the straight line $u=-1 / 2$, which is evident from inspection of Equation (9.66).

The frequency response for a system is shown in Figure 9.24 for two gain values where $K_{2}>K_{1}$. The frequency response curve for the system with gain $K_{1}$ is tangent to magnitude circle $M_{1}$ at a frequency $\omega_{r 1}$. Similarly, the frequency response curve for gain $K_{2}$ is tangent to magnitude circle $M_{2}$ at the frequency $\omega_{r 2}$. Therefore, the closed-loop frequency response magnitude curves are estimated as shown in Figure 9.25. Hence, we can obtain the closed-loop frequency response of a system

FIGURE 9.23 Constant $M(\omega)$ circles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0650.jpg?height=541&width=908&top_left_y=1562&top_left_x=506)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0651.jpg?height=508&width=665&top_left_y=167&top_left_x=91)

FIGURE 9.24 The frequency response plot of $G_{c}(j \omega) G(j \omega)$ for two values of a gain $\left(K_{2}>K_{1}\right)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0651.jpg?height=432&width=832&top_left_y=245&top_left_x=786)

FIGURE 9.25 Closed-loop frequency response of $T(j \omega)=G_{c}(j \omega) G(j \omega) /\left(1+G_{c}(j \omega) G(j \omega)\right)$. Note that $K_{2}>K_{1}$.

from the $L(s)$-plane. If the maximum magnitude, $M_{p \omega}$, is the only information desired, then it is sufficient to read this value directly from the Nyquist plot. The maximum magnitude of the closed-loop frequency response, $M_{p \omega}$, is the value of the $M$ circle that is tangent to the $L(j \omega)$-locus. The point of tangency occurs at the frequency $\omega_{r}$, the resonant frequency. The complete closed-loop frequency response of a system can be obtained by reading the magnitude $M$ of the circles that the $L(j \omega)$-locus intersects at several frequencies. Therefore, the system with a gain $K=K_{2}$ has a closed-loop magnitude $M_{1}$ at the frequencies $\omega_{1}$ and $\omega_{2}$. This magnitude is read from Figure 9.24 and is shown on the closed-loop frequency response in Figure 9.25. The bandwidth for $K_{1}$ is shown as $\omega_{B 1}$.

It may be empirically shown that the crossover frequency $\omega_{c}$ on the open-loop Bode plot is related to the closed-loop system bandwidth $\omega_{B}$ by the approximation for $\zeta$ in the range 0.2 to 0.8 :

$$
\omega_{B}=1.6 \omega_{c}
$$

In a similar manner, we can obtain circles of constant closed-loop phase angles. Thus, for Equation (9.62), the angle relation is

$$
\begin{aligned}
\phi & =\angle T(j \omega)=\angle(u+j v) /(1+u+j v) \\
& =\tan ^{-1}\left(\frac{v}{u}\right)-\tan ^{-1}\left(\frac{v}{1+u}\right) .
\end{aligned}
$$

Taking the tangent of both sides and rearranging, we have

$$
u^{2}+v^{2}+u-\frac{v}{N}=0
$$

where $N=\tan \phi$. Adding the term $1 / 4\left[1+1 / N^{2}\right]$ to both sides of the equation and simplifying, we obtain

$$
\left(u+\frac{1}{2}\right)^{2}+\left(v-\frac{1}{2 N}\right)^{2}=\frac{1}{4}\left(1+\frac{1}{N^{2}}\right),
$$

which is the equation of a circle with its center at $u=-1 / 2$ and $v=+1 /(2 N)$. The radius of the circle is equal to $1 / 2\left[1+1 / N^{2}\right]^{1 / 2}$. Therefore, the constant phase angle curves can be obtained for various values of $N$ in a manner similar to the $M$ circles.

The constant $M$ and $N$ circles can be used for analysis and design in the $L(s)$ plane. However, it is much easier to obtain the Bode plot for a system, and it would be preferable if the constant $M$ and $N$ circles were translated to a logarithmic gain phase. N. B. Nichols transformed the constant $M$ and $N$ circles to the log-magnitudephase diagram, and the resulting chart is called the Nichols chart [3, 7]. The $M$ and $N$ circles appear as contours on the Nichols chart shown in Figure 9.26. The coordinates of the log-magnitude-phase diagram are the same as those used in Section 8.5. However, superimposed on the log-magnitude-phase plane we find constant $M$ and $N$ lines. The constant $M$ lines are given in decibels and the $N$ lines in degrees. An example will illustrate the use of the Nichols chart to determine the closed-loop frequency response.

\section{EXAMPLE 9.7 Stability using the Nichols chart}

Consider a unity feedback system with a loop transfer function in Equation (9.50). The frequency response of $L(j \omega)$ is plotted on the Nichols chart and is shown in Figure 9.27. The maximum magnitude, $M_{p \omega}$, is equal to $+2.5 \mathrm{~dB}$ and occurs at a frequency $\omega_{r}=0.8$. The closed-loop phase angle at $\omega_{r}$ is equal to $-72^{\circ}$. The $3-\mathrm{dB}$ closed-loop bandwidth, where the closed-loop magnitude is $-3 \mathrm{~dB}$, is equal to $\omega_{B}=1.33$, as shown in Figure 9.27. The closed-loop phase angle at $\omega_{B}$ is equal to $-142^{\circ}$.

\section{EXAMPLE 9.8 Third-order system}

Let us consider a unity feedback system with a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{0.64}{s\left(s^{2}+s+1\right)},
$$

where $\zeta=0.5$ for the complex poles. The Nichols chart for this system is shown in Figure 9.28. The phase margin for this system as it is determined from the Nichols chart is $30^{\circ}$. On the basis of the phase, we use Equation (9.58) to estimate the system damping ratio as $\zeta=0.30$. The maximum magnitude is equal to $+9 \mathrm{~dB}$ occurring at a frequency $\omega_{r}=0.88$. Therefore,

$$
20 \log \mathrm{M}_{p \omega}=9 \mathrm{~dB}, \text { or } \quad M_{p \omega}=2.8 .
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0653.jpg?height=1689&width=1244&top_left_y=155&top_left_x=333)

FIGURE 9.26 Nichols chart. The phase curves for the closed-loop system are shown as heavy curves. FIGURE 9.27 Nichols chart for $G_{c}(j \omega) G(j \omega)=$ $1 /(j \omega(j \omega+1)$ $(0.2 j \omega+1))$. Three points on curve are shown for $\omega=0.5$, 0.8 , and 1.35 , respectively.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0654.jpg?height=1195&width=922&top_left_y=155&top_left_x=543)

Solving Equation (9.63), we find that $\zeta=0.18$. We are confronted with two conflicting damping ratios, where one is obtained from a phase margin measure and another from a peak frequency response measure. In this case, we have discovered an example in which the correlation between the frequency domain and the time domain is unclear and uncertain. This apparent conflict is caused by the nature of the frequency response which slopes rapidly toward the $180^{\circ}$ line from the 0 - $\mathrm{dB}$ axis. If we determine the roots of the characteristic equation for $1+L(s)$, we obtain

$$
(s+0.77)\left(s^{2}+0.225 s+0.826\right)=0 .
$$

The damping ratio of the complex conjugate roots is equal to 0.124 , where the complex roots do not dominate the response of the system. Therefore, the real root will add some damping to the system, and we might estimate the damping ratio to be approximately the value determined from the $M_{p \omega}$ index; that is, $\zeta=0.18$. A designer must use the frequency-domain-to-time-domain correlations with caution. However, we are usually safe if the lower value of the damping ratio resulting from the phase margin and the $M_{p \omega}$ relation is used for analysis and design purposes. FIGURE 9.28 Nichols chart for $G_{c}(j \omega) G(j \omega)=$ $0.64 /\left(j \omega\left[(j \omega)^{2}+\right.\right.$ $j \omega+1)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0655.jpg?height=1183&width=920&top_left_y=166&top_left_x=582)

The Nichols chart can be used for design purposes by altering the frequency response of the loop transfer fraction, $L(s)=G_{c}(s) G(s)$, so we can obtain a desirable phase margin and $M_{p \omega}$. The system gain $K$ is readily adjusted to provide a suitable phase margin and $M_{p \omega}$ by inspecting the Nichols chart. For example, let us consider again Example 9.8, where

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s\left(s^{2}+s+1\right)} .
$$

The $G_{c}(j \omega) G(j \omega)$-locus on the Nichols chart for $K=0.64$ is shown in Figure 9.28. Let us determine a suitable value for $K$ so that the system damping ratio is greater than 0.30. From Equation (9.63), we find that it is required that $M_{p \omega}$ be less than $1.75(4.9 \mathrm{~dB})$. From Figure 9.28, we find that the $G_{c}(j \omega) G(j \omega)$-locus will be tangent to the $4.9-\mathrm{dB}$ curve if the magnitude is lowered by a factor of $2.2 \mathrm{~dB}$. Therefore, $K$ should be reduced by 1.28 . Thus, the gain $K$ must be less than $0.64 / 1.28=0.50$ if the system damping ratio is to be greater than 0.30 . 

\subsection{SYSTEM BANDWIDTH}

The bandwidth of the closed-loop control system is an excellent measure of the response of the system. In systems where the low-frequency magnitude is $0 \mathrm{~dB}$ on the Bode plot, the bandwidth is measured at the $-3-\mathrm{dB}$ frequency. The speed of response to a step input will be roughly proportional to $\omega_{B}$, and the settling time is inversely proportional to $\omega_{B}$. Thus, we seek a large bandwidth consistent with reasonable system components [12].

Consider the two second-order systems with closed-loop transfer functions

$$
T_{1}(s)=\frac{100}{s^{2}+10 s+100} \quad \text { and } \quad T_{2}(s)=\frac{900}{s^{2}+30 s+900} .
$$

Both systems have $\zeta=0.5$. The frequency response of both closed-loop systems is shown in Figure 9.29(a). The natural frequency is $\omega_{n_{1}}=10$ and $\omega_{n_{2}}=30$ for systems $T_{1}(s)$ and $T_{2}(s)$, respectively. The bandwidth is $\omega_{B_{1}}=12.7$ and $\omega_{B_{2}}=38.1$ for systems $T_{1}(s)$ and $T_{2}(s)$, respectively. Both systems have a $P . O .=16 \%$, but $T_{1}(s)$ has a peak time of $T_{p}=0.12 \mathrm{~s}$ compared to $T_{p}=0.36$ for $T_{2}(\mathrm{~s})$, as shown in Figure 9.29(b). Also, note that the settling time for $T_{2}(s)$ is $T_{s}=0.27 \mathrm{~s}$, while the settling time for $T_{1}(s)$ is $T_{s}=0.8 \mathrm{~s}$. The system with a larger bandwidth provides a faster response.

\subsection{THE STABILITY OF CONTROL SYSTEMS WITH TIME DELAYS}

Many control systems have a time delay within the closed loop of the system that affects the stability. A time delay is the time interval between the start of an event at one point in a system and its resulting action at another point in the system. Fortunately, the Nyquist criterion can be utilized to determine the effect of the time delay on the relative stability of the feedback system. A pure time delay, without attenuation, is represented by the transfer function

$$
G_{d}(s)=e^{-s T}
$$

where $T$ is the delay time. The Nyquist criterion remains valid for a system with a time delay because the factor $e^{-s T}$ does not introduce any additional poles or zeros within the contour. The factor adds a phase shift to the frequency response without altering the magnitude curve.

This type of time delay occurs in systems that have a movement of a material that requires a finite time to pass from an input or control point to an output or measured point $[8,9]$. For example, a steel rolling mill control system is shown in Figure 9.30. The motor adjusts the separation of the rolls so that the thickness error is minimized. If the steel is traveling at a velocity $v$, then the time delay between the roll adjustment and the measurement is

$$
T=\frac{d}{v}
$$

Therefore, to have a negligible time delay, we must decrease the distance to the measurement and increase the velocity of the flow of steel. Usually, we cannot eliminate the effect of time delay; thus, the loop transfer function is [10]

$$
L(s)=G_{c}(s) G(s) e^{-s T} .
$$

FIGURE 9.29

Response of two second-order systems.

FIGURE 9.30 Steel rolling mill control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0657.jpg?height=487&width=1094&top_left_y=152&top_left_x=375)

Frequency $(\mathrm{rad} / \mathrm{s})$

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0657.jpg?height=602&width=1108&top_left_y=750&top_left_x=375)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0657.jpg?height=308&width=640&top_left_y=1403&top_left_x=430)

The frequency response of this system is obtained from

$$
L(j \omega)=G_{c}(j \omega) G(j \omega) e^{-j \omega T} .
$$

The frequency response of the loop transfer function is graphed on the Nyquist plot and the stability ascertained relative to the -1 point. Alternatively, we can obtain the Bode plot including the delay factor and investigate the stability relative to the $0-\mathrm{dB},-180^{\circ}$ point. The delay factor $e^{-j \omega T}$ results in a phase shift

$$
\phi(\omega)=-\omega T
$$

and is readily added to the phase shift resulting from $G_{c}(j \omega) G(j \omega)$. Note that the angle is in radians in Equation (9.80). An example will show the simplicity of this approach on the Bode diagram.

\section{EXAMPLE 9.9 Liquid level control system}

A level control system is shown in Figure 9.31(a) and the block diagram in Figure 9.31(b) [11]. The time delay between the valve adjustment and the fluid output is $T=d / v$. Therefore, if the flow rate is $v=5 \mathrm{~m}^{3} / \mathrm{s}$, and the distance is equal to $d=5 \mathrm{~m}$, then we have a time delay $T=1 \mathrm{~s}$. The loop transfer function is then

$$
\begin{aligned}
L(s) & =G_{A}(s) G(s) G_{f}(s) e^{-s T} \\
& =\frac{31.5}{(s+1)(30 s+1)\left[\left(s^{2} / 9\right)+(s / 3)+1\right]} e^{-s T} .
\end{aligned}
$$

The Bode plot for this system is shown in Figure 9.32. The phase angle is shown both for the denominator factors alone and with the additional phase lag due to the time delay. The logarithmic gain curve crosses the 0 - $\mathrm{dB}$ line at $\omega=0.8$. Therefore, the phase margin of the system without the pure time delay would be P.M. $=40^{\circ}$. However, with the time delay added, we find that the phase margin is equal to $P . M .=-3^{\circ}$, and the system is unstable. Consequently, the system gain must be reduced in order to provide a reasonable phase margin. To provide a phase margin of $P . M .=30^{\circ}$, the gain would have to be decreased by a factor of $5 \mathrm{~dB}$, to $K=31.5 / 1.78=17.7$.

A time delay $e^{-s T}$ in a feedback system introduces an additional phase lag and results in a less stable system. Therefore, as pure time delays are unavoidable in many systems, it is often necessary to reduce the loop gain in order to obtain a stable response. However, the cost of stability is the resulting increase in the steadystate error of the system as the loop gain is reduced.

The systems considered by most analytical tools are described by rational functions (that is, transfer functions) or by a finite set of ordinary constant coefficient differential equations. Since the time-delay is given by $e^{-s T}$, where $T$ is the delay, we see that the time delay is nonrational. It would be helpful if we could obtain a rational function approximation of the time-delay. Then it would be more convenient to incorporate the delay into the block diagram for analysis and design purposes.

The Padé approximation uses a series expansion of the transcendental function $e^{-s T}$ and matches as many coefficients as possible with a series expansion of a rational function of specified order. For example, to approximate the function $e^{-s T}$ with a first-order rational function, we begin by expanding both functions in a series (actually a Maclaurin series ${ }^{1}$ ),

$$
\begin{gathered}
e^{-s T}=1-s T+\frac{(s T)^{2}}{2 !}-\frac{(s T)^{3}}{3 !}+\frac{(s T)^{4}}{4 !}-\frac{(s T)^{5}}{5 !}+\cdots, \\
{ }^{1} f(s)=f(0)+\frac{s}{1 !} f(0)+\frac{s^{2}}{2 !} f(0)+\cdots
\end{gathered}
$$

FIGURE 9.31

(a) Liquid level control system.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0659.jpg?height=592&width=1008&top_left_y=139&top_left_x=368)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0659.jpg?height=364&width=1192&top_left_y=820&top_left_x=373)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0659.jpg?height=708&width=848&top_left_y=1405&top_left_x=374)

Frequency (rad/s)
FIGURE 9.32

Bode plot for the liquid level control system. and

$$
\frac{n_{1} s+n_{0}}{d_{1} s+d_{0}}=\frac{n_{0}}{d_{0}}+\left(\frac{d_{0} n_{1}-n_{0} d_{1}}{d_{0}^{2}}\right) s+\left(\frac{d_{1}^{2} n_{0}}{d_{0}^{3}}-\frac{d_{1} n_{1}}{d_{0}^{2}}\right) s^{2}+\cdots
$$

For a first-order approximation, we want to find $n_{0}, n_{1}, d_{0}$, and $d_{1}$ such that

$$
e^{-s T} \approx \frac{n_{1} s+n_{0}}{d_{1} s+d_{0}}
$$

Equating the corresponding coefficients of the terms in $s$, we obtain the relationships

$$
\frac{n_{0}}{d_{0}}=1, \frac{n_{1}}{d_{0}}-\frac{n_{0} d_{1}}{d_{0}^{2}}=-T, \frac{d_{1}^{2} n_{0}}{d_{0}^{3}}-\frac{d_{1} n_{1}}{d_{0}^{2}}=\frac{T^{2}}{2}, \cdots
$$

Solving for $n_{0}, d_{0}, n_{1}$, and $d_{1}$ yields

$$
n_{0}=d_{0}, d_{1}=\frac{d_{0} T}{2}, \quad \text { and } \quad n_{1}=-\frac{d_{0} T}{2} .
$$

Setting $d_{0}=1$ and solving yields

$$
e^{-s T} \approx \frac{n_{1} s+n_{0}}{d_{1} s+d_{0}}=\frac{-\frac{T}{2} s+1}{\frac{T}{2} s+1} .
$$

A series expansion of Equation (9.83) yields

$$
\frac{n_{1} s+n_{0}}{d_{1} s+d_{0}}=\frac{-\frac{T}{2} s+1}{\frac{T}{2} s+1}=1-T s+\frac{T^{2} s^{2}}{2}-\frac{T^{3} s^{3}}{4}+\cdots
$$

Comparing Equation (9.84) to Equation (9.82), we verify that the first three terms match. So for small $s$, the Padé approximation is a reasonable representation of the time-delay. Higher-order rational functions can be obtained.

\subsection{DESIGN EXAMPLES}

In this example, we present three illustrative examples. The first example we consider is a design problem that supports green engineering and involves controlling the pitch angles of blades on large-scale wind turbines. The wind speeds are assumed to be high enough so that the pitch angle of the turbine blades can be prescribed properly to shed excess power to regulate the generated wind power at desired levels. The second example is a remotely controlled reconnaissance vehicle control design. The Nichols chart is illustrated as a key element of the design of a controller gain to meet time-domain specifications. The third example considers the control of a hot ingot robot used in manufacturing. The goal is to minimize the tracking error in the presence of disturbances and a known time-delay. The design process is illustrated, leading to a PI controller that meets a mixture of time-domain and frequency-domain performance specifications.

\section{EXAMPLE 9.10 PID control of wind turbines for clean energy}

Wind energy is currently the fastest-growing energy source in the world. It is a cost-effective, environmentally friendly solution to energy needs. Modern wind turbines are large, flexible structures operating in uncertain environments as wind direction and flow constantly changes. There are many controls challenges associated with efficient energy capture and delivery for wind turbines. In this design problem, we consider the so-called "above-rated" operational mode of the wind turbine. In this mode, the wind speeds are high enough that the pitch angle of the turbine blades needs to be prescribed properly to shed excess power so that the generated wind power is regulated at desired levels. This mode of operation readily permits the application of linear control theory.

Wind turbines are generally constructed in either a vertical axis configuration or a horizontal axis configuration, as shown in Figure 9.33. The horizontal axis configuration is the most common for energy production today. A horizontal axis wind turbine is mounted on a tower with two or three blades rotating placed atop a tall tower and driving an electric generator. The high placement of the blades takes advantage of the higher wind velocities. The vertical axis wind turbines are generally smaller and present a reduced noise footprint.

When there is sufficient wind, in order to regulate the rotor speed of the turbine shaft and thus the generator, the pitch of the wind turbine blades is collectively adjusted using a blade pitch motor, as illustrated in Figure 9.34(a). A simplified model of the turbine from the pitch command to the rotor speed is obtained by including a generator mode represented by a first-order transfer function in series with the

FIGURE 9.33

(a) Vertical axis wind turbine (photo courtesy of Visions of America/ SuperStock), and (b) horizontal axis wind turbine (photo courtesy of David Williams/Alamy).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0661.jpg?height=640&width=480&top_left_y=1442&top_left_x=447)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0661.jpg?height=640&width=421&top_left_y=1432&top_left_x=956)

(b) drive train compliance represented by a second-order transfer function [32]. The third-order transfer function of the turbine is given by

$$
G(s)=\left[\frac{1}{\tau s+1}\right]\left[\frac{K \omega_{n_{g}}^{2}}{s^{2}+2 \zeta \omega_{n_{g}} s+\omega_{n_{g}}^{2}}\right],
$$

where $K=-7000, \tau_{g}=5 \mathrm{~s}, \zeta_{g}=0.005$, and $\omega_{n_{g}}=20 \mathrm{rad} / \mathrm{s}$. The input to the turbine model is the commanded pitch angle (in radians) plus disturbances and the output is the rotor speed (in rpm). For commercial wind turbines, pitch control is often achieved using a PID controller, as shown in Figure 9.34(b). Selecting a PID controller requires selecting the coefficients of the controller $K_{P}, K_{I}$, and $K_{D}$. The objective is to design the PID system for fast and accurate control. The control specifications are gain margin G.M. $\geq 6 \mathrm{~dB}$ and phase margin $30^{\circ} \leq$ P.M. $\leq 60^{\circ}$. The specifications for the transient response are rise time $T_{r_{1}}<4 \mathrm{~s}$ and time to peak $T_{P}<10 \mathrm{~s}$.

The output $\omega(s)$ shown in Figure 9.34 is actually the deviation from the rated speed of the turbine. At the rated speed, the pitch control of the blades is used to regulate the rotor speed. In the linear setting described by Figure 9.34, the input desired rotor speed $\omega_{d}(s)=0$ and the goal is to regulate the output to zero in the presence of disturbances.

The loop transfer function is

$$
L(s)=K \omega_{n_{g}}^{2} K_{D} \frac{s^{2}+\left(K_{P} / K_{D}\right) s+\left(K_{I} / K_{D}\right)}{s(\tau s+1)\left(s^{2}+2 \zeta \omega_{n_{g}} s+\omega_{n_{g}}^{2}\right)} .
$$

The objective is to determine the gains $K_{P}, K_{I}$, and $K_{D}$ to meet the control design specifications. The phase margin specification can be used to determine a target damping of the dominant roots yielding

FIGURE 9.34

(a) Block diagram model of the wind turbine system.

(b) Block diagram for control system design.

$$
\zeta=\frac{P . M .}{100}=0.3,
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0662.jpg?height=428&width=1250&top_left_y=1317&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0662.jpg?height=256&width=1261&top_left_y=1824&top_left_x=508)

(b) where we target for a phase margin P.M. $=30^{\circ}$. Then we utilize the rise time design formula to obtain a target natural frequency of the dominant roots. To this end, we use the design formula

$$
T_{r_{1}}=\frac{2.16 \zeta+0.6}{\omega_{n}}<4 \mathrm{~s}
$$

to obtain $\omega_{n}>0.31$ when $\zeta=0.3$. For design purposes, we choose $\omega_{n}=0.4$ and $\zeta=0.3$ for the dominant poles. As a final check on the target damping and natural frequency, we verify that the time to peak specification is reachable with $\omega_{n}=0.4$ and $\zeta=0.3$. The rise time and time to peak are estimated to be

$$
T_{r_{1}}=\frac{2.16 \zeta+0.6}{\omega_{n}}=3 \mathrm{~s} \text { and } T_{P}=\frac{\pi}{\omega_{n} \sqrt{1-\zeta^{2}}}=8 \mathrm{~s},
$$

which meet the design specification. First we locate the PID zeros in the left halfplane in the desired performance region defined by $\omega_{n}$ and $\zeta$ by specifying the ratios $K_{P} / K_{D}$ and $K_{I} / K_{D}$ and select the gain $K_{D}$ to meet the phase margin and gain margin specifications using frequency response plots (that is, Bode plot).

The Bode plot is shown in Figure 9.35, where $K_{P} / K_{D}=5$ and $K_{I} / K_{D}=20$. The value of $K_{D}=-6.22 \times 10^{-6}$ was determined by observing the effects of varying the gain on the phase and gain margins and selecting the gain that satisfied the specifications as closely as possible. The PID controller is then given by

$$
G_{c}(s)=-6.22 \times 10^{-6}\left[\frac{s^{2}+5 s+20}{s}\right] .
$$

The final design results in a phase margin of $P . M .=32.9^{\circ}$ and a gain margin of $G . M .=13.9 \mathrm{~dB}$. The step response is shown in Figure 9.36. The rise time $T_{r_{1}}=3.2 \mathrm{~s}$ and the time to peak $T_{P}=7.6 \mathrm{~s}$. All the specifications are satisfied.

FIGURE 9.35

Bode plot with $K_{P} / K_{D}=5$, $K_{1} / K_{D}=20$, and $K_{D}=-6.22 \times 10^{-6}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0663.jpg?height=786&width=1000&top_left_y=1350&top_left_x=374)FIGURE 9.36

Closed-loop step response to a unit step showing rise time and time to peak specifications are satisfied.
FIGURE 9.37

Disturbance response showing the rotor speed deviation from the rated speed.
The dominant poles of the closed-loop feedback control system are $\omega_{n}=0.41$ and $\zeta=0.29$. This is very close to the design values which demonstrates the effectiveness of the design formulas even when the system under consideration is not a second-order system.

The response of the wind turbine to an impulsive disturbance is shown in Figure 9.37. In this numerical experiment, the disturbance (possibly a wind gust) imparts a step change in the wind turbine blade pitch angle. In practice, the disturbance would lead to varying pitch angle disturbances on the each blade, but for purposes of demonstration, we model this as a single step disturbance input. The result of the disturbance is a change on the rotor speed from the nominal that is brought back to zero in about 25 seconds.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0664.jpg?height=1428&width=878&top_left_y=679&top_left_x=520)

\section{EXAMPLE 9.11 Remotely controlled vehicle}

One concept of a remotely controlled vehicle is shown in Figure 9.38(a), $R(s)$ and a proposed speed control system is shown in Figure 9.38(b). The desired speed is transmitted by radio to the vehicle; the disturbance $T_{d}(s)$ represents hills and rocks. The goal is to achieve good overall control with a low steady-state error and a low-overshoot response to step commands, $R(s)$ [13].

First, to achieve a low steady-state error for a unit step command, we calculate

$$
\begin{aligned}
e_{s s} & =\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} s\left[\frac{R(s)}{1+L(s)}\right] \\
& =\frac{1}{1+L(s)}=\frac{1}{1+K / 2},
\end{aligned}
$$

where $L(s)=G_{c}(s) G(s)$. If we select $K=20$, we will obtain a steady-state error of $9 \%$ of the magnitude of the input command. Using $K=20$, we reformulate $L(s)=G_{c}(s) G(s)$ for the Bode plot calculations, obtaining

$$
L(s)=G_{c}(s) G(s)=\frac{10(1+s / 2)}{(1+s)\left(1+s / 2+s^{2} / 4\right)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0665.jpg?height=548&width=1094&top_left_y=1137&top_left_x=375)

FIGURE 9.38

(a) Remotely controlled reconnaissance vehicle. (b) Speed control system. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0665.jpg?height=284&width=1038&top_left_y=1782&top_left_x=429)

(b) The Nichols chart for $K=20$ is shown in Figure 9.39. Examining the Nichols chart, we find that $M_{p \omega}=12 \mathrm{~dB}$ and the phase margin is $P . M .=15^{\circ}$. The step response of this system is underdamped, and we use Equation (9.58) to compute $\zeta \simeq 0.15$ to predict an excessive overshoot of approximately P.O. $=61 \%$.

To reduce the percent overshoot to a step input, we can reduce the gain to achieve a predicted overshoot. To limit the percent overshoot to P.O. $=25 \%$, we select a desired $\zeta$ of the dominant roots as 0.4 and thus require $M_{p \omega}=1.35$ (from Equation (9.63)) or $20 \log \mathrm{M}_{p \omega}=2.6 \mathrm{~dB}$. To lower the gain, we will move the frequency response vertically down on the Nichols chart, as shown in Figure 9.39. At $\omega_{1}=2.8$, we just intersect the $2.6-\mathrm{dB}$ closed-loop curve. The reduction (vertical drop) in gain is equal to $13 \mathrm{~dB}$, or a factor of 4.5. Thus, $K=20 / 4.5=4.44$. For this reduced gain, the steady-state error is

$$
e_{\mathrm{SS}}=\frac{1}{1+4.4 / 2}=0.31,
$$

so that we have a $e_{\mathrm{ss}}=31 \%$ steady-state error.

FIGURE 9.39

Nichols chart for the design example when $K=20$ and for two reduced gains.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0666.jpg?height=1197&width=926&top_left_y=926&top_left_x=506)

FIGURE 9.40

The response of the system for three values of $K$ for a unit step input $r(t)$.

The actual step response when $K=4.44$, as shown in Figure 9.40, has an overshoot of P.O. $=32 \%$. If we use a gain of 10 , we have a percent overshoot of P.O. $=48 \%$ with a steady-state error of $e_{\mathrm{ss}}=17 \%$. The performance of the system is summarized in Table 9.2. As a suitable compromise, we select $K=10$ and draw the frequency response on the Nichols chart by moving the response for $K=20$ down by $20 \log 2=6 \mathrm{~dB}$, as shown in Figure 9.39.

Examining the Nichols chart for $K=10$, we have $M_{p \omega}=7 \mathrm{~dB}$, and a phase margin of P.M. $=26^{\circ}$. Thus, we estimate a $\zeta$ for the dominant roots of $\zeta=0.26$ which should result in an overshoot to a step input of $P . O .=43 \%$. The actual response is recorded in Table 9.2. The bandwidth of the system is $\omega_{B}=5.4 \mathrm{rad} / \mathrm{s}$. Therefore, we predict a settling time (with a $2 \%$ criterion) of

$$
T_{s}=\frac{4}{\zeta \omega_{n}}=\frac{4}{(0.26)(3.53)}=4.4 \mathrm{~s},
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0667.jpg?height=906&width=1058&top_left_y=789&top_left_x=374)

Table 9.2 Actual Response for Selected Gains

$\boldsymbol{K}$

Percent overshoot (\%)

Settling time (seconds)

Peak time (seconds)

$e_{s s}$
4.44

32.4

4.94

1.19

$31 \%$
10

48.4

5.46

0.88

$16.7 \%$
20

61.4

6.58

0.67

$9.1 \%$ FIGURE 9.41

Artist's depiction of the hot ingot robot control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0668.jpg?height=614&width=1045&top_left_y=154&top_left_x=517)

since

$$
\omega_{n}=\frac{\omega_{B}}{-1.19 \zeta+1.85}
$$

The actual settling time is approximately $T_{s}=5.4 \mathrm{~s}$, as shown in Figure 9.41. The steady-state effect of a unit step disturbance can be determined by using the final-value theorem with $R(s)=0$, as follows:

$$
y(\infty)=\lim _{s \rightarrow 0} s\left[\frac{G(s)}{1+L(s)}\right]\left(\frac{1}{s}\right)=\frac{1}{4+2 K} .
$$

Thus, the unit disturbance is reduced by the factor $4+2 K$. For $K=10$, we have $y(\infty)=1 / 24$, or the steady-state disturbance is reduced to $4 \%$ of the disturbance magnitude. Thus we have achieved a reasonable result with $K=10$.

The best compromise design would be $K=10$, since we achieve a compromise steady-state error of $e_{s s}=16.7 \%$. If the percent overshoot and settling time are excessive, then we need to reshape the frequency response on the Nichols chart.

\section{EXAMPLE 9.12 Hot ingot robot control}

The hot ingot robot mechanism is shown in Figure 9.41. The robot picks up hot ingots and sets them in a quenching tank. A vision sensor is in place to provide a measurement of the ingot position. The controller uses the sensed position information to orient the robot over the ingot (along the $x$-axis). The vision sensor provides the desired position input $R(s)$ to the controller. The block diagram depiction of the closed-loop system is shown in Figure 9.42. More information on robots and robot vision systems can be found in $[15,30,31]$.

The position of the robot along the track is also measured (by a sensor other than the vision sensor) and is available for feedback to the controller. We assume that the position measurement is noise free. This is not a restrictive assumption FIGURE 9.42

Hot ingot robot control system block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0669.jpg?height=233&width=1192&top_left_y=156&top_left_x=373)

since many accurate position sensors are available today. For example some laser diode systems are self-contained (including the power supply, optics, and laser diode) and provide position accuracy of over $99.9 \%$.

The robot dynamics are modeled as a second-order system with two poles at $s=-1$ and include a time delay of $T=\pi / 4 \mathrm{~s}$. Therefore,

$$
G(s)=\frac{e^{-s T}}{(s+1)^{2}},
$$

where $T=\pi / 4 \mathrm{~s}$. The elements of the design process emphasized in this example are highlighted in Figure 9.43. The control goal is as follows:

\section{Control Goal}

Minimize the tracking error $E(s)=R(s)-Y(s)$ in the presence of external disturbances while accounting for the known time-delay.

To this end the following control specifications must be satisfied:

\section{Design Specifications}

DS1 Achieve a steady-state tracking error $e_{s s} \leq 10 \%$ for a step input.

DS2 Phase margin P.M. $\geq 50^{\circ}$ with the time-delay $T=\pi / 4 \mathrm{~s}$.

DS3 Percent overshoot P.O. $\leq 10 \%$ for a step input.

Our design method is first to consider a proportional controller. We will show that the design specifications cannot be simultaneously satisfied with a proportional controller; however, the feedback system with proportional control provides a useful vehicle to discuss in some detail the effects of the time-delay. In particular, we consider the effects of the time-delay on the Nyquist plot. The final design uses a PI controller, which is capable of providing adequate performance (that is, it satisfies all design specifications).

As a first attempt, we consider a simple proportional controller:

$$
G_{c}(s)=K .
$$

Then ignoring the time-delay for the moment, we have the loop gain

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+1)^{2}}=\frac{K}{s^{2}+2 s+1} .
$$

Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0670.jpg?height=1020&width=1164&top_left_y=238&top_left_x=500)

FIGURE 9.43 Elements of the control system design process emphasized in the hot ingot robot control example.

FIGURE 9.44

Hot ingot robot control system block diagram with the proportional controller and no time-delay.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0670.jpg?height=294&width=1226&top_left_y=1377&top_left_x=469)

The feedback control system is shown in Figure 9.44 with a proportional controller and no time-delay. The system is a type-zero system, so we expect a nonzero steadystate tracking error to a step input. The closed-loop transfer function is

$$
T(s)=\frac{K}{s^{2}+2 s+1+K} .
$$

With the tracking error defined as

$$
E(s)=R(s)-Y(s),
$$

and with $R(s)=a / s$, where $a$ is the input magnitude, we have

$$
E(s)=\frac{s^{2}+2 s+1}{s^{2}+2 s+1+K} \frac{a}{s} .
$$

Using the final value theorem (which is possible since the system is stable for all positive values of $K$ ) yields

$$
e_{\mathrm{Ss}}=\lim _{s \rightarrow 0} s E(s)=\frac{a}{1+K}
$$

Per specification DS1, we require the steady-state tracking error be less than $10 \%$. Therefore,

$$
e_{\mathrm{Ss}} \leq \frac{a}{10}
$$

Solving for the appropriate gain $K$ yields $K \geq 9$. With $K=9$, we obtain the Bode plot shown in Figure 9.45.

If we raise the gain above $K=9$, we find that the crossover moves to the right (that is, $\omega_{c}$ increases) and the corresponding phase margin decreases. Is a $P . M .=38.9^{\circ}$ at $\omega=2.8 \mathrm{rad} / \mathrm{s}$ sufficient for stability in the presence of a time-delay of $T=\pi / 4 \mathrm{~s}$ ? The addition of the time-delay term causes a phase lag without changing the magnitude plot. The amount of time-delay that our system can withstand while remaining stable is $\phi=-\omega T$ which implies that

$$
\frac{-38.9 \pi}{180}=-2.8 T \text {. }
$$

FIGURE 9.45 Bode plot with $K=9$ and no timedelay showing gain margin G.M. $=\infty$ and phase margin P.M. $=38.9^{\circ}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0671.jpg?height=752&width=998&top_left_y=1370&top_left_x=374)Solving for $T$ yields $T=0.24 \mathrm{~s}$. Thus for time-delays less than $T=0.24 \mathrm{~s}$, our closed-loop system remains stable. However, the time-delay $T=\pi / 4 \mathrm{~s}$ will cause instability. Raising the gain only exacerbates matters, since the phase margin goes down further. Lowering the gain raises the phase margin, but the steady-state tracking error exceeds the $10 \%$ limit. A more complex controller is necessary. Before proceeding, let us consider the Nyquist plot and see how it changes with the addition of the time-delay. The Nyquist plot for the system (without the time-delay)

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+1)^{2}}
$$

is shown in Figure 9.46, where we use $K=9$. The number of open-loop poles of $G_{c}(s) G(s)$ in the right half-plane is $P=0$. From Figure 9.46 we see that there are no encirclements of the -1 point, thus, $N=0$.

By the Nyquist theorem, we know that the net number of encirclements $N$ equals the number of zeros $Z$ (or closed-loop system poles) in the right half-plane minus the number of open-loop poles $P$ in the right half-plane. Therefore,

$$
Z=N+P=0 .
$$

Since $Z=0$, the closed-loop system is stable. More importantly, even when the gain $K$ is increased (or decreased), the -1 point is never encircled-the gain margin is $\infty$. Similarly when the time-delay is absent, the phase margin is always positive. The value of the P.M. varies as $K$ varies, but the P.M. is always greater than zero.

With the time-delay in the loop, we can rely on analytic methods to obtain the Nyquist plot. The loop transfer function with the time-delay is

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+1)^{2}} e^{-s T} .
$$

FIGURE 9.46 Nyquist plot with $K=9$ and no time-delay showing no encirclements of the minus 1 point.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0672.jpg?height=746&width=969&top_left_y=1358&top_left_x=520)

Using the Euler identity

$$
e^{-j \omega T}=\cos (\omega T)-j \sin (\omega T),
$$

$L(s)$ and substituting $s=j \omega$ into $L(s)$ yields

$$
\begin{aligned}
& L(j \omega)=\frac{K}{(j \omega+1)^{2}} e^{-j \omega T} \\
& =\frac{K}{\Delta}\left(\left[\left(1-\omega^{2}\right) \cos (\omega T)-2 \omega \sin (\omega T)-j\left(1-\omega^{2}\right) \sin (\omega T)+2 \omega \cos (\omega T)\right],\right.
\end{aligned}
$$

where

$$
\Delta=\left(1-\omega^{2}\right)^{2}+4 \omega^{2}
$$

Generating a plot of $\operatorname{Re}(L(j \omega))$ versus $\operatorname{Im}(L(j \omega))$ yields the plot shown in Figure 9.47. With $K=9$, the number of encirclements of the -1 point is $N=2$. Therefore, the system is unstable since $Z=N+P=2$.

Figure 9.48 shows the Nyquist plot for four values of time-delay: $T=0,0.1$, 0.24 , and $\pi / 4=0.78 \mathrm{~s}$. For $T=0$ there is no possibility of an encirclement of the -1 point as $K$ varies (see the upper left graph of Figure 9.48). We have stability (that is, $N=0$ ) for $T=0.1 \mathrm{~s}$ (upper right graph), marginal stability for $T=0.24 \mathrm{~s}$ (lower left graph), and for $T=\pi / 4=0.78 \mathrm{~s}$ we have $N=1$ (lower right graph), thus the closed-loop system is unstable.

Since we know that $T=\pi / 4$ in this example, the proportional gain controller is not a viable controller. With it we cannot meet the steady-state error specifications and have a stable closed-loop system in the presence of the time-delay $T=\pi / 4$.

FIGURE 9.47 Nyquist plot with $K=9$ and $T=\pi / 4$ showing two encirclements of the -1 point, $N=2$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0673.jpg?height=772&width=997&top_left_y=1338&top_left_x=374)


![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0674.jpg?height=868&width=1226&top_left_y=162&top_left_x=488)

FIGURE 9.48 Nyquist plot with $K=9$ and various time-delays.

However, before proceeding with the design of a controller that meets all the specifications, let us take a closer look at the Nyquist plot with a time-delay.

Suppose we have the case where $K=9$ and $T=0.1 \mathrm{~s}$. The associated Nyquist plot is shown in the upper right of Figure 9.48. The Nyquist plot intersects (or crosses over) the real axis whenever the imaginary part of $G_{c}(j \omega) G(j \omega)=0$, or

$$
\left(1-\omega^{2}\right) \sin (0.1 \omega)+2 \omega \cos (0.1 \omega)=0 .
$$

Thus we obtain the relation that describes the frequencies $\omega$ at which crossover occurs:

$$
\frac{\left(1-\omega^{2}\right) \tan (0.1 \omega)}{2 \omega}=-1 .
$$

Equation (9.90) has an infinite number of solutions. The first real-axis crossing (farthest in the left half-plane) occurs when $\omega=4.43 \mathrm{rad} / \mathrm{s}$.

The magnitude of $|L(j 4.43)|$ is equal to $0.0484 \mathrm{~K}$. For stability we require that $|L(j \omega)|<1$ when $\omega=4.43$ (to avoid an encirclement of the -1 point). Thus, for stability we find

$$
K<\frac{1}{0.0484}=20.67
$$

when $T=0.1$. When $K=9$, the closed-loop system is stable, as we already know. If the gain $K=9$ increases by a factor of 2.3 to $K=20.67$, we will be on the border of instability. This factor $\delta$ is the gain margin:

$$
\text { G.M. }=20 \log _{10} 2.3=7.2 \mathrm{~dB} .
$$

Consider the PI controller

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=\frac{K_{P} s+K_{I}}{s} .
$$

The loop system transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K_{P} s+K_{I}}{s} \frac{K}{(s+1)^{2}} e^{-s T} .
$$

The system type is now equal to 1; thus we expect a zero steady-state error to a step input. The steady-state error specification DS1 is satisfied. We can now concentrate on meeting specification DS3, P.O. $<10 \%$ and DS2, the requirement for stability in the presence of the time-delay $T=\pi / 4 \mathrm{~s}$.

From the percent overshoot specification we can determine a desired system damping ratio. Thus we determine for P.O. $\leq 10 \%$ that $\zeta \geq 0.59$. Due to the PI controller, the system now has a zero at $s=-K_{I} / K_{P}$. The zero will not affect the closed-loop system stability, but it will affect the performance. Using the approximation (valid for small $\zeta, P . M$. expressed in degrees)

$$
\zeta \approx \frac{P \cdot M .}{100}
$$

we determine a good target phase margin (since we want $\zeta \geq 0.59$ ) to be $60 \%$. We can rewrite the PI controller as

$$
G_{c}(s)=K_{I} \frac{1+\tau s}{s},
$$

where $1 / \tau=K_{I} / K_{P}$ is the break frequency of the controller. The PI controller is essentially a low-pass filter and adds phase lag to the system below the break frequency. We would like to place the break frequency below the crossover frequency so that the phase margin is not reduced significantly due to the presence of the PI zero.

The uncompensated Bode plot is shown in Figure 9.49 for

$$
G(s)=\frac{9}{(s+1)^{2}} e^{-s T},
$$

where $T=\pi / 4$. The uncompensated system phase margin is $P . M .=-88.34^{\circ}$ at $\omega_{c}=2.83 \mathrm{rad} / \mathrm{s}$. Since we want P.M. $=60^{\circ}$, we need the phase to be minus $120^{\circ}$ at the crossover frequency. In Figure 9.49 we can estimate the phase $\phi=-120^{\circ}$ at $\omega \approx 0.87 \mathrm{rad} / \mathrm{s}$. This is an approximate value but is sufficiently accurate for the design procedure. At $\omega=0.87$ the magnitude is about $14.5 \mathrm{~dB}$. If we want the FIGURE 9.49

Uncompensated Bode plot with $K=9$ and $T=\pi / 4$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0676.jpg?height=856&width=1138&top_left_y=166&top_left_x=520)

crossover to be $\omega_{c}=0.87 \mathrm{rad} / \mathrm{s}$, the controller needs to attenuate the system gain by $14.5 \mathrm{~dB}$, so that the magnitude is $0 \mathrm{~dB}$ at $\omega_{c}=0.87$. With

$$
G_{c}(s)=K_{p} \frac{s+\frac{K_{I}}{K_{P}}}{s},
$$

we can consider $K_{P}$ to be the gain of the compensator (a good approximation for large $\omega)$. Therefore,

$$
K_{P}=10^{-(14.5 / 20)}=0.188
$$

Finally we need to select $K_{I}$. Since we want the break frequency of the controller to be below the crossover frequency (so that the phase margin is not reduced significantly due to the presence of the PI zero), a good rule-of-thumb is to select $1 / \tau=K_{I} / K_{P}=0.1 \omega_{c}$. To make the break frequency of the controller zero one decade below the crossover frequency. The final value of $K_{I}$ is computed to be $K_{I}=0.1 \omega_{c} K_{P}=0.0164$, where $\omega_{c}=0.87 \mathrm{rad} / \mathrm{s}$. Thus the PI controller is

$$
G_{c}(s)=\frac{0.188 s+0.0164}{s} .
$$

The Bode plot of $G_{c}(s) G(s) e^{-s T}$ is shown in Figure 9.50, where $T=\pi / 4$. The gain and phase margins are G.M. $=5.3 \mathrm{~dB}$ and $P . M .=56.5^{\circ}$.

We consider whether the design specifications have been met. The steadystate tracking specification (DS1) is certainly satisfied since our system is type one; FIGURE 9.50

Compensated Bode plot with $K=9$ and $T=\pi / 4$ and with its $\mathrm{PI}$ controller.

FIGURE 9.51 Hot ingot robot control step response with the PI controller.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0677.jpg?height=1692&width=1148&top_left_y=166&top_left_x=375)

the PI controller introduced an integrator. The phase margin (with the time-delay) is $P . M .=56.5^{\circ}$, so the phase margin specification, DS2, is satisfied. The unit step response is shown in Figure 9.51. The percent overshoot is approximately P.O. $\approx 4.2 \%$. The target percent overshoot was P.O. $=10 \%$, so DS3 is satisfied. Overall the design specifications are satisfied. 

\subsection{PID CONTROLLERS IN THE FREQUENCY DOMAIN}

The PID controller provides a proportional term, an integral term, and a derivative term. We then have the PID controller transfer function as

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+\mathrm{K}_{D} s
$$

In general, we note that PID controllers are particularly useful for reducing the steady-state error and improving the transient response when $G(s)$ has one or two poles (or may be approximated by a second-order process).

We may use frequency response methods to represent the addition of a PID controller. The PID controller, Equation (9.93), may be rewritten as

$$
G_{c}(s)=\frac{K_{I}\left(\frac{K_{D}}{K_{I}} s^{2}+\frac{K_{P}}{K_{I}} s+1\right)}{s}=\frac{K_{I}(\tau s+1)\left(\frac{\tau}{\alpha} s+1\right)}{s} .
$$

The Bode plot of Equation (9.94) is shown in Figure 9.52 for $K_{I}=2, \tau=1$, and $\alpha=10$. The PID controller is a form of a notch (or bandstop) compensator with a variable gain, $K_{I}$. Of course, it is possible that the controller will have complex zeros and a Bode plot that will be dependent on the $\zeta$ of the complex zeros. The PID controller with complex zeros is

$$
G_{c}(j \omega)=\frac{K_{I}\left[1+\left(2 \zeta / \omega_{n}\right) j \omega-\left(\omega / \omega_{n}\right)^{2}\right]}{j \omega} .
$$

Typically, we choose $0.9>\zeta>0.7$.

FIGURE 9.52

Bode plot for a PID controller using the asymptomatic approximation for the magnitude curve with $K_{1}=2, \alpha=10$, and $\tau=1$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0678.jpg?height=609&width=649&top_left_y=1502&top_left_x=520)



\subsection{STABILITY IN THE FREQUENCY DOMAIN USING CONTROL DESIGN SOFTWARE}

We now approach the issue of stability using the computer as a tool. This section revisits the Nyquist plot, the Nichols chart, and the Bode plot in our discussions on relative stability. Two examples will illustrate the frequency-domain design approach. We will make use of the frequency response of the closed-loop transfer function $T(j \omega)$ as well as the loop transfer function $L(j \omega)$. We also present an illustrative example that shows how to deal with a time delay in the system by utilizing a Padé approximation [6]. The functions covered in this section are nyquist, nichols, margin, pade, and ngrid.

It is generally more difficult to manually generate the Nyquist plot than the Bode plot. However, we can use the control design software to generate the Nyquist plot. The Nyquist plot is generated with the nyquist function, as shown in Figure 9.53. When nyquist is used without left-hand arguments, the Nyquist plot is automatically generated; otherwise, the real and imaginary parts of the frequency response (along with the frequency vector $\omega$ ) is returned. An illustration of the nyquist function is given in Figure 9.54.

As discussed in Section 9.4, relative stability measures of gain margin and phase margin can be determined from both the Nyquist plot and the Bode plot. The gain margin is a measure of how much the system gain would have to be increased for the $L(j \omega)$ locus to pass through the $-1+j 0$ point, thus resulting in an unstable system. The phase margin is a measure of the additional phase lag required before the system becomes unstable. Gain and phase margins can be determined from both the Nyquist plot and the Bode plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0679.jpg?height=795&width=762&top_left_y=1216&top_left_x=407)

FIGURE 9.53 The nyquist function. $>>$ num $=[0.5] ;$ den=[1 $\left.\begin{array}{lll}1 & 1 & 0.5\end{array}\right]$;

$>>$ sys=tf(num,den);

>>nyquist(sys)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0680.jpg?height=732&width=929&top_left_y=330&top_left_x=505)

FIGURE 9.54 An example of the nyquist function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0680.jpg?height=181&width=753&top_left_y=1222&top_left_x=508)

FIGURE 9.55 A closed-loop control system example for Nyquist and Bode with relative stability.

Consider the system shown in Figure 9.55. Relative stability can be determined from the Bode plot using the margin function, which is shown in Figure 9.56. If the margin function is invoked without left-hand arguments, the Bode plot is automatically generated with the gain and phase margins labeled on the plot. This is illustrated in Figure 9.57 for the system shown in Figure 9.55.

The script to generate the Nyquist plot for the system in Figure 9.55 is shown in Figure 9.58. In this case, the number of poles of $L(s)=G_{c}(s) G(s)$ with positive real parts is zero, and the number of counterclockwise encirclements of -1 is zero; hence, the closed-loop system is stable. We can also determine the gain margin and phase margin, as indicated in Figure 9.58.

Nichols charts can be generated using the nichols function, shown in Figure 9.59. If the nichols function is invoked without left-hand arguments, the Nichols chart is automatically generated; otherwise the nichols function returns the magnitude and FIGURE 9.56

The margin function.
Example

num $=[0.5] ;$ den $=\left[\begin{array}{llll}1 & 2 & 1 & 0.5\end{array}\right]$ sys=tf(num, den); margin(sys);

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0681.jpg?height=263&width=628&top_left_y=301&top_left_x=893)

$\mathrm{Gm}=$ gain margin $(\mathrm{dB})$

$\mathrm{Pm}=$ phase margin $(\mathrm{deg})$

$\mathrm{Wcg}=$ freq. for phase $=-180$

$\mathrm{Wcp}=$ freq. for gain $=0 \mathrm{~dB}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0681.jpg?height=272&width=659&top_left_y=692&top_left_x=863)

Frequency ( $\mathrm{rad} / \mathrm{s})$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0681.jpg?height=756&width=910&top_left_y=1076&top_left_x=387)

FIGURE 9.57

The Bode plot for the system in Figure 9.55 with the gain margin and the phase margin indicated on the plots. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0682.jpg?height=757&width=927&top_left_y=158&top_left_x=489)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0682.jpg?height=649&width=809&top_left_y=983&top_left_x=602)

(b)

FIGURE 9.58 (a) The Nyquist plot for the system in Figure 9.55 with gain and phase margins.

(b) m-file script.

phase in degrees (along with the frequency $\omega$ ). A Nichols chart grid is drawn on the existing plot with the ngrid function. The Nichols chart, shown in Figure 9.60, is for the system

$$
G(j \omega)=\frac{1}{j \omega(j \omega+1)(0.2 j \omega+1)} .
$$

FIGURE 9.59

The nichols function.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0683.jpg?height=1586&width=890&top_left_y=147&top_left_x=366)

Set up to generate

Figure 9.27

num=[1]; den=[0.2 1.210 ]; sys=tf(num,den);

$\mathrm{w}=$ logspace $(-1,1,400)$;

nichols(sys, w);

ngrid

Plot Nichols chart and add grid lines. 

\section{EXAMPLE 9.13 Liquid level control system}

Consider a liquid level control system described by the block diagram shown in Figure 9.31. Note that this system has a time delay. The loop transfer function is given by

$$
L(s)=\frac{31.5 e^{-s T}}{(s+1)(30 s+1)\left(s^{2} / 9+s / 3+1\right)} .
$$

We first change Equation (9.97) in such a way that $L(s)$ has a transfer function form with polynomials in the numerator and the denominator. To do this, we can make an approximation to $e^{-s T}$ with the pade function, shown in Figure 9.61. For example, suppose our time delay is $T=1 \mathrm{~s}$, and we want a second-order approximation $n=2$. Using the pade function, we find that

$$
e^{-s T}=\frac{s^{2}-6 s+12}{s^{2}+6 s+12}
$$

Substituting Equation (9.98) into Equation (9.97) yields

$$
L(s)=\frac{31.5\left(s^{2}-6 s+12\right)}{(s+1)(30 s+1)\left(s^{2} / 9+s / 3+1\right)\left(s^{2}+6 s+12\right)} .
$$

Now we can build a script to investigate the relative stability of the system using the Bode plot. Our goal is to have a phase margin of $P . M .=30^{\circ}$. The associated script is shown in Figure 9.62. To make the script interactive, we let the gain $K$ (now set at $K=31.5$ ) be adjustable and defined outside the script at the command level. Then we set $K$ and run the script to check the phase margin and iterate if necessary. The final selected gain is $K=16$. Remember that we have utilized a second-order Padé approximation of the time delay in our analysis.

\section{EXAMPLE 9.14 Remotely controlled vehicle}

Consider the speed control system for a remotely controlled vehicle shown in Figure 9.38. The design objective is to achieve good control with a low steady-state error and a low overshoot to a step command. Building a script will allow us to

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0684.jpg?height=442&width=552&top_left_y=1670&top_left_x=505)


![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0685.jpg?height=826&width=1096&top_left_y=156&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0685.jpg?height=597&width=969&top_left_y=1087&top_left_x=447)

(a) Bode plot for the liquid level control system. (b) m-file script.

(b)

perform many design iterations quickly and efficiently. First, we investigate the steady-state error specification. The steady-state error to a unit step command is

$$
e_{\mathrm{ss}}=\frac{1}{1+K / 2} \text {. }
$$

The effect of the gain $K$ on the steady-state error is clear from Equation (9.99): If $K=20$, the error is $e_{s s}=9 \%$ of the input magnitude; if $K=10$, the error is $e_{s s}=17 \%$ of the input magnitude. Now we can investigate the overshoot specification in the frequency domain. Suppose we require that the percent overshoot is less than $50 \%$. Solving

$$
\text { P.O. } \approx 100 \exp ^{-\zeta \pi / \sqrt{1-\zeta^{2}}} \leq 50
$$

for $\zeta$ yields $\zeta \geq 0.215$. Referring to Equation (9.63), we find that $M_{p \omega} \leq 2.45$. We must keep in mind that Equation (9.63) is for second-order systems only and can be used here only as a guideline. We now compute the closed-loop Bode plot and check the values of $M_{p \omega}$. Any gain $K$ for which $M_{p \omega} \leq 2.45$ may be a valid gain for our design, but we will have to investigate step responses further to check the actual overshoot. The script in Figure 9.63 aids us in this task. We further investigate the gains $K=20,10$, and 4.44 (even though $M_{p \omega}>2.45$ for $K=20$ ).

We can plot the step responses to quantify the percent overshoot as shown in Figure 9.64. Additionally, we could have used a Nichols chart to aid the design process, as shown in Figure 9.65.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0686.jpg?height=570&width=931&top_left_y=858&top_left_x=520)

(a)

FIGURE 9.63

Remotely controlled vehicle. (a) Closed-loop system Bode plot. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0686.jpg?height=457&width=797&top_left_y=1566&top_left_x=617)

FIGURE 9.64

Remotely controlled vehicle. (a) Step response. (b) $\mathrm{m}$-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0687.jpg?height=614&width=999&top_left_y=152&top_left_x=373)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0687.jpg?height=501&width=929&top_left_y=871&top_left_x=448)

(b)

The results of the analysis are summarized in Table 9.3 for $K=20,10$, and 4.44. We choose $K=10$ as our design gain. Then we obtain the Nyquist plot and check relative stability, as shown in Figure 9.66. The gain margin is G.M. $=\infty$ and the phase margin is $P . M .=26.1^{\circ}$.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this chapter, we will examine the disk drive read system including the effect of the flexure resonance and incorporating a PD controller with a zero at $s=-1$. We will determine the system gain margin and phase margin when $K=400$.

The Bode plot for the system when $K=400$ is shown in Figure 9.67. The gain margin is G.M. $=22.9 \mathrm{~dB}$, and the phase margin is $P . M .=37.2^{\circ}$. The plot of the step response of this system is shown in Figure 9.68. The settling time of this design is $T_{s}=9.6 \mathrm{~ms}$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0688.jpg?height=905&width=1134&top_left_y=333&top_left_x=508)

(a)

FIGURE 9.65

Remotely controlled vehicle. (a) Nichols chart. (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0688.jpg?height=496&width=891&top_left_y=1354&top_left_x=671)

(b) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0689.jpg?height=496&width=626&top_left_y=161&top_left_x=388)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0689.jpg?height=401&width=685&top_left_y=751&top_left_x=398)

(a) Nyquist plot for the remotely controlled vehicle with $K=10$.

(b) m-file script.

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0689.jpg?height=816&width=1190&top_left_y=1297&top_left_x=374)

FIGURE 9.67

Bode plot of the disk drive read system.

Frequency $(\mathrm{rad} / \mathrm{s})$ FIGURE 9.68

Response of the disk drive read system to a step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0690.jpg?height=896&width=1155&top_left_y=154&top_left_x=523)

\subsection{SUMMARY}

The stability of a feedback control system can be determined in the frequency domain by utilizing Nyquist's criterion. Furthermore, Nyquist's criterion provides us with two relative stability measures: (1) gain margin and (2) phase margin. These relative stability measures can be utilized as indices of the transient performance on the basis of correlations established between the frequency domain and the time-domain transient response. The magnitude and phase of the closed-loop system can be determined from the frequency response of the open-loop transfer function by utilizing constant magnitude and phase circles on the polar plot. Alternatively, we can utilize a log-magnitudephase diagram with closed-loop magnitude and phase curves superimposed (called the Nichols chart) to obtain the closed-loop frequency response. A measure of relative stability, the maximum magnitude of the closed-loop frequency response, $M_{p \omega}$, is available from the Nichols chart. The frequency response, $M_{p \omega}$, can be correlated with the damping ratio of the time response and is a useful index of performance. Finally, a control system with a pure time delay can be investigated in a manner similar to that for systems without time delay. A summary of the Nyquist criterion, the relative stability measures, and the Nichols chart is given in Table 9.3 for several transfer functions.

Table 9.3 is very useful and important to the designer and analyst of control systems. If we have the model of a process $G(s)$ and a controller $G_{c}(s)$, then we can determine $L(s)=G_{c}(s) G(s)$. With this loop transfer function, we can examine the transfer function table in column 1. This table contains fifteen typical transfer functions. For a selected transfer function, the table gives the Bode plot, the Nichols chart, and the root locus. With this information, the designer can determine or estimate the performance of the system and consider the addition or alteration of the controller $G_{c}(s)$. Table 9.3 Key Plots for Typical Loop Transfer Functions

1. $\frac{K}{s \tau_{1}+1}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0691.jpg?height=346&width=1004&top_left_y=278&top_left_x=602)

2. $\frac{K}{\left(s \tau_{1}+1\right)\left(s \tau_{2}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0691.jpg?height=342&width=998&top_left_y=694&top_left_x=603)

3. $\frac{K}{\left(s \tau_{1}+1\right)\left(s \tau_{2}+1\right)\left(s \tau_{3}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0691.jpg?height=344&width=1016&top_left_y=1140&top_left_x=600)

4. $\frac{K}{S}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0691.jpg?height=350&width=1012&top_left_y=1558&top_left_x=603)Table 9.3 (continued)

Nichols Chart
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0692.jpg?height=1644&width=402&top_left_y=301&top_left_x=236)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0692.jpg?height=400&width=384&top_left_y=301&top_left_x=744)

\section{Comments}

Stable; gain margin $=\infty$

Elementary regulator; stable; gain margin $=\infty$
Regulator with additional energystorage component; unstable, but can be made stable by reducing gain

Ideal integrator; stable Nyquist Plot

5. $\frac{K}{s\left(s \tau_{1}+1\right)}$

6. $\frac{K}{s\left(s \tau_{1}+1\right)\left(s \tau_{2}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0693.jpg?height=1278&width=400&top_left_y=276&top_left_x=597)

8. $\frac{K}{s^{2}}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0693.jpg?height=351&width=395&top_left_y=1633&top_left_x=602)

\section{Bode Plot}
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0693.jpg?height=1702&width=544&top_left_y=283&top_left_x=1071)Table 9.3 (continued)

Nichols Chart
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0694.jpg?height=1752&width=412&top_left_y=272&top_left_x=227)

\section{Root Locus}
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0694.jpg?height=1764&width=398&top_left_y=268&top_left_x=730)

\section{Comments}

Elementary instrument servo; inherently stable; gain margin $=\infty$

Instrument servo with field control motor or power servo with elementary Ward-Leonard drive; stable as shown, but may become unstable with increased gain

Elementary instrument servo with phase-lead (derivative) compensator; stable

Inherently marginally stable; must be compensated 

\section{Nyquist Plot}

9. $\frac{K}{s^{2}\left(s \tau_{1}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0695.jpg?height=1356&width=400&top_left_y=263&top_left_x=600)

12. $\frac{K\left(s \tau_{a}+1\right)}{s^{3}}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0695.jpg?height=388&width=397&top_left_y=1692&top_left_x=601)

\section{Bode Plot}
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0695.jpg?height=1792&width=512&top_left_y=278&top_left_x=1069)Table 9.3 (continued)

Nichols Chart
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0696.jpg?height=1704&width=362&top_left_y=255&top_left_x=224)

Root Locus
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0696.jpg?height=1718&width=358&top_left_y=260&top_left_x=731)

\section{Comments}

Inherently unstable; must be compensated
Stable for all gains

Inherently unstable

Inherently unstable 13. $\frac{K\left(s \tau_{a}+1\right)\left(s \tau_{b}+1\right)}{s^{3}}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0697.jpg?height=396&width=978&top_left_y=272&top_left_x=601)

14. $\frac{K\left(s \tau_{a}+1\right)\left(s \tau_{b}+1\right)}{s\left(s \tau_{1}+1\right)\left(s \tau_{2}+1\right)\left(s \tau_{3}+1\right)\left(s \tau_{4}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0697.jpg?height=394&width=906&top_left_y=734&top_left_x=766)

15. $\frac{K\left(s \tau_{a}+1\right)}{s^{2}\left(s \tau_{1}+1\right)\left(s \tau_{2}+1\right)}$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0697.jpg?height=398&width=892&top_left_y=1245&top_left_x=766)Table 9.3 (continued)

Nichols Chart
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0698.jpg?height=1256&width=362&top_left_y=282&top_left_x=238)

\section{Comments}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0698.jpg?height=357&width=430&top_left_y=285&top_left_x=735)

Conditionally stable; becomes unstable if gain is too low

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0698.jpg?height=377&width=372&top_left_y=670&top_left_x=743)

Conditionally stable; stable at low gain, becomes unstable as gain is raised, again becomes stable as gain is further increased, and becomes unstable for very high gains
Conditionally stable; becomes unstable at high gain 

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 9.69 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0699.jpg?height=263&width=875&top_left_y=426&top_left_x=539)

FIGURE 9.69 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answers.

1. The gain margin of a system is the increase in the system gain when the phase is $-180^{\circ}$ that will result in a marginally stable system.

True or False

2. A conformal mapping is a contour mapping that retains the angles on the $s$-plane on the transformed $F(s)$-plane.

True or False

3. The gain and phase margin are readily evaluated on either a Bode plot or a Nyquist plot.

True or False

4. A Nichols chart displays curves describing the relationship between the open-loop and closed-loop frequency responses.

True or False

5. The phase margin of a second-order system (with no zeros) is a function of both the damping ratio $\zeta$ and the natural frequency, $\omega_{n}$.

True or False

6. Consider the closed-loop system in Figure 9.69 where

$$
L(s)=G_{c}(s) G(s)=\frac{3.25(1+s / 6)}{s(1+s / 3)(1+s / 8)} .
$$

The crossover frequency and the phase margin are:
a. $\omega=2.0 \mathrm{rad} / \mathrm{s}, P . M .=37.2^{\circ}$
b. $\omega=2.6 \mathrm{rad} / \mathrm{s}, P . M .=54.9^{\circ}$
c. $\omega=5.3 \mathrm{rad} / \mathrm{s}, P . M .=68.1^{\circ}$
d. $\omega=10.7 \mathrm{rad} / \mathrm{s}, P . M .=47.9^{\circ}$

7. Consider the block diagram in Figure 9.69. The plant transfer function is

$$
G(s)=\frac{1}{(1+0.25 s)(0.5 s+1)},
$$

and the controller is

$$
G_{c}(s)=\frac{s+0.2}{s+5} .
$$

Utilize the Nyquist stability criterion to characterize the stability of the closed-loop system.

a. The closed-loop system is stable.

b. The closed-loop system is unstable.

c. The closed-loop system is marginally stable.

d. None of the above.

For Problems 8 and 9, consider the block diagram in Figure 9.69 where

$$
G(s)=\frac{9}{(s+1)\left(s^{2}+3 s+9\right)},
$$

and the controller is the proportional-plus-derivative (PD) controller

$$
G_{c}(s)=K\left(1+T_{d} s\right) .
$$

8. When $T_{d}=0$, the PD controller reduces to a proportional controller, $G_{c}(s)=K$. In this case, use the Nyquist plot to determine the limiting value of $K$ for closed-loop stability.
a. $K=0.5$
b. $K=1.6$
c. $K=2.4$
d. $K=4.3$

9. Using the value of $K$ in Problem 8, compute the gain and phase margins when $T_{d}=0.2$.
a. $G \cdot M .=14 \mathrm{~dB}, P . M .=27^{\circ}$
b. $G . M .=20 \mathrm{~dB}, P . M .=64.9^{\circ}$
c. $G . M .=\infty \mathrm{dB}, P . M .=60^{\circ}$
d. Closed-loop system is unstable

10. Determine whether the closed-loop system in Figure 9.69 is stable or not, given the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+1}{s^{2}(4 s+1)} .
$$

In addition, if the closed-loop system is stable, compute the gain and phase margins.

a. Stable, G.M. $=24 \mathrm{~dB}, P . M .=2.5^{\circ}$

b. Stable, G.M. $=3 \mathrm{~dB}, P . M .=24^{\circ}$

c. Stable, G.M. $=\infty \mathrm{dB}, P . M .=60^{\circ}$

d. Unstable

11. Consider the closed-loop system in Figure 9.69, where the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+4)}{s^{2}} .
$$

Determine the value of the gain $K$ such that the phase margin is P.M. $=40^{\circ}$.
a. $K=1.64$
b. $K=2.15$
c. $K=2.63$
d. Closed-loop system is unstable for all $K>0$ 12. Consider the feedback system in Figure 9.69 , where

$$
G_{c}(s)=K \quad \text { and } \quad G(s)=\frac{e^{-0.2 s}}{s+5} .
$$

Notice that the plant contains a time-delay of $T=0.2$ seconds. Determine the gain $K$ such that the phase margin of the system is $P . M .=50^{\circ}$. What is the gain margin for the same gain $K$ ?
a. $K=8.36$, G.M. $=2.6 \mathrm{~dB}$
b. $K=2.15, G \cdot M .=10.7 \mathrm{~dB}$
c. $K=5.22, G . M .=\infty \mathrm{dB}$
d. $K=1.22, G \cdot M .=14.7 \mathrm{~dB}$

13. Consider the control system in Figure 9.69, where the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{1}{s(s+1)} .
$$

The value of the resonant peak, $M_{p_{\omega}}$ and the damping factor, $\zeta$, for the closed-loop system are:
a. $M_{p_{\omega}}=0.37, \zeta=0.707$
b. $M_{p_{\omega}}=1.15, \zeta=0.5$
c. $M_{p_{\omega}}=2.55, \zeta=0.5$
d. $M_{p_{\omega}}=0.55, \zeta=0.25$

14. A feedback model of human reaction time used in analysis of vehicle control can use the block diagram model in Figure 9.69 with

$$
G_{c}(s)=e^{-s T} \quad \text { and } \quad G(s)=\frac{1}{s(0.2 s+1)} .
$$

A typical driver has a reaction time of $T=0.3 \mathrm{~s}$. Determine the bandwidth of the closedloop system.
a. $\omega_{b}=0.5 \mathrm{rad} / \mathrm{s}$
b. $\omega_{b}=10.6 \mathrm{rad} / \mathrm{s}$
c. $\omega_{b}=1.97 \mathrm{rad} / \mathrm{s}$
d. $\omega_{b}=200.6 \mathrm{rad} / \mathrm{s}$

15. Consider a control system with unity feedback as in Figure 9.69 with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{(s+4)}{s(s+1)(s+5)} .
$$

The gain and phase margin are:
a. $G \cdot M .=\infty \mathrm{dB}, P . M .=58.1^{\circ}$
b. $G . M .=20.4 \mathrm{~dB}, P . M .=47.3^{\circ}$
c. $G . M .=6.6 \mathrm{~dB}, P . M .=60.4^{\circ}$
d. Closed-loop system is unstable In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.
a. Time delay
The frequency response of the closed-loop transfer function $T(j \omega)$.

b. Cauchy's theorem

A chart displaying the curves for the relationship between the open-loop and closed-loop frequency response.

c. Bandwidth

A contour mapping that retains the angles on the $s$-plane on the $F(s)$-plane.

d. Contour map

e. Nichols chart

If a contour encircles $Z$ zeros and $P$ poles of $F(s)$ traversing clockwise, the corresponding contour in the $F(s)$-plane encircles the origin of the $F(s)$-plane $N=Z-P$ times clockwise.

The amount of phase shift of $G_{c}(j \omega) G(j \omega)$ at unity magnitude that will result in a marginally stable system with intersections of the point $-1+j 0$ on the Nyquist diagram.

f. Closed-loop frequency response

Events occurring at time $t$ at one point in the system occur at another point in the system at a later time, $t+T$.

g. Logarithmic (decibel) measure

A feedback system is stable if and only if the contour in the $G(s)$-plane does not encircle the $(-1,0)$ point when the number of poles of $G(s)$ in the right-hand $s$-plane is zero. If $G(s)$ has $P$ poles in the right-hand plane, then the number of counterclockwise encirclements of the $(-1,0)$ point must be equal to for a stable system.

h. Gain margin

i. Nyquist stability criterion

A contour or trajectory in one plane is mapped into another plane by a relation $F(s)$.

The increase in the system gain when plane $=-180^{\circ}$ that will result in a marginally stable system with intersection of the $-1+j 0$ point on the Nyquist diagram.

j. Phase margin

The frequency at which the frequency response has declined $3 \mathrm{~dB}$ from its low-frequency value.

k. Conformal mapping

A measure of the gain margin.

\section{EXERCISES}

E9.1 A system has the open-loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{3(1+5 s)}{s(4+s)\left(1+2 s+2 s^{2}\right)} .
$$

Obtain the Bode plot. Show that the phase margin is $P . M .=20.1^{\circ}$ and that the gain margin is $G . M .=$ $6.61 \mathrm{~dB}$.
E9.2 A system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(1+s / 20)}{s(1+s / 8)(1+s+10)},
$$

where $K=4$. Show that the system crossover frequency is $\omega_{c}=3.51 \mathrm{rad} / \mathrm{s}$ and that the phase margin is P.M. $=56.9^{\circ}$. E9.3 An integrated circuit is available to serve as a feedback system to regulate the output voltage of a power supply. The Bode plot of the loop transfer function is shown in Figure E9.3 Estimate the phase margin of the regulator.

Answer: P.M. $=75^{\circ}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0703.jpg?height=482&width=614&top_left_y=425&top_left_x=86)

FIGURE E9.3 Power supply regulator.

E9.4 Consider a system with a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{100}{s(s+10)} .
$$

We wish to obtain a resonant peak $M_{p \omega}=3.0 \mathrm{~dB}$ for the closed-loop system. The peak occurs between 6 and $9 \mathrm{rad} / \mathrm{s}$ and is only $1.25 \mathrm{~dB}$. Plot the Nichols chart for the range of frequency from 6 to $15 \mathrm{rad} / \mathrm{s}$. Show that the system gain needs to be raised by $4.6 \mathrm{~dB}$ to 171. Determine the resonant frequency for the adjusted system.

Answer: $\omega_{r}=11 \mathrm{rad} / \mathrm{s}$

E9.5 An integrated CMOS digital circuit can be represented by the Bode plot shown in Figure E9.5. (a) Find the gain and phase margins of the circuit. (b) Estimate how much we would need to reduce the system gain (dB) to obtain a phase margin of P.M. $=60^{\circ}$.

E9.6 A system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+10)}{s(s+6)(s+15)} .
$$

Determine the range of $K$ for closed-loop stability. Find the gain margin and phase margin of the system with $K=40$.

E9.7 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s-5} .
$$

Determine the range of $K$ for which the system is stable using the Nyquist plot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0703.jpg?height=391&width=679&top_left_y=155&top_left_x=940)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0703.jpg?height=322&width=678&top_left_y=582&top_left_x=938)

FIGURE E9.5 Bode plot of the CMOS circuit.

E9.8 Consider a unity feedback with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+2)(s+6)} .
$$

(a) For $K=27$, show that the gain margin is G.M. $=11 \mathrm{~dB}$.

(b) To achieve a gain margin G.M. $=28 \mathrm{~dB}$, determine the value of the gain $K$.

Answer: (b) $K=3.8$

E9.9 Consider a unity feedlack system with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{10}{s\left(s^{2}+11 s+10\right)} .
$$

Compute the phase margin and gain margin.

E9.10 Consider a system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{250(s+5)}{s(s+0.25)\left(s^{2}+12.5 s+120\right)} .
$$

Obtain the Bode plot, and show that the P.M. $=16.9^{\circ}$ and that the G.M. $=9.63 \mathrm{~dB}$. Also, show that the bandwidth of the closed-loop system is $\omega_{B}=4.57 \mathrm{rad} / \mathrm{s}$.

E9.11 Consider a unity feedback system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{5(1+0.5 s)}{s(1+2 s)\left(2+0.25 s+0.05 s^{2}\right)} .
$$

(a) Obtain the Bode plot. (b) Find the gain margin and the phase margin. E9.12 A unity feedback system with the loop transfer function

$$
G_{c}(s) G(s)=\frac{K}{s\left(1+\tau_{1} s\right)\left(1+\tau_{2} s\right)},
$$

where $\tau_{1}=0.01$ and $\tau_{2}=0.3 \mathrm{~s}$. (a) Select a gain $K$ so that the steady-state error for a ramp input is $20 \%$ of the magnitude of the ramp function $A$, where $r(t)=A(t), t \geq 0$. (b) Obtain the Bode plot of loop transfer function, and determine the phase and gain margins. (c) Determine the bandwidth $\omega_{B}$, the resonant peak $M_{p \omega}$, and the resonant frequency $\omega_{r}$ of the closed-loop system.

\section{Answer:}
(a) $K=20$
(b) P.M. $=19^{\circ}, G \cdot M .=14.6 \mathrm{~dB}$
(c) $\omega_{B}=12.4, M_{p \omega}=9.82, \omega_{r}=7.92$

E9.13 A unity feedback system has a loop transfer function

$$
G_{c}(s) G(s)=\frac{200}{s(s+4)} .
$$

(a) Find the maximum magnitude of the closed-loop frequency response. (b) Find the bandwidth and the resonant frequency of this system. (c) Use these frequency measures to estimate the overshoot of the system to a step response.

Answers:(a) $11.1 \mathrm{~dB},(\mathrm{~b}) \omega_{B}=21.8 \mathrm{rad} / \mathrm{s}, \omega_{r}=13.9$

E9.14 A Nichols chart is given in Figure E9.14 for a system with $G_{c}(j \omega) G(j \omega)$. Using the following table, find (a) the peak resonance $M_{p \omega}$ in $\mathrm{dB}$; (b) the resonant frequency $\omega_{r}$; (c) the 3-dB bandwidth; and (d) the phase margin of the system.

\begin{tabular}{lcccc} 
& $\omega_{1}$ & $\omega_{2}$ & $\omega_{3}$ & $\omega_{4}$ \\
\hline $\mathbf{r a d} / \mathbf{s}$ & 1 & 3 & 6 & 10
\end{tabular}

E9.15 Consider a unity feedback system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{100}{s(s+20)} .
$$

Find the bandwidth of the closed-loop system.

Answer: $\omega_{B}=6.4 \mathrm{rad} / \mathrm{s}$
FIGURE E9.14 Nichols chart for $G_{c}(j \omega) G(j \omega)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0704.jpg?height=1089&width=832&top_left_y=1076&top_left_x=506)

E9.16 The pure time delay $e^{-s T}$ may be approximated by a transfer function as

$$
e^{-s T} \approx \frac{1-T s / 2}{1+T s / 2} .
$$

Obtain the Bode plot for the actual transfer function and the approximation for $T=0.05$ for $0<\omega<100$.

$$
G_{c}(s) G(s)=\frac{K(s+4)}{s\left(s^{2}+3 s+20\right)} .
$$

(a) Obtain the Bode plot, and (b) determine the gain $K$ required to obtain a phase margin of $P \cdot M .=56^{\circ}$. What is the steady-state error for a ramp input for the gain of part (b)?

E9.17 A unity feedback system has a loop transfer E9.18 An actuator for a disk drive uses a shock mount function

to absorb vibrational energy at approximately $60 \mathrm{~Hz}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0705.jpg?height=741&width=1021&top_left_y=575&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0705.jpg?height=703&width=1019&top_left_y=1389&top_left_x=375)

RE E9.18 FIGURE E9.20

Automobile control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0706.jpg?height=250&width=1047&top_left_y=148&top_left_x=504)

[14]. The Bode plot of the loop transfer function of the control system is shown in Figure E9.18. (a) Find the expected percent overshoot for a step input for the closed-loop system, (b) estimate the bandwidth of the closed-loop system, and (c) estimate the settling time (with a $2 \%$ criterion) of the system.

E9.19 A unity feedback system with $G_{c}(s)=K$ has

$$
G(s)=\frac{e^{-0.12 s}}{(s+15)} .
$$

Select a gain $K$ so that the phase margin of the system is $P . M .=40^{\circ}$. Determine the gain margin for the selected gain, $K$.

E9.20 Consider a simple model of an automobile driver following another car on the highway at high speed. The model shown in Figure E9.20 incorporates the driver's reaction time, $T$. One driver has $T=1 \mathrm{~s}$, and another has $T=1.5 \mathrm{~s}$. Determine the time response $y(t)$ of the system for both drivers for a step change in the command signal $R(s)=-1 / s$, due to the braking of the lead car.

E9.21 A unity feedback control system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+2)(s+50)} .
$$

Determine the phase margin, the crossover frequency, and the gain margin when $K=1300$.

E9.22 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+2)^{2}} .
$$

(a) Using a Bode plot for $K=40$, determine the system phase margin. (b) Select a gain $K$ so that the phase margin is $P . M . \geq 55^{\circ}$.

E9.23 Consider again the system of E9.21 when $K=100$. Determine the closed-loop system bandwidth, resonant frequency, and $M_{p \omega}$.

Answers: $\omega_{B}=5.44 \mathrm{rad} / \mathrm{s}, \omega_{r}=3.61 \mathrm{rad} / \mathrm{s}$, $M_{p \omega}=5.75$
E9.24 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(-1+\tau s)},
$$

where $K=0.4$ and $\tau=1$. The Nyquist plot for $G_{c}(j \omega) G(j \omega)$ is shown in Figure E9.24. Determine whether the system is stable by using the Nyquist criterion.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0706.jpg?height=538&width=724&top_left_y=766&top_left_x=1028)

FIGURE E9.24 Nyquist plot for $G_{c}(s) G(s)=K /(-1+\tau s)$ where $K=0.4$.

E9.25 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{11.7}{s(1+0.05 s)(1+0.1 s)} .
$$

Determine the phase margin and the crossover frequency.

Answer: P.M. $=28^{\circ}, \omega_{c}=8.31 \mathrm{rad} / \mathrm{s}$

E9.26 For the system of E9.25, determine $M_{p \omega}, \omega_{r}$, and $\omega_{B}$ for the closed-loop frequency response by using the Nichols chart.

E9.27 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+3)^{2}} .
$$

(a) Determine the maximum gain $K$ for which the phase margin is $P . M . \geq 30^{\circ}$, and the gain margin is G.M. $=8 \mathrm{~dB}$. (b) Determine the value of gain $K$ and cross over frequency for marginal stability.

E9.28 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{10}{s(s+0.8)} .
$$

(a) Determine the phase margin for the system. (b) Use the phase margin to estimate the damping ratio, and predict the percent overshoot. (c) Calculate the actual response for this system, and compare the result with the part (b) estimate.

E9.29 A loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{1}{s+2} .
$$

Using the contour in the $s$-plane shown in Figure E9.29, determine the corresponding contour in the $F(s)$-plane $(B=-1+j)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0707.jpg?height=687&width=684&top_left_y=927&top_left_x=86)

FIGURE E9.29 Contour in the s-plane.
E9.30 A system is represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{cc}
-3 & -2 \\
1 & 0
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
1 \\
0
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{ll}
0 & 501
\end{array}\right], \mathbf{D}=[0] .
\end{aligned}
$$

Sketch the Bode plot.

E9.31 A closed-loop feedback system is shown in Figure E9.31. Sketch the Bode plot, and determine the phase margin.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0707.jpg?height=245&width=593&top_left_y=748&top_left_x=955)

FIGURE E9.31 Nonunity feedback system.

E9.32 Consider the system described in state variable form by

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t)
\end{gathered}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-4 & -1
\end{array}\right], \mathbf{B}=\left[\begin{array}{c}
0 \\
3.2
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
2 & 0
\end{array}\right] .
$$

Compute the phase margin.

E9.33 Consider the system shown in Figure E9.33. Compute the loop transfer function $L(s)$, and sketch the Bode plot. Determine the phase margin and gain margin when the controller gain $K=5$.
FIGURE E9.33

Nonunity feedback system with proportional controller $K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0707.jpg?height=306&width=1028&top_left_y=1804&top_left_x=460)



\section{PROBLEMS}

P9.1 For the Nyquist plots of Problem P8.1, use the Nyquist criterion to ascertain the stability of the various systems. In each case, specify the values of $N, P$, and $Z$.

P9.2 Sketch the Nyquist plots of the following loop transfer functions $L_{1}(s)=G c_{1}(s) G_{1}(s)$, and determine whether the system is stable by applying the Nyquist criterion:
(a) $L(s)=G_{c}(s) G(s)=\frac{K}{s\left(s^{2}+2 s+5\right)}$.
(b) $L(s)=G_{c}(s) G(s)=\frac{K(s+2)}{s^{2}(s+5)}$.

If the system is stable, find the maximum value for $K$ by determining the point where the Nyquist plot crosses the $u$-axis.

P9.3 (a) Find a suitable contour $\Gamma_{s}$ in the $s$-plane that can be used to determine whether all roots of the characteristic equation have damping ratios greater than $\zeta_{1}$. (b) Find a suitable contour $\Gamma_{s}$ in the $s$-plane that can be used to determine whether all the roots of the characteristic equation have real parts less than $s=-\sigma_{1}$. (c) Using the contour of part (b) and Cauchy's theorem, determine whether the following characteristic equation has roots with real parts less than $s=-1$ :

$$
q(s)=s^{3}+11 s^{2}+56 s+96 .
$$

P9.4 The Nyquist plot of a conditionally stable system is shown in Figure P9.4 for a specific gain $K$. (a) Determine

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0708.jpg?height=468&width=659&top_left_y=1271&top_left_x=282)

whether the system is stable, and find the number of roots (if any) in the right-hand $s$-plane. The system has no poles of $G_{c}(s) G(s)$ in the right half-plane. (b) Determine whether the system is stable if the -1 point lies at the dot on the axis.

P9.5 A speed control for a gasoline engine is shown in Figure P9.5. Because of the restriction at the carburetor intake and the capacitance of the reduction manifold, the lag $\tau_{t}$ occurs and is equal to 1.5 seconds. The engine time constant $\tau_{e}$ is equal to $J / b=4 \mathrm{~s}$. The speed measurement time constant is $\tau_{m}=0.6 \mathrm{~s}$. (a) Determine the necessary gain $K$ if the steadystate speed error is required to be less than $20 \%$ of the speed reference setting. (b) With the gain determined from part (a), apply the Nyquist criterion to investigate the stability of the system. (c) Determine the phase and gain margins of the system.

P9.6 A direct-drive arm is an innovative mechanical arm in which no reducers are used between motors and their loads. Because the motor rotors are directly coupled to the loads, the drive systems have no backlash, small friction, and high mechanical stiffness, which are all important features for fast and accurate positioning and dexterous handling using sophisticated torque control.

The goal of the MIT direct-drive arm project is to achieve arm speeds of $10 \mathrm{~m} / \mathrm{s}$ [15]. The arm has torques of up to $660 \mathrm{~N} \mathrm{~m}(475 \mathrm{ft} \mathrm{lb})$. Feedback and a set of position and velocity sensors are used with each motor. The frequency response of one joint of the arm is shown in Figure P9.6(a). The two poles appear at $3.7 \mathrm{~Hz}$ and $68 \mathrm{~Hz}$. Figure P9.6(b) shows the step response with position and velocity feedback used. The time constant of the closed-loop system is $82 \mathrm{~ms}$. Develop the block diagram of the drive system and prove that $82 \mathrm{~ms}$ is a reasonable result.

P9.7 A vertical takeoff (VTOL) aircraft is an inherently unstable vehicle and requires an automatic stabilization system. An attitude stabilization system for the K-16B U.S. Army VTOL aircraft has been designed and is shown in block diagram form in Figure P9.7 [16]. (a) Obtain the Bode plot of the loop transfer function $L(s)$ when the gain is $K=2$. (b) Determine the

FIGURE P9.4 Nyquist plot of conditionally

stable system.

FIGURE P9.5

Engine speed control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0708.jpg?height=244&width=1012&top_left_y=1863&top_left_x=517)

FIGURE P9.6

The MIT arm:

(a) frequency response, and (b) position response.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0709.jpg?height=414&width=1264&top_left_y=153&top_left_x=372)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0709.jpg?height=263&width=537&top_left_y=668&top_left_x=731)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0709.jpg?height=345&width=1133&top_left_y=1121&top_left_x=372)

FIGURE P9.7

VTOL aircraft stabilization system. thus controlling the hydraulic fluid flow to the actuator. The block diagram of a closed-loop electrohydraulic servomechanism using pressure feedback to obtain damping is shown in Figure P9.8(b) [17, 18]. Typical values for this system are $\tau=0.02 \mathrm{~s}$; for the hydraulic system they are $\omega_{2}=7(2 \pi)$ and $\zeta_{2}=0.05$. The structural resonance $\omega_{1}$ is equal to $10(2 \pi)$, and the damping is $\zeta_{1}=0.05$. The loop gain is $K_{A} K_{1} K_{2}=1.0$. (a) Sketch the Bode plot and determine the phase margin of the system. (b) The damping of the system can be increased by drilling a small hole in the piston so that $\zeta_{2}=0.25$. Sketch the Bode plot and determine the phase margin of this system.

P9.9 The space shuttle, shown in Figure P9.9(a), carried large payloads into space and returned them to Earth FIGURE P9.8

(a) A servovalve and actuator

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0710.jpg?height=541&width=593&top_left_y=153&top_left_x=821)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0710.jpg?height=414&width=1275&top_left_y=807&top_left_x=480)

(b)

$$
G_{a}(s)=\frac{X(s)}{Y(s)}=\frac{K_{a}}{s\left(\tau_{a} s+1\right)},
$$

edge of the wing and a brake on the tail to control the flight during entry. The block diagram of a pitch rate control system is shown in Figure P9.9(b).

(a) Sketch the Bode plot of the system when $G_{c}(s)=2$ and determine the stability margin. (b) Sketch the Bode plot of the system when

$$
G_{c}(s)=K_{P}+K_{I} / s \text { and } K_{I} / K_{P}=0.5 \text {. }
$$

The gain $K_{P}$ should be selected so that the gain margin is $10 \mathrm{~dB}$.

P9.10 Machine tools are often automatically controlled as shown in Figure P9.10. These automatic systems are often called numerical machine controls [9]. On each axis, the desired position of the machine tool is compared with the actual position and is used to actuate a solenoid coil and the shaft of a hydraulic actuator. The transfer function of the actuator is where $K_{a}=1$ and $\tau_{a}=0.4 \mathrm{~s}$. The output voltage of the difference amplifier is

$$
E_{0}(s)=K_{1}\left(X(s)-X_{d}(s)\right)
$$

where $x_{d}(t)$ is the desired position input. The force on the shaft is proportional to the current $i(t)$, so that $F=K_{2} i(t)$, where $K_{2}=3.0$. The spring constant $K_{s}$ is equal to $1.5, R=0.1$, and $L=0.2$.

(a) Determine the gain $K_{1}$ that results in a system with a phase margin of P.M. $=30^{\circ}$. (b) For the gain $K_{1}$ of part (a), determine $M_{p \omega}, \omega_{r}$, and the closed-loop system bandwidth. (c) Estimate the percent overshoot of the transient response to a step input $X_{d}(s)=1 / s$, and the settling time (to within $2 \%$ of the final value). 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0711.jpg?height=593&width=774&top_left_y=155&top_left_x=483)

(a)

FIGURE P9.9

(a) The Earthorbiting space shuttle against the blackness of space. The remote manipulator robot is shown with the cargo bay doors open in this top view, taken by a satellite. (b) Pitch rate control system. (Courtesy of NASA.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0711.jpg?height=353&width=985&top_left_y=854&top_left_x=378)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0711.jpg?height=612&width=1228&top_left_y=1265&top_left_x=376)

GURE P9.10

Machine tool control.

P9.11 A control system for a chemical concentration control system is shown in Figure P9.11. The system receives a granular feed of varying composition, and we want to maintain a constant composition of the output mixture by adjusting the feed-flow valve.
The transport of the feed along the conveyor requires a transport (or delay) time, $T=1.5 \mathrm{~s}$. (a) Sketch the Bode plot when $K_{1}=K_{2}=1$, and investigate the stability of the system. (b) Sketch the Bode plot when $K_{1}=0.1$ and $K_{2}=0.04$, and investigate FIGURE P9.11

Chemical concentration control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0712.jpg?height=856&width=1060&top_left_y=155&top_left_x=519)

the stability of the system. (c) When $K_{1}=0$, use the Nyquist criterion to calculate the maximum allowable gain $K_{2}$ for the system to remain stable.

P9.12 A simplified model of the control system for regulating the pupillary aperture in the human eye is shown in Figure P9.12 [20]. The gain $K$ represents the pupillary gain, and $\tau$ is the pupil time constant, which is $0.75 \mathrm{~s}$. The time delay $T$ is equal to $0.6 \mathrm{~s}$. The pupillary gain is $K=2.5$.

(a) Assuming the time delay is negligible, sketch the Bode plot for the system. Determine the phase margin of the system. (b) Include the effect of the time delay by adding the phase shift due to the delay.
Determine the phase margin of the system with the time delay included.

P9.13 A controller is used to regulate the temperature of a mold for plastic part fabrication, as shown in Figure P9.13. The value of the delay time is estimated as $1.2 \mathrm{~s}$. (a) Using the Nyquist criterion, determine the stability of the system for $K_{a}=K=1$. (b) Determine a suitable value for $K_{a}$ for a stable system that will yield a phase margin P.M. $\geq 50^{\circ}$ when $K=1$.

P9.14 Electronics and computers are being used to control automobiles. Figure P9.14 is an example of an automobile control system, the steering control for a research automobile. The control stick is used
FIGURE P9.12

Human pupil aperture control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0712.jpg?height=437&width=943&top_left_y=1675&top_left_x=507)

FIGURE P9.13

Temperature controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0713.jpg?height=273&width=1113&top_left_y=536&top_left_x=375)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0713.jpg?height=290&width=1154&top_left_y=144&top_left_x=372)

FIGURE P9.14

Automobile steering control. for steering. A typical driver has a reaction time of $T=0.2 \mathrm{~s}$.

(a) Using the Nichols chart, determine the magnitude of the gain $K$ that will result in a system with a peak magnitude of the closed-loop frequency response $M_{p \omega} \leq 2 \mathrm{~dB}$.

(b) Estimate the damping ratio of the system based on (1) $M_{p \omega}$ and (2) the phase margin. Compare the results and explain the difference, if any.

(c) Determine the closed-loop bandwidth of the system.

P9.15 Consider the automatic ship-steering system transfer function.

$$
G(s)=\frac{-0.164(s+0.2)(s-0.32)}{s^{2}(s+0.25)(s-0.009)} .
$$

The deviation of the tanker from the straight track is measured by radar and is used to generate the error signal, as shown in Figure P9.15. This error signal is used to control the rudder angle $\delta(s)$.

(a) Is this system stable? Discuss what an unstable ship-steering system indicates in terms of the transient response of the system. Recall that the system under consideration is a ship attempting to follow a straight track.

(b) Is it possible to stabilize this system by lowering the gain of the transfer function $G(s)$ ?

(c) Is it possible to stabilize this system with a derivative feedback controller?

(d) Suggest a suitable feedback controller.

(e) Repeat part (a), (b), and (c) when switch $S$ is closed.

P9.16 An electric carrier that automatically follows a tape track laid out on a factory floor is shown in Figure P9.16(a) [15]. Closed-loop feedback systems are used

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0713.jpg?height=417&width=737&top_left_y=883&top_left_x=878)

FIGURE P9.15 Automatic ship steering.

to control the guidance and speed of the vehicle. The cart senses the tape path by means of an array of 16 phototransistors. The block diagram of the steering system is shown in Figure P9.16(b). Select a gain $K$ so that the phase margin is $P . M .=30^{\circ}$.

P9.17 The primary objective of many control systems is to maintain the output variable at the desired or reference condition when the system is subjected to a disturbance [22]. A typical chemical reactor control scheme is shown in Figure P9.17. The disturbance is represented by $U(s)$, and the chemical process by $G_{3}$ and $G_{4}$. The controller is represented by $G_{1}$ and the valve by $G_{2}$. The feedback sensor is $H(s)$ and will be assumed to be equal to 1 . We will assume that $G_{2}, G_{3}$, and $G_{4}$ are all of the form

$$
G_{i}(s)=\frac{K_{i}}{1+\tau_{i} s},
$$

where $\tau_{3}=\tau_{4}=4 \mathrm{~s}$ and $K_{3}=K_{4}=0.1$. The valve constants are $K_{2}=20$ and $\tau_{2}=0.5 \mathrm{~s}$. We want to FIGURE P9.16

(a) An electric carrier vehicle (photo courtesy of Control Engineering Corporation).

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0714.jpg?height=781&width=1157&top_left_y=155&top_left_x=520)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0714.jpg?height=235&width=1136&top_left_y=1042&top_left_x=523)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0714.jpg?height=329&width=1211&top_left_y=1402&top_left_x=519)

FIGURE P9.17

Chemical reactor control. a percent overshoot of P.O. $\leq 30 \%$, but P.O. $\geq$ $5 \%$. For parts (a) and (b), use the approximation of the damping ratio as a function of phase margin that yields $\zeta=0.01 \phi_{\mathrm{pm}}$. For these calculations, assume that $U(s)=0$.

(c) Estimate the settling time (with a $2 \%$ criterion) of the step response of the system for the controller of parts (a) and (b). (b) If the controller has a proportional term plus an integral term so that $G_{1}(s)=K_{1}(1+1 / s)$, determine a suitable gain to yield a system with maintain a steady-state error $e_{s s}=5 \%$ of the desired

(a) When $G_{1}(s)=K_{1}$, find the necessary gain to satisfy the error-constant requirement. For this condition, determine the expected percent overshoot to a step change in the reference signal $r(t)$. (d) The system is expected to be subjected to a step disturbance $U(s)=A / s$. For simplicity, assume that the desired reference is $r(t)=0$ when the system has settled. Determine the response of the system of part (b) to the disturbance.

P9.18 A model of an automobile driver attempting to steer a course is shown in Figure P9.18, where $K=2.0$. (a) Find the frequency response and the gain and phase margins when the reaction time $T=0$. (b) Find the phase margin when the reaction time is $T=0.3 \mathrm{~s}$. (c) Find the reaction time that will cause the system to be borderline stable $\left(P . M .=0^{\circ}\right)$.

P9.19 In the United States, billions of dollars are spent annually for solid waste collection and disposal. One system, which uses a remote-control pick-up arm for collecting waste bags, is shown in Figure P9.19. The loop transfer function of the remote pick-up arm is

$$
L(s)=G_{c}(s) G(s)=\frac{0.8}{s(3 s+1)(s+6)} .
$$

(a) Plot Nichols chart, and show that the gain margin G.M. is $33.5 \mathrm{~dB}$. (b) Determine the phase margin and the $M_{p \omega}$ for the closed loop. Also, determine the closed-loop bandwidth.

P9.20 The Bell-Boeing V-22 Osprey Tiltrotor is both an airplane and a helicopter. Its advantage is the ability to rotate its engines to a vertical position, as shown in Figure P7.33(a), for takeoffs and landings and then switch the engines to a horizontal position for cruising as an airplane. The altitude control system in the helicopter mode is shown in Figure P9.20. (a) Obtain the frequency response of the system for $K=100$. (b) Find the gain margin and the phase margin for this system. (c) Select a suitable gain $K$ so that the phase margin is P.M. $=40^{\circ}$. (Decrease the gain above $K=100$.)

(d) Find the response $y(t)$ of the system for the gain selected in part (c).

P9.21 Consider a unity feedback system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+3)(s+5)} .
$$

FIGURE P9.18

Automobile and driver control.

FIGURE P9.19

Waste collection system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0715.jpg?height=1120&width=1266&top_left_y=994&top_left_x=352)

FIGURE P9.20

Tiltrotor aircraft control. (a) Sketch the Bode plot for $K=1$. Determine P9.23 A closed-loop system has a loop transfer function (b) the gain margin, (c) the value of $K$ required to provide a gain margin equal to $20 \mathrm{~dB}$, and (d) the value of $K$ to yield a steady-state error of $10 \%$ of the magnitude $A$ for the ramp input $r(t)=A t, t>0$. Can this gain be utilized and achieve acceptable performance?

P9.22 The Nichols chart for $G_{c}(j \omega) G(j \omega)$ of a closed-loop system is shown in Figure P9.22. The frequency for each point on the graph is given in the following table:

\begin{tabular}{cccccccccc} 
Point & $\mathbf{1}$ & $\mathbf{2}$ & $\mathbf{3}$ & $\mathbf{4}$ & $\mathbf{5}$ & $\mathbf{6}$ & $\mathbf{7}$ & $\mathbf{8}$ & $\mathbf{9}$ \\
\hline & 1 & 2.0 & 2.6 & 3.4 & 4.2 & 5.2 & 6.0 & 7.0 & 8.0
\end{tabular}

Determine (a) the resonant frequency, (b) the bandwidth, (c) the phase margin, and (d) the gain margin. (e) Estimate the overshoot and settling time (with a $2 \%$ criterion) of the response to a step input.

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+3)(s+10)} .
$$

(a) Determine the gain $K$ so that the phase margin is $P . M .=40^{\circ}$. (b) For the gain $K$ selected in part (a), determine the gain margin of the system.

P9.24 A closed-loop system with unity feedback has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+30)}{s^{2}} .
$$

(a) Determine the gain $K$ so that the phase margin is $P . M .=35^{\circ}$. (b) For the gain $K$ selected in part (a) determine the gain margin of the system. (c) Predict the bandwidth of the closed-loop system.

FIGURE P9.22 Nichols chart.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0716.jpg?height=1197&width=908&top_left_y=926&top_left_x=520)

P9.25 A closed-loop system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K e^{-s T}}{(s+1)} .
$$

(a) Determine the gain $K$ so that the phase margin is $P . M .=60^{\circ}$ when $T=0.15$. (b) Plot the phase margin versus the time delay $T$ for $K$ as in part (a).

P9.26 A specialty machine shop is improving the efficiency of its surface-grinding process [21]. The existing machine is mechanically sound, but manually operated. Automating the machine will free the operator for other tasks and thus increase overall throughput of the machine shop. The grinding machine is shown in Figure P9.26(a) with all three axes automated with motors and feedback systems. The control system for the $y$-axis is shown in Figure P9.26(b). To achieve a low steady-state error to a ramp command, we choose $K=2$. Sketch the Bode plot and Nichols chart.
Determine the gain margin and phase margin of the system and the bandwidth of the closed-loop system. Estimate the damping ratio of the system and the predicted percent overshoot and settling time.

P9.27 Consider the system shown in Figure P9.27. Determine the maximum value of $K=K_{\max }$ for which the closed-loop system is stable. Plot the phase margin as a function of the gain $1 \leq K \leq K_{\max }$. Explain what happens to the phase margin as $K$ approaches $K_{\max }$.

P9.28 Consider the feedback system shown in Figure P9.28.

(a) Determine the value of $K_{P}$ such that the phase margin is P.M. $=60^{\circ}$.

(b) Using the P.M. obtained, predict the percent overshoot of the closed-loop system to a unit step input.

(c) Plot the step response, and compare the actual percent overshoot with the predicted percent overshoot.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0717.jpg?height=607&width=680&top_left_y=823&top_left_x=74)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0717.jpg?height=188&width=891&top_left_y=1244&top_left_x=693)

(b)

FIGURE P9.26 Surface-grinding wheel control system.

FIGURE P9.27

Nonunity feedback system with proportional controller $K$.

FIGURE P9.28 A unity feedback system with a proportional controller in the loop.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0717.jpg?height=568&width=1042&top_left_y=1559&top_left_x=370)

\section{ADVANCED PROBLEMS}

AP9.1 For positive constants of $K, T_{1}$, and $T_{2}$, a control system is described by its loop transfer function as

$$
L(s)=G_{c}(s) H(s)=\frac{K\left(1+T_{1} s\right)}{s^{2}\left(1+T_{2} s\right)} .
$$

Considering gain $K=0.06$, compute the phase margin and gain margin for (a) $T_{1}=5$ and $T_{2}=2$. (b) $T_{1}=2$ and $T_{2}=5$. (c) Comment on the stability.

AP9.2 Anesthesia is used in surgery to induce unconsciousness. One problem with drug-induced unconsciousness is differences in patient responsiveness. Furthermore, the patient response changes during an operation. A model of drug-induced anesthesia control is shown in Figure AP9.2. The proxy for unconsciousness is the arterial blood pressure.

(a) Obtain the Bode plot and determine the gain margin and the phase margin when $T=0.05 \mathrm{~s}$.

(b) Repeat part (a) when $T=0.1 \mathrm{~s}$. Describe the effect of the $100 \%$ increase in the time delay $T$. (c) Using the phase margin, predict the percent overshoot for a step input for parts (a) and (b).

AP9.3 Figure AP9.3 shows an automatic water treatment plant. It is typically a mechanical-chemical arrangement that uses reagent to purify water. The plant comprises an input pipeline embedded with a flow meter and sensors. The temperature and the flow rate of the boiler and the cooling water are regulated based on the input-output concentration of the chemical water.

The transfer function of the system is given by

$L(s)=G(s) H(s)=\frac{0.2 s^{3}+0.06 s^{2}+0.03 s+0.04}{s^{3}+1.12 s^{2}+0.8 s+0.4}$.

(a) Draw the Bode plot indicating the gain margin and phase margin. (b) Find the peak overshoot of the system for unit step input.
FIGURE AP9.2

Control of blood pressure with anesthesia.
FIGURE AP9.3

An automatic water treatment plant.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0718.jpg?height=1162&width=1122&top_left_y=956&top_left_x=516)AP9.4 The loop transfer function of a system is described as

$$
L(s)=G(s) H(s)=\frac{K}{s(s+2.45)^{3}} .
$$

Find the value of $K$ for marginal stability. Find the gain margin and the phase margin for $K=22$ and $K=42$.

AP9.5 A unity feedback control system given by

$$
L(s)=G(s) H(s)=\frac{5 e^{-s T}}{s(s+3)(s+4)} .
$$

Determine the (a) phase margin for $T=0$ and (b) limiting value of $T$ for stability.

AP9.6 The acidity of water draining from a coal mine is often controlled by adding lime to the water. A valve controls the lime addition and a sensor is downstream. For the model of the system shown in Figure AP9.6, determine $K$ and the distance $D$ to maintain stability. We require $D>2$ meters in order to allow full mixing before sensing.

AP9.7 Building elevators are limited to about 800 meters. Above that height, elevator cables become too thick and too heavy for practical use. One solution is to eliminate the cable. The key to the cordless elevator is the linear motor technology now being applied to the development of magnetically levitated rail transportation systems. Under consideration is a linear synchronous motor that propels a passenger car along the track like guideway running the length of the elevator shaft. The motor works by the interaction of an electromagnetic field from electric coils on the guideway with magnets on the car [28].

If we assume that the motor has negligible friction, the system may be represented by the model shown in Figure AP9.7. Determine $K$ so that the phase margin of the system is $P . M .=60^{\circ}$. For the gain $K$ selected, determine the system bandwidth. Also calculate the maximum value of the output for a unit step disturbance for the selected gain.
FIGURE AP9.6

Mine water acidity control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0719.jpg?height=237&width=1044&top_left_y=1034&top_left_x=372)

FIGURE AP9.7

Elevator position

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0719.jpg?height=327&width=1242&top_left_y=1365&top_left_x=374)

AP9.8 A control system is shown in Figure AP9.8. The gain $K$ is greater than 500 and less than 4000 . Select a gain that will cause the system step response to have a percent overshoot of P.O. $\leq 20 \%$. Plot the Nichols chart and calculate the phase margin.

AP9.9 Consider a unity feedback system with

$$
G(s)=\frac{1}{s\left(s^{2}+6 s+12\right)}
$$

and

$$
G_{c}(s)=K_{P}+\frac{K_{1}}{s} .
$$

Let

$$
\frac{K_{P}}{K_{1}}=0.3
$$

and determine the gain $K_{P}$ that provides the maximum phase margin.

AP9.10 A multiloop block diagram is shown in Figure AP9.10.

(a) Compute the transfer function $T(s)=Y(s) / R(s)$. (b) Determine $K$ such that the steady-state tracking error to a unit step input $R(s)=1 / s$ is zero. Plot the unit step response.

(c) Using $K$ from part (b), compute the system bandwidth $\omega_{b}$.

AP9.11 Patients with a cardiological illness and less than normal heart muscle strength can benefit from an assistance device. An electric ventricular assist device (EVAD) converts electric power into blood flow by moving a pusher plate against a flexible blood sac. The pusher plate reciprocates to eject blood in systole and to allow the sac to fill in diastole. The EVAD will be implanted in tandem or in parallel with the intact natural heart as shown in Figure AP9.11(a). The EVAD is driven by rechargeable batteries, and the electric power is transmitted inductively across the skin through a transmission system. The batteries and the transmission system limit the electric energy storage and the transmitted peak power. We desire to drive the EVAD in a fashion that minimizes its electric power consumption [33].

The EVAD has a single input, the applied motor voltage, and a single output, the blood flow rate. The control system of the EVAD performs two main
FIGURE AP9.8

Gain selection.

FIGURE AP9.10

Multiloop feedback control system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0720.jpg?height=676&width=1040&top_left_y=1074&top_left_x=519)FIGURE AP9.11

(a) An electric ventricular assist device for cardiology patients.

(b) Feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0721.jpg?height=769&width=873&top_left_y=152&top_left_x=542)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0721.jpg?height=270&width=1100&top_left_y=1027&top_left_x=372)

(b) tasks: It adjusts the motor voltage to drive the pusher plate through its desired stroke, and it varies the EVAD blood flow to meet the body's cardiac output demand. The blood flow controller adjusts the blood flow rate by varying the EVAD beat rate. A model of the feedback control system is shown in Figure AP9.11(b). The motor, pump, and blood sac can be modeled by a nominal time delay with $T=2 \mathrm{~s}$. The goal is to achieve a step response with zero steady-state error and percent overshoot P.O. $\leq 15 \%$.
Consider the controller

$$
G_{c}(s)=\frac{2}{s(s+7)} .
$$

For the nominal time delay of $T=2 \mathrm{~s}$, plot the step response and verify that steady-state tracking error and percent overshoot specifications are satisfied. Determine the maximum time delay, $T$, possible with the controller that continues to stabilize the closed-loop system. Plot the phase margin as a function of time delay up to the maximum allowed for stability.

\section{DESIGN PROBLEMS}

CDP9.1 The system of Figure CDP4.1 uses a controller $G_{c}(s)=K_{a}$. Determine the value of $K_{a}$ so that the phase margin is $P . M .=70^{\circ}$. Plot the response of this system to a step input.
DP9.1 A mobile robot for toxic waste cleanup is shown in Figure DP9.1(a) [23]. The closed-loop speed control is a unity feedback system. The Nichols chart in Figure DP9.1(b) shows the plot of $G_{c}(j \omega) G(j \omega) / K$ versus $\omega$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0722.jpg?height=390&width=423&top_left_y=158&top_left_x=729)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0722.jpg?height=1479&width=1127&top_left_y=639&top_left_x=227)

cleanup. (b) Nichols chart.

(b) The value of the frequency at the points indicated is DP9.4 A robot tennis player is shown in Figure DP9.4(a), recorded in the following table:

\begin{tabular}{cccccc} 
Point & $\mathbf{1}$ & $\mathbf{2}$ & $\mathbf{3}$ & $\mathbf{4}$ & $\mathbf{5}$ \\
\hline & 2 & 5 & 10 & 20 & 50
\end{tabular}
and a simplified control system for $\theta_{2}(t)$ is shown in Figure DP9.4(b). The goal of the control system is to attain the best step response while attaining a high $K_{v}$ for the system. Select $K_{v 1}=0.35$ and $K_{v 2}=0.65$, and determine the phase margin, gain margin, bandwidth, percent overshoot, and settling time for each case. Obtain the step response for each case, and select the best value for $K$.

closed-loop system when $K=1$. (b) Determine the resonant peak in $\mathrm{dB}$ and the resonant frequency for $K=1$. (c) Determine the system bandwidth and estimate the settling time (with a $2 \%$ criterion) and percent overshoot of this system for a step input. (d) Determine the appropriate gain $K$ so that the percent overshoot to a step input is P.O. $=30 \%$, and estimate the settling time of the system.

DP9.2 Flexible-joint robotic arms are constructed of lightweight materials and exhibit lightly damped open-loop dynamics [15]. A feedback control system for a flexible arm is shown in Figure DP9.2. Select $K$ so that the system has maximum phase margin. Predict the percent overshoot for a step input based on the phase margin attained, and compare it to the actual overshoot for a step input. Determine the bandwidth of the closed-loop system. Predict the settling time (with a $2 \%$ criterion) of the system to a step input and compare it to the actual settling time. Discuss the suitability of this control system.

DP9.3 An automatic drug delivery system is used in the regulation of critical care patients suffering from cardiac failure [24]. The goal is to maintain stable patient status within narrow bounds. Consider the use of a drug delivery system for the regulation of blood pressure by the infusion of a drug. The feedback control system is shown in Figure DP9.3. Select an appropriate gain $K$ that maintains narrow deviation for blood pressure while achieving a good dynamic response.

DP9.5 An electrohydraulic actuator is used to actuate large loads for a robot manipulator, as shown in Figure DP9.5 [17]. The system is subjected to a step input, and we desire the steady-state error to be minimized. However, we wish to keep the percent overshoot P.O. $\leq 10 \%$. Let $T=0.8 \mathrm{~s}$.

(a) Select the gain $K$ when $G_{c}(s)=K$, and determine the resulting percent overshoot, settling time (with a $2 \%$ criterion), and steady-state error. (b) Repeat part (a) when $G_{c}(s)=K_{1}+K_{2} / s$ by selecting $K_{1}$ and $K_{2}$. Sketch the Nichols chart for the selected gains $K_{1}$ and $K_{2}$.

DP9.6 The physical representation of a steel strip-rolling mill is a damped-spring system [8]. The output thickness sensor is located a negligible distance from the output of the mill, and the objective is to keep the thickness as close to a reference value as possible. Any change of the input strip thickness is regarded as a disturbance. The system is a nonunity feedback system, as shown in Figure DP9.6. Depending on the maintenance of the mill, the parameter varies as $50 \leq b<400$.

Determine the phase margin and gain margin for the two extreme values of $b$ when the normal value of the gain is $K=100$. Recommend a reduced value for $K$ so that the phase margin is $P . M . \geq 45^{\circ}$ and the gain margin is G.M. $\geq 6 \mathrm{~dB}$ for the range of $b$.

FIGURE DP9.2

Control of a flexible robot arm.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0723.jpg?height=582&width=1040&top_left_y=1523&top_left_x=374)

FIGURE DP9.3

Automatic drug delivery. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0724.jpg?height=452&width=426&top_left_y=160&top_left_x=690)

(a)

FIGURE DP9.4

(a) An articulated two-link tennis player robot.

(b) Unity feedback control system.

FIGURE DP9.5 Electrohydraulic actuator.

FIGURE DP9.6 Steel strip-rolling mill.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0724.jpg?height=188&width=776&top_left_y=710&top_left_x=508)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0724.jpg?height=646&width=1040&top_left_y=1032&top_left_x=508)

DP9.7 Vehicles for lunar construction and exploration work will face conditions unlike anything found on Earth. Furthermore, they will be controlled via remote control. A block diagram of such a vehicle and the control are shown in Figure DP9.7. Select the gain $K$ to have a percent overshoot of P.O. $=10 \%$. For this $K$, what is the maximum allowed time delay $T$ for stability?

DP9.8 The control of a high-speed steel-rolling mill is a challenging problem. The goal is to keep the strip thickness accurate and readily adjustable. The model of the control system is shown in Figure DP9.8. Design a control system by selecting $K$ so that the step response of the system is as fast as possible with a percent overshoot of P.O. $\leq 0.7 \%$, and a settling time (with a $2 \%$ criterion) of $T_{\mathrm{s}} \leq 4 \mathrm{~s}$. Use the root locus to select $K$, and calculate the roots for the selected $K$. Describe the dominant root(s) of the system.

DP9.9 A two-tank system containing a heated liquid has the model shown in Figure DP9.9(a), where $T_{0}$ is the temperature of the fluid flowing into the first tank FIGURE DP9.7

Lunar vehicle

control.

FIGURE DP9.8

Steel-rolling mill control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0725.jpg?height=1026&width=1250&top_left_y=154&top_left_x=372)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0725.jpg?height=317&width=948&top_left_y=1281&top_left_x=387)

(b) and $T_{2}$ is the temperature of the liquid flowing out of the second tank. The block diagram model is shown in Figure DP9.9(b). The system of the two tanks has a heater in tank 1 with a controllable heat input $Q$. The time constants are $\tau_{1}=10 \mathrm{~s}$ and $\tau_{2}=50 \mathrm{~s}$.

(a) Determine $T_{2}(s)$ in terms of $T_{0}(s)$ and $T_{2 d}(s)$.

(b) If $T_{2 d}(s)$, the desired output temperature, is changed instantaneously from $T_{2 d}(s)=A / s$ to $T_{2 d}(s)=2 A / s$, determine the transient response of $T_{2}(t)$ when $G_{c}(s)=K=500$. Assume that, prior to the abrupt temperature change, the system is at steady state. (c) Find the steady-state error $e_{\mathrm{ss}}$ for the system of part (b), where $E(s)=T_{2 d}(s)-T_{2}(s)$.

(d) Let $G_{c}(s)=K / s$ and repeat parts (b) and (c). Use a gain $K$ such that the percent overshoot is P.O. $\leq 10 \%$.

(e) Design a controller that will result in a system with a settling time (with a $2 \%$ criterion) of $T_{s} \leq 150 \mathrm{~s}$ and a percent overshoot of P.O. $\leq 10 \%$, while maintaining a zero steady-state error when

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s} .
$$

FIGURE DP9.11

Nuclear reactor control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0726.jpg?height=635&width=1077&top_left_y=151&top_left_x=506)

(f) Prepare a table comparing the percent overshoot, settling time, and steady-state error for the designs of parts (b) through (e).

DP9.10 Consider the system is described in state variable form by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & 1 \\
2 & 3
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right] .
$$

Assume that the input is a linear combination of the states, that is,

$$
u(t)=-\mathbf{K x}(t)+r(t),
$$

where $r(t)$ is the reference input and the gain matrix is $\mathrm{K}=\left[\begin{array}{ll}K_{1} & K_{2}\end{array}\right]$. Substituting $u(t)$ into the state variable equation yields the closed-loop system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =[\mathbf{A}-\mathbf{B K}] \mathbf{x}(t)+\mathbf{B} r(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t) .
\end{aligned}
$$

(a) Obtain the characteristic equation associated with A-BK. (b) Design the gain matrix $\mathbf{K}$ to meet the following specifications: (i) the closed-loop system is stable; (ii) the system bandwidth $\omega_{b} \geq 1 \mathrm{rad} / \mathrm{s}$; and (iii) the steady-state error to a unit step input $R(s)=1 / s$ is zero.

DP9.11 The primary control loop of a nuclear power plant includes a time delay due to the need to transport the fluid from the reactor to the measurement point as shown in Figure DP9.11. The transfer function of the controller is

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s} .
$$

The transfer function of the reactor and time delay is

$$
G(s)=\frac{e^{-s T}}{\tau s+1},
$$

where $T=0.5 \mathrm{~s}$ and $\tau=0.3 \mathrm{~s}$. Using frequency response methods, design the controller so that the percent overshoot of the system is P.O. $\leq 20 \%$. With this controller in the loop, estimate the percent overshoot and settling time (with a $2 \%$ criterion) to a unit step. Determine the actual overshoot and settling time, and compare with the estimated values.

\section{COMPUTER PROBLEMS}

CP9.1 Consider a unity negative feedback control system with

$$
L(s)=G_{c}(s) G(s)=\frac{141}{s^{2}+2 s+12} .
$$

Verify that the gain margin is $\infty$ and that the phase margin is $10^{\circ}$. CP9.2 Using the nyquist function, obtain the Nyquist plot CP9.6 A block diagram of the yaw acceleration control for the following transfer functions:
(a) $G(s)=\frac{15}{s+20}$;
(b) $G(s)=\frac{40}{s^{2}+6 s+25}$;
(c) $G(s)=\frac{12}{s^{3}+4 s^{2}+4 s+1}$.

CP9.3 Using the nichols function, obtain the Nichols chart with a grid for the following transfer functions:

(a) $G(s)=\frac{1}{s+0.2}$;

(b) $G(s)=\frac{1}{s^{2}+2 s+1}$;

(c) $G(s)=\frac{12}{s^{3}+6 s^{2}+11 s+6}$.

Determine the approximate phase and gain margins from the Nichols charts and label the charts accordingly.

CP9.4 A negative feedback control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K e^{-T s}}{s+15} .
$$

(a) When $T=0.05 \mathrm{~s}$, find $K$ such that the phase margin is $P . M . \geq 55^{\circ}$ using the margin function. (b) Obtain a plot of phase margin versus $T$ for $K$ as in part (a), with $0 \leq T \leq 0.4 \mathrm{~s}$.

CP9.5 Consider a unity feedlach system with the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+25)}{s(s+10)(s+20)} .
$$

Develop an m-file to plot the bandwidth of the closedloop system as $K$ varies in the interval $1 \leq K \leq 80$. system for a bank-to-turn missile is shown in Figure CP9.6. The input is yaw acceleration command (in g's), and the output is missile yaw acceleration (in g's). The controller is specified to be a proportional, integral

(PI) controller. The nominal value of $b_{0}$ is 0.5 .

(a) Using the margin function, compute the phase margin, gain margin, and system crossover frequency assuming the nominal value of $b_{0}$.

(b) Using the gain margin from part (a), determine the maximum value of $b_{0}$ for a stable system. Verify your answer with a Routh-Hurwitz analysis of the characteristic equation.

CP9.7 An engineering laboratory has presented a plan to operate an Earth-orbiting satellite that is to be controlled from a ground station. A block diagram of the proposed system is shown in Figure CP9.7. It takes $T$ seconds for a signal to reach the spacecraft from the ground station and the identical delay for a return signal. The proposed ground-based controller is a proportional-derivative (PD) controller, where

$$
G_{c}(s)=K_{P}+K_{D} s .
$$

(a) Assume no transmission time delay (i.e., $T=0$ ), and design the controller to the following specifications: (1) percent overshoot P.O. $\leq 20 \%$ to a unit step input and (2) time to peak $T_{p} \leq 30 \mathrm{~s}$.

(b) Compute the phase margin with the controller in the loop but assuming a zero transmission time delay. Estimate the amount of allowable time delay for a stable system from the phase margin calculation.

(c) Using a second-order Padé approximation to the time delay, determine the maximum allowable delay $T_{\max }$ for system stability by developing a

FIGURE CP9.6 A feedback control system for the yaw acceleration control of a bank-to-turn missile.

\section{FIGURE CP9.7}

A block diagram of a ground-controlled satellite.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0727.jpg?height=578&width=1100&top_left_y=1538&top_left_x=372)$\mathrm{m}$-file script that employs the pade function and computes the closed-loop system poles as a function of the time delay $T$. Compare your answer with the one obtained in part (b).

CP9.8 Consider the system represented in state variable

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 2 \\
-1 & -18
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
20
\end{array}\right] u(t) \\
y(t)=\left[\begin{array}{ll}
6 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t)
\end{gathered}
$$

Using the nyquist function, obtain the Nyquist plot.

CP9.9 For the system in CP9.8, use the nichols function to obtain the Nichols chart and determine the phase margin and gain margin.

CP9.10 A closed-loop feedback system is shown in Figure CP9.10. (a) Obtain the Nyquist plot, and determine the phase margin. Assume that the time delay $T=0 \mathrm{~s}$. (b) Compute the phase margin when $T=0.05 \mathrm{~s}$. (c) Determine the minimum time delay that destabilizes the closed-loop system.

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) True; (4) True; (5) False

Multiple Choice: (6) b; (7) a; (8) d; (9) a; (10) d; (11) b; (12) a; (13) b; (14) c; (15) a

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0728.jpg?height=296&width=759&top_left_y=381&top_left_x=994)

FIGURE CP9.10 Nonunity feedback system with a time delay.

\section{TERMS AND CONCEPTS}

Bandwidth The frequency at which the frequency response has declined $3 \mathrm{~dB}$ from its low-frequency value.

Cauchy's theorem If a contour encircles $Z$ zeros and $P$ poles of $F(s)$ traversing clockwise, the corresponding contour in the $F(s)$-plane encircles the origin of the $F(s)$-plane $N=Z-P$ times clockwise.

Closed-loop frequency response The frequency response of the closed-loop transfer function $T(j \omega)$.

Conformal mapping A contour mapping that retains the angles on the $s$-plane on the $F(s)$-plane.

Contour map A contour or trajectory in one plane is mapped into another plane by a relation $F(s)$.

Gain margin The increase in the system gain when phase $=-180^{\circ}$ that will result in a marginally stable system with intersection of the $-1+j 0$ point on the Nyquist diagram.

Logarithmic (decibel) measure A measure of the gain margin defined as $20 \log _{10}(1 / d)$, where $\frac{1}{d}=\frac{1}{|L(j \omega)|}$ when the phase shift is $-180^{\circ}$.
Word Match (in order, top to bottom): f, e, k, b, j, a, i, d, h, c, g
Nichols chart A chart displaying the curves for the relationship between the open-loop and closed-loop frequency response.

Nyquist stability criterion A feedback system is stable if, and only if, the contour in the $L(s)$-plane does not encircle the $(-1,0)$ point when the number of poles of $L(s)$ in the right-hand $s$-plane is zero. If $L(s)$ has $P$ poles in the right-hand plane, then the number of counterclockwise encirclements of the $(-1,0)$ point must be equal to $P$ for a stable system.

Phase margin The amount of phase shift of the $L(j \omega)$ at unity magnitude that will result in a marginally stable system with intersections of the $-1+j 0$ point on the Nyquist diagram.

Principle of the argument See Cauchy's theorem.

Time delay A time delay $T$, so that events occurring at time $t$ at one point in the system occur at another point in the system at a later time $t+T$. 

\section{CHAPTER 10 \\ The Design of Feedback Control Systems}

10.1 Introduction 729

10.2 Approaches to System Design 730

10.3 Cascade Compensators 731

10.4 Phase-Lead Design Using the Bode Plot 735

10.5 Phase-Lead Design Using the Root Locus 741

10.6 System Design Using Integration Compensators 747

10.7 Phase-Lag Design Using the Root Locus 750

10.8 Phase-Lag Design Using the Bode Plot 753

10.9 Design on the Bode Plot Using Analytical Methods 758

10.10 Systems with a Prefilter 759

10.11 Design for Deadbeat Response 762

10.12 Design Examples 764

10.13 System Design Using Control Design Software 774

10.14 Sequential Design Example: Disk Drive Read System 781

10.15 Summary 783

\section{PREVIEW}

In this chapter, we address the central issue of the design of compensators. Using the methods of the previous chapters, we develop several design techniques in the frequency domain that enable us to achieve the desired system performance. The powerful lead and lag controllers are used in several design examples. Phase-lead and phase-lag control design approaches using both root locus plots and Bode plots are presented. The proportional-integral (PI) controller is revisited in the context of achieving high steady-state tracking accuracies. The chapter concludes with a proportional-derivative (PD) controller design with prefiltering for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 10, students should be able to:

$\square \quad$ Explain the design of lead and lag compensators using root locus and Bode plot methods.

$\square \quad$ Identify the value of prefilters and design for deadbeat response.

$\square$ Distinguish between the varied approaches available for control system design. 

\subsection{INTRODUCTION}

The performance of a feedback control system is of primary importance. A suitable control system is stable and results in an acceptable response to input commands, is less sensitive to system parameter changes, results in a minimum steady-state error for input commands, and is able to reduce the effect of undesirable disturbances. A feedback control system that provides an optimum performance without any necessary adjustments is rare. Usually, we find it necessary to compromise among the many conflicting and demanding specifications and to adjust the system parameters to provide a suitable and acceptable performance when it is not possible to obtain all the desired optimum specifications.

It is generally possible to adjust the system parameters in order to provide the desired system response. However, we may find that it is not sufficient to adjust a single system parameter and obtain the desired performance. Rather, we may be required to consider the structure of the system and redesign the system in order to obtain a suitable one. That is, sometimes we must examine the scheme or plan of the system and obtain a new design or plan that results in a suitable system. Thus, the design of a control system is concerned with the arrangement, or the plan, of the system structure and the selection of suitable components and parameters. For example, if we desire a set of performance measures to be less than some specified values, we often encounter a conflicting set of requirements. Hence, if we wish a system to have a percent overshoot less P.O. $\leq 20 \%$ and $\omega_{n} T_{p}=3.3$, we obtain a conflicting requirement on the system damping ratio $\zeta$. If we are unable to relax these two performance requirements, we must alter the system in some way. The alteration or adjustment of a control system in order to provide a suitable performance is called compensation; that is, compensation is the adjustment of a system in order to make up for deficiencies or inadequacies.

In redesigning a control system to alter the system response, an additional component is inserted within the structure of the feedback system. It is this additional component or device that equalizes or compensates for the performance deficiency. The compensating device is often called a compensator.

\section{A compensator is an additional component that is inserted into a control system to compensate for a deficient performance.}

The transfer function of a compensator is designated as $G_{c}(s)=E_{\mathrm{o}}(s) / E_{\text {in }}(s)$, and the compensator can be placed in a suitable location within the structure of the system. Several types of compensation are shown in Figure 10.1 for a simple, single-loop feedback control system. The compensator placed in the feedforward path is called a cascade compensator (Figure 10.1a). Similarly, the other compensation schemes are called feedback, output (or load), and input compensation, as shown in Figures 10.1(b), (c), and (d), respectively. The selection of the compensation scheme depends upon a consideration of the specifications, the power levels at various signal nodes in the system, and the networks available for use. Usually, the output $Y(s)$ is a direct output of the process $G(s)$ and the output compensation of Figure $10.1(\mathrm{c})$ is not physically realizable. FIGURE 10.1

Types of compensation.

(a) Cascade

compensation.

(b) Feedback

compensation.

(c) Output, or load, compensation.

(d) Input

compensation.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0731.jpg?height=230&width=647&top_left_y=158&top_left_x=354)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0731.jpg?height=193&width=647&top_left_y=487&top_left_x=354)

(c)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0731.jpg?height=183&width=548&top_left_y=205&top_left_x=1053)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0731.jpg?height=191&width=564&top_left_y=483&top_left_x=1054)

(d)

\subsection{APPROACHES TO SYSTEM DESIGN}

The performance of a control system can be described in terms of the time-domain performance measures or the frequency-domain performance measures. The performance of a system can be specified by requiring a certain peak time, $T_{p}$, maximum percent overshoot, P.O., and settling time, $T_{s}$, for a step input. Furthermore, it is usually necessary to specify the maximum allowable steady-state error for several test signal inputs and disturbance inputs. These performance specifications can be defined in terms of the desirable location of the poles and zeros of the closed-loop system transfer function $T(s)$. Thus, the location of the $s$-plane poles and zeros of $T(s)$ can be specified. The locus of the roots of the closed-loop system can be readily obtained for the variation of one system parameter. However, when the locus of roots does not result in a suitable root configuration, we must add a compensator to alter the locus of the roots as the parameter is varied. Therefore, we can use the root locus method and determine a suitable compensator so that the resultant root locus yields the desired closed-loop root configuration.

Alternatively, we can describe the performance of a feedback control system in terms of frequency performance measures. Then a system can be described in terms of the peak of the closed-loop frequency response, $M_{p \omega}$, the resonant frequency, $\omega_{r}$, the bandwidth, $\omega_{B}$, the gain margin, G.M., and the phase margin, P.M., of the system. We can add a suitable compensator, if necessary, in order to satisfy the system specifications. The design of the compensator, represented by $G_{c}(s)$, is developed in terms of the frequency response as portrayed on the Nyquist plot, the Bode plot, or the Nichols chart. Because a cascade transfer function is readily accounted for on a Bode plot by adding the frequency response of the network, we often prefer to approach the frequency response methods.

Thus, the design of a system is concerned with the alteration of the frequency response or the root locus of the system in order to obtain a suitable system performance. For frequency response methods, we are concerned with altering the system so that the frequency response of the compensated system will satisfy the system specifications. Hence, in the frequency response approach, we use compensators to alter and reshape the system characteristics represented on the Nyquist plot, Bode plot, or Nichols chart.

Alternatively, the design of a control system can be accomplished in the $s$-plane by root locus methods. For the case of the $s$-plane, the designer wishes to alter and reshape the root locus so that the roots of the system lie in the desired locations in the s-plane.

When possible, one way to improve the performance of a control system is to alter the process itself. That is, if the system designer is able to specify and alter the design of the process represented by the transfer function $G(s)$, then the performance of the system may be improved. For example, to improve the transient behavior of a servomechanism position controller, we might choose a better motor for the system. In the case of an airplane control system, we might be able to alter the aerodynamic design of the airplane and thus improve the flight transient characteristics. Thus, a control system designer should recognize that an alteration of the process may result in an improved system. However, the process is often unalterable or has been altered as much as possible and still results in unsatisfactory performance. Then the addition of compensators becomes imperative for improving the performance of the system.

In the following sections, we will assume that the process has been improved as much as possible and that the $G(s)$ representing the process is unalterable. First, we shall consider the addition of a phase-lead compensator and describe the design of the network by root locus and frequency response techniques. Then, using both the root locus and frequency response techniques, we will describe the design of the integration compensators in order to obtain a suitable system performance.

\subsection{CASCADE COMPENSATORS}

In this section, we consider the design of a cascade compensator, as shown in Figures 10.1(a) and (b), respectively. The compensator, $G_{c}(s)$, is cascaded with the process $G(s)$ to provide a suitable loop transfer function $L(s)=G_{c}(s) G(s) H(s)$. The compensator $G_{c}(s)$ can be chosen to alter either the shape of the root locus or the frequency response. In either case, the compensator may be chosen to have a transfer function

$$
G_{c}(s)=\frac{K \prod_{i=1}^{M}\left(s+z_{i}\right)}{\prod_{j=1}^{n}\left(s+p_{j}\right)} .
$$

Then the problem reduces to the judicious selection of the poles and zeros of the compensator. To illustrate the properties, we consider a first-order compensator. The compensation approach developed on the basis of a first-order compensator can then be extended to higher-order compensators, for example, by cascading several first-order compensators.

A compensator $G_{c}(s)$ is used with a process $G(s)$ so that the overall loop gain can be set to satisfy the steady-state error requirement, and then $G_{c}(s)$ is used to adjust the system dynamics favorably without affecting the steady-state error. FIGURE 10.2

Pole-zero diagram of the phase-lead compensator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0733.jpg?height=369&width=483&top_left_y=152&top_left_x=370)

Consider the first-order compensator with the transfer function

$$
G_{c}(s)=\frac{K(s+z)}{s+p} .
$$

The design problem then becomes the selection of $z, p$, and $K$ in order to provide a suitable performance. When $|z|<|p|$, the compensator is called a phase-lead compensator and has a pole-zero $s$-plane configuration, as shown in Figure 10.2. If the pole was negligible, that is, $|p| \gg|z|$, and the zero occurred at the origin of the $s$-plane, we would have a differentiator so that

$$
G_{c}(s) \approx \frac{K}{p} s .
$$

Thus, a compensator of the form of Equation (10.2) is a differentiator-type compensator. The differentiator compensator of Equation (10.3) has the frequency characteristic

$$
G_{c}(j \omega)=j \frac{K}{p} \omega=\left(\frac{K}{p} \omega\right) e^{+j 90^{\circ}}
$$

and a phase angle of $+90^{\circ}$. Similarly, the frequency response of the differentiating compensator of Equation (10.2) is

$$
G_{c}(j \omega)=\frac{K(j \omega+z)}{j \omega+p}=\frac{K(1+j \omega \alpha \tau)}{\alpha(1+j \omega \tau)},
$$

where $\tau=1 / p$ and $p=\alpha z$. The frequency response of this phase-lead compensator is shown in Figure 10.3. The angle of the frequency characteristic is

$$
\phi(\omega)=\tan ^{-1}(\alpha \omega \tau)-\tan ^{-1}(\omega \tau) .
$$

Because the zero occurs first on the frequency axis, we obtain a phase-lead characteristic, as shown in Figure 10.3. The slope of the asymptotic magnitude curve is $+20 \mathrm{~dB} /$ decade.

The phase-lead compensator transfer function can be written as

$$
G_{c}(s)=\frac{K(1+\alpha \tau s)}{\alpha(1+\tau s)}
$$

FIGURE 10.3

Bode plot of the phase-lead compensator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0734.jpg?height=562&width=1244&top_left_y=152&top_left_x=507)

where $\tau=1 / p$ and $\alpha=p / z>1$. The maximum value of the phase lead occurs at a frequency $\omega_{m}$, where $\omega_{m}$ is the geometric mean of $p=1 / \tau$ and $z=1 /(\alpha \tau)$; that is, the maximum phase lead occurs halfway between the pole and zero frequencies on the logarithmic frequency scale. Therefore,

$$
\omega_{m}=\sqrt{z p}=\frac{1}{\tau \sqrt{\alpha}}
$$

To obtain an equation for the maximum phase-lead angle, we rewrite the phase angle of Equation (10.5) as

$$
\phi=\tan ^{-1} \frac{\alpha \omega \tau-\omega \tau}{1+(\omega \tau)^{2} \alpha} .
$$

Then, substituting the frequency for the maximum phase angle, $\omega_{m}=1 /(\tau \sqrt{a})$, we have

$$
\tan \phi_{m}=\frac{\alpha / \sqrt{\alpha}-1 / \sqrt{\alpha}}{1+1}=\frac{\alpha-1}{2 \sqrt{\alpha}} .
$$

We use the trigonometric relationship $\sin \phi=\tan \phi / \sqrt{1+\tan ^{2} \phi}$ and obtain

$$
\sin \phi_{m}=\frac{\alpha-1}{\alpha+1}
$$

Equation (10.11) is very useful for calculating a necessary $\alpha$ ratio between the pole and zero of a compensator in order to provide a required maximum phase lead. A plot of $\phi_{m}$ versus $\alpha$ is shown in Figure 10.4. The phase angle readily obtainable from this compensator is not much greater than $70^{\circ}$. Also, there are practical limitations on the maximum value of $\alpha$ that we should attempt to FIGURE 10.4

Maximum phase angle $\phi_{m}$ versus $\alpha$ for a phase-lead compensator.
FIGURE 10.5

Pole-zero diagram of the phase-lag compensator.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0735.jpg?height=756&width=790&top_left_y=166&top_left_x=374)

obtain. Therefore, if we required a maximum angle greater than $70^{\circ}$, two cascade compensators could be used.

It is often useful to add a cascade compensator that provides a phase-lag characteristic. The phase-lag compensator transfer function is

$$
G_{c}(s)=K \alpha \frac{1+\tau s}{1+\alpha \tau s},
$$

where $\tau=1 / z$ and $\alpha=z / p>1$. The pole lies closest to the origin of the $s$-plane, as shown in Figure 10.5. This type of compensator is often called an integrating compensator because it has a frequency response like an integrator over a finite range of frequencies. The Bode plot of the phase-lag compensator is obtained from the transfer function

$$
G_{c}(j \omega)=K \alpha \frac{1+j \omega \tau}{1+j \omega \alpha \tau}
$$

and is shown in Figure 10.6. The form of the Bode plot of the lag compensator is similar to that of the phase-lead compensator; the difference is the resulting attenuation and phase-lag angle instead of amplification and phase-lead angle. However, note that the shapes of the diagrams of Figures 10.3 and 10.6 are similar. Therefore, we can show that the maximum phase lag occurs at $\omega_{m}=\sqrt{z p}$.

In the succeeding sections, we wish to utilize these compensation networks to obtain a desired system frequency response or $s$-plane root location. The lead compensator can provide a phase-lead angle and thus a satisfactory phase margin for a system. Alternatively, the phase-lead compensator can enable us to reshape the root locus and thus provide the desired root locations. The phase-lag compensator 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0736.jpg?height=932&width=1409&top_left_y=155&top_left_x=356)

FIGURE 10.6 Bode plot of the phase-lag compensator.

is used, not to provide a phase-lag angle, which is normally a destabilizing influence, but rather to provide an attenuation and to increase the steady-state error constant [3].

\subsection{PHASE-LEAD DESIGN USING THE BODE PLOT}

The Bode plot is used to design a suitable phase-lead compensator in preference to other frequency response plots. The frequency response of the cascade compensator is added to the frequency response of the uncompensated system. That is, because the total loop transfer function of Figure 10.1(a) is $L(j \omega)=G_{c}(j \omega) G(j \omega) H(j \omega)$, we will first plot the Bode plot for $G(j \omega) H(j \omega)$. Then we can examine the plot for $G(j \omega) H(j \omega)$ and determine a suitable location for $p$ and $z$ of $G_{c}(j \omega)$ in order to satisfactorily reshape the frequency response. The uncompensated $G(j \omega) H(j \omega)$ is plotted with the desired gain to allow an acceptable steady-state error. Then the phase margin and the expected $M_{p \omega}$ are examined to find whether they satisfy the specifications. If the phase margin is not sufficient, phase lead can be added to the phase-angle curve of the system by placing the $G_{c}(j \omega)$ in a suitable location. To obtain maximum additional phase lead, we adjust the network so that the frequency $\omega_{m}$ is located at the frequency where the magnitude of the compensated magnitude curve crosses the 0 - $\mathrm{dB}$ axis. The value of the added phase lead required allows us to determine the necessary value for $\alpha$ from Equation (10.11) or Figure 10.4. The zero $z=1 /(\alpha \tau)$ is located by noting that the maximum phase lead should occur at $\omega_{m}=\sqrt{z p}$, halfway between the pole and the zero. Because the total magnitude gain for the compensator is $20 \log \alpha$, we expect a gain of $10 \log \alpha$ at $\omega_{m}$. Thus, we determine the compensator by completing the following steps:

1. Evaluate the uncompensated system phase margin when the error constants are satisfied.

2. Allowing for a small amount of safety, determine the necessary additional phase lead $\phi_{m}$.

3. Evaluate $\alpha$ from Equation (10.11).

4. Assume $K / \alpha=1$ in $G_{s}(s)$ in Equation (10.7). This gain will be adjusted in step 8 .

5. Evaluate $10 \log \alpha$ and determine the frequency where the uncompensated magnitude curve is equal to $-10 \log \alpha \mathrm{dB}$. Because the compensator provides a gain of $10 \log \alpha$ at $\omega_{m}$, this frequency is the new 0 - $\mathrm{dB}$ crossover frequency and $\omega_{m}$ simultaneously.

6. Calculate the pole $p=\omega_{m} \sqrt{a}$ and $z=p / \alpha$.

7. Draw the compensated frequency response, check the resulting phase margin, and repeat the steps if necessary.

8. Finally, for an acceptable design, raise the gain, $K$, compensator in order to account for the attenuation $(1 / \alpha)$.

\section{EXAMPLE 10.1 A lead compensator for a type-two system}

Let us consider a single-loop feedback control system as shown in Figure 10.1(a), where

$$
G(s)=\frac{10}{s^{2}}
$$

and $H(s)=1$. The uncompensated system is a type-two system and at first appears to possess a satisfactory steady-state error for both step and ramp input signals. However, the response of the uncompensated system is an undamped oscillation because

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{10}{s^{2}+10} .
$$

Therefore, the compensator is added so that the loop transfer function is $L(s)=G_{c}(s) G(s)$. The specifications for the system are

Settling time, $T_{s} \leq 4 \mathrm{~s}$;

System damping constant $\zeta \geq 0.45$.

The settling time (with a $2 \%$ criterion) requirement is

therefore,

$$
T_{s}=\frac{4}{\zeta \omega_{n}}=4 ;
$$

$$
\omega_{n}=\frac{1}{\zeta}=\frac{1}{0.45}=2.22 \text {. }
$$

FIGURE 10.7

Bode plot for Example 10.1.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0738.jpg?height=618&width=1267&top_left_y=152&top_left_x=486)

Perhaps the easiest way to check the value of $\omega_{n}$ for the frequency response is to relate $\omega_{n}$ to the bandwidth $\omega_{B}$, and evaluate the $-3-\mathrm{dB}$ bandwidth of the closedloop system. For a closed-loop system with $\zeta=0.45$, we estimate the closed-loop bandwidth $\omega_{B}=(-1.19 \zeta+1.85) \omega_{n}=3.00$. The bandwidth can be checked following compensation by utilizing the Nichols chart. The Bode plot of

$$
G(j \omega)=\frac{10}{(j \omega)^{2}}
$$

is shown as solid lines in Figure 10.7. The phase margin of the system is required to be approximately

$$
\phi_{\mathrm{pm}}=\frac{\zeta}{0.01}=\frac{0.45}{0.01}=45^{\circ} .
$$

The phase margin of the uncompensated system is $0^{\circ}$ because the double integration results in a constant $180^{\circ}$ phase lag. Therefore, we must add a $45^{\circ}$ phase-lead angle at the crossover $(0-\mathrm{dB})$ frequency of the compensated magnitude curve. Evaluating the value of $\alpha$, we have

$$
\frac{\alpha-1}{\alpha+1}=\sin \phi_{m}=\sin 45^{\circ},
$$

and thus $\alpha=5.8$. To provide a margin of safety, we will use $\alpha=6$. The value of $10 \log \alpha$ is then equal to $7.78 \mathrm{~dB}$. Then the lead compensator will add an additional gain of $7.78 \mathrm{~dB}$ at the frequency $\omega_{m}$, and we want to have $\omega_{m}$ equal to the compensated slope near the 0 - $\mathrm{dB}$ axis (the dashed line) so that the new crossover is $\omega_{m}$ and the dashed magnitude curve is $7.78 \mathrm{~dB}$ above the uncompensated curve at the crossover frequency. Thus, the compensated crossover frequency is located by evaluating the frequency where the uncompensated magnitude curve is equal to $-7.78 \mathrm{~dB}$, which in this case is $\omega=4.95$. Then the maximum phase-lead angle is added to $\omega=\omega_{m}=4.95$, as shown in Figure 10.7. Using step 6, we determine the pole $p=\omega_{m} \sqrt{\alpha}=12.0$ and the zero $z=p / \alpha=2.0$.

The transfer function of the compensator is

$$
G_{c}(s)=K \frac{(1+\alpha \tau s)}{\alpha(1+\tau s)}=\frac{K}{6} \frac{1+s / 2.0}{1+s / 12.0},
$$

in the form of Equation (10.8). We select $K=6$ so that the total loop gain is still equal to 10 . When we add the compensated Bode plot to the uncompensated Bode plot, as in Figure 10.7, we assume that we can raise the gain to account for the $1 / \alpha$ attenuation.

The total loop transfer function is

$$
L(s)=\frac{10(1+s / 2)}{s^{2}(1+s / 12)}=\frac{60(s+2)}{s^{2}(s+12)} .
$$

The closed-loop transfer function is

$$
T(s)=\frac{60(s+2)}{s^{3}+12 s^{2}+60 s+120} \approx \frac{60(s+2)}{\left(s^{2}+6 s+20\right)(s+6)},
$$

and the effects of the zero at $s=-2$ and the third pole at $s=-6$ will affect the transient response. The percent overshoot is $P . O .=34 \%$, the settling time is $T_{s}=1.3 \mathrm{~s}$, the bandwidth is $\omega_{B}=8.4 \mathrm{rad} / \mathrm{s}$, and the phase margin is $P . M .=45.6^{\circ}$.

\section{EXAMPLE 10.2 A lead compensator for a second-order system}

A unity feedback control system has a loop transfer function

$$
L(s)=\frac{40}{s(s+2)},
$$

where $L(s)=G_{c}(s) G(s)$. We want to have a steady-state error for a ramp input of $e_{s s}=5 \%$ of the velocity of the ramp. Therefore, we require that

$$
K_{v}=\frac{A}{e_{\mathrm{ss}}}=\frac{A}{0.05 A}=20 .
$$

Furthermore, we desire that the phase margin of the system be at least P.M. $=40^{\circ}$. The first step is to obtain the Bode plot of the uncompensated transfer function

$$
G(j \omega)=\frac{20}{j \omega(0.5 j \omega+1)},
$$

where $K=K_{v}$, as shown in Figure 10.8(a). The frequency at which the magnitude curve crosses the $0-\mathrm{dB}$ line is $6.2 \mathrm{rad} / \mathrm{s}$, and the phase margin at this frequency is determined readily from

$$
\angle G(j \omega)=\phi(\omega)=-90^{\circ}-\tan ^{-1}(0.5 \omega) .
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0740.jpg?height=418&width=868&top_left_y=165&top_left_x=544)

\section{क्र
है
$\theta$}

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0740.jpg?height=1357&width=833&top_left_y=672&top_left_x=508)

(a) Bode plot for Example 10.2.

(b) Nichols chart for Example 10.2.

(b) At the crossover frequency $\omega=\omega_{c}=6.2 \mathrm{rad} / \mathrm{s}$, we have

$$
\phi(\omega)=-162^{\circ}
$$

and therefore the phase margin is $P . M .=18^{\circ}$. We need to add a phase-lead compensator so that the phase margin is raised to $P . M .=40^{\circ}$ at the new crossover $(0-\mathrm{dB})$ frequency. Because the compensation crossover frequency is greater than the uncompensated crossover frequency, the phase lag of the uncompensated system is also greater. We shall account for this additional phase lag by attempting to obtain a maximum phase lead of $40^{\circ}-18^{\circ}=22^{\circ}$, plus a small increment of phase lead to account for the added lag. Thus, we will design a compensator with a maximum phase lead equal to $22^{\circ}+8^{\circ}=30^{\circ}$. Then, calculating $\alpha$, we obtain

$$
\frac{\alpha-1}{\alpha+1}=\sin 30^{\circ}=0.5
$$

and therefore $\alpha=3$.

The maximum phase lead occurs at $\omega_{m}$, and this frequency will be selected so that the new crossover frequency and $\omega_{m}$ coincide. The lead compensator will add an additional $10 \log \alpha=10 \log 3=4.8 \mathrm{~dB}$ at $\omega_{m}$. The compensated crossover frequency is then evaluated where the magnitude of $G(j \omega)$ is $-4.8 \mathrm{~dB}$, and thus $\omega_{m}=\omega_{c}=8.4$. Drawing the compensated magnitude line so that it intersects the 0 - $\mathrm{dB}$ axis at $\omega=\omega_{c}=8.4$, we find that $z=\omega_{m} / \sqrt{\alpha}=4.8$ and $p=\alpha z=14.4$. Therefore, the compensator is

$$
G_{c}(s)=\frac{K}{3} \frac{1+s / 4.8}{1+s / 14.4}
$$

The total loop gain must be raised by a factor of three in order to account for the factor $1 / \alpha$. With $K=3$, the compensated loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{20(s / 4.8+1)}{s(0.5 s+1)(s / 14.4+1)} .
$$

To verify the final phase margin, we can evaluate the phase of $G_{c}(j \omega) G(j \omega)$ at $\omega=\omega_{c}=8.4$ and thus obtain the phase margin. The phase angle is then

$$
\begin{aligned}
\phi\left(\omega_{c}\right) & =-90^{\circ}-\tan ^{-1} 0.5 \omega_{c}-\tan ^{-1} \frac{\omega_{c}}{14.4}+\tan ^{-1} \frac{\omega_{c}}{4.8} \\
& =-90^{\circ}-76.5^{\circ}-30.0^{\circ}+60.2^{\circ} \\
& =-136.3^{\circ} .
\end{aligned}
$$

Therefore, the phase margin for the compensated system is $P . M .=43.7^{\circ}$. The step response of this system yields $P . O .=28 \%$ with a settling time of $T_{s}=0.9 \mathrm{~s}$. The compensated system has a steady-state error of $5 \%$ to a ramp, as desired.

The Nichols chart for the compensated and uncompensated system is shown in Figure 10.8(b). The reshaping of the frequency response locus is clear on this chart. Note the increased phase margin for the compensated system as well as the reduced magnitude of $M_{p \omega}$, the maximum magnitude of the closed-loop frequency response. In this case, $M_{p \omega}$ has been reduced from an uncompensated value of $+12 \mathrm{~dB}$ to a compensated value of approximately $+3.2 \mathrm{~dB}$. Also, we note that the closed-loop $3-\mathrm{dB}$ bandwidth of the compensated system is equal to $12 \mathrm{rad} / \mathrm{s}$ compared with 9.5 $\mathrm{rad} / \mathrm{s}$ for the uncompensated system.

\subsection{PHASE-LEAD DESIGN USING THE ROOT LOCUS}

The design of the phase-lead compensator can also be readily accomplished using the root locus. The locations of the compensator zero and pole are selected so as to result in a satisfactory root locus for the compensated system. The specifications of the system are used to specify the desired location of the dominant roots of the system. The $s$-plane root locus method is as follows:

1. List the system specifications and translate them into a desired root location for the dominant roots.

2. Sketch the root locus with a constant gain controller, $G_{c}(s)=K$, and determine whether the desired root locations can be realized.

3. If a compensator is necessary, place the zero of the phase-lead compensator directly below the desired root location (or to the left of the first two real poles).

4. Determine the pole location so that the total angle at the desired root location is $180^{\circ}$ and therefore is on the compensated root locus.

5. Evaluate the total system gain at the desired root location and then calculate the error constant.

6. Repeat the steps if the error constant is not satisfactory.

Therefore, we first locate our desired dominant root locations so that the dominant roots satisfy the specifications in terms of $\zeta$ and $\omega_{n}$, as shown in Figure 10.9(a). The root locus of the system with $G_{c}(s)=K$ is sketched as illustrated in Figure 10.9(b). Then the zero is added to provide a phase lead by placing it to the left of the first two real poles. Some caution is necessary because the zero must not alter the dominance of the desired roots; that is, the zero should not be placed closer to the origin than the second pole on the real axis, or a real root near the origin will result and will dominate the system response. Thus, in Figure 10.9(c), we note that the desired root is directly above the second pole, and we place the zero $z$ somewhat to the left of the second real pole.

Consequently, the real root may be near the real zero, and the coefficient of this term of the partial fraction expansion may be relatively small. Hence, the response due to this real root may have very little effect on the overall system response. Nevertheless, the designer must be continually aware that the compensated system response will be influenced by the roots and zeros of the system and that the dominant roots will not by themselves dictate the response. It is usually wise to allow for some margin of error in the design and to test the compensated system using a computer simulation.

Because the desired root is a point on the root locus when the final compensation is accomplished, we expect the algebraic sum of the vector angles to be $180^{\circ}$ at that point. Thus, we calculate the angle $\theta_{p}$ from the pole of the compensator in FIGURE 10.9

Compensation on the s-plane using a phase-lead compensator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0743.jpg?height=414&width=588&top_left_y=167&top_left_x=353)

(a) Desired root location

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0743.jpg?height=421&width=579&top_left_y=683&top_left_x=350)

(c) Addition of zero

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0743.jpg?height=411&width=642&top_left_y=166&top_left_x=977)

(b) Root locus with $G_{c}(s)=K$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0743.jpg?height=417&width=667&top_left_y=683&top_left_x=951)

(d) Location of new pole

order to result in a total angle of $180^{\circ}$. Then, locating a line at an angle $\theta_{p}$ intersecting the desired root, we are able to evaluate the compensator pole $p$, as shown in Figure 10.9(d).

The advantage of the root locus method is the ability of the designer to specify the location of the dominant roots and therefore the dominant transient response. The disadvantage of the method is that we cannot directly specify an error constant (for example, $K_{v}$ ) as in the Bode plot approach. After the design is complete, we evaluate the gain of the system at the root location, which depends on $p$ and $z$, and then calculate the error constant for the compensated system. If the error constant is not satisfactory, we must repeat the design steps and alter the location of the desired root as well as the location of the compensator pole and zero.

\section{EXAMPLE 10.3 Lead compensator using the root locus}

Consider again the system of Example 10.1 where the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{10 K}{s^{2}} .
$$

The characteristic equation of the closed-loop system is

$$
1+L(s)=1+K \frac{10}{s^{2}}=0,
$$

and the root locus is the $j \omega$-axis. Therefore, we propose to compensate this system with the compensator

$$
G_{c}(s)=K \frac{s+z}{s+p},
$$

where $|z|<|p|$. The specifications for the system are

Settling time (with a $2 \%$ criterion), $T_{s} \leq 4 \mathrm{~s}$;

Percent overshoot for a step input P.O. $\leq 35 \%$.

Therefore, the damping ratio should be $\zeta \geq 0.32$. The settling time requirement is

$$
T_{s}=\frac{4}{\zeta \omega_{n}}=4,
$$

so $\zeta \omega_{n}=1$. We will choose a desired dominant root location as

$$
r_{1}, \hat{r}_{1}=-1 \pm j 2,
$$

as shown in Figure 10.10 (hence, $\zeta=0.45$ ).

Now we place the zero of the compensator directly below the desired location at $s=-z=-1$, as shown in Figure 10.10. Measuring the angle at the desired root, we have

$$
\phi=-2\left(116^{\circ}\right)+90^{\circ}=-142^{\circ} .
$$

FIGURE 10.10

Phase-lead compensator design for Example 10.3.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0744.jpg?height=924&width=567&top_left_y=1189&top_left_x=507)

Therefore, to have a total of $180^{\circ}$ at the desired root, we evaluate the angle from the undetermined pole, $\theta_{p}$, as

$$
-180^{\circ}=-142^{\circ}-\theta_{p},
$$

or $\theta_{p}=38^{\circ}$. Then a line is drawn at an angle $\theta_{p}=38^{\circ}$ intersecting the desired root location and the real axis, as shown in Figure 10.10. The point of intersection with the real axis is then $s=-p=-3.6$. Therefore, the compensator is

$$
G_{c}(s)=K \frac{s+1}{s+3.6}
$$

and the compensated loop transfer function for the system is

$$
L(s)=G_{c}(s) G(s)=\frac{10 K(s+1)}{s^{2}(s+3.6)} .
$$

The gain $K$ is evaluated by measuring the vector lengths from the poles and zeros to the root location. Hence,

$$
K=\frac{(2.23)^{2}(3.25)}{2(10)}=0.81 .
$$

Finally, the error constants of this system are evaluated. We find that this system with two open-loop integrations will result in a zero steady-state error for a step and ramp input signal. The acceleration constant is

$$
K_{a}=\frac{10(0.81)}{3.6}=2.25
$$

The steady-state performance of this system is quite satisfactory, and therefore the compensation is complete. When we compare the compensator evaluated by the $s$-plane method with the compensator obtained by using the Bode plot approach, we find that the magnitudes of the poles and zeros are different. However, the resulting system will have the same performance, and we need not be concerned with the difference. In fact, the difference arises from the design step (number 3), which places the zero directly below the desired root location. If we placed the zero at $s=-2.0$, we would find that the pole evaluated by the $s$-plane method is approximately equal to the pole evaluated by the Bode plot approach.

The specifications for the transient response of this system were originally expressed in terms of the percent overshoot and the settling time. These specifications were translated, on the basis of an approximation of the system by a second-order system, to an equivalent $\zeta$ and $\omega_{n}$ and therefore a desired root location. However, the original specifications will be satisfied only if the selected roots are dominant. The zero of the compensator and the root resulting from the addition of the compensator pole result in a third-order system with a zero. The validity of approximating this system with a second-order system without a zero is dependent upon the validity of the dominance assumption. Often, the designer will simulate the final design and obtain the actual transient response of the system. The actual percent overshoot is P.O. $=46 \%$ and a settling time (to within $2 \%$ of the final value) is $T_{s}=3.8 \mathrm{~s}$ for a step input. These values compare moderately well with the specified values of $P . O .=35 \%$ and $T_{S}=4 \mathrm{~s}$, and they justify the use of the dominant root specifications. The difference in the percent overshoot from the specified value is due to the zero, which is not negligible. Thus, again we find that the specification of dominant roots is a useful approach but must be utilized with caution and understanding. A second attempt to obtain a compensated system with a percent overshoot of P.O. $=30 \%$ would use a prefilter to eliminate the effect of the zero in the closed-loop transfer function.

\section{EXAMPLE 10.4 Lead compensator for a type-one system}

Consider the system of Example 10.2 and design a compensator based on the root locus approach. The system loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{40 K}{s(s+2)},
$$

when $G_{c}(s)=K$. We want the damping ratio of the dominant roots of the system to be $\zeta=0.4$ and the velocity error constant to be $K_{v} \geq 20$.

To achieve a rapid settling time, we will select the real part of the desired roots as $\zeta \omega_{n}=4$, and therefore $T_{s}=1 \mathrm{~s}$. This implies the natural frequency of these roots is fairly large, $\omega_{n}=10$; hence, the velocity constant should be reasonably large. The location of the desired roots is shown in Figure 10.11(a) for $\zeta \omega_{n}=4, \zeta=0.4$, and $\omega_{n}=10$.

The zero of the compensator is placed at $s=-z=-4$, directly below the desired root location. Then the angle at the desired root location is

$$
\phi=-114^{\circ}-102^{\circ}+90^{\circ}=-126^{\circ} .
$$

Therefore, the angle from the undetermined pole is determined from

$$
-180^{\circ}=-126^{\circ}-\theta_{p},
$$

and thus $\theta_{p}=54^{\circ}$. This angle is drawn to intersect the desired root location, and $p$ is evaluated as $s=-p=-10.6$, as shown in Figure 10.11(a). The gain of the compensated system is then

$$
K=\frac{10(9.4)(11.3)}{9.2(40)}=2.9 .
$$

The compensated system loop transfer function is then

$$
L(s)=G_{c}(s) G(s)=\frac{115.5(s+4)}{s(s+2)(s+10.6)} .
$$

Therefore, the velocity constant of the compensated system is

$$
K_{v}=\lim _{s \rightarrow 0} s\left[G_{c}(s) G(s)\right]=\frac{115.5(4)}{2(10.6)}=21.8 .
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0747.jpg?height=698&width=900&top_left_y=159&top_left_x=378)

(a)

FIGURE 10.11

(a) Design of a phase-lead compensator on the s-plane for Example 10.4. (b) Step response of the compensated system of Example 10.4.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0747.jpg?height=715&width=871&top_left_y=920&top_left_x=390)

(b)

The velocity constant of the compensated system meets the requirement $K_{v} \geq 20$.

The step response of the compensated system yields a percent overshoot of P.O. $=34 \%$ with a settling time of $T_{s}=1.06 \mathrm{~s}$, as shown in Figure 10.11(b). The phase margin is $P . M .=38.4^{\circ}$.

The phase-lead compensator is useful for altering the performance of a control system. The phase-lead compensator adds a phase-lead angle to provide an adequate phase margin. Using an $s$-plane design approach, we can choose the phase-lead compensator in order to alter the system root locus and place the roots of the system in a desired position in the $s$-plane. When the design specifications include an error constant requirement, the Bode plot method is more suitable, because the error constant of a system designed on the $s$-plane must be ascertained following the choice of a compensator pole and zero. Therefore, the root locus method often results in an iterative design procedure when the error constant is specified. On the other hand, the root locus is a very satisfactory approach when the specifications are given in terms of percent overshoot and settling time, thus specifying the $\zeta$ and $\omega_{n}$ of the desired dominant roots in the $s$-plane. The use of a lead compensator extends the bandwidth of a feedback system, which may be objectionable for systems subjected to large amounts of noise. Also, lead compensators are not suitable for providing high steady-state accuracy in systems requiring very high error constants. To provide large error constants, typically $K_{p}$ and $K_{v}$, we must consider the use of integration-type compensators.

\subsection{SYSTEM DESIGN USING INTEGRATION COMPENSATORS}

For many control systems, the primary objective is obtaining a high steady-state accuracy. Another goal is maintaining the transient performance of these systems within reasonable limits. The steady-state accuracy of many feedback systems can be improved by increasing the gain in the forward channel. However, the resulting transient response may be unacceptable-even unstable. Therefore, it is often necessary to introduce a compensator in the forward path of a feedback control system in order to provide a sufficient steady-state accuracy.

Consider the single-loop control system shown in Figure 10.12. The compensator is chosen to provide a large error constant. With $G_{p}(s)=1$, the steady-state error of this system is

$$
\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s \frac{R(s)}{1+G_{c}(s) G(s) H(s)} .
$$

The steady-state error of a system depends on the number of poles at the origin for $L(s)=G_{c}(s) G(s) H(s)$. A pole at the origin can be considered an integration, and therefore the steady-state accuracy of a system ultimately depends on the number of integrations in the loop transfer function. If the steady-state accuracy is not sufficient, we will introduce an integration-type compensator $G_{c}(s)$ in order to compensate for the lack of integration in the uncompensated loop transfer function $G_{c}(s) H_{c}(s)$.

One widely used form of controller is the proportional plus integral (PI) controller, which has a transfer function

$$
G_{c}(s)=K_{p}+\frac{K_{I}}{s}
$$

FIGURE 10.12

Single-loop feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0748.jpg?height=193&width=793&top_left_y=1919&top_left_x=507)

As an example, consider a control system where the transfer function $H(s)=1$, and the transfer function of the process is [28]

$$
G(s)=\frac{K}{\left(\tau_{1} s+1\right)\left(\tau_{2} s+1\right)} .
$$

The steady-state error of the uncompensated system is

$$
\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s \frac{A / s}{1+G(s)}=\frac{A}{1+K},
$$

where $R(s)=A / s$, and $K=\lim _{s \rightarrow 0} G(s)$. To obtain a small steady-state error, the magnitude of the gain $K$ must be quite large. However, when $K$ is quite large, the transient performance of the system will very likely be unacceptable. Therefore, we must consider the addition of a compensator $G_{c}(s)$, as shown in Figure 10.12. To eliminate the steady-state error of this system, we might choose

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=\frac{K_{P} s+K_{I}}{s} .
$$

The steady-state error for a step input of the system is always zero, because

$$
\begin{aligned}
\lim _{t \rightarrow \infty} e(t) & =\lim _{s \rightarrow 0} s \frac{A / s}{1+G_{c}(s) G(s)} \\
& =\lim _{s \rightarrow 0} \frac{A}{1+\left(K_{P} s+K_{I}\right) / s K /\left[\left(\tau_{1} s+1\right)\left(\tau_{2} s+1\right)\right]}=0 .
\end{aligned}
$$

The transient performance can be adjusted to satisfy the system specifications by adjusting the constants $K, K_{P}$, and $K_{I}$. The adjustment of the transient response is perhaps best accomplished by using root locus methods and drawing a root locus for the gain $K_{P} K$ after locating the zero $s=-K_{I} / K_{P}$ on the $s$-plane.

The addition of an integration as $G_{c}(s)=K_{P}+K_{I} / s$ can also be used to reduce the steady-state error for a ramp input $r(t)=t, t \geq 0$. For example, if the uncompensated system $G(s)$ possessed one integration, the additional integration due to $G_{c}(s)$ would result in a zero steady-state error for a ramp input.

\section{EXAMPLE 10.5 Temperature control system}

The transfer function of a temperature control system process is

$$
G(s)=\frac{1}{(s+0.5)(s+2)} .
$$

To maintain zero steady-state error for a step input, we will add the PI compensation compensator

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=K_{P} \frac{s+K_{I} / K_{P}}{s} .
$$

FIGURE 10.13

The s-plane design of an integration compensator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0750.jpg?height=522&width=694&top_left_y=155&top_left_x=507)

Therefore, the loop transfer function is

$$
L(s)=G_{c}(s) G(s)=K_{P} \frac{s+K_{I} / K_{P}}{s(s+0.5)(s+2)} .
$$

The transient response of the system is required to have a percent overshoot less than or equal to P.O. $\leq 20 \%$. Since the PI compensator introduces a zero that will interact with the dominant poles, we will target a slightly higher damping ratio of the dominant poles to increase the likelihood of achieving the desired percent overshoot. Therefore, the dominant complex roots will be placed on the $\zeta=0.6$ line, as shown in Figure 10.13. We will adjust the compensator zero so that the negative real part of the complex roots is $\zeta \omega_{n}=0.75$, and thus the settling time (with a $2 \%$ criterion) is $T_{s}=4 /\left(\zeta \omega_{n}\right)=\frac{16}{3} \mathrm{~s}$. We determine the location of the zero $z=-K_{I} / K_{P}$ by ensuring that the angle at the desired root is $-180^{\circ}$. Therefore, the sum of the angles at the desired root is

$$
-180^{\circ}=-127^{\circ}-104^{\circ}-38^{\circ}+\theta_{z},
$$

where $\theta_{z}$ is the angle from the undetermined zero. Consequently, we find that $\theta_{z}=+89^{\circ}$, and the location of the zero is $z=-0.75$. Finally, to determine the gain at the desired root, we evaluate the vector lengths from the poles and zeros and obtain

$$
K_{P}=\frac{1.25(1.03) 1.6}{1.0}=2 \text {. }
$$

The compensated root locus and the location of the zero are shown in Figure 10.13. Note that the zero $z=-K_{I} / K_{P}$ should be placed to the left of the pole at $s=-0.5$ to ensure that the complex roots dominate the transient response. In fact, the third root of the compensated system of Figure 10.13 can be determined as $s=-1.0$, and therefore this real root is only $\frac{4}{3}$ times the real part of the complex roots. Although complex roots dominate the response of the system, the equivalent damping of the system is somewhat less than $\zeta=0.60$ due to the real root and zero.

The closed-loop transfer function is

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}=\frac{2(s+0.75)}{(s+1) /\left(s^{2}+1.5 s+1.5\right)} .
$$

The effect of the zero is to increase the overshoot to a step input. The percent overshoot is P.O. $=16 \%$, the setting time is $T_{s}=4.9 \mathrm{~s}$, and the steady-state error to a unit step is zero, as desired.

\subsection{PHASE-LAG DESIGN USING THE ROOT LOCUS}

The phase-lag compensator is an integration-type compensator and can be used to increase the error constant of a feedback control system. The transfer function of the phase-lag compensator is of the form

$$
G_{c}(s)=K \frac{s+z}{s+p}=K \alpha \frac{1+\tau s}{1+\alpha \tau s},
$$

where

$$
z=\frac{1}{\tau} \quad \text { and } \quad p=z / \alpha
$$

Begin by supposing that the controller is a constant gain controller, $G_{c}(s)=K$. We refer to the system with loop transfer function $L(s)=K G(s)$ as the uncompensated system. Then, for example, the velocity error constant of a type-one uncompensated system is

$$
K_{v, \text { unc }}=K \lim _{s \rightarrow 0} s G(s) .
$$

If we add the phase-lag compensator in Equation (10.55), we have

$$
K_{v, \mathrm{comp}}=\frac{z}{p} K_{v, \text { unc }}
$$

or

$$
\frac{K_{v, \text { comp }}}{K_{v \text {,unc }}}=\alpha .
$$

Now, if the pole and zero of the compensator are chosen so that $|z|=\alpha|p|<1$, the resultant $K_{v \text {,comp }}$ will be increased at the desired root location by $\alpha$. Then, for example, if $z=0.1$ and $p=0.01$, the velocity constant of the desired root location will be increased by a factor of 10 . If the compensator pole and zero appear relatively close together on the $s$-plane, their effect on the location of the desired root will be negligible. Therefore, the compensator pole-zero combination near the origin of the $s$-plane can be used to increase the error constant of a feedback system by the factor $\alpha$ while altering the root location very slightly.

The steps necessary for the design of a phase-lag compensator on the s-plane are as follows:

1. Obtain the root locus of the uncompensated system with a constant gain controller, $G_{c}(s)=K$.

2. Determine the transient performance specifications for the system and locate suitable dominant root locations on the uncompensated root locus that will satisfy the specifications. 3. Calculate the loop gain at the desired root location and thus the uncompensated system error constant.

4. Compare the uncompensated error constant with the desired error constant, and calculate the necessary increase that must result from the pole-zero ratio $\alpha$ of the compensator.

5. With the known ratio of the pole-zero combination of the compensator, determine a suitable location of the pole and zero of the compensator so that the compensated root locus will still pass through the desired root location. Locate the pole and zero near the origin of the $s$-plane.

The fifth requirement can be satisfied if the magnitudes of the pole and zero are significantly less than $\omega_{n}$ of the dominant roots and they appear to merge as measured from the desired root location. The pole and zero will appear to merge at the root location if the angles from the compensator pole and zero are essentially equal as measured to the root location. One method of locating the zero and pole of the compensator is based on the requirement that the difference between the angle of the pole and the angle of the zero as measured at the desired root is less than $2^{\circ}$.

\section{EXAMPLE 10.6 Design of a phase-lag compensator}

Consider a unity feedback system where the uncompensated loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+2)} .
$$

We require the damping ratio of the dominant complex roots to be $\zeta \geq 0.45$, with a system velocity constant $K_{v} \geq 20$. The uncompensated root locus is a vertical line at $s=-1$ and results in a root on the $\zeta=0.45$ line at $s=-1 \pm j 2$, as shown in Figure 10.14. Measuring the gain at this root, we have $K=(2.24)^{2}=5$. Therefore, the velocity constant of the uncompensated system is

$$
K_{v}=\frac{K}{2}=\frac{5}{2}=2.5
$$

FIGURE 10.14

Root locus of the uncompensated system of Example 10.6.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0752.jpg?height=588&width=416&top_left_y=1519&top_left_x=507)

FIGURE 10.15

Root locus of the compensated system of Example 10.6. Note that the actual root will differ from the desired root by a slight amount. The vertical portion of the locus leaves the $\sigma$ axis at $\sigma=-0.95$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0753.jpg?height=586&width=586&top_left_y=168&top_left_x=375)

Thus, the required ratio of the zero to the pole of the compensator is

$$
\left|\frac{z}{p}\right|=\alpha=\frac{K_{v, \text { comp }}}{K_{v, \text { unc }}}=\frac{20}{2.5}=8
$$

Examining Figure 10.15, we find that we might set $z=0.1$ and then $p=0.1 / 8$. The difference of the angles from $p$ and $z$ at the desired root is approximately $1^{\circ}$; therefore, $s=-1 \pm j 2$ is still the location of the dominant roots. The compensated root locus is shown as a heavy line in Figure 10.15. Thus, the compensated system loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{5(s+0.1)}{s(s+2)(s+0.0125)} .
$$

\section{EXAMPLE 10.7 Design of a phase-lag compensator}

Consider a system that is difficult to design using a phase-lead compensator. The loop transfer function of the uncompensated unity feedback system is

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+10)^{2}} .
$$

It is specified that the velocity constant of this system be $K_{v} \geq 20$, while the damping ratio of the dominant roots is equal to $\zeta=0.707$. The gain necessary for a $K_{v}=20$ is

$$
K_{v}=20=\frac{K}{(10)^{2}},
$$

or $K=2000$. However, using Routh's criterion, we find that the roots of the characteristic equation lie on the $j \omega$-axis at $\pm j 10$ when $K=2000$. The roots of the system when the $K_{v}$ requirement is satisfied are a long way from satisfying the damping ratio specification, and it would be difficult to bring the dominant roots from the $j \omega$-axis FIGURE 10.16 Design of a phaselag compensator on the s-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0754.jpg?height=783&width=969&top_left_y=154&top_left_x=520)

to the $\zeta=0.707$ line by using a phase-lead compensator. Therefore, we will attempt to satisfy the $K_{v}$ and $\zeta$ requirements by using a phase-lag compensator. The uncompensated root locus of this system is shown in Figure 10.16, and the roots are shown when $\zeta=0.707$ and $s=-2.9 \pm j 2.9$. Measuring the gain at these roots, we find that $K=242$. Therefore, the necessary ratio of the zero to the pole of the compensator is

$$
\alpha=\left|\frac{z}{p}\right|=\frac{2000}{242}=8.3 .
$$

Thus, we will choose $z=0.1$ and $p=0.1 / 9$ in order to allow a small margin of safety. Examining Figure 10.16, we find that the difference between the angle from the pole and zero of $G_{c}(s)$ is negligible. Therefore, the compensated system loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{242(s+0.1)}{s(s+10)^{2}(s+0.0111)},
$$

where $G_{c}(s)=\frac{242(s+0.1)}{(s+0.0111)}$

\subsection{PHASE-LAG DESIGN USING THE BODE PLOT}

The design of a phase-lag compensator can be readily accomplished on the Bode plot.

The transfer function of the phase-lag compensator, written in Bode plot form, is

$$
G_{c}(j \omega)=K \alpha \frac{1+j \omega \tau}{1+j \omega \alpha \tau} .
$$

The Bode plot of the phase-lag compensator is shown in Figure 10.6. On the Bode plot, the pole and the zero of the compensator have a magnitude much smaller than the smallest pole of the uncompensated system. Thus, the phase lag is not the useful effect of the compensator; it is the attenuation $-20 \log \alpha$ that is the useful effect for compensation. The phase-lag compensator is used to provide an attenuation and therefore to lower the $0-\mathrm{dB}$ (crossover) frequency of the system. However, at lower crossover frequencies, we usually find that the phase margin of the system is increased, and our specifications can be satisfied. The design procedure for a phaselag compensator on the Bode plot is as follows:

1. Obtain the Bode plot of the uncompensated system with the constant gain controller, $G_{c}(s)=K$, and with the gain adjusted for the desired error constant.

2. Determine the phase margin of the uncompensated system and, if it is insufficient, proceed with the following steps.

3. Determine the frequency where the phase margin requirement would be satisfied if the magnitude curve crossed the $0-\mathrm{dB}$ line at this frequency, $\omega_{c}^{\prime}$. (Allow for $5^{\circ}$ phase lag from the phase-lag compensator when determining the new crossover frequency.)

4. Place the zero of the compensator one decade below the new crossover frequency $\omega_{c}^{\prime}$, and thus ensure only $5^{\circ}$ of additional phase lag at $\omega_{c}^{\prime}$ (see Figure 10.8) due to the lag network.

5. Measure the necessary attenuation at $\omega_{c}^{\prime}$ to ensure that the magnitude curve crosses at this frequency.

6. Calculate $\alpha$ by noting that the attenuation introduced by the phase-lag compensator is $-20 \log \alpha$ at $\omega_{c}^{\prime}$.

7. Calculate the pole as $\omega_{p}=1 /(\alpha \tau)=\omega_{z} / \alpha$, and the design is completed.

An example of this design procedure will illustrate that the method is simple to carry out in practice.

\section{EXAMPLE 10.8 Design of a phase-lag compensator}

Consider the unity feedback system of Example 10.6 and design a phase-lag compensator so that the desired phase margin is obtained. The uncompensated loop transfer function is

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{K}{j \omega(j \omega+2)}=\frac{K_{v}}{j \omega(0.5 j \omega+1)},
$$

where $K_{v}=K / 2$. We want $K_{v} \geq 20$ with a phase margin of $P . M .=45^{\circ}$. The uncompensated Bode plot is shown as a solid line in Figure 10.17. The uncompensated system has a phase margin of P.M. $=18^{\circ}$, and the phase margin must be increased. Allowing $5^{\circ}$ for the phase-lag compensator, we locate the frequency $\omega$ where $\phi(\omega)=-130^{\circ}$, which is to be our new crossover frequency $\omega_{c}^{\prime}$. In this case, we find that $\omega_{c}^{\prime}=1.66$. We select $\omega_{c}^{\prime}=1.5$ to allow for a small margin of safety. The attenuation necessary to cause $\omega_{c}^{\prime}$ to be the new crossover frequency is equal to $20 \mathrm{~dB}$. Both the compensated and uncompensated magnitude curves are an asymptotic approximation. Thus, $\omega_{c}^{\prime}=1.5$, and the required attenuation is $20 \mathrm{~dB}$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0756.jpg?height=826&width=1251&top_left_y=161&top_left_x=461)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0756.jpg?height=892&width=1134&top_left_y=1031&top_left_x=428)

(b)

FIGURE 10.17 (a) Design of a phase-lag compensator on the Bode plot for Example 10.8. (b) Time response to a step input for the uncompensated system (solid line) and the compensated system (dashed line) of Example 10.8. Then we find that $20 \mathrm{~dB}=20 \log \alpha$, or $\alpha=10$. Therefore, the zero is one decade below the crossover, or $\omega_{z}=\omega_{c}^{\prime} / 10=0.15$, and the pole is at $\omega_{p}=\omega_{z} / 10=0.015$. The compensated system is then

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{20(6.66 j \omega+1)}{j \omega(0.5 j \omega+1)(66.6 j \omega+1)},
$$

and the phase-lag compensator is

$$
G_{c}(s)=\frac{4(s+0.15)}{(s+0.015)} .
$$

The frequency response of the compensated system is shown in Figure 10.17(a) with dashed lines. It is evident that the phase lag introduces an attenuation that lowers the crossover frequency and therefore increases the phase margin. Note that the phase angle of the lag compensator has almost totally disappeared at the crossover frequency $\omega_{c}^{\prime}$. As a final check, we numerically evaluate the phase margin and find that P.M. $=46.9^{\circ}$ at $\omega_{c}^{\prime}=1.58$ which is the desired result. Using the Nichols chart, we find that the closed-loop bandwidth of the system has been reduced from $\omega=10 \mathrm{rad} / \mathrm{s}$ for the uncompensated system to $\omega=2.5 \mathrm{rad} / \mathrm{s}$ for the compensated system. Due to the reduced bandwidth, we expect a slower time response to a step command.

The time response of the system is shown in Figure 10.17(b). Note that the percent overshoot is P.O. $=25 \%$ and the peak time is $T_{p}=1.84 \mathrm{~s}$. Thus, the response is within the specifications.

\section{EXAMPLE 10.9 Design of a phase-lag compensator}

Consider the unity feedback system of Example 10.7 with

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{K}{j \omega(j \omega+10)^{2}}=\frac{K_{v}}{j \omega(0.1 j \omega+1)^{2}},
$$

where $K_{v}=K / 100$. A velocity constant of $K_{v} \geq 20$ is specified. Furthermore, we aim for a phase margin P.M. $=70^{\circ}$. The frequency response of the uncompensated system is shown in Figure 10.18. The phase margin of the uncompensated system is $0^{\circ}$. Allowing $5^{\circ}$ for the phase-lag compensator, we locate the frequency where the phase is $\phi(\omega)=-105^{\circ}$. This frequency is equal to $\omega=1.3$, and therefore we will attempt to locate the new crossover frequency at $\omega_{c}^{\prime}=1.3$. Measuring the necessary attenuation at $\omega=\omega_{c}{ }^{\prime}$, we find that $24 \mathrm{~dB}$ is required; then $24=20 \log \alpha$ gives $\alpha=16$. The zero of the compensator is located one decade below the crossover frequency, and thus

$$
\omega_{z}=\frac{\omega_{c}^{\prime}}{10}=0.13
$$

The pole is then

$$
\omega_{p}=\frac{\omega_{z}}{\alpha}=\frac{0.13}{16.0}
$$

Therefore, the compensated system is

$$
L(j \omega)=G_{c}(j \omega) G(j \omega)=\frac{20(7.69 j \omega+1)}{j \omega(0.1 j \omega+1)^{2}(123.1 j \omega+1)},
$$

FIGURE 10.18

Design of a phaselag compensator on the Bode plot for Example 10.9.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0758.jpg?height=863&width=1291&top_left_y=152&top_left_x=460)

where

$$
G_{c}(s)=\frac{125(s+0.13)}{(s+0.00815)} .
$$

The compensated frequency response is shown in Figure 10.18. As a final check, we evaluate the phase margin at $\omega_{c}^{\prime}=1.24$ and find that $P . M .=70.3^{\circ}$, which is within the specifications.

We have seen that a phase-lag compensator can be used to alter the frequency response of a feedback control system in order to attain satisfactory system performance. The system design is satisfactory when the asymptotic curve for the magnitude of the compensated system crosses the 0-dB line with a slope of $-20 \mathrm{~dB} /$ decade. The attenuation of the phase-lag compensator reduces the magnitude of the crossover $(0-\mathrm{dB})$ frequency to a point where the phase margin of the system is satisfactory. Thus, in contrast to the phase-lead compensator, the phaselag compensator reduces the closed-loop bandwidth of the system as it maintains a suitable error constant.

The phase-lead compensator alters the frequency response of a system by adding a positive (leading) phase angle and therefore increases the phase margin at the crossover $(0-\mathrm{dB})$ frequency. It becomes evident that a designer might wish to consider using a compensator that provides the attenuation of a phase-lag compensator and the lead-phase angle of a phase-lead compensator. Such a network does exist. It is called a lead-lag network. The transfer function of this compensator is

$$
G_{c}(s)=K \frac{\beta}{\alpha} \frac{\left(1+\alpha \tau_{1} s\right)\left(1+\tau_{2} s\right)}{\left(1+\tau_{1} s\right)\left(1+\beta \tau_{2} s\right)} .
$$

The first factors in the numerator and denominator, which are functions of $\tau_{1}$, provide the phase-lead portion of the compensator. The second factors, which are functions of $\tau_{2}$, provide the phase-lag portion of the compensator. The parameter $\beta$ is adjusted to provide suitable attenuation of the low-frequency portion of the frequency response, and the parameter $\alpha$ is adjusted to provide an additional phase lead at the new crossover $(0-\mathrm{dB})$ frequency. Alternatively, the compensation can be designed on the $s$-plane by placing the lead pole and zero compensation in order to locate the dominant roots in a desired location. Then the phase-lag compensator is used to raise the error constant at the dominant root location. The design of a phase lead-lag compensator follows the procedures already discussed. Other literature will further illustrate the utility of lead-lag compensation [2, 3, 25].

\subsection{DESIGN ON THE BODE PLOT USING ANALYTICAL METHODS}

An analytical technique of selecting the parameters of a single-stage compensator has been developed for the Bode plot [3-5]. For a single-stage compensator,

$$
G_{c}(s)=\frac{1+\alpha \tau s}{1+\tau s}
$$

where $\alpha<1$ yields a phase lag and $\alpha>1$ yields phase lead. The phase contribution of the compensator at the desired crossover frequency $\omega_{c}$ (see Equation 10.9) is given by

$$
p=\tan \phi=\frac{\alpha \omega_{c} \tau-\omega_{c} \tau}{1+\left(\omega_{c} \tau\right)^{2} \alpha}
$$

The magnitude $M$ (in $\mathrm{dB}$ ) of the compensator in Equation (10.70) at $\omega_{c}$ is

$$
c=10^{M / 10}=\frac{1+\left(\omega_{c} \alpha \tau\right)^{2}}{1+\left(\omega_{c} \tau\right)^{2}} .
$$

Eliminating $\omega_{c} \tau$ from Equations (10.71) and (10.72), we obtain the nontrivial solution equation for $\alpha$ as

$$
\left(p^{2}-c+1\right) \alpha^{2}+2 p^{2} c \alpha+p^{2} c^{2}+c^{2}-c=0 .
$$

For a single-stage compensator, it is necessary that $c>p^{2}+1$. If we solve for $\alpha$ from Equation (10.73), we can obtain $\tau$ from

$$
\tau=\frac{1}{\omega_{c}} \sqrt{\frac{1-c}{c-\alpha^{2}}} .
$$

The design steps for adding phase lead are:

1. Select the desired $\omega_{c}$.

2. Determine the phase margin desired and therefore the required phase $\phi$ for Equation (10.71).

3. Verify that the phase lead is applicable: $\phi>0$ and $M>0$.

4. Determine whether a single stage will be sufficient by testing $c>p^{2}+1$. 5. Determine $\alpha$ from Equation (10.73).

6. Determine $\tau$ from Equation (10.74).

If we need to design a single-stage, phase-lag compensator, then $\phi<0$ and $M<0$ (step 3). Step 4 will require $c<1 /\left(1+p^{2}\right)$. Otherwise the method is similar.

\section{EXAMPLE 10.10 Design using an analytical technique}

Consider the system of Example 10.1 using the analytical technique. Examine the uncompensated curves in Figure 10.7. We select $\omega_{c}=5$. Then, as before, we desire a phase margin of P.M. $=45^{\circ}$. The compensator must yield this phase, so

$$
p=\tan 45^{\circ}=1 .
$$

The required magnitude contribution is $8 \mathrm{~dB}$, or $M=8$, so that

$$
c=10^{8 / 10}=6.31 \text {. }
$$

Using $c$ and $p$, we obtain

$$
-4.31 \alpha^{2}+12.62 \alpha+73.32=0
$$

Solving for $\alpha$, we obtain $\alpha=5.84$. Solving Equation (10.74), we obtain $\tau=0.087$. Therefore, the compensator is

$$
G_{c}(s)=\frac{1+0.515 s}{1+0.087 s}
$$

The pole is equal to 11.5 , and the zero is 1.94 . This can be written in phase-lead compensator form as

$$
G_{c}(s)=5.9 \frac{s+1.94}{s+11.5}
$$

\subsection{SYSTEMS WITH A PREFILTER}

In the earlier sections of this chapter, we utilized compensators of the form

$$
G_{c}(s)=K \frac{s+z}{s+p}
$$

that alter the roots of the characteristic equation of the closed-loop system. However, the closed-loop transfer function $T(s)$ will contain the zero of $G_{c}(s)$ as a zero of $T(s)$. This zero will significantly affect the response of the system $T(s)$.

Let us consider the system shown in Figure 10.19, where

$$
G(s)=\frac{1}{s}
$$

We will introduce a PI compensator, so that

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}=\frac{K_{P} s+K_{I}}{s} .
$$

FIGURE 10.19

Control system with a prefilter $G_{p}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0761.jpg?height=219&width=1061&top_left_y=154&top_left_x=373)

The closed-loop transfer function of the system with a prefilter is

$$
T(s)=\frac{\left(K_{P} s+K_{I}\right) G_{p}(s)}{s^{2}+K_{P} s+K_{I}} .
$$

For illustrative purposes, the specifications require a settling time (with a $2 \%$ criterion) of $T_{S}=0.5 \mathrm{~s}$ and a percent overshoot of approximately P.O. $=4 \%$. We use $\zeta=1 / \sqrt{2}$ and note that

$$
T_{s}=\frac{4}{\zeta \omega_{n}} .
$$

Thus, we require that $\zeta \omega_{n}=8$ or $\omega_{n}=8 \sqrt{2}$. We now obtain

$$
K_{P}=2 \zeta \omega_{n}=16 \quad \text { and } \quad K_{I}=\omega_{n}^{2}=128
$$

The closed-loop transfer function when $G_{p}(s)=1$ is then

$$
T(s)=\frac{16(s+8)}{s^{2}+16 s+128} .
$$

The effect of the zero on the step response is significant. The percent overshoot to a step is $P . O .=21 \%$.

We use a prefilter $G_{p}(s)$ to eliminate the zero from $T(s)$ while maintaining the $\mathrm{DC}$ gain of 1 , thus requiring that

$$
G_{p}(s)=\frac{8}{s+8}
$$

Then we have

$$
T(s)=\frac{128}{s^{2}+16 s+128}
$$

and the percent overshoot of this system is P.O. $=4.5 \%$, as expected.

Let us now consider again Example 10.3, which includes the design of a lead compensator. The resulting closed-loop transfer function can be determined to be (using Figure 10.22)

$$
T(s)=\frac{8.1(s+1) G_{p}(s)}{\left(s^{2}+1.94 s+4.88\right)(s+1.66)} .
$$

If $G_{p}(s)=1$ (no prefilter), then we obtain a response with a percent overshoot of P.O. $=46.6 \%$ and a settling time of $T_{s}=3.8 \mathrm{~s}$. If we use a prefilter, 

$$
G_{p}(s)=\frac{1}{s+1},
$$

we obtain a percent overshoot of P.O. $=6.7 \%$ and a settling time of $T_{S}=$ $3.8 \mathrm{~s}$. The real root at $s=-1.66$ helps to damp the step response. The prefilter is very useful in permitting the designer to introduce a compensator with a zero to adjust the root locations (poles) of the closed-loop transfer function while eliminating the effect of the zero incorporated in $T(s)$.

In general, we will add a prefilter for systems with lead compensators or PI compensators. Typically, we will not use a prefilter for a system with a lag compensator, since we expect the effect of the zero to be insignificant. To check this assertion, let us consider again the design obtained in Example 10.6. The system with a phase-lag compensator is

$$
L(s)=G(s) G_{c}(s)=\frac{5(s+0.1)}{s(s+2)(s+0.0125)} .
$$

The closed-loop transfer function is then

$$
T(s)=\frac{5(s+0.1)}{\left(s^{2}+1.98 s+4.83\right)(s+0.104)} \approx \frac{5}{s^{2}+1.98 s+4.83},
$$

since the zero at $s=-0.1$ and the pole at $s=-0.104$ approximately cancel. We expect a percent overshoot of $P . O .=20 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s}=4.0 \mathrm{~s}$ for the design parameters $\zeta=0.45$ and $\zeta \omega_{n}=1$. The actual response has a percent overshoot of P.O. $=26 \%$ and a settling time of $T_{s}=5.8 \mathrm{~s}$. Thus, we usually do not use a prefilter with systems that utilize lag compensators.

\section{EXAMPLE 10.11 Design of a third-order system}

Consider a system of the form shown in Figure 10.19 with

$$
G(s)=\frac{1}{s(s+1)(s+5)} .
$$

Design a system that will yield a step response with a percent overshoot $P . O . \leq 2 \%$ and a settling time $T_{s} \leq 3 \mathrm{~s}$ by using both $G_{c}(s)$ and $G_{p}(s)$ to achieve the desired response.

Consider the lead compensator

$$
G_{c}(s)=\frac{K(s+1.2)}{s+10}
$$

and select $K$ to find the complex roots with $\zeta=1 / \sqrt{2}$. Then, with $K=78.7$, the closed-loop transfer function is

$$
T(s)=\frac{78.7(s+1.2) G_{p}(s)}{\left(s^{2}+3.42 s+5.83\right)(s+1.45)(s+11.1)} .
$$

If we choose

$$
G_{p}(s)=\frac{p}{s+p},
$$

Table 10.1 Effect of a Prefilter on the Step Response

\begin{tabular}{llll}
$\mathrm{G}_{p}(\mathrm{~s})$ & $\boldsymbol{p = 1}$ & $\boldsymbol{p}=\mathbf{1 . 2 0}$ & $p=2.4$ \\
\hline Percent overshoot & $0 \%$ & $0 \%$ & $5 \%$ \\
$90 \%$ rise time (seconds) & 2.6 & 2.2 & 1.60 \\
Settling time (seconds) & 4.0 & 3.0 & 3.2 \\
\hline
\end{tabular}

the closed-loop transfer function is

$$
T(s)=\frac{78.7 p(s+1.2)}{\left(s^{2}+3.42 s+5.83\right)(s+1.45)(s+11.1)(s+p)} .
$$

If $p=1.2$, we cancel the effect of the zero. The response of the system with a prefilter is summarized in Table 10.1. We choose the appropriate value for $p$ to achieve the response desired. Note that $p=2.40$ will provide a response that may be desirable, since it effects a faster rise time than $p=1.20$. The prefilter provides an additional parameter to select for design purposes.

\subsection{DESIGN FOR DEADBEAT RESPONSE}

Often, the goal for a control system is to achieve a fast response to a step command with minimal overshoot. We define a deadbeat response as a response that proceeds rapidly to the desired level and holds at that level with minimal overshoot. We use the $\pm 2 \%$ band at the desired level as the acceptable range of variation from the desired response. Then, if the response enters the band at time $T_{s}$, it has satisfied the settling time $T_{s}$ upon entry to the band, as illustrated in Figure 10.20. A deadbeat response has the following characteristics:

1. Steady-state error $=0$

2. Fast response $\rightarrow$ minimum $T_{r}$ and $T_{s}$

3. $0.1 \% \leq P . O .<2 \%$

4. Percent undershoot P.O. $<2 \%$.

Characteristics (3) and (4) require that the response remain within the $\pm 2 \%$ band so that the entry to the band occurs at the settling time.

Consider the transfer function $T(s)$ of a closed-loop system. To determine the coefficients that yield the optimal deadbeat response, the standard transfer function is first normalized. An example of this for a third-order system is

$$
T(s)=\frac{\omega_{n}^{3}}{s^{3}+\alpha \omega_{n} s^{2}+\beta \omega_{n}^{2} s+\omega_{n}^{3}} .
$$

Dividing the numerator and denominator by $\omega_{n}^{3}$ yields

$$
T(s)=\frac{1}{\frac{s^{3}}{\omega_{n}^{3}}+\alpha \frac{s^{2}}{\omega_{n}^{2}}+\beta \frac{s}{\omega_{n}}+1} .
$$

FIGURE 10.20 The deadbeat response. $A$ is the magnitude of the step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0764.jpg?height=705&width=1284&top_left_y=153&top_left_x=468)

Let $\bar{s}=s / \omega_{n}$ to obtain

$$
T(s)=\frac{1}{\bar{s}^{3}+\alpha \bar{s}^{2}+\beta \bar{s}+1} .
$$

Equation (10.83) is the normalized, third-order, closed-loop transfer function. For a higher order system, the same method is used to derive the normalized equation. The coefficients of the equation $-\alpha, \beta, \gamma$, and so on - are then assigned the values necessary to meet the requirement of deadbeat response. The coefficients recorded in Table 10.2 were selected to achieve deadbeat response and minimize settling time and rise time $T_{r}$. The form of Equation (10.83) is normalized since $\bar{s}=s / \omega_{n}$. Thus, we choose $\omega_{n}$ based on the desired settling time or rise time. Therefore, if we have a third-order system with a required settling time of $T_{s}=1.2 \mathrm{~s}$, we note from Table 10.2 that the normalized settling time is

$$
\omega_{n} T_{s}=4.04
$$

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline \multirow{2}{*}{$\begin{array}{l}\text { System } \\
\text { Order }\end{array}$} & \multicolumn{5}{|c|}{ Coefficients } & \multirow{2}{*}{$\begin{array}{l}\text { Percent } \\
\text { Overshoot P.O. }\end{array}$} & \multirow{2}{*}{$\begin{array}{l}\text { Percent } \\
\text { Overshoot P.U. }\end{array}$} & \multirow{2}{*}{$\begin{array}{l}90 \% \text { Rise } \\
\text { Time } T_{r}\end{array}$} & \multirow{2}{*}{$\begin{array}{l}\text { Settling } \\
\text { Time } T_{s}\end{array}$} \\
\hline & $\alpha$ & $\beta$ & $\gamma$ & $\delta$ & $\in$ & & & & \\
\hline 2nd & 1.82 & & & & & $0.10 \%$ & $0.00 \%$ & 3.47 & 4.82 \\
\hline $3 r d$ & 1.90 & 2.20 & & & & $1.65 \%$ & $1.36 \%$ & 3.48 & 4.04 \\
\hline 4 th & 2.20 & 3.50 & 2.80 & & & $0.89 \%$ & $0.95 \%$ & 4.16 & 4.81 \\
\hline 5 th & 2.70 & 4.90 & 5.40 & 3.40 & & $1.29 \%$ & $0.37 \%$ & 4.84 & 5.43 \\
\hline 6th & 3.15 & 6.50 & 8.70 & 7.55 & 4.05 & $1.63 \%$ & $0.94 \%$ & 5.49 & 6.04 \\
\hline
\end{tabular}

\section{Table 10.2 Coefficients and Response Measures of a Deadbeat System}

Note: All times are normalized. Therefore, we require that

$$
\omega_{n}=\frac{4.04}{T_{s}}=\frac{4.04}{1.2}=3.37 .
$$

Once $\omega_{n}$ is chosen, the complete closed-loop transfer function is known, having the form of Equation (10.81). When designing a system to obtain a deadbeat response, the compensator is chosen, and the closed-loop transfer function is found. This compensated transfer function is then set equal to Equation (10.81), and the required compensator can be determined.

\section{EXAMPLE 10.12 Design of a system with a deadbeat response}

Consider a unity feedback system with a compensator $G_{c}(s)$ and a prefilter $G_{p}(s)$. The process is

$$
G(s)=\frac{K}{s(s+1)},
$$

and the compensator is

$$
G_{c}(s)=\frac{s+z}{s+p} .
$$

Using the necessary prefilter yields

$$
G_{p}(s)=\frac{z}{s+z} .
$$

The closed-loop transfer function is

$$
T(s)=\frac{K z}{s^{3}+(1+p) s^{2}+(K+p) s+K z} .
$$

We use Table 10.2 to determine the required coefficients, $\alpha=1.90$ and $\beta=2.20$. If we select a settling time (with a $2 \%$ criterion) of $T_{s}=2 \mathrm{~s}$, then $\omega_{n} T_{s}=4.04$, and thus $\omega_{n}=2.02$. The required closed-loop system has the characteristic equation

$$
q(s)=s^{3}+\alpha \omega_{n} s^{2}+\beta \omega_{n}^{2} s+\omega_{n}^{3}=s^{3}+3.84 s^{2}+8.98 s+8.24 .
$$

Then, we determine that $p=2.84, z=1.34$, and $K=6.14$. The response of this system will have $T_{s}=2 \mathrm{~s}$, and $T_{r}=1.72 \mathrm{~s}$.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. The first example is a rotor winder control system where both a lead and lag compensator are designed using root locus methods. In the second example, precise control of a milling machine used in manufacturing is employed to illustrate the design process. A lag compensator is designed using root locus methods to meet steady-state tracking error and percent overshoot specifications. FIGURE 10.21

(a) Rotor winder control system.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0766.jpg?height=538&width=853&top_left_y=152&top_left_x=559)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0766.jpg?height=195&width=934&top_left_y=787&top_left_x=516)

(b)

\section{EXAMPLE 10.13 Rotor winder control system}

Our goal is to replace a manual operation using a machine to wind copper wire onto the rotors of small motors. Each motor has three separate windings of several hundred turns of wire. It is important that the windings be consistent and that the throughput of the process be high. The operator simply inserts an unwound rotor, pushes a start button, and then removes the completely wound rotor. The DC motor is used to achieve accurate rapid windings. Thus, the goal is to achieve high steady-state accuracy for both position and velocity. The control system is shown in Figure 10.21(a) and the block diagram in Figure 10.21(b). This system has zero steady-state error for a step input, and the steady-state error for a ramp input is

$$
e_{s s}=A / K_{v}
$$

where

$$
K_{v}=\lim _{s \rightarrow 0} \frac{G_{c}(s)}{50} .
$$

When $G_{c}(s)=K$, we have $K_{v}=K / 50$. If we select $K=500$, we will have $K_{v}=10$, but the percent overshoot to a step is $P . O .=70 \%$, and the settling time is $T_{S}=8 \mathrm{~s}$.

We first try a lead compensator so that

$$
G_{c}(s)=\frac{K\left(s+z_{1}\right)}{s+p_{1}} .
$$

FIGURE 10.22

Root locus for lead compensator.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0767.jpg?height=812&width=821&top_left_y=168&top_left_x=370)

Selecting $z_{1}=4$ and the pole $p_{1}$ so that the complex roots have a $\zeta=0.6$, we have (see Figure 10.22)

$$
G_{c}(s)=\frac{191.2(s+4)}{s+7.3} .
$$

We find the response to a step input has a P.O. $=3 \%$ and a settling time of $T_{s}=1.5 \mathrm{~s}$. However, the velocity constant is

$$
K_{v}=\frac{191.2(4)}{7.3(50)}=2.1 \text {, }
$$

which is inadequate.

If we use a phase-lag compensator, we select

$$
G_{c}(s)=\frac{K\left(s+z_{2}\right)}{s+p_{2}}
$$

in order to achieve $K_{v}=38$. Thus, the velocity constant of the phase-lag compensated system is

$$
K_{v}=\frac{K z_{2}}{50 p_{2}}
$$

Using a root locus, we select $K=105$ in order to achieve a reasonable uncompensated step response with a percent overshoot of P.O. $\leq 10 \%$. We select $\alpha=z / p$ to achieve the desired $K_{v}$. We then have

$$
\alpha=\frac{50 K_{v}}{K}=\frac{50(38)}{105}=18.1 .
$$

Table 10.3 Design Example Results

\begin{tabular}{lllll} 
Controller & Gain, $K$ & $\begin{array}{l}\text { Lead } \\
\text { Compensator }\end{array}$ & $\begin{array}{l}\text { Lag } \\
\text { Compensator }\end{array}$ & $\begin{array}{l}\text { Lead-Lag } \\
\text { Compensator }\end{array}$ \\
\hline Step overshoot & $70 \%$ & $3 \%$ & $12 \%$ & $5 \%$ \\
Settling time (seconds) & 8 & 1.5 & 2.5 & 2.0 \\
Steady-state error for ramp & $10 \%$ & $48 \%$ & $2.6 \%$ & $4.8 \%$ \\
$K_{v}$ & 10 & 2.1 & 38 & 21 \\
\hline
\end{tabular}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0768.jpg?height=468&width=736&top_left_y=561&top_left_x=262)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0768.jpg?height=454&width=744&top_left_y=563&top_left_x=1011)

(b)

FIGURE 10.23 (a) Step response and (b) ramp response for rotor winder system.

Selecting $z_{2}=0.1$ to avoid affecting the uncompensated root locus, we have $p_{2}=0.0055$. We then obtain a step response with a P.O. $=12 \%$ and a settling time of $T_{s}=2.5 \mathrm{~s}$. The results for the simple gain, the lead network, and the lag network are summarized in Table 10.3.

Let us return to the phase-lead compensator system and add a cascade phaselag compensator, so that the lead-lag compensator is

$$
G_{c}(s)=\frac{K\left(s+z_{1}\right)\left(s+z_{2}\right)}{\left(s+p_{1}\right)\left(s+p_{2}\right)} .
$$

The lead compensator of Equation (10.86) requires $K=191.2, z_{1}=4$, and $p_{1}=7.3$. The root locus for the system is shown in Figure 10.22. We recall that this lead compensator resulted in $K_{v}=2.1$ (see Table 10.3). To obtain $K_{v}=21$, we use $\alpha=10$ and select $z_{2}=0.1$ and $p_{2}=0.01$. Then the compensated loop transfer function is

$$
L(s)=G(s) G_{c}(s)=\frac{191.2(s+4)(s+0.1)}{s(s+5)(s+10)(s+7.28)(s+0.01)} .
$$

The step response and ramp response of this system are shown in Figure 10.23 in parts (a) and (b), respectively, and are summarized in Table 10.3. Clearly, the leadlag design is suitable for satisfaction of the design goals. FIGURE 10.24

A depiction of the milling machine.

\section{EXAMPLE 10.14 Milling machine control system}

Smaller, lighter, less costly sensors are being developed by engineers for machining and other manufacturing processes. A milling machine table is depicted in Figure 10.24. This particular machine table has a new sensor that obtains information about the cutting process (that is, the depth-of-cut) from the acoustic emission (AE) signals. Acoustic emissions are low-amplitude, high-frequency stress waves that originate from the rapid release of strain energy in a continuous medium. The AE sensors are commonly piezoelectric amplitude sensitive in the $100 \mathrm{kHz}$ to $1 \mathrm{MHz}$ range; they are cost effective and can be mounted on most machine tools.

There is a relationship between the sensitivity of the AE power signal and small depth-of-cut changes $[15,18,19]$. This relationship can be exploited to obtain a feedback signal or measurement of the depth-of-cut. A simplified block diagram of the feedback system is shown in Figure 10.25. The elements of the design process emphasized in this example are highlighted in Figure 10.26.

Since the acoustic emissions are sensitive to material, tool geometry, tool wear, and cutting parameters such as cutter rotational speed, the measurement of the depth-of-cut is modeled as being corrupted by noise, denoted by $N(s)$ in Figure 10.25. Also disturbances to the process, denoted by $T_{d}(s)$, are modeled. These could represent external disturbances resulting in unwanted motion of the cutter, fluctuations in the cutter rotation speed, and so forth.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0769.jpg?height=572&width=1277&top_left_y=1537&top_left_x=338)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0769.jpg?height=484&width=662&top_left_y=1033&top_left_x=372)

noise
FIGURE 10.25

A simplified block diagram of the milling machine feedback system. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0770.jpg?height=1020&width=1312&top_left_y=238&top_left_x=445)

FIGURE 10.26 Elements of the control system design process emphasized in this milling machine control system design example.

The process model $G(s)$ is given by

$$
G(s)=\frac{2}{s(s+1)(s+5)},
$$

and represents the model of the cutter apparatus and the AE sensor dynamics. The input to $G(s)$ is a control signal to actuate an electromechanical device, which then applies downward pressure on the cutter.

There are a variety of methods available to obtain the model represented by Equation (10.88). One approach would be to use basic principles to obtain a mathematical model in the form of a nonlinear differential equation, which can then be linearized about an operating point leading to a linear model (or equivalently, a transfer function). The basic principles include Newton's laws, the various conservation laws, and Kirchhoff's laws. Another approach would be to assume a form of the model (such as a second-order system) with unknown parameters (such as $\omega_{n}$ and $\zeta$ ), and then experimentally obtain good values of the unknown parameters. FIGURE 10.27

Hypothetical impulse response of the milling machine.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0771.jpg?height=842&width=1096&top_left_y=155&top_left_x=374)

A third approach is to conduct a laboratory experiment to obtain the step or impulse response of the system. In other words we can apply an input (in this case, a voltage) to the system and measure the output - the depth-of-cut into the desired workpiece. Suppose, for example, we have the impulse response data shown in Figure 10.27 (the small circles on the graph represent the data). If we had access to the function $C_{\mathrm{imp}}(t)$-the impulse response function of the milling machine-we could take the Laplace transform to obtain the transfer function model. There are many methods available for curve fitting the data to obtain the function $C_{\mathrm{imp}}(t)$. We will not cover curve fitting here, but we can say a few words regarding the basic structure of the function.

From Figure 10.27 we see that the response approaches a steady-state value:

$$
C_{\mathrm{imp}}(t) \rightarrow C_{\mathrm{imp}, s s} \approx \frac{2}{5} \text { as } \mathrm{t} \rightarrow \infty .
$$

So we expect that

$$
C_{\text {imp }}(t)=\frac{2}{5}+\Delta C_{\text {imp }}(t),
$$

where $\Delta C_{\text {imp }}(t)$ is a function that goes to zero as $t$ gets large. This leads us to consider $\Delta C_{\mathrm{imp}}(t)$ as a sum of stable exponentials. Since the response does not oscillate, we might expect that the exponentials are, in fact, real exponentials,

$$
\Delta C_{\text {imp }}(t)=\sum_{i} k_{i} e^{-\tau_{i} t},
$$

where $\tau_{i}$ are positive real numbers. The data in Figure 10.27 can be fitted by the function

$$
C_{\text {imp }}(t)=\frac{2}{5}+\frac{1}{10} e^{-5 t}-\frac{1}{2} e^{-t},
$$

for which the Laplace transform is

$$
G(s)=\mathscr{L}\left\{C_{\text {imp }}(t)\right\}=\frac{2}{5} \frac{1}{s}+\frac{1}{10} \frac{1}{s+5}-\frac{1}{2} \frac{1}{s+1}=\frac{2}{s(s+1)(s+5)} .
$$

Thus we can obtain the transfer function model of the milling machine.

The control goal is to develop a feedback system to track a desired step input. In this case the reference input is the desired depth-of-cut. The control goal is stated as

\section{Control Goal}

Control the depth-of-cut to the desired value.

The variable to be controlled is the depth-of-cut, or

\section{Variable to Be Controlled}

Depth-of-cut $y(t)$.

Since we are focusing on lead and lag controllers in this chapter, the key tuning parameters are the parameters associated with the compensator given in Equation (10.89).

\section{Select Key Tuning Parameters}

Compensator variables: $p, z$, and $K$.

The control design specifications are

\section{Control Design Specifications}

DS1 Track a ramp input, $R(s)=a / s^{2}$, with a steady-state tracking error less than $a / 8$, where $a$ is the ramp velocity.

DS2 Percent overshoot to a step input of P.O. $\leq 20 \%$.

The phase-lag compensator is given by

$$
G_{c}(s)=K \frac{s+z}{s+p}=K \alpha \frac{(1+\tau s)}{(1+\alpha \tau s)},
$$

where $\alpha=z / p>1$ and $\tau=1 / z$. The tracking error is

$$
E(s)=R(s)-Y(s)=(1-T(s)) R(s),
$$

where

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}
$$

Therefore,

$$
E(s)=\frac{1}{1+G_{c}(s) G(s)} R(s)
$$

With $R(s)=a / s^{2}$ and using the final value theorem, we find that

$$
e_{s s}=\lim _{t \rightarrow \infty} e(t)=\lim _{s \rightarrow 0} s E(s)=\lim _{s \rightarrow 0} s \frac{1}{1+G_{c}(s) G(s)} \frac{a}{s^{2}},
$$

or equivalently,

$$
\lim _{s \rightarrow 0} s E(s)=\frac{a}{\lim _{s \rightarrow 0} s G_{c}(s) G(s)} .
$$

According to DS1, we require that

$$
\frac{a}{\lim _{s \rightarrow 0} s G_{c}(s) G(s)}<\frac{a}{8},
$$

or

$$
\lim _{s \rightarrow 0} s G_{c}(s) G(s)>8
$$

Substituting for $G(s)$ and $G_{c}(s)$ from Equations (10.88) and (10.89), respectively, we obtain the compensated velocity constant

$$
K_{v, \mathrm{comp}}=\frac{2}{5} K \frac{z}{p}>8 .
$$

The compensated velocity constant is the velocity constant of the system when the phase-lag compensator is in the loop.

The loop transfer function is

$$
L(s)=G_{c}(s) G(s)=\frac{s+z}{s+p} \frac{2 K}{s(s+1)(s+5)} .
$$

We separate the phase-lag compensator from the process and obtain the uncompensated root locus by considering the feedback loop with the gain $K$, but not the phase-lag compensator zero and pole factors. The uncompensated root locus for the characteristic equation

$$
1+K \frac{2}{s(s+1)(s+5)}=0
$$

is shown in Figure 10.28.

From DS2 we determine that the target damping ratio of the dominant roots is $\zeta>0.45$. We find that $K \leq 2.09$ at $\zeta \geq 0.45$. Then with $K=2.0$ the uncompensated velocity constant is

$$
K_{v, \text { unc }}=\lim _{s \rightarrow 0} s \frac{2 K}{s(s+1)(s+5)}=\frac{2 K}{5}=0.8 .
$$

FIGURE 10.28

Root locus for the uncompensated system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0774.jpg?height=781&width=1002&top_left_y=153&top_left_x=522)

The compensated velocity constant is

$$
K_{v, \text { comp }}=\lim _{s \rightarrow 0} s \frac{s+z}{s+p} \frac{2 K}{s(s+1)(s+5)}=\frac{z}{p} K_{v, \text { unc }} .
$$

Therefore with $\alpha=z / p$, we obtain the relationship

$$
\alpha=\frac{K_{v, \text { comp }}}{K_{v, \text { unc }}} .
$$

We require $K_{v \text {,comp }}>8$. A possible choice is $K_{v \text {,comp }}=10$ as the desired velocity constant. Then

$$
\alpha=\frac{K_{v, \text { comp }}}{K_{v, \text { unc }}}=\frac{10}{0.8}=12.5
$$

But $\alpha=z / p$, thus our phase-lag compensator should have $p=0.08 z$. If we select $z=0.01$ then $p=0.0008$.

The compensated loop transfer function is given by

$$
L(s)=G_{c}(s) G(s)=K \frac{s+z}{s+p} \frac{2}{s(s+1)(s+5)} .
$$

The phase-lag compensator with $z$ and $p$ as above is determined to be

$$
G_{c}(s)=2.0 \frac{s+0.01}{s+0.0008} .
$$

The step response is shown in Figure 10.29. The percent overshoot is P.O. $=22 \%$. The velocity error constant is $K_{v}=10$, which satisfies DS1. FIGURE 10.29

Step response for the compensated system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0775.jpg?height=748&width=985&top_left_y=155&top_left_x=373)

\subsection{SYSTEM DESIGN USING CONTROL DESIGN SOFTWARE}

We want to use computers, when appropriate, to assist the designer in the selection of the parameters of a compensator. The development of algorithms for computer-aided design is an important alternative approach to the trial-and-error methods considered in earlier sections. Computer programs have been developed for the selection of suitable parameter values for compensators based on satisfaction of frequency response criteria such as the phase margin $[3,4]$.

In this section, the compensation of control systems is illustrated using frequency response and $s$-plane methods. We will consider again the rotor winder design. To illustrate the use of $\mathrm{m}$-file scripts in designing and developing control systems with good performance characteristics. We examine both the phase-lead and phase-lag compensators for this design example and obtain the system response using computer-based analysis tools.

\section{EXAMPLE 10.15 Rotor winder control system}

Consider again the rotor winder control system shown in Figure 10.21. The design objective is to achieve high steady-state accuracy to a ramp input. The steady-state error to a unit ramp input $R(s)=1 / s^{2}$ is

$$
e_{\mathrm{ss}}=\frac{1}{K_{v}},
$$

where

$$
K_{v}=\lim _{s \rightarrow 0} \frac{G_{c}(s)}{50} .
$$

The performance specification of percent overshoot and settling time must be considered, as must the steady-state tracking error. In all likelihood, a simple gain will not be satisfactory, so we will also consider compensation utilizing phase-lead and phase-lag compensators, using both Bode plot and root locus plot design methods. Our approach is to develop a series of $\mathrm{m}$-file scripts to aid in the compensator designs.

Consider a simple gain controller

$$
G_{c}(s)=K \text {. }
$$

Then the steady-state error is

$$
e_{s s}=\frac{50}{K}
$$

The larger we make $K$, the smaller is the steady-state error $e_{s s}$. However, we must consider the effect that increasing $K$ has on the transient response, as shown in Figure 10.30 . When $K=500$, our steady-state error for a ramp is $10 \%$, but the percent overshoot is $P . O .=70 \%$, and the settling time is approximately $T_{s}=8 \mathrm{~s}$ for a step input. We consider this to be unacceptable performance and thus turn

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0776.jpg?height=501&width=654&top_left_y=916&top_left_x=555)

(a)

FIGURE 10.30

(a) Transient response for simple gain controller. (b) m-file script.
Compute response for four gains.

numg=[1]; deng=[1 1550 0]; sysg=tf(numg, deng); $\mathrm{t}=[0: 0.1: 5]$; $\%$

for $i=1: 4$ sys=feedback(K(i)*sysg,[1]); $\mathrm{y}=$ step(sys,t);

Ys(:,i)=y; end $\%$ $\operatorname{plot}(\mathrm{t}, \mathrm{Ys}(:, 1), \mathrm{t}, \mathrm{Ys}(:, 2), \mathrm{t}, \mathrm{Ys}(:, 3), \mathrm{t}, \mathrm{Ys}(:, 4))$ xlabel('Time $(\mathrm{s})$ '), ylabel('y(t)')
Store response for $i$ th gain in $Y s$.
Closed-loop transfer function. to compensation. The two important compensator types that we consider are phase-lead and phase-lag compensators.

First, we try a phase-lead compensator

$$
G_{c}(s)=\frac{K(s+z)}{s+p},
$$

where $|z|<|p|$ The phase-lead compensator will give us the capability to improve the transient response. We will use a frequency-domain approach to design the phase-lead compensator.

We want a steady-state error of $e_{s s} \leq 10 \%$ to a ramp input and $K_{v}=10$. In addition to the steady-state specifications, we want to meet certain performance specifications: (1) settling time (with a $2 \%$ criterion) $T_{s} \leq 3 \mathrm{~s}$, and (2) percent overshoot for a step input P.O. $\leq 10 \%$. Solving for $\zeta$ and $\omega_{n}$ using

$$
\text { P.O. }=100 \exp ^{-\zeta \pi / \sqrt{1-\zeta^{2}}}=10 \text { and } \quad T_{s}=\frac{4}{\zeta \omega_{n}}=3
$$

yields $\zeta=0.59$ and $\omega_{n}=2.26$. We thus obtain the phase margin requirement:

$$
\phi_{\mathrm{pm}}=\frac{\zeta}{0.01} \approx 60^{\circ} \text {. }
$$

The steps leading to the final design are as follows:

1. Obtain the uncompensated system Bode plot with $K=500$, and compute the phase margin.

2. Determine the amount of necessary phase lead $\phi_{m}$.

3. Evaluate $\alpha$ from $\sin \phi_{m}=(\alpha-1) /(\alpha+1)$.

4. Compute $10 \log \alpha$ and find the frequency $\omega_{m}$ on the uncompensated Bode plot where the magnitude curve is equal to $-10 \log \alpha$.

5. In the neighborhood of $\omega_{m}$ on the uncompensated Bode plot draw a line through the 0 -dB point at $\omega_{m}$ with slope equal to the current slope plus $20 \mathrm{~dB} / \mathrm{decade}$. Locate the intersection of the line with the uncompensated Bode plot to determine the phase-lead compensation zero location. Then calculate the phase-lead compensator pole location as $p=\alpha z$.

6. Obtain the compensated Bode plot and check the phase margin. Repeat any steps if necessary.

7. Raise the gain to account for the attenuation $1 / \alpha$.

8. Verify the final design with simulation using step function inputs, and repeat any design steps if necessary.

We use three scripts in the design. The design scripts are shown in Figures 10.31-10.33. The script in Figure 10.31 is for the Bode plot of the uncompensated system. The script in Figure 10.32 is for the detailed Bode plot of the compensated system. The script in Figure 10.33 is for the step response analysis. The final phase-lead compensator design is

$$
G_{c}(s)=\frac{1800(s+3.5)}{s+25},
$$

where $K=1800$ was selected after iteratively using the m-file script. FIGURE 10.31

(a) Bode plot.

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0778.jpg?height=522&width=718&top_left_y=151&top_left_x=582)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0778.jpg?height=532&width=883&top_left_y=789&top_left_x=540)

Additional phase lead.

Compute $\alpha$.

Plot $-10 \log (\alpha)$ line to aid in locating $\omega_{m}$.

(b)

The settling time and percent overshoot specifications are satisfied, but $K_{v}=5$, resulting in a $20 \%$ steady-state error to a ramp input. It is possible to continue the design iteration and refine the compensator somewhat, although it should be clear that the phase-lead compensator has added phase margin and improved the transient response as anticipated.

To reduce the steady-state error, we can consider the phase-lag compensator, which has the form

$$
G_{c}(s)=\frac{K(s+z)}{s+p},
$$

where $|p|<|z|$. We will use a root locus approach to design the phase-lag compensator, although it can be done using a Bode plot as well. The desired root location region of the dominant roots is specified by

$$
\zeta=0.59 \text { and } \omega_{n}=2.26 \text {. }
$$


![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0779.jpg?height=462&width=598&top_left_y=161&top_left_x=500)

(a)

FIGURE 10.32

Phase-lead compensator:

(a) compensated Bode plot, (b) m-file script.
FIGURE 10.33

Phase-lead compensator:
(a) step response,
(b) m-file script.

\section{$\mathrm{K}=1800$;}

numg=[1]; deng=[1 1550 0];

numgc $=K^{*}\left[\begin{array}{ll}1 & 3.5\end{array}\right]$; dengc $=\left[\begin{array}{ll}1 & 25\end{array}\right]$

sysg=tf(numg,deng);

sysgc=tf(numgc, dengc);

sys=series(sysgc,sysg);

margin(sys)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0779.jpg?height=344&width=532&top_left_y=1218&top_left_x=449)

Increase $K$ to account for attenuation of $1 / \alpha$.

Lead compensator.

(a)

$\mathrm{K}=1800$;

$\%$

numg=[1]; deng=[1 1550 0]; sysg=tf(numg,deng);

numgc $=K^{\star}\left[\begin{array}{ll}13.5\end{array}\right] ;$ dengc $=\left[\begin{array}{ll}1 & 25\end{array}\right] ;$ sysgc $=t f($ numgc, dengc $)$;

$\%$

syso $=$ series $($ sysgc, sysg);

sys=feedback(syso,[1]);

$\%$

$\mathrm{t}=[0: 0.01: 2]$;

step(sys,t)

ylabel ('y(t)') (b) 

\section{FIGURE 10.34}

Phase-lag compensator: (a) uncompensated root locus, (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0780.jpg?height=560&width=722&top_left_y=153&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0780.jpg?height=400&width=608&top_left_y=826&top_left_x=579)

(b)

The steps in the design are as follows:

1. Obtain the root locus of the uncompensated system.

2. Locate suitable root locations on the uncompensated system that lie in the region defined by $\zeta=0.59$ and $\omega_{n}=2.26$.

3. Calculate the loop gain at the desired root location and the system error constant, $K_{v, \text { unc }}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0780.jpg?height=42&width=755&top_left_y=1710&top_left_x=563)

5. With $\alpha$ known, determine suitable locations of the compensator pole and zero so that the compensated root locus still passes through the desired location.

6. Verify with simulation and repeat any steps if necessary.

The design methodology is illustrated in Figures 10.34-10.36. Using the rlocfind function, we can compute the gain $K$ associated with the roots of our choice on the uncompensated root locus that lie in the performance region. We then compute $\alpha$ to ensure that we achieve the desired $K_{v}$. We place the lag compensator pole and zero to avoid affecting the uncompensated root locus. In Figure 10.35, the phase-lag compensator pole and zero are very near the origin, at $z=-0.1$ and $p=-0.01$. FIGURE 10.35

Phase-lag compensator:

(a) compensated root locus, (b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0781.jpg?height=562&width=734&top_left_y=152&top_left_x=376)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0781.jpg?height=362&width=711&top_left_y=843&top_left_x=409)

(b)

\section{Table 10.4 Compensator Design Results}

\begin{tabular}{llll} 
Controller & Gain, $\boldsymbol{K}=\mathbf{5 0 0}$ & Lead & Lag \\
\hline Step overshoot & $70 \%$ & $8 \%$ & $13 \%$ \\
Settling time (seconds) & 8 & 1 & 9 \\
Steady-state error for ramp & $10 \%$ & $20 \%$ & $10 \%$ \\
$K_{v}$ & 10 & 5 & 10 \\
\hline
\end{tabular}

The settling time and percent overshoot specifications are not satisfied, but $K_{v}=10$, as desired. It is possible to continue the design iteration and refine the compensator somewhat, although it should be clear that the phase-lag compensator has improved the steady-state errors to a ramp input relative to the phase-lead compensator design. The final phase-lag compensator design is

$$
G_{c}(s)=\frac{100(s+0.1)}{s+0.01} .
$$

The resulting performance is summarized in Table 10.4. FIGURE 10.36

Phase-lag compensator:

(a) step response,

(b) m-file response.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0782.jpg?height=557&width=736&top_left_y=154&top_left_x=521)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0782.jpg?height=325&width=745&top_left_y=826&top_left_x=556)

(b)

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this chapter, we design a PD controller to achieve the specified response to a unit step input. The specifications are given in Table 10.5. The closed-loop system is shown in Figure 10.37. A prefilter is used to eliminate any undesired effects of the term $s+z$ introduced in the closed-loop transfer function. We will use the deadbeat system, where the desired closed-loop transfer function is

$$
T(s)=\frac{\omega_{n}^{2}}{s^{2}+\alpha \omega_{n} s+\omega_{n}^{2}} .
$$

\section{Table 10.5 Disk Drive Control System Specifications and Actual Performance}

\begin{tabular}{lll} 
Performance Measure & Desired Value & Actual Response \\
\hline Percent overshoot & Less than $5 \%$ & $0.1 \%$ \\
Settling time & Less than $250 \mathrm{~ms}$ & $40 \mathrm{~ms}$ \\
$\begin{array}{l}\text { Maximum response } \\
\text { to a unit disturbance }\end{array}$ & Less than $5 \times 10^{-3}$ & $6.9 \times 10^{-5}$ \\
\hline
\end{tabular}



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0783.jpg?height=276&width=1466&top_left_y=161&top_left_x=149)

FIGURE 10.37 Disk drive control system with PD controller (second-order model).

For the second-order model shown in Figure 10.37, we require $\alpha=1.82$ (see Table 10.2). Then the settling time is

$$
\omega_{n} T_{s}=4.82
$$

Since we want a settling time $T_{s} \leq 50 \mathrm{~ms}$, we will use $\omega_{n}=120$. Then we expect $T_{s}=40 \mathrm{~ms}$. Therefore, the denominator of Equation (10.91) is

$$
s^{2}+218.4 s+14400
$$

The characteristic equation of the closed-loop system of Figure 10.37 is

$$
s^{2}+\left(20+5 K_{D}\right) s+5 K_{P}=0 .
$$

Equating Equations (10.92) and (10.93), we have

$$
218.4=20+5 K_{D}
$$

and

$$
14400=5 K_{P}
$$

Therefore, $K_{P}=2880$ and $K_{D}=39.68$. Then we note that

$$
G_{c}(s)=39.68(s+72.58) \text {. }
$$

The prefilter will then be

$$
G_{p}(s)=\frac{72.58}{s+72.58}
$$

The model neglected the motor field. Nevertheless, this design will be very accurate. The actual response is given in Table 10.5. All the specifications are satisfied. 

\subsection{SUMMARY}

In this chapter, we have considered several alternative approaches to the design of feedback control systems. In the first two sections, we discussed the concepts of design and compensation and noted the several design cases. Then we examined the possibility of introducing cascade compensators within the feedback loops of control systems. The cascade compensators are useful for altering the shape of the root locus or frequency response of a system. The phase-lead compensator and the phase-lag compensator were considered in detail as candidates for system compensators. Then system compensation was studied by using a phase-lead compensator on the Bode plot and the root locus. We noted that the phase-lead compensator increases the phase margin of the system and thus provides additional stability. When the design specifications include an error constant, the design of a phase-lead compensator is more readily accomplished on the Bode plot. Alternatively, when an error constant is not specified but the settling time and percent overshoot for a step input are specified, the design of a phase-lead compensator is more readily carried out on the $s$-plane. When large error constants are specified for a feedback system, it is usually easier to compensate the system by using integration (phase-lag) compensators. We also noted that the phase-lead compensation increases the system bandwidth, whereas the phase-lag compensation decreases the system bandwidth. The bandwidth may often be an important factor when noise is present at the input and generated within the system. Also, we noted that a satisfactory system is obtained when the asymptotic course for magnitude of the compensated system crosses the 0 - $\mathrm{dB}$ line with a slope of $-20 \mathrm{~dB} /$ decade. The characteristics of the phase-lead and phase-lag compensators are summarized in Table 10.6. Operational amplifier circuits for phase-lead and phase-lag and for PI and PD compensators are summarized in Table 10.7 [1].

\section{Table 10.6 A Summary of the Characteristics of Phase-Lead and Phase-Lag Compensators}

\begin{tabular}{|c|c|c|}
\hline & \multicolumn{2}{|c|}{ Compensation } \\
\hline & Phase-Lead & Phase-Lag \\
\hline Approach & $\begin{array}{l}\text { Addition of phase-lead angle near cross- } \\
\text { over frequency on Bode plot. Add lead } \\
\text { compensator to yield desired dominant } \\
\text { roots in } s \text {-plane. }\end{array}$ & $\begin{array}{l}\text { Addition of phase-lag to yield an increased } \\
\text { error constant while maintaining desired } \\
\text { dominant roots in } s \text {-plane or phase margin } \\
\text { on Bode plot }\end{array}$ \\
\hline Results & $\begin{array}{l}\text { 1. Increases system bandwidth } \\
\text { 2. Increases gain at higher frequencies }\end{array}$ & 1. Decreases system bandwidth \\
\hline Advantages & $\begin{array}{l}\text { 1. Yields desired response } \\
\text { 2. Improves dynamic response }\end{array}$ & $\begin{array}{l}\text { 1. Suppresses high-frequency noise } \\
\text { 2. Reduces steady-state error }\end{array}$ \\
\hline Disadvantages & $\begin{array}{l}\text { 1. Requires additional amplifier gain } \\
\text { 2. Increases bandwidth and thus } \\
\text { susceptibility to noise }\end{array}$ & 1. Slows down transient response \\
\hline Applications & 1. When fast transient response is desired & 1. When error constants are specified \\
\hline $\begin{array}{l}\text { Situations not } \\
\text { applicable }\end{array}$ & $\begin{array}{l}\text { 1. When phase decreases rapidly near } \\
\text { crossover frequency }\end{array}$ & $\begin{array}{l}\text { 1. When no low-frequency range exists where } \\
\text { phase is equal to desired phase margin }\end{array}$ \\
\hline
\end{tabular}

Table 10.7 Operational Amplifier Circuits for Compensators

Type of

Controller

$$
G_{c}(s)=\frac{V_{0}(s)}{V_{1}(s)}
$$

\section{PD}

$G_{c}=\frac{R_{4} R_{2}}{R_{3} R_{1}}\left(R_{1} C_{1} s+1\right)$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0785.jpg?height=184&width=306&top_left_y=341&top_left_x=731)

$v_{1}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0785.jpg?height=254&width=564&top_left_y=358&top_left_x=1054)

PI

$$
G_{c}=\frac{R_{4} R_{2}\left(R_{2} C_{2} s+1\right)}{R_{3} R_{1}\left(R_{2} C_{2} s\right)}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0785.jpg?height=268&width=884&top_left_y=628&top_left_x=734)

Lead or lag

Lead if

$R_{1} C_{1}>R_{2} C_{2}$

Lag if

$R_{1} C_{1}<R_{2} C_{2}$
$G_{c}=\frac{R_{4} R_{2}\left(R_{1} C_{1} s+1\right)}{R_{3} R_{1}\left(R_{2} C_{2} s+1\right)}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0785.jpg?height=309&width=884&top_left_y=951&top_left_x=734)

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 10.38 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0785.jpg?height=261&width=873&top_left_y=1756&top_left_x=556)

FIGURE 10.38 Block diagram for the Skills Check. In the following True or False and Multiple Choice problems, circle the correct answer.

1. A cascade compensator is a compensator that is placed in parallel with the system process.

True or False

2. Generally, a phase-lag compensator speeds up the transient response.

3. The arrangement of the system and the selection of suitable components and parameters is part of the process of control system design.

True or False

4. A deadbeat response of a system is a rapid response with minimal percent overshoot and zero steady-state error to a step input.

True or False

5. A phase-lead compensator can be used to increase the system bandwidth. True or False

6. Consider the feedback system in Figure 10.38, where

$$
G(s)=\frac{1000}{s(s+400)(s+20)} .
$$

A phase-lag compensator is designed for the system:

$$
G_{c}(s)=\frac{1+0.25 s}{1+2 s} .
$$

When compared with the uncompensated system (that is, $G_{c}(s)=1$ ), the compensated system utilizing the phase-lag compensator:

a. Increases the phase lag near the cross-over frequency.

b. Increases the phase margin.

c. Provides additional attenuation at higher frequencies.

d. All of the above.

7. A position control system can be analyzed using the feedback system in Figure 10.38, where the process transfer function is

$$
G(s)=\frac{5}{s(s+1)(0.4 s+1)} .
$$

A phase-lag compensator that provides a phase margin of $P . M . \approx 30^{\circ}$ is:
a. $G_{c}(s)=\frac{1+s}{1+106 s}$
b. $G_{c}(s)=\frac{1+26 s}{1+115 s}$
c. $G_{c}(s)=\frac{1+106 s}{1+118 s}$
d. None of the above

8. Consider a unity feedback system in Figure 10.38, where

$$
G(s)=\frac{1450}{s(s+3)(s+25)} .
$$

A phase-lead compensator is introduced into the feedback loop, where

$$
G_{c}(s)=\frac{1+0.3 s}{1+0.03 s} \text {. }
$$

The peak magnitude and the bandwidth of the closed-loop frequency response are:
a. $M_{p_{\omega}}=1.9 \mathrm{~dB} ; \omega_{b}=12.1 \mathrm{rad} / \mathrm{s}$
b. $M_{p_{\omega}}=12.8 \mathrm{~dB} ; \omega_{b}=14.9 \mathrm{rad} / \mathrm{s}$
c. $M_{p_{\omega}}=5.3 \mathrm{~dB} ; \omega_{b}=4.7 \mathrm{rad} / \mathrm{s}$
d. $M_{p_{\omega}}=4.3 \mathrm{~dB} ; \omega_{b}=24.2 \mathrm{rad} / \mathrm{s}$ 9. Consider the feedback system in Figure 10.38, where the plant model is

$$
G(s)=\frac{500}{s(s+50)}
$$

and the controller is a proportional-plus-integral (PI) controller given by

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s} .
$$

Selecting $K_{I}=1$, determine a suitable value of $K_{P}$ for a percent overshoot of P. $O=20 \%$.
a. $K_{P}=0.5$
b. $K_{P}=1.5$
c. $K_{P}=2.5$
d. $K_{P}=5.0$

10. Consider the feedback system in Figure 10.38, where

$$
G(s)=\frac{1}{s(1+s / 8)(1+s / 20)} \text {. }
$$

The design specifications are: $K_{v} \geq 100, G . M . \geq 10 \mathrm{~dB}, P . M . \geq 45^{\circ}$, and the crossover frequency, $\omega_{c} \geq 10 \mathrm{rad} / \mathrm{s}$. Which of the following controllers meets these specifications?
a. $G_{c}(s)=\frac{(1+s)(1+20 s)}{(1+s / 0.01)(1+s / 50)}$
b. $G_{c}(s)=\frac{100(1+s)(1+s / 5)}{(1+s / 0.1)(1+s / 50)}$
c. $G_{c}(s)=\frac{1+100 s}{1+120 s}$
d. $G_{c}(s)=100$

11. Consider a feedback system in which a phase-lead compensator

$$
G_{c}(s)=\frac{1+0.4 s}{1+0.04 s}
$$

is placed in series with the plant

$$
G(s)=\frac{500}{(s+1)(s+5)(s+10)} .
$$

The feedback system is a negative unity feedback control system shown in Figure 10.38. Compute the gain and phase margin.
a. $G \cdot M .=\infty \mathrm{dB}, P . M .=60^{\circ}$
b. $G . M .=20.5 \mathrm{~dB}, P . M .=47.8^{\circ}$
c. $G . M .=8.6 \mathrm{~dB}, P . M .=33.7^{\circ}$
d. Closed-loop system is unstable.

12. Consider the feedback system in Figure 10.38, where

$$
G(s)=\frac{1}{s(s+10)(s+15)} .
$$

Which of the following represents a suitable phase-lag compensator that achieves a steady-state $e_{s s} \leq 0.1$ for a unit ramp input and a damping ratio of the closed-loop system dominant roots of $\zeta \approx 0.707$.
a. $G_{c}(s)=\frac{2850(s+1)}{(10 s+1)}$
b. $G_{c}(s)=\frac{100(s+1)(s+5)}{(s+10)(s+50)}$
c. $G_{c}(s)=\frac{10}{s+1}$
d. Closed-loop system cannot track a ramp input for any $G_{c}(s)$.

13. A viable phase-lag compensator for a unity negative feedback system with plant transfer function

$$
G(s)=\frac{1000}{(s+8)(s+14)(s+20)}
$$

that satisfies the design specifications: (i) no percent overshoot; (ii) rise time $T_{r}<5 \mathrm{~s}$, and (iii) position error constant $K_{p}>6$, is which of the following:
a. $G_{c}(s)=\frac{s+1}{s+0.074}$
b. $G_{c}(s)=\frac{s+0.074}{s+1}$
c. $G_{c}(s)=\frac{20 s+1}{100 s+1}$
d. $G_{c}(s)=20$

14. Consider the feedback system depicted in Figure 10.38, where

$$
G(s)=\frac{1}{s(s+4)^{2}} .
$$

A suitable compensator for $G_{c}(s)$ this system that satisfies the specifications:

(i) P.O. $\leq 20 \%$, and (ii) velocity error constant $K_{v} \geq 10$, is which of the following:

a. $G_{c}(s)=\frac{s+4}{(s+1)}$

b. $G_{c}(s)=\frac{160(10 s+1)}{200 s+1}$

c. $G_{c}(s)=\frac{24(s+1)}{s+4}$

d. None of the above

15. Using a Nichols chart, determine the gain and phase margin of the system in Figure 10.38 with loop gain transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{8 s+1}{s\left(s^{2}+2 s+4\right)} .
$$
a. $G . M .=20.4 \mathrm{~dB}, P . M .=58.1^{\circ}$
b. $G \cdot M .=\infty \mathrm{dB}, P \cdot M .=47^{\circ}$
c. $G \cdot M .=6 \mathrm{~dB}, P \cdot M .=45^{\circ}$
d. $G \cdot M .=\infty \mathrm{dB}, P . M .=23^{\circ}$ In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Deadbeat response A system with a rapid response, minimal overshoot, an zero steady-state error for a step input.

b. Phase lead A network that provides a positive phase angle over the compensation

c. PI controller

d. Lead-lag compensator frequency range of interest.

A compensator hat acts, in part, like an integrator.

A compensator with the characteristics of both a lead compensator and a lag compensator.

e. Design of a control system

A compensator that provides a negative phase angle and a significant attenuation over the frequency range of interest.

f. Phase lag compensation

g. Integration network

h. Compensator

i. Compensation

An additional component or circuit that is inserted into the system to compensate for a performance deficiency.

A compensator placed in cascade or series with the system process.

Controller with a proportional term and an integral term.

A transfer function, $G_{P}(s)$, that filters the input signal $R(s)$ prior to calculating the error signal.

j. Phase-lag network

k. Cascade compensation network

1. Phase-lead network A widely-used compensator that possesses one zero and one pole with the pole closer to the origin of the $s$-plane.

m. Prefilter

A widely-used compensator that possesses one zero and one pole with the zero closer to the origin of the $s$-plane.

\section{EXERCISES}

E10.1 A negative feedback control system has a transfer E10.2 A control system with negative unity feedback has function

$$
G_{c}(s) G(s)=\frac{K}{s+5} .
$$

We select a compensator

$$
G_{c}(s)=\frac{s+a}{s},
$$

in order to achieve zero steady-state error for a step input. Select $a$ and $K$ to target a percent overshoot to a step of P.O. $\leq 10 \%$ and the settling time (with a $2 \%$ criterion) of $T_{s} \leq 1 \mathrm{~s}$. Does the actual P.O. and $T_{s}$ match the targeted values? If not, explain why not.

Answer: $K=3, a=15.27$ a process

$$
G(s)=\frac{400}{s(s+40)},
$$

and we select a proportional plus integral compensation, where

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s} .
$$

Note that the steady-state error of this system for a ramp input is zero. (a) Set $K_{I}=1$ and find a suitable value of $K_{P}$ so the step response will have a percent overshoot of P.O. $\leq 20 \%$. (b) What is the expected settling time (with a $2 \%$ criterion) of the compensated system?

Answer: $K_{P}=0.5$

E10.3 A unity feedback control system in a manufacturing system has a process transfer function

$$
G(s)=\frac{e^{-2 s}}{s+1},
$$

and it is proposed to use a compensator to achieve a percent overshoot P.O. $\leq 5 \%$ to a step input. The compensator is [4]

$$
G_{c}(s)=K\left(1+\frac{1}{\tau s}\right),
$$

which provides proportional plus integral control. Show that one solution is $K=0.44$ and $\tau=1.5$.

E10.4 Consider a unity feedback system with

$$
G(s)=\frac{K}{s(s+5)(s+10)},
$$

where $K$ is set equal to 100 in order to achieve a specified $K_{v}=2$. We wish to add a lead-lag compensator

$$
G_{c}(s)=\frac{(s+0.15)(s+0.7)}{(s+0.015)(s+7)} \text {. }
$$

Show that the gain margin of the compensated system is $G \cdot M .=28.6 \mathrm{~dB}$ and that the phase margin is P.M. $=75.4^{\circ}$.
E10.5 Consider a unity feedback system with the transfer function

$$
G(s)=\frac{K}{s(s+3)(s+5)}
$$

We desire to obtain the dominant roots with $\omega_{n}=2$ and $\zeta=0.55$. The compensator is

$$
G_{c}(s)=\frac{s+7}{s+13}
$$

Determine the value of $K$ that should be selected.

Answer: $K=42$

E10.6 Consider the system with the loop transfer functions

$$
L(s)=G_{c}(s) G(s)=\frac{K(s+4)}{s(s+0.2)\left(s^{2}+15 s+150\right)} .
$$

When $K=10$, find $T(s)$ and estimate the expected percent overshoot and settling time (with a $2 \%$ criterion). Compare your estimates with the actual percent overshoot of P.O. $=47.5 \%$ and a settling time of $T_{s}=32.1 \mathrm{~s}$.

E10.7 NASA astronauts retrieved a satellite and brought it into the cargo bay of the space shuttle, as shown in Figure E10.7(a). A model of the feedback control system is shown in Figure E10.7(b). Determine the value of $K$ that will result in a phase margin of P.M. $=40^{\circ}$ when $T=0.6 \mathrm{~s}$.

Answer: $K=34.15$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0790.jpg?height=573&width=1023&top_left_y=1200&top_left_x=519)

(a)

FIGURE E10.7

Retrieval of a satellite. (Photo courtesy of NASA.)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0790.jpg?height=193&width=1021&top_left_y=1858&top_left_x=520)

Visual feedback

(b) E10.8 A unity feedback system has a plant

$$
G(s)=\frac{2257}{s(\tau s+1)},
$$

where $\tau=2.8 \mathrm{~ms}$. Select a compensator

$$
G_{c}(s)=K_{P}+K_{I} / s,
$$

so that the dominant roots of the characteristic equation have damping ratio equal to $\zeta=1 / \sqrt{2}$. Plot $y(t)$ for a step input.

E10.9 A control system with a controller is shown in Figure E10.9. Select $K_{P}$ and $K_{I}$ so that the percent overshoot to a step input is P.O. $=4 \%$, and the velocity constant $K_{v}$ is equal to 10 . Verify the results of your design.

E10.10 A control system with a controller is shown in Figure E10.10. Select $K_{I}=2$ in order to provide a reasonable steady-state error to a step [8]. Find $K_{P}$ to obtain a phase margin of P.M. $=60^{\circ}$. Find the peak time and percent overshoot of this system.

E10.11 A unity feedback system has

$$
G(s)=\frac{1350}{s(s+1)(s+25)} .
$$

A lead network is selected so that

$$
G_{c}(s)=\frac{1+0.5 s}{1+0.05 s} .
$$

Determine the peak magnitude, $M_{p \omega}$, and the bandwidth, $\omega_{\mathrm{b}}$, of the closed-loop frequency response. From $M_{p \omega}$, estimate the percent overshoot, P.O., to a unit step. Compare with the actual P.O. and comment.

E10.12 The control of an automobile ignition system has unity feedback and a loop transfer function $L(s)=G_{c}(s) G(s)$, where

$$
G(s)=\frac{K}{s(s+6)} \quad \text { and } \quad G_{c}(s)=K_{P}+K_{I} / s .
$$

Let $K_{I} / K_{P}=1$ and determine $K K_{P}$ so that the complex roots have a damping ratio of $\zeta=1 / \sqrt{2}$.

E10.13 The design of Example 10.3 determined a lead network in order to obtain desirable dominant root locations using a cascade compensator $G_{c}(s)$ in the system configuration shown in Figure 10.1(a). The same lead network would be obtained if we used the feedback compensation configuration of Figure 10.1(b). Determine the closed-loop transfer function $T(s)=Y(s) / R(s)$ of both the cascade and feedback configurations, and show how the transfer function of each configuration differs. Explain how the response to a step $R(s)$ will be different for each system.

E10.14 A robot will be operated by NASA to build a permanent lunar station. The unity feedback position control system for the gripper tool has the process transfer function

$$
G(s)=\frac{6}{s(1+0.5 s)(1+0.166 s)} .
$$

Determine a phase-lag compensator $G_{c}(s)$ that will provide a phase margin of $P . M .=40^{\circ}$.

Answer: $G(s)=\frac{(1+7.69)}{(1+28.92 s)}$

E10.15 A unity feedback control system has a plant transfer function

$$
G(s)=\frac{100}{s(s+8)} .
$$

We desire to attain a steady-state error to a ramp $r(t)=A t$ of less than $0.16 A$ and a phase margin of $P . M .=35^{\circ}$. We desire to have a crossover frequency $\omega_{c}=20 \mathrm{rad} / \mathrm{s}$. Determine whether a phase-lead or a phase-lag compensator is required.
FIGURE E10.9

Design of a PI controller.

FIGURE E10.10 Design of a PI controller.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0791.jpg?height=516&width=930&top_left_y=1598&top_left_x=372)E10.16 Consider again the system and specifications of Exercise E10.15 when the required crossover frequency is $\omega_{c}=3 \mathrm{rad} / \mathrm{s}$.

E10.17 Consider again the system of Exercise 10.9. Select $K_{P}$ and $K_{I}$ so that the step response is deadbeat and the settling time (with a $2 \%$ criterion) is $T_{s} \leq 2 \mathrm{~s}$.

E10.18 The nonunity feedback control system shown in Figure E10.18 has the transfer functions

$$
G(s)=\frac{1}{s-20} \quad \text { and } \quad H(s)=10 .
$$

Design a compensator $G_{c}(s)$ and prefilter $G_{p}(s)$ so that the closed-loop system is stable and meets the following specifications: (i) a percent overshoot to a unit step input of $P . O . \leq 10 \%$, (ii) a settling time of $T_{s} \leq 2 \mathrm{~s}$, and (iii) zero steady-state tracking error to a unit step.

E10.19 A unity feedback control system has the plant transfer function

$$
G(s)=\frac{1}{s(s-2)} .
$$

Design a PID controller of the form

$$
G_{c}(s)=K_{p}+K_{D} s+\frac{K_{I}}{s},
$$

so that the closed-loop system has a settling time of $T_{s} \leq 0.5 \mathrm{~s}$ to a unit step input.

E10.20 Consider the system shown in Figure E10.20. Design the proportional-derivative controller $G_{c}(s)$ such that the system has a phase margin of $40^{\circ} \leq$ P.M. $\leq 60^{\circ}$.

E10.21 Consider the unity feedback system shown in Figure E10.21. Design the controller gain, $K$, such that the maximum value of the output $y(t)$ in response to a unit step disturbance $T_{d}(s)=1 / s$ is less than 0.1.
FIGURE E10.18 Nonunity feedback system with a prefilter.

FIGURE E10.20 Unity feedback system with $\mathrm{PD}$ controller.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0792.jpg?height=1170&width=1126&top_left_y=944&top_left_x=507)

FIGURE E10.21 Closed-loop feedback system with a disturbance input. 

\section{PROBLEMS}

P10.1 The design of a lunar excursion module is an interesting control problem. The attitude control system for the lunar vehicle is shown in Figure P10.1. The vehicle damping is negligible, and the attitude is controlled by gas jets. The torque, as a first approximation, will be considered to be proportional to the signal $V(s)$ so that $T(s)=K_{2} V(s)$. The loop gain may be selected by the designer in order to provide a suitable damping. A damping ratio of $\zeta=0.6$ with a settling time (with a $2 \%$ criterion) of less than 2.5 seconds is required. Using a lead network compensation, select the necessary compensator $G_{c}(s)$ by using (a) frequency response techniques and (b) root locus methods.

P10.2 A magnetic tape recorder transport for modern computers requires a high-accuracy, rapid-response control system. The requirements for a specific transport are as follows: (1) The tape must stop or start in $10 \mathrm{~ms}$, and (2) it must be possible to read 45,000 characters per second. This system is illustrated in Figure P10.2. We will use a tachometer in this case and set $K_{a}=50000$ and $K_{2}=1$. To provide a suitable performance, a compensator $G_{c}(s)$ is inserted immediately following the photocell transducer. Select a compensator $G_{c}(s)$ so that the percent overshoot of the system for a step input is $P . O \leq 25 \%$. We assume that $\tau_{1}=0.1 \mathrm{~ms}, \tau_{a}=0.1 \mathrm{~ms}, K_{1}=2, R / L=0.5 \mathrm{~ms}, K_{b}=$ $0.4, r=0.2, K_{T} / L J=2.0$, and $K_{p}=1$.

P10.3 A simplified version of the attitude rate control for a supersonic aircraft is shown in Figure P10.3. When the vehicle is flying at four times the speed of sound (Mach 4) at an altitude of $100,000 \mathrm{ft}$, the parameters are [26]

$$
\begin{array}{rlrl}
\tau_{a} & =1.1, & K_{1} & =1.25, \\
\zeta \omega_{a} & =1.0, \quad \text { and } \quad \omega_{a}=4 .
\end{array}
$$

FIGURE P10.1

Attitude control system for a lunar excursion module.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0793.jpg?height=732&width=1550&top_left_y=921&top_left_x=91)

FIGURE P10.2 Block diagram of a tape control system.

FIGURE P10.3

Aircraft attitude control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0793.jpg?height=369&width=1133&top_left_y=1749&top_left_x=372)

Design a compensator $G_{c}(s)$ so that the response to a step input has a percent overshoot of $P . O \leq 10 \%$.

P10.4 Magnetic particle clutches are useful actuator devices for high power requirements because they can typically provide a $200-\mathrm{W}$ mechanical power output. The particle clutches provide a high torque-to-inertia ratio and fast time-constant response. A particle clutch positioning system for nuclear reactor rods is shown in Figure P10.4. The motor drives two counterrotating clutch housings. The clutch housings are geared through parallel gear trains, and the direction of the servo output is dependent on the clutch that is energized. The time constant of a $200-\mathrm{W}$ clutch is $\tau=1 / 10 \mathrm{~s}$. The constants are such that $K_{T} n / J=1$. We want the percent overshoot for a step input to be P.O. $\leq 20 \%$. Design a compensator so that the system is adequately stabilized. The settling time (with a $2 \%$ criterion) of the system should be $T_{s} \leq 7 \mathrm{~s}$.

P10.5 A stabilized precision rate table uses a precision tachometer and a DC direct-drive torque motor, as shown in Figure P10.5. We want to maintain a high steady-state accuracy for the speed control. To obtain a zero steady-state error for a step command design, select a proportional plus integral compensator. Select the appropriate gain constants so that the system has a percent overshoot of P.O. $=15 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 2 \mathrm{~s}$.

P10.6 Repeat Problem P10.5 by using a phase-lead compensator and compare the results.

P10.7 A chemical reactor process whose production rate is a function of catalyst addition is shown in block diagram form in Figure P10.7 [10]. The time delay is $T=50 \mathrm{~s}$, and the time constant $\tau$ is approximately 40 s. The gain of the process is $K=1$. Design a compensator using Bode plot methods in order to provide a suitable system response. We want to have a steadystate error less than $0.10 A$ for a step input $R(s)=A / s$. For the system with the compensation added, estimate the settling time of the system.

P10.8 A numerical path-controlled machine turret lathe is an interesting problem in attaining sufficient accuracy $[2,23]$. A block diagram of a turret lathe control system is shown in Figure P10.8. The gear ratio is $n=0.2, J=10^{-3}$, and $b=2.0 \times 10^{-2}$. It is necessary
FIGURE P10.4 Nuclear reactor rod control.

FIGURE P10.5 Stabilized rate table.

FIGURE P10.7 Chemical reactor control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0794.jpg?height=1028&width=1434&top_left_y=1016&top_left_x=350)

FIGURE P10.8 Path-controlled turret lathe. to attain an accuracy of $5 \times 10^{-4}$ in., and therefore a steady-state position accuracy of $2.5 \%$ is specified for a ramp input. Design a cascade compensator to be inserted before the silicon-controlled rectifiers in order to provide a response to a step command with a percent overshoot of $P . O . \leq 5 \%$. A suitable damping ratio for this system is $\zeta=0.7$. The gain of the silicon-controlled rectifiers is $K_{R}=5$. Design a suitable phase-lag compensator.

P10.9 The Avemar ferry, shown in Figure P10.9(a), is a large 670-ton ferry hydrofoil built for Mediterranean ferry service. It is capable of 45 knots $(52 \mathrm{mph})$ [29]. The boat's appearance, like its performance, derives from the innovative design of the narrow "wavepiercing" hulls which move through the water like racing shells. Between the hulls is a third quasihull which gives additional buoyancy in rough seas. Loaded with 900 passengers and crew, and a mix of cars, buses, and freight cars trucks, one of the boats can carry almost its own weight. The Avemar is capable of operating in seas with waves up to $8 \mathrm{ft}$ in amplitude at a speed of 40 knots as a result of an automatic stabilization control system. Stabilization is achieved by means of flaps on the main foils and the adjustment of the aft foil. The stabilization control system maintains a level flight through rough seas. Thus, a system that minimizes deviations from a constant lift force or, equivalently, that minimizes the pitch angle $\theta(t)$ has been designed. A block diagram of the lift control system is shown in Figure P10.9(b). The desired response of the system to wave disturbance is a constant-level travel of the craft. Establish a set of reasonable specifications and design a compensator $G_{c}(s)$ so that the performance of the system is suitable. Assume that the disturbance is due to waves with a frequency $\omega=6 \mathrm{rad} / \mathrm{s}$.

P10.10 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=G_{c}(s) \frac{5}{s\left(s^{2}+5 s+12\right)} .
$$

(a) Determine the step response when $G_{c}(s)=1$, and calculate the settling time and steady state for a ramp input $r(t)=t, t>0$. (b) Design a phase-lag compensator using the root locus method so that the velocity constant is increased to 10 . Determine the settling time (with a $2 \%$ criterion) of the compensated system.

P10.11 A unity feedback control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=G_{c}(s) \frac{160}{s^{2}} .
$$

Select a lead-lag compensator so that the percent overshoot for a step input is P.O. $\leq 5 \%$ and the settling time (with a $2 \%$ criterion) is $T_{s} \leq 1 \mathrm{~s}$. It also is desired that the acceleration constant $K_{a}$ be greater than 7500 .

P10.12 A unity feedback control system has a plant

$$
G(s)=\frac{25}{s(1+0.2 s)(1+0.1 s)} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0795.jpg?height=332&width=993&top_left_y=1325&top_left_x=501)

FIGURE P10.9

(a) The Avemar ferry built for ferry service between Barcelona and the Balearic Islands. (b) A block diagram of the lift control system. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0795.jpg?height=318&width=1263&top_left_y=1739&top_left_x=354)

(b) Select a compensator $G_{c}(s)$ so that the phase margin is $P . M . \geq 80^{\circ}$. Use a two-stage lead compensator

$$
G_{c}(s)=\frac{K\left(1+s / \omega_{1}\right)\left(1+s / \omega_{3}\right)}{\left(1+s / \omega_{2}\right)\left(1+s / \omega_{4}\right)} .
$$

It is required that the error for a ramp input be $1 \%$ of the magnitude of the ramp input $\left(K_{v}=100\right)$.

P10.13 Materials testing requires the design of control systems that can faithfully reproduce normal specimen operating environments over a range of specimen parameters [23]. From the control system design viewpoint, a materials-testing machine system can be considered a servomechanism in which we want to have the load waveform track the reference signal. The system is shown in Figure P10.13.

(a) With $G_{c}(s)=K$, choose $K$ so that a phase margin of P.M. $=45^{\circ}$ is achieved. Determine the system bandwidth for this design.

(b) The additional requirement introduced is that the velocity constant $K_{v}$ be equal to 1 . Design a lag compensator so that the phase margin is $P . M .=45^{\circ}$ and $K_{v}=1$.

P10.14 For the system described in Problem P10.13, the goal is to achieve a phase margin of $P . M .=45^{\circ}$ with the additional requirement that the time to settle (to within $2 \%$ of the final value) is $T_{s} \leq 10 \mathrm{~s}$. Design a phase-lead compensator to meet the specifications. As before, we require $K_{v}=1$.

P10.15 A robot with an extended arm has a heavy load, whose effect is a disturbance, as shown in Figure P10.15 [22]. Let $R(s)=0$ and design $G_{c}(s)$ so that the maximum value of the disturbance response is less than 0.25 and the steady-state error to a unit step disturbarce is zero.

P10.16 A driver and car may be represented by the simplified model shown in Figure P10.16 [17]. The goal is to have the speed adjust to a step input with a percent overshoot of P.O. $\leq 10 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s}=1 \mathrm{~s}$. Select a proportional plus integral (PI) controller to yield these specifications. For the selected controller, determine the actual response (a) for $G_{p}(s)=1$ and (b) with a prefilter $G_{p}(s)$ that removes the zero from the closed-loop transfer function $T(s)$.

P10.17 A unity feedback control system for a robot submarine has a plant with a third-order transfer function [20]:

$$
G(s)=\frac{K}{s(s+10)(s+50)} .
$$

We want the percent overshoot to be P.O. $=7.5 \%$ for a step input and the settling time (with a $2 \%$ criterion) of the system be $T_{s}=400 \mathrm{~ms}$. Find a suitable lead compensator by using root locus
FIGURE P10.13 Materials testing machine system.

FIGURE P10.15 Robot control.

FIGURE P10.16 Speed control of an automobile.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0796.jpg?height=876&width=1080&top_left_y=1236&top_left_x=504)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0797.jpg?height=531&width=1249&top_left_y=153&top_left_x=373)

(a)

FIGURE P10.18

(a) Conceptual diagram of a remote manipulator on the Moon controlled by a person on the Earth. (b) Feedback diagram of the remote manipulator control system with $\tau=$ transmission time delay of the video signal.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0797.jpg?height=322&width=1214&top_left_y=789&top_left_x=390)

(b) methods. Let the zero of the compensator be located at $s=-15$, and determine the compensator pole. Determine the resulting system $K_{v}$.

P10.18 NASA is developing remote manipulators that can be used to extend the hand and the power of humankind through space by means of radio. A concept of a remote manipulator is shown in Figure P10.18(a) $[11,22]$. The closed-loop control is shown schematically in Figure P10.18(b). Assuming an average distance of 238,855 miles from Earth to the Moon, the time delay $T$ in transmission of a communication signal is $1.28 \mathrm{~s}$. The operator uses a control stick to control remotely the manipulator placed on the Moon to assist in geological experiments, and the TV display to access the response of the manipulator. The time constant of the manipulator is $1 / 4$ second.

(a) Set the gain $K_{1}$ so that the system has a phase margin of P.M. $=30^{\circ}$. Evaluate the percentage steady-state error for this system for a step input. (b) To reduce the steady-state error for a position command input to $5 \%$, add a lag compensation network in cascade with $K_{1}$. Plot the step response.

P10.19 There have been significant developments in the application of robotics technology to nuclear power plant maintenance problems. Thus far, robotics technology in the nuclear industry has been used primarily on spent-fuel reprocessing and waste management. The industry is applying the technology to such areas as primary containment inspection, reactor maintenance, facility decontamination, and accident recovery activities. These developments suggest that the application of remotely operated devices can significantly reduce radiation exposure to personnel and improve maintenance-program performance.

Currently, an operational robotic system is under development to address particular operational problems within a nuclear power plant. This device, IRIS (Industrial Remote Inspection System), is a general-purpose surveillance system that conducts particular inspection and handling tasks with the goal of significantly reducing personnel exposure to high radiation fields [12]. The device is shown in Figure P10.19. The open-loop transfer function is

$$
G(s)=\frac{K e^{-s T}}{(s+1)(s+3)} .
$$

(a) Determine a suitable gain $K$ for the system when $T=0.5 \mathrm{~s}$, so that the percent overshoot to a step FIGURE P10.19

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0798.jpg?height=446&width=983&top_left_y=158&top_left_x=520)

Remotely controlled robot for nuclear plants.

input is P.O. $\leq 30 \%$. Determine the steady-state error. (b) Design a compensator

$$
G_{c}(s)=\frac{s+2}{s+b}
$$

to improve the step response for the system in part (a) so that the steady-state error is less than $12 \%$. Assume a unity feedback control system.

P10.20 An uncompensated control system with unity feedback has a plant transfer function

$$
G(s)=\frac{K}{s(s / 2+1)(s / 6+1)} .
$$

We want to have a velocity error constant of $K_{v}=20$. We also want to have a phase margin of P.M. $=45^{\circ}$ and a closed-loop bandwidth $\omega_{B} \geq 4 \mathrm{rad} / \mathrm{s}$. Use two identical cascaded phase-lead compensators to compensate the system.

P10.21 For the system of Problem P10.20, design a phaselag compensator to yield the desired specifications, with the exception that a bandwidth $\omega_{B} \geq 2 \mathrm{rad} / \mathrm{s}$ will be acceptable.

P10.22 For the system of Problem P10.20, we wish to achieve the same phase margin and $K_{v}$, but in addition, we wish to limit the bandwidth to $2 \mathrm{rad} / \mathrm{s} \leq \omega_{B} \leq 10 \mathrm{rad} / \mathrm{s}$. Use a lead-lag compensation to compensate the system. The compensator could be of the form

$$
G_{c}(s)=\frac{(1+s / 10 a)(1+s / b)}{(1+s / a)(1+s / 10 b)},
$$

where $a$ is to be selected for the phase-lag portion of the compensator, and $b$ is to be selected for the phase-lead portion of the compensator. The ratio $\alpha$ is chosen to be 10 for both the lead and lag portions.

P10.23 A system the loop transfer function with unity feedback has

$$
L(s)=G_{c}(s) G(s)=\frac{K}{(s+4)^{2}} .
$$

We desire the steady-state error to a step input to be approximately $4 \%$ and the phase margin to be $P . M .=60^{\circ}$. Design a phase-lag compensator to meet these specifications.

P10.24 The stability and performance of the rotation of a robot (similar to waist rotation) presents a challenging control problem. The system requires high gains in order to achieve high resolution; yet a large percent overshoot of the transient response cannot be tolerated. The block diagram of an electrohydraulic system for rotation control is shown in Figure P10.24 [15].

We want to have $K_{v}=20$ for the compensated system. Design a compensator that results in a percent overshoot to a step input of P.O. $\leq 10 \%$.

P10.25 The possibility of overcoming wheel friction, wear, and vibration by contactless suspension for passenger-carrying mass-transit vehicles is being investigated throughout the world. One design uses a magnetic suspension with an attraction force between the vehicle and the guideway with an accurately controlled airgap. A system is shown in Figure P10.25, which incorporates feedback compensation.
FIGURE P10.24 Robot position control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0798.jpg?height=239&width=1266&top_left_y=1899&top_left_x=487)

FIGURE P10.25

Airgap control of train.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0799.jpg?height=393&width=1190&top_left_y=156&top_left_x=372)

Using root locus methods, select a suitable value for $K_{1}$ and $b$ so the system has a damping ratio for the underdamped roots of $\zeta=0.50$.

P10.26 A computer uses a printer as a fast output device. We desire to maintain accurate position control while moving the paper rapidly through the printer. Consider a system with unity feedback and a transfer function for the motor and amplifier of

$$
G(s)=\frac{0.2}{s(s+1)(6 s+1)} .
$$

Design a phase-lead compensator so that the system bandwidth is $\omega_{B}=0.8 \mathrm{rad} / \mathrm{s}$ and the phase margin is $P . M . \geq 30^{\circ}$.

P10.27 An engineering design team is attempting to control a process shown in Figure P10.27. It is agreed that a system with a phase margin of $P . M .=50^{\circ}$ is acceptable. Determine $G_{c}(s)$.

First, let $G_{c}(s)=K$ and find (a) a value of $K$ that yields a phase margin of $P . M .=50^{\circ}$ and the system step response for this value of $K$. (b) Determine the settling time, percent overshoot, and the peak time. (c) Obtain the system closed-loop frequency response, and determine $M_{p \omega}$ and the bandwidth.

The team has decided to let

$$
G_{c}(s)=\frac{K(s+12)}{(s+20)}
$$

and to repeat parts (a), (b), and (c). Determine the gain $K$ that results in a phase margin of P.M. $=50^{\circ}$ and then proceed to evaluate the time response and the closed-loop frequency response. Prepare a table contrasting the results of the two selected controllers for $G_{c}(s)$ by comparing settling time (with a $2 \%$ criterion), percent overshoot, peak time, $M_{p \omega}$, and bandwidth.

P10.28 An adaptive suspension vehicle uses a legged locomotion principle. The control of the leg can be represented by a unity feedback system with [12]

$$
G(s)=\frac{K}{s(s+10)(s+14)} .
$$

We desire to achieve a steady-state error for a ramp input of $10 \%$ and a damping ratio of the dominant roots of $\zeta=0.707$. Determine a suitable lag compensator, and determine the actual overshoot and the time to settle (to within $2 \%$ of the final value).

P10.29 A liquid-level control system has a loop transfer function

$$
L(s)=G_{c}(s) G(s),
$$

where $G_{c}(s)$ is a compensator, and the plant is

$$
G(s)=\frac{10 e^{-s T}}{s^{2}(s+10)},
$$

where $T=50 \mathrm{~ms}$. Design a compensator so that $M_{p \omega}$ does not exceed $3.5 \mathrm{~dB}$ and $\omega_{r}$ is approximately $1.4 \mathrm{rad} / \mathrm{s}$. Predict the percent overshoot and settling time (with a $2 \%$ criterion) of the compensated system when the input is a step. Plot the actual response.

P10.30 An automated guided vehicle (AGV) can be considered as an automated mobile conveyor designed

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0799.jpg?height=234&width=1005&top_left_y=1882&top_left_x=375)

FIGURE P10.30 Steering control for vehicle.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0800.jpg?height=254&width=993&top_left_y=155&top_left_x=515)

to transport materials. Most AGVs require some type of guide path. The steering stability of the guidance control system has not been fully solved. The slight "snaking" of the AGV about the track generally has been acceptable, although it indicates instability of the steering guidance control system [9].

Most AGVs have a specification of maximum speed of about $1 \mathrm{~m} / \mathrm{s}$, although in practice they are usually operated at half that speed. In a fully automated manufacturing environment, there should be few personnel in the production area; therefore, the AGV should be able to be run at full speed. As the speed of the AGV increases, so does the difficulty in designing stable and smooth tracking controls.

A steering system for an $\mathrm{AGV}$ is shown in Figure P10.30, where $\tau_{1}=40 \mathrm{~ms}$ and $\tau_{2}=1 \mathrm{~ms}$. We require that the velocity constant $K_{v}$ be 100 so that the steady-state error for a ramp input will be $1 \%$ of the slope of the ramp. Neglect $\tau_{2}$ and design a lead compensator so that the phase margin is

$$
45^{\circ} \leq P \cdot M . \leq 65^{\circ} .
$$

Attempt to obtain the two limiting cases for phase margin, and compare your results for the two designs by determining the actual percent overshoot and settling time for a step input.

P10.31 For the system of Problem P10.30, use a phase-lag compensator and attempt to achieve a phase margin of P.M. $=50^{\circ}$. Determine the actual percent overshoot and peak time for the compensated system.

P10.32 When a motor drives a flexible structure, the structure's natural frequencies, as compared to the bandwidth of the servodrive, determine the contribution of the structural flexibility to the errors of the resulting motion. In current industrial robots, the drives are often relatively slow, and the structures are relatively rigid, so that overshoots and other errors are caused mainly by the servodrive. However, depending on the accuracy required, the structural deflections of the driven members can become significant. Structural flexibility must be considered the major source of motion errors in space structures and manipulators. Because of weight restrictions in space, large arm lengths result in flexible structures. Furthermore, future industrial robots should require lighter and more flexible manipulators.
To investigate the effects of structural flexibility and how different control schemes can reduce unwanted oscillations, an experimental apparatus was constructed consisting of a DC motor driving a slender aluminum beam. The purpose of the experiments was to identify simple and effective control strategies to deal with the motion errors that occur when a servomotor is driving a very flexible structure [13].

The experimental apparatus is shown in Figure P10.32(a), and the control system is shown in Figure $\mathrm{P} 10.32(\mathrm{~b})$. The goal is that the system will have a $K_{v}$ of 100. (a) When $G_{c}(s)=K$, determine $K$ and obtain the Bode plot. Find the phase margin and gain margin. (b) Using the Nichols chart, find $\omega_{r}, M_{p \omega}$, and $\omega_{B}$. (c) Select a compensator so that the phase margin is P.M. $\geq 35^{\circ}$ and find $\omega_{r}, M_{p \omega}$, and $\omega_{B}$ for the compensated system.

P10.33 Consider the block diagram of the extender robot system shown in Figure P10.33 [14]. The goal is that the compensated system will have a velocity constant $K_{v}$ equal to 80 , so that the settling time (with a $2 \%$ criterion) will be $T_{s}=1.6 \mathrm{~s}$, and that the percent overshoot will be P.O. $=16 \%$, so that the dominant roots have a $\zeta=0.5$. Determine a lead-lag compensator using root locus methods.

P10.34 A magnetically levitated train operated in Berlin, Germany from 1989-1991. Fully automated trains can run at short intervals and operate with excellent energy efficiency. The control system for the levitation of the car is shown in Figure P10.34. Select a compensator so that the phase margin of the system is $45^{\circ} \leq P . M . \leq 55^{\circ}$. Predict the response of the system to a step command, and determine the actual step response for comparison.

P10.35 A unity feedback system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K s+0.54}{s(s+1.76)} e^{-T s},
$$

where $T$ is a time delay and $K$ is the controller proportional gain. The block diagram is illustrated in Figure P10.35. The nominal value of $K=2$. Plot the phase margin of the system for $0 \leq T \leq 2$ s when $K=2$. What happens to the phase margin as the time delay 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0801.jpg?height=489&width=976&top_left_y=158&top_left_x=415)

(a)

FIGURE P10.32

Flexible arm control.

FIGURE P10.33 Extender robot control.

FIGURE P10.34 Magnetically levitated train control.

FIGURE P10.35 Unity feedback system with a time delay and PI controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0801.jpg?height=202&width=1056&top_left_y=753&top_left_x=375)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0801.jpg?height=768&width=1170&top_left_y=1041&top_left_x=372)

increases? What is the maximum time delay allowed before the system becomes unstable? the compensated system and plot the step response. Assume a unity feedback system.

P10.36 A system transfer function is a pure time delay of P10.37 A unity feedback system has the loop transfer $0.5 \mathrm{~s}$, so that $G(s)=e^{-s / 2}$. Select a compensator $G_{c}(s)$ so that the steady-state error for a step input is less than $2 \%$ of the magnitude of the step and the phase margin is P.M. $\geq 30^{\circ}$. Determine the bandwidth of function

$$
L(s)=G_{c}(s) G(s)=G_{c}(s) \frac{1}{(s+2)(s+8)} .
$$

Design a compensator $G_{c}(s)$ so that the percent overshoot for a step input $R(s)$ is $P . O . \leq 5 \%$ and the steady-state error is less than $1 \%$. Determine the bandwidth of the system.

P10.38 A unity feedback system has a plant

$$
G(s)=\frac{30}{s(s+3)} .
$$

We desire to have a phase margin of $P . M .=35^{\circ}$ and a relatively large bandwidth. Select the crossover frequency $\omega_{c}=10 \mathrm{rad} / \mathrm{s}$, and design a phase-lead compensator. Verify the results.

P10.39 A unity feedback system has a plant

$$
G(s)=\frac{40}{s(s+2)} .
$$

We desire that the phase margin be P.M. $=30^{\circ}$. For a ramp input $r(t)=t$, we want the steady-state error to be equal to 0.05 . Design a phase-lag compensator to satisfy the requirements. Verify the results.
P10.40 For the system and requirements of Problem P10.39, determine the required compensator when the steadystate error for the ramp input must be equal to 0.02 .

P10.41 Repeat Example 10.12 when we want the rise time to be $T_{r}=1 \mathrm{~s}$.

P10.42 Consider the system shown in Figure P10.42 and let $R(s)=0$ and $T_{d}(s)=0$. Design the compensator $G_{c}(s)=K$ such that, in the steady-state, the response of the system is less than $-40 \mathrm{~dB}$ when the noise $N(s)$ is a sinusoidal input at a frequency of $\omega \geq 100 \mathrm{rad} / \mathrm{s}$.

P10.43 A unity feedback system has a loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K\left(s^{2}+2 s+20\right)}{s(s+2)\left(s^{2}+2 s+1\right)} .
$$

Plot the percent overshoot of the closed-loop system response to a unit step input for $K$ in the range $0<K \leq 100$. Explain the behavior of the system response for $K$ in the range $0.129<K \leq 69.872$.
FIGURE P10.42 Unity feedback system with proportional controller and measurement noise.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0802.jpg?height=352&width=1216&top_left_y=946&top_left_x=521)

\section{ADVANCED PROBLEMS}

AP10.1 A three-axis pick-and-place application requires the precise movement of a robotic arm in three-dimensional space, as shown in Figure AP10.1 for joint 2. The arm has specific linear paths it must follow to avoid other pieces of machinery. The overshoot for a step input should be less than $13 \%$.

(a) Let $G_{c}(s)=K$, and determine the gain $K$ that satisfies the requirement. Determine the resulting settling time (with a $2 \%$ criterion). (b) Use pole-zero cancellation to reduce the settling time to $T_{s} \leq 5 \mathrm{~s}$.

AP10.2 The system of Advanced Problem AP10.1 is to have a percent overshoot of $P . O . \leq 13 \%$. In addition, we desire that the steady-state error for a unit ramp input will be less than $0.125\left(K_{v}=8\right)$ [24]. Design a lag compensator to meet the specifications. Check the resulting percent overshoot and settling time (with a $2 \%$ criterion) for the design.
AP10.3 The system of Advanced Problem AP10.1 is required to have a percent overshoot of P.O. $\leq 13 \%$ with a steady-state error for a unit ramp input less than $0.125\left(K_{v}=8\right)$. Design a proportional plus integral (PI) controller to meet the specifications.

AP10.4 A DC motor control system with unity feedback has the form shown in Figure AP10.4. Select $K_{1}$ and $K_{2}$ so that the system response has a settling time (with a $2 \%$ criterion) $T_{s} \leq 0.5 \mathrm{~s}$ and a percent overshoot of P.O. $\leq 10 \%$ for a step input.

AP10.5 A unity feedback system is shown in Figure AP10.5. We want the step response of the system to have a percent overshoot of P.O. $\leq 10 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 4 \mathrm{~s}$.

(a) Design a phase-lead compensator $G_{c}(s)$ to achieve the dominant roots desired. (b) Determine the step response of the system when $G_{p}(s)=1$. (c) Select FIGURE AP10.1

Pick-and-place robot.

FIGURE AP10.4 Motor control system.

FIGURE AP10.5 Unity feedback with a prefilter.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0803.jpg?height=783&width=1044&top_left_y=154&top_left_x=372)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0803.jpg?height=186&width=858&top_left_y=1055&top_left_x=465)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0803.jpg?height=644&width=1190&top_left_y=1460&top_left_x=374)a prefilter $G_{p}(s)$, and determine the step response of the system with the prefilter.

AP10.6 Consider a unity feedback system with loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+z}{s+p} \frac{K}{s(s+1)} .
$$

We wish to minimize the settling time of the system while requiring that $K<52$. Determine the appropriate compensator parameters $p$ and $z$ that will minimize the settling time. Plot the system response.

AP10.7 A unity feedback system has

$$
G(s)=\frac{1}{s(s+1)(s+5)},
$$

with a phase-lead compensator

$$
G_{c}(s)=\frac{K(s+2)}{s+15} .
$$

Determine $K$ so that the complex roots have $\zeta=1 / \sqrt{2}$. Consider the prefilter

$$
G_{p}(s)=\frac{p}{s+p}
$$

(a) Determine the percent overshoot and rise time for $G_{p}(s)=1$ and for $p=1$. (b) Select an appropriate value for $p$ that will give an overshoot of P.O. $\leq 1 \%$, and compare the results.

AP10.8 The Manutec robot has large inertia and arm length resulting in a challenging control problem, as shown in Figure AP10.8(a). The block diagram model of the system is shown in Figure AP10.8(b).

The percentage overshoot for a step input should be $P . O . \leq 20 \%$ with a rise time of $T_{r} \leq 0.5 \mathrm{~s}$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 1.2 \mathrm{~s}$. Also, we desire that for a ramp input $K_{v} \geq 10$. Determine a suitable phase-lead compensator.

AP10.9 The plant dynamics of a chemical process are represented by

$$
G(s)=\frac{100}{s(s+5)(s+10)} .
$$

We desire that the unity feedback system have a small steady-state error for a ramp input so that $K_{v}=100$. For stability purposes, we desire a gain margin of G.M. $\geq 10 \mathrm{~dB}$ and a phase margin of P.M. $\geq 40^{\circ}$. Determine a lead-lag compensator that meets these specifications.
FIGURE AP10.8

(a) Manutec robot.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0804.jpg?height=505&width=459&top_left_y=1220&top_left_x=711)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0804.jpg?height=230&width=1004&top_left_y=1823&top_left_x=519)

(b) 

\section{DESIGN PROBLEMS}

CDP10.1 The capstan-slide system of Figure CDP4.1 uses a PD controller. Determine the necessary values of the gain constants of the PD controller so that the deadbeat response is achieved. Also, we want the settling time (with a $2 \%$ criterion) to be $T_{s} \leq 250 \mathrm{~ms}$. Verify the results.

DP10.1 In Figure DP10.1, two robots are shown cooperating with each other to manipulate a long shaft to insert it into the hole in the block resting on the table. Long part insertion is a good example of a task that can benefit from cooperative control. The unity feedback control system of one robot joint has the process transfer function

$$
G(s)=\frac{15}{s(s+3)} .
$$

The specifications require a steady-state error for a unit ramp input of 0.01 , and the step response has an overshoot of P.O. $\leq 5 \%$ with a settling time (with a $2 \%$ criterion) of $T_{s} \leq 1 \mathrm{~s}$. Determine a lead-lag compensator that will meet the specifications, and plot the compensated responses for the ramp and step inputs.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0805.jpg?height=680&width=682&top_left_y=1095&top_left_x=146)

FIGURE DP10.1 Two robots cooperate to insert a shaft.

DP10.2 The heading control of the traditional bi-wing aircraft, shown in Figure DP10.2(a), is represented by the block diagram of Figure DP10.2(b).

(a) Determine the minimum value of the gain $K$ when $G_{c}(s)=K$, so that the steady-state effect of a unit step disturbance $T_{d}(s)=1 / s$ is less than or equal to $5 \%$ of the unit step $(y(\infty)=0.05)$.

(b) Determine whether the system using the gain of part (a) is stable.

(c) Design a compensator using one stage of lead compensation, so that the phase margin is P.M. $=30^{\circ}$.

(d) Design a two-stage lead compensator so that the phase margin is P.M. $=55^{\circ}$.

(e) Compare the bandwidth of the systems of parts (c) and (d).

(f) Plot the step response $y(t)$ for the systems of parts (c) and (d) and compare percent overshoot settling time (with a $2 \%$ criterion), and peak time.

DP10.3 NASA has identified the need for large deployable space structures, which will be constructed of lightweight materials and will contain large numbers of joints or structural connections. This need is evident for programs such as the space station. These deployable space structures may have precision shape requirements and a need for vibration suppression during in-orbit operations [16].

One such structure is the mast flight system, which is shown in Figure DP10.3(a). The intent of the system is to provide an experimental test bed for controls and dynamics. The basic element in the mast flight system is a $60.7-\mathrm{m}$-long truss beam structure, which is attached to the shuttle orbiter. Included at the tip of the truss structure are the primary actuators and collocated sensors. A deployment/retraction subsystem, which also secures the stowed beam package during launch and landing, is provided.

The system uses a large motor to move the structure and has the block diagram shown in Figure DP10.3(b). The goal is a percent overshoot to a step response of P.O. $\leq 20 \%$; thus, we estimate the system $\zeta=0.5$ and the required phase margin as P.M. $=50^{\circ}$. Design for $0.75<K<2.0$ and record the percent overshoot, rise time, and phase margin for selected gains.

DP10.4 A high-speed train is under development in Texas [21] with a design based on the French Train à Grande Vitesse (TGV). Train speeds of 186 miles per hour are foreseen. To achieve these speeds on tight curves, the train may use independent axles combined with the ability to tilt the train. Hydraulic cylinders connecting the passenger compartments to their wheeled bogies allow the train to lean into curves like a motorcycle. A pendulum like device on the leading bogie of each car senses when it is entering a curve and feeds this information to the hydraulic system. Tilting does not make the train safer, but it does make passengers more comfortable. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0806.jpg?height=393&width=696&top_left_y=156&top_left_x=696)

(a)

FIGURE DP10.2 (a) Bi-wing aircraft. (Source: The Illustrated London News, October 9, 1920.) (b) Control system.
Wind

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0806.jpg?height=282&width=1018&top_left_y=687&top_left_x=507)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0806.jpg?height=487&width=741&top_left_y=1182&top_left_x=575)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0806.jpg?height=181&width=884&top_left_y=1763&top_left_x=508)

(b) FIGURE DP10.4

High-speed train

feedback control

system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0807.jpg?height=205&width=1173&top_left_y=154&top_left_x=373)

Consider the tilt control shown in Figure DP10.4. Design a compensator $G_{c}(s)$ for a step-input command so that the percent overshoot is P.O. $\leq 10 \%$ and the settling time (with a $2 \%$ criterion) $T_{s} \leq 1 \mathrm{~s}$. We also desire that the steady-state error for a velocity (ramp) input be less than $0.2 A$, where $r(t)=A t, t>0$. Verify the results for the design.

DP10.5 High-performance tape transport systems are designed with a small capstan to pull the tape past the $\mathrm{read} /$ write heads and with take-up reels turned by DC motors. The tape is to be controlled at speeds up to 200 inches per second, with start-up as fast as possible, while preventing permanent distortion of the tape. Since we wish to control the speed and the tension of the tape, we will use a DC tachometer for the speed sensor and a potentiometer for the position sensor. We will use a DC motor for the actuator. Then the linear model for the system is a unity feedback system with

$$
\begin{gathered}
\frac{Y(s)}{E(s)}=G(s)= \\
\frac{K(s+4000)}{s(s+1000)(s+3000)\left(s^{2}+4000 s+8,000,000\right)},
\end{gathered}
$$

where $Y(s)$ is position.

The specifications for the system are (1) settling time of $T_{s} \leq 12 \mathrm{~ms}$, (2) a percent overshoot to a step position command of P.O. $\leq 10 \%$, and (3) a steadystate velocity error of less than $0.5 \%$. Determine a compensator to achieve these specifications.

DP10.6 The past years have witnessed a significant engine model-building activity in the automotive industry in a category referred to as "control-oriented" or "control design" models. These models contain representations of the throttle body, engine pumping phenomena, induction process dynamics, fuel system, engine torque generation, and rotating inertia.
The control of the fuel-to-air ratio in an automobile carburetor became of prime importance as automakers worked to reduce exhaust-pollution emissions. Thus, auto engine designers turned to the feedback control of the fuel-to-air ratio. Operation of an engine at or near a particular air-to-fuel ratio requires management of both air and fuel flow into the manifold system. The fuel command is considered the input and the engine speed is considered the output $[9,10]$.

The block diagram of the system is shown in Figure DP10.6, where $T=0.066 \mathrm{~s}$. A compensator is required to yield zero steady-state error for a step input and a percent overshoot of P.O. $\leq 10 \%$. We also desire that the settling time (with a $2 \%$ criterion) of $T_{s} \leq 10 \mathrm{~s}$.

DP10.7 A high-performance jet airplane is shown in Figure DP10.7(a), and the roll-angle control system is shown in Figure DP10.7(b). Design a controller $G_{c}(s)$ so that the step response is well behaved and the steady-state error is zero. That is, $P . O . \leq 10 \%$ and $\mathrm{T}_{\mathrm{s}} \leq 2 \mathrm{~s}$.

DP10.8 A simple closed-loop control system has been proposed to demonstrate proportional-integral (PI) control of a windmill radiometer [27]. The windmill radiometer is shown in Figure DP10.8(a) and the control system is shown in Figure DP10.8(b). The variable to be controlled is the angular velocity $\omega$ of the windmill radiometer whose vanes turn when exposed to infrared radiation. An experimental setup using a reflexive photoelectric sensor and basic electronic circuitry makes possible the design and implementation of a high performance control system.

Assume $\tau=20 \mathrm{~s}$. Design a PI controller so that the system achieves a deadbeat response with a settling time of $T_{s} \leq 25 \mathrm{~s}$.

DP10.9 Consider the feedback control system shown in Figure DP10.9. Design a PID compensator $G_{c 1}(s)$ and a lead-lag compensator $G_{c 2}(s)$ such that, in each
FIGURE DP10.6

Engine control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0807.jpg?height=275&width=1117&top_left_y=1843&top_left_x=373)

FIGURE DP10.7

Roll-angle control of a jet airplane.

FIGURE DP10.8

(a) Radiometric windmill. (b) Control system.

FIGURE DP10.9

Feedback control system with a time-delay.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0808.jpg?height=280&width=397&top_left_y=152&top_left_x=846)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0808.jpg?height=193&width=955&top_left_y=529&top_left_x=520)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0808.jpg?height=618&width=306&top_left_y=827&top_left_x=520)

(a)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0808.jpg?height=438&width=868&top_left_y=1000&top_left_x=842)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0808.jpg?height=320&width=935&top_left_y=1538&top_left_x=518)

case, the closed-loop system is stable in the presence of a time-delay $T=0.1 \mathrm{~s}$. Discuss the capability of each compensator to insure stability in the presence of an increase in the time-delay uncertainty of up to 0.2 second.
DP10.10 A unity feedback system has the process transfer function

$$
G(s)=\frac{s+1.59}{s(s+3.7)\left(s^{2}+2.4 s+0.43\right)} .
$$

Design the controller $G_{c}(s)$ such that the Bode magnitude plot of the loop transfer function $L(s)=$ $G_{c}(s) G(s)$ is greater than $20 \mathrm{~dB}$ for $\omega \leq 0.01 \mathrm{rad} / \mathrm{s}$ and less than $-20 \mathrm{~dB}$ for $\omega \leq 10 \mathrm{rad} / \mathrm{s}$. The desired shape of the loop transfer function Bode plot magnitude is illustrated in Figure DP10.10. Explain why we would want the gain to be high at low-frequency and the gain to be low at high-frequency.
DP10.11 Modern microanalytical systems used for polymerase chain reaction (PCR) requires fast, damped tracking response [30]. The control of the temperature of the PCR reactor can be represented as shown in Figure DP10.11. The controller is chosen to be PID controller, denoted by $G_{c}(s)$, with a prefilter, denoted by $G_{p}(s)$.

It is required that the percent overshoot P.O. $<1 \%$ and the settling time $T_{s}<3$ s to a unit step input. Design a controller $G_{c}(s)$ and prefilter $G_{p}(s)$ to achieve the control specifications.
FIGURE DP10.10

Bode plot loop shaping requirements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0809.jpg?height=757&width=983&top_left_y=572&top_left_x=374)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0809.jpg?height=223&width=1452&top_left_y=1389&top_left_x=163)

FIGURE DP10.11 Polymerase chain reaction control system.

\section{COMPUTER PROBLEMS}

CP10.1 Consider the control system in Figure CP10.1, where

$$
G(s)=\frac{1}{s+9.5} \text { and } G_{c}(s)=\frac{99}{s} .
$$

Develop an $\mathrm{m}$-file to show that the phase margin is approximately P.M. $=50^{\circ}$ and that the percent overshoot to a unit step input is approximately $P . O .=18 \%$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0809.jpg?height=153&width=720&top_left_y=1843&top_left_x=877)

FIGURE CP10.1 A feedback control system with compensation. FIGURE CP10.2

Single-loop feedback system

with proportional controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0810.jpg?height=283&width=911&top_left_y=150&top_left_x=542)

FIGURE

CP10.4 An aircraft pitch rate feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0810.jpg?height=264&width=1317&top_left_y=543&top_left_x=468)

CP10.2 A unity feedback control system is shown in Figure CP10.2. Design the proportional controller $G_{c}(s)=K$ so that the system has a phase margin of $P . M .=55^{\circ}$. Develop an m-file to obtain a Bode plot, and verify that the design specification is satisfied.

CP10.3 Consider the system in Figure CP10.1, where

$$
G(s)=\frac{1}{s(s+3)} .
$$

Design a compensator $G_{c}(s)$ so that the steady-state tracking error to a ramp input is zero and the settling time (with a $2 \%$ criterion) is $T_{S} \leq 5 \mathrm{~s}$. Obtain the response of the closed-loop system to the input $R(s)=1 / s^{2}$, and verify that the settling time requirement has been satisfied and that the steady-state error is zero.

CP10.4 Consider the aircraft unity feedback control system in Figure CP10.4, where $\dot{\theta}(t)$ is the pitch rate $(\mathrm{rad} / \mathrm{s})$ and $\delta(t)$ is the elevator deflection (rad). The four poles represent the phugoid and short-period modes. The phugoid mode has a natural frequency of $0.1 \mathrm{rad} / \mathrm{s}$, and the short period mode is $1.4 \mathrm{rad} / \mathrm{s}$.

(a) Using Bode plot methods, design a phaselead compensator to meet the following specifications: (1) settling time (with a $2 \%$ criterion) to a unit step of $T_{s} \leq 2 \mathrm{~s}$, and (2) percent overshoot of P.O. $\leq 10 \%$.

(b) Simulate the closed-loop system with a step input of $10 \% \mathrm{~s}$, and show the time history of $\dot{\theta}(t)$.

CP10.5 The pitch attitude motion of a rigid spacecraft is described by

$$
J \ddot{\theta}(t)=u(t)
$$

where $J$ is the principal moment of inertia, and is the input torque on the vehicle [7]. Consider the PD controller

$$
G_{c}(s)=K_{P}+K_{D} s .
$$

(a) Design a unity feedback control system to meet the following specifications: (1) closed-loop system bandwidth about $\omega_{B}=10 \mathrm{rad} / \mathrm{s}$, and (2) percent overshoot of P.O. $\leq 20 \%$ to a $10^{\circ}$ step input. Complete the design by developing and using an interactive m-file script. (b) Verify the design by simulating the response to a $10^{\circ}$ step input. (c) Include a closed-loop transfer function Bode plot to verify that the bandwidth requirement is satisfied.

CP10.6 Consider the control system shown in Figure CP10.6. Design a lag compensator using root locus methods to meet the following specifications:(1) steadystate error less than $10 \%$ for a step input, (2) phase margin of P.M. $\geq 45^{\circ}$, and (3) settling time (with a $2 \%$ criterion) of $T_{s} \leq 5 \mathrm{~s}$ for a unit step input.

(a) Design a phase-lag compensator utilizing root locus methods to meet the design specifications. Develop a set of m-file scripts to assist in the design process. (b) Test the controller developed in part (a) by simulating the closed-loop system response to unit step input. Provide the time histories of the output $y(t)$. (c) Compute the phase margin using the margin function.

CP10.7 A lateral beam guidance system has an inner loop as shown in Figure CP10.7 [26].

(a) Design a control system to meet the following specifications: (1) settling time (with a $2 \%$ criterion) to a unit step input of $T_{s} \leq 1 \mathrm{~s}$, and (2) steady-state tracking error for a unit ramp input of less than 0.1 . (b) Verify the design by simulation. FIGURE CP10.6

A unity feedback control system.
FIGURE CP10.7

A lateral beam guidance system inner loop.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0811.jpg?height=576&width=1060&top_left_y=152&top_left_x=410)

CP10.8 Consider a unity feedback system with the loop CP10.9 Consider a circuit with the transfer function transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{s+z}{s+p} \frac{12.2}{s^{2}}
$$

$$
G(s)=\frac{V_{o}(s)}{V_{i}(s)}=\frac{1+R_{2} C_{2} s}{1+R_{1} C_{1} s},
$$

where $\quad C_{1}=1 \mathrm{mF}, C_{2}=0.1 \mu \mathrm{F}, R_{1}=10 \Omega, \quad$ and $R_{2}=10 \mathrm{k} \Omega$. Plot the frequency response of the circuit.

where $z=2$ and $p=5$. The actual percent overshoot CP10.10 Consider the feedback control system shown in of the compensated system will be P.O. $=59.1 \%$. We want to reduce the percent overshoot to P.O. $=35 \%$. Using an m-file script, determine an appropriate value for the zero of $G_{c}(s)$.

Figure CP10.10. The time delay is $T=0.7 \mathrm{~s}$. Plot the phase margin for the system versus the gain in the range $0.1 \leq K \leq 10$. Determine the gain $K$ that maximizes the phase margin. What is the stability limit for $K$ ?
FIGURE CP10.10 Feedback control system with a time delay.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0811.jpg?height=221&width=887&top_left_y=1289&top_left_x=410)

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) False; (2) False; (3) True; (4) True; (5) True

Multiple Choice: (6) d; (7) b; (8) d; (9) a; (10) b; (11) c; (12) a; (13) a; (14) b; (15) b
Word Match (in order, top to bottom): a, l, g, d, j, h, k, c, m, e, i, f, b 

\section{TERMS AND CONCEPTS}

Cascade compensator A compensator placed in cascade or series with the system process.

Compensation The alteration or adjustment of a control Phase lead compensation A widely-used compensator system in order to provide a suitable performance.

Compensator An additional component or circuit that is inserted into the system to compensate for a performance deficiency.

Deadbeat response A system with a rapid response, minimal overshoot, and zero steady-state error for a step input.

Design of a control system The arrangement or the plan of the system structure and the selection of suitable components and parameters.

Integration compensator A compensator that acts, in part, like an integrator.

Lag network See Phase-lag compensator.

Lead-lag compensator A compensator with the characteristics of both a phase-lead compensator and a phase-lag compensator.

Lead compensator See Phase-lead compensator.

Phase lag compensation A widely-used compensator that possesses one zero and one pole with the pole closer to the origin of the $s$-plane. This compensator reduces the steady-state tracking errors. that possesses one zero and one pole with the zero closer to the origin of the $s$-plane. This compensator increases the system bandwidth and improves the dynamic response.

Phase-lag compensator A compensator that provides a negative phase angle and a significant attenuation over the frequency range of interest.

Phase-lead compensator A widely-used compensator that provides a positive phase angle over the frequency range of interest. Thus, phase lead can be used to cause a system to have an adequate phase margin.

PD controller Controller with a proportional term and a derivative term (Proportional-Derivation).

PI controller Controller with a proportional term and an integral term (Proportional-Integral).

Prefilter A transfer function $G_{p}(s)$ that filters the input signal $R(s)$ prior to calculating the error signal. 

\author{
11.1 Introduction 813 \\ 11.2 Controllability and Observability 813 \\ 11.3 Full-State Feedback Control Design 819 \\ 11.4 Observer Design 825 \\ 11.5 Integrated Full-State Feedback and Observer 829 \\ 11.6 Reference Inputs 835 \\ 11.7 Optimal Control Systems 837 \\ 11.8 Internal Model Design 845 \\ 11.9 Design Examples 848 \\ 11.10 State Variable Design Using Control Design Software 855 \\ 11.11 Sequential Design Example: Disk Drive Read System 860 \\ 11.12 Summary 862
}

\section{PREVIEW}

The design of controllers utilizing state feedback is the subject of this chapter. We first present a system test for controllability and observability. Using the powerful notion of state variable feedback, we introduce the pole placement design technique. Ackermann's formula can be used to determine the state variable feedback gain matrix to place the system poles at the desired locations. The closed-loop system pole locations can be arbitrarily placed if and only if the system is controllable. When the full state is not available for feedback, we introduce an observer. The observer design process is described and the applicability of Ackermann's formula is established. The state variable compensator is obtained by connecting the fullstate feedback law to the observer. We consider optimal control system design and then describe the use of internal model design to achieve prescribed steady-state response to selected input commands. The chapter concludes by revisiting the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 11, students should be able to:

$\square \quad$ Describe the concepts of controllability and observability.

$\square \quad$ Design full-state feedback controllers and observers.

$\square$ Explain pole-placement methods and Ackermann's formula.

$\square$ Explain the separation principle and construct state variable compensators.

$\square \quad$ Identify reference inputs, optimal control, and describe internal model design. 

\subsection{INTRODUCTION}

The time-domain method, employing state variables, can be used to design a suitable compensation scheme for a control system. Typically, we are interested in controlling the system with a control signal $\mathbf{u}(t)$ that is a function of several measurable state variables. Then we develop a state variable controller that operates on the information available in measured form. This type of system compensation is quite useful for system optimization and will be considered in this chapter.

State variable design typically comprises three steps. In the first step, we assume that all the state variables are measurable and utilize them in a full-state feedback control law. Full-state feedback is usually not practical because it is not possible (in general) to measure all the states. In practice, only certain states (or linear combinations thereof) are measured and provided as system outputs. The second step in state variable design is to construct an observer to estimate the states that are not directly measured and available as outputs. Observers can either be full-state observers or reduced-order observers. Reduced-order observers account for the fact that certain states are already available as system outputs; hence they do not need to be estimated [26]. In this chapter, we consider only full-state observers. The final step in the design process is to appropriately connect the observer to the full-state feedback control law. It is common to refer to the state-variable controller (full-state control law plus observer) as a compensator. The state variable design yields a compensator of the form depicted in Figure 11.1. Additionally, it is possible to consider non-zero reference inputs to the state variable compensator to complete the design. All three steps in the design process are discussed in the subsequent sections, as well as how to incorporate the reference inputs.

\subsection{CONTROLLABILITY AND OBSERVABILITY}

A key question that arises in the design of state variable compensators is whether or not all the poles of the closed-loop system can be arbitrarily placed in the complex plane. Recall that the poles of the closed-loop system are equivalent to the

FIGURE 11.1

State variable compensator employing full-state feedback in series with a full-state observer.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0814.jpg?height=538&width=1059&top_left_y=1582&top_left_x=503)

eigenvalues of the system matrix in state variable format. As we shall see, if the system is controllable and observable, then we can accomplish the design objective of placing the poles precisely at the desired locations to meet the performance specifications. Full-state feedback design commonly relies on pole-placement techniques $[2,27]$. Pole placement is discussed more fully in Section 11.3. It is important to note that a system must be completely controllable and completely observable to allow the flexibility to place all the closed-loop system poles arbitrarily. The concepts of controllability and observability (discussed in this section) were introduced by Kalman in the 1960s [28-30]. Rudolph Kalman was a central figure in the development of mathematical systems theory upon which much of the subject of state variable methods rests. Kalman is well known for his role in the development of the so-called Kalman filter, which was instrumental in the successful Apollo moon landings [31, 32].

\section{A system is completely controllable if there exists an unconstrained control $u(t)$ that can transfer any initial state $\mathbf{x}\left(t_{0}\right)$ to any other desired location $\mathbf{x}(\mathbf{t})$ in a finite time, $t_{0} \leq t \leq T$.}

For the system

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

we can determine whether the system is controllable by examining the algebraic condition

$$
\operatorname{rank}\left[\begin{array}{lll}
\mathbf{B} & \mathbf{A B} & \mathbf{A}^{2} \mathbf{B} \ldots \mathbf{A}^{n-1} \mathbf{B}
\end{array}\right]=n .
$$

The matrix $\mathbf{A}$ is an $n \times n$ matrix and $\mathbf{B}$ is an $n \times 1$ matrix. For multi-input systems, $\mathbf{B}$ can be $n \times m$, where $m$ is the number of inputs.

For a single-input, single-output system, the controllability matrix $\mathbf{P}_{c}$ is described in terms of $\mathbf{A}$ and $\mathbf{B}$ as

$$
\mathbf{P}_{c}=\left[\begin{array}{lll}
\mathbf{B} & \mathbf{A B} & \mathbf{A}^{2} \mathbf{B} \ldots \mathbf{A}^{n-1} \mathbf{B}
\end{array}\right]
$$

which is an $n \times n$ matrix. Therefore, if the determinant of $\mathbf{P}_{c}$ is nonzero, the system is controllable [11].

Advanced state variable design techniques can handle situations wherein the system is not completely controllable, but where the states (or linear combinations thereof) that cannot be controlled are inherently stable. These systems are classified as stabilizable. If a system is completely controllable, it is also stabilizable. The Kalman state-space decomposition provides a mechanism for partitioning the state-space so that it becomes apparent which states (or state combinations) are controllable and which are not $[12,18]$. The controllable subspace is thus exposed, and if the system is stabilizable, the control system design can, in theory, proceed. In this chapter, we consider only completely controllable systems. 

\section{EXAMPLE 11.1 Controllability of a system}

Let us consider the system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-a_{0} & -a_{1} & -a_{2}
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

The signal-flow graph and block diagram model are illustrated in Figure 11.2. Then we have

$$
\mathbf{A}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-a_{0} & -a_{1} & -a_{2}
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right], \quad \mathbf{A B}=\left[\begin{array}{c}
0 \\
1 \\
-a_{2}
\end{array}\right], \quad \text { and } \mathbf{A}^{2} \mathbf{B}=\left[\begin{array}{c}
1 \\
-a_{2} \\
a_{2}^{2}-a_{1}
\end{array}\right]
$$

Therefore, we obtain

$$
\mathbf{P}_{c}=\left[\begin{array}{lll}
\mathbf{B} & \mathbf{A B} & \mathbf{A}^{2} \mathbf{B}
\end{array}\right]=\left[\begin{array}{ccc}
0 & 0 & 1 \\
0 & 1 & -a_{2} \\
1 & -a_{2} & a_{2}^{2}-a_{1}
\end{array}\right] .
$$

The determinant of $\mathbf{P}_{c}=-1 \neq 0$, hence this system is controllable.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0816.jpg?height=259&width=1096&top_left_y=1310&top_left_x=508)

(a)

FIGURE 11.2

Third-order system.

(a) Signal-flow

graph model.

(b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0816.jpg?height=343&width=1018&top_left_y=1670&top_left_x=554)

(b) 

\section{EXAMPLE 11.2 Controllability of a two-state system}

Let us consider a system represented by the two state equations

$$
\dot{x}_{1}(t)=-2 x_{1}(t)+u(t), \quad \text { and } \quad \dot{x}_{2}(t)=-3 x_{2}(t)+d x_{1}(t)
$$

where $d$ is a constant and determine the condition for controllability. Also, we have $y(t)=x_{2}(t)$, as shown in Figure 11.3. The system state variable model is

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{cc}
-2 & 0 \\
d & -3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t), \\
y(t) & =\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

We can determine the requirement on the parameter $d$ by generating the matrix $\mathrm{P}_{c}$. So, with

$$
\mathbf{B}=\left[\begin{array}{l}
1 \\
0
\end{array}\right] \text { and } \mathbf{A B}=\left[\begin{array}{cc}
-2 & 0 \\
d & -3
\end{array}\right]\left[\begin{array}{l}
1 \\
0
\end{array}\right]=\left[\begin{array}{r}
-2 \\
d
\end{array}\right],
$$

we have

$$
\mathbf{P}_{c}=\left[\begin{array}{cc}
1 & -2 \\
0 & d
\end{array}\right]
$$

The determinant of $\mathbf{P}_{c}$ is equal to $d$, which is nonzero whenever $d$ is nonzero.

All the poles of the closed-loop system can be placed arbitrarily in the complex plane if and only if the system is observable and controllable. Observability refers to the ability to estimate a state variable.

A system is completely observable if and only if there exists a finite time $\boldsymbol{T}$ such that the initial state $\mathbf{x}(0)$ can be determined from the observation history given $\mathbf{y}(\boldsymbol{t})$ the control $\mathbf{u}(\mathbf{t}), \mathbf{0} \leq \boldsymbol{t} \leq \boldsymbol{T}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0817.jpg?height=198&width=1266&top_left_y=1519&top_left_x=350)

FIGURE 11.3

(a) Flow graph model for Example 11.2. (b) Block diagram model. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0817.jpg?height=228&width=987&top_left_y=1829&top_left_x=485)

(b) Consider the single-input, single-output system

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \quad \text { and } \quad y(t)=\mathbf{C x}(t)
$$

where $\mathbf{C}$ is a $1 \times n$ row vector, and $\mathbf{x}$ is an $n \times 1$ column vector. This system is completely observable when the determinant of the observability matrix $\mathbf{P}_{o}$ is nonzero, where

$$
\mathbf{P}_{o}=\left[\begin{array}{c}
\mathbf{C} \\
\mathbf{C A} \\
\vdots \\
\mathbf{C A}^{n-1}
\end{array}\right]
$$

which is an $n \times n$ matrix.

As discussed in this section, advanced state variable design techniques can handle situations wherein the system is not completely controllable, as long as the system is stabilizable. These same techniques can handle cases wherein the system is not completely observable, but where the states (or linear combinations thereof) that cannot be observed are inherently stable. These systems are classified as detectable. If a system is completely observable, it is also detectable. The Kalman state-space decomposition provides a mechanism for partitioning the state-space so that it becomes apparent which states (or state combinations) are observable and which are not $[12,18]$. The unobservable subspace is thus exposed, and if the system is detectable, the control system design can, in theory, proceed. In this chapter, we consider only completely observable systems. The approach to state-variable design involves first verifying that the system under consideration is completely controllable and completely observable. If so, the pole placement design technique considered here can provide acceptable closed-loop system performance.

\section{EXAMPLE 11.3 Observability of a system}

Consider again the system of Example 11.1. The model is shown in Figure 11.2. To construct $\mathbf{P}_{o}$, we use

$$
\mathbf{A}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-a_{0} & -a_{1} & -a_{2}
\end{array}\right] \text { and } \mathbf{C}=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right]
$$

Therefore,

$$
\mathbf{C A}=\left[\begin{array}{lll}
0 & 1 & 0
\end{array}\right] \text { and } \quad \mathbf{C A}^{2}=\left[\begin{array}{lll}
0 & 0 & 1
\end{array}\right]
$$

Thus, we obtain

$$
\mathbf{P}_{o}=\left[\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right]
$$

The det $\mathbf{P}_{o}=1$, and the system is completely observable. 

\section{EXAMPLE 11.4 Observability of a two-state system}

Consider the system given by

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
2 & 0 \\
-1 & 1
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
1 \\
-1
\end{array}\right] u(t) \text { and } y(t)=\left[\begin{array}{ll}
1 & 1
\end{array}\right] \mathbf{x}(t) .
$$

The system is illustrated in Figure 11.4. We can check the system controllability and observability using the $\mathbf{P}_{c}$ and $\mathbf{P}_{o}$ matrices.

From the system definition, we obtain

$$
\mathbf{B}=\left[\begin{array}{c}
1 \\
-1
\end{array}\right] \text { and } \mathbf{A B}=\left[\begin{array}{c}
2 \\
-2
\end{array}\right]
$$

Therefore, the controllability matrix is determined to be

$$
\mathbf{P}_{c}=\left[\begin{array}{cc}
\mathbf{B} & \mathbf{A B}
\end{array}\right]=\left[\begin{array}{cc}
1 & 2 \\
-1 & -2
\end{array}\right],
$$

and det $\mathbf{P}_{c}=0$. Thus, the system is not controllable.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0819.jpg?height=377&width=1118&top_left_y=1011&top_left_x=410)

(a)

FIGURE 11.4

Two state system model for Example 11.4. (a) Signal-flow graph model.

(b) Block diagram model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0819.jpg?height=548&width=738&top_left_y=1502&top_left_x=600)

(b) From the system definition, we have

$$
\mathbf{C}=\left[\begin{array}{ll}
1 & 1
\end{array}\right] \text { and } \mathbf{C A}=\left[\begin{array}{ll}
1 & 1
\end{array}\right] .
$$

Therefore, computing the observability matrix yields

$$
\mathbf{P}_{o}=\left[\begin{array}{c}
\mathbf{C} \\
\mathbf{C A}
\end{array}\right]=\left[\begin{array}{ll}
1 & 1 \\
1 & 1
\end{array}\right],
$$

and det $\mathbf{P}_{o}=0$. Hence, the system is not observable.

If we look again at the state model, we note that

$$
y(t)=x_{1}(t)+x_{2}(t) .
$$

However,

$$
\dot{x}_{1}(t)+\dot{x}_{2}(t)=2 x_{1}(t)+\left(x_{2}(t)-x_{1}(t)\right)+u(t)-u(t)=x_{1}(t)+x_{2}(t) .
$$

Thus, the system state variables do not depend on $u$, and the system is not controllable. Similarly, the output $x_{1}(t)+x_{2}(t)$ depends on $x_{1}(0)$ plus $x_{2}(0)$ and does not allow us to determine $x_{1}(0)$ and $x_{2}(0)$ independently. Consequently, the system is not observable.

\subsection{FULL-STATE FEEDBACK CONTROL DESIGN}

In this section, we consider full-state variable feedback to achieve the desired pole locations of the closed-loop system. The first step in the state variable design process requires us to assume that all the states are available for feedback - that is, we have access to the complete state $\mathbf{x}(t)$ for all $t$. Suppose the system input $u(t)$ is given by

$$
u(t)=-\mathbf{K x}(t) .
$$

Determining the gain matrix $\mathbf{K}$ is the objective of the full-state feedback design procedure. The beauty of the state variable design process is that the problem naturally separates into a full-state feedback component and an observer design component. These two design procedures can occur independently, and in fact, the separation principle provides the proof that this approach is optimal. We will show later that the stability of the closed-loop system is guaranteed if the full-state feedback control law stabilizes the system (under the assumption of access to the complete state) and the observer is stable (the tracking error is asymptotically stable). Observers are discussed in Section 11.4. The full-state feedback block diagram is illustrated in Figure 11.5. With the system defined by the state variable model

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

and the control feedback given by

$$
u(t)=-\mathbf{K x}(t),
$$

FIGURE 11.5

Full-state feedback block diagram (with no reference input).

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0821.jpg?height=405&width=533&top_left_y=162&top_left_x=373)

we find the closed-loop system to be

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)=\mathbf{A} \mathbf{x}(t)-\mathbf{B K} \mathbf{x}(t)=(\mathbf{A}-\mathbf{B K}) \mathbf{x}(t) .
$$

The characteristic equation associated with Equation (11.5) is

$$
\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=0 .
$$

If all the roots of the characteristic equation lie in the left half-plane, then the closedloop system is stable. In other words, for any initial condition $\mathbf{x}\left(t_{0}\right)$, it follows that

$$
\mathbf{x}(t)=e^{(\mathbf{A}-\mathbf{B K}) t} \mathbf{x}\left(t_{0}\right) \rightarrow 0 \quad \text { as } t \rightarrow \infty .
$$

Given the pair (A, B), we can always determine $\mathbf{K}$ to place all the system closed-loop poles in the left half-plane if and only if the system is completely controllable-that is, if and only if the controllability matrix $\mathbf{P}_{c}$ is full rank (for a single-input, singleoutput system, full rank implies that $\mathbf{P}_{c}$ is invertible).

The addition of a reference input can be written as

$$
u(t)=-\mathbf{K x}(t)+N r(t)
$$

where $r(t)$ is the reference input. The question of reference inputs is addressed in Section 11.6. When $r(t)=0$ for all $t>t_{0}$, the control design problem is known as the regulator problem. That is, we want to compute $\mathbf{K}$ so that all initial conditions are driven to zero in a specified fashion (as determined by the design specifications).

When using this state variable feedback, the roots of the characteristic equation are placed where the transient performance meets the desired response.

\section{EXAMPLE 11.5 Design of a third-order system}

Let us consider the third-order system with the differential equation

$$
\frac{d^{3} y(t)}{d t^{3}}+5 \frac{d^{2} y(t)}{d t^{2}}+3 \frac{d y(t)}{d t}+2 y(t)=u(t) .
$$

We can select the state variables as the phase variables so that $x_{1}(t)=y(t)$, $x_{2}(t)=d y(t) / d t, x_{3}(t)=d^{2} y(t) / d t^{2}$, and then

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-2 & -3 & -5
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] u(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

and

$$
y(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
$$

If the state variable feedback matrix is

$$
\mathbf{K}=\left[\begin{array}{lll}
k_{1} & k_{2} & k_{3}
\end{array}\right]
$$

and

$$
u(t)=-\mathbf{K x}(t)
$$

then the closed-loop system is

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)-\mathbf{B K} \mathbf{x}(t)=(\mathbf{A}-\mathbf{B K}) \mathbf{x}(t) .
$$

The state feedback matrix is

$$
\mathbf{A}-\mathbf{B K}=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
-2-k_{1} & -3-k_{2} & -5-k_{3}
\end{array}\right]
$$

and the characteristic equation is

$$
\Delta(\lambda)=\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=\lambda^{3}+\left(5+k_{3}\right) \lambda^{2}+\left(3+k_{2}\right) \lambda+\left(2+k_{1}\right)=0 .
$$

If we seek a rapid response with a low overshoot, we choose a desired characteristic equation such as

$$
\Delta(\lambda)=\left(\lambda^{2}+2 \zeta \omega_{n} \lambda+\omega_{n}^{2}\right)\left(\lambda+\zeta \omega_{n}\right) .
$$

We choose $\zeta=0.8$ for minimal overshoot and $\omega_{n}$ to meet the settling time requirement. If we want a settling time (with a $2 \%$ criterion) equal to 1 second, then

$$
T_{s}=\frac{4}{\zeta \omega_{n}}=\frac{4}{(0.8) \omega_{n}} \approx 1 .
$$

If we choose $\omega_{n}=6$, the desired characteristic equation is

$$
\left(\lambda^{2}+9.6 \lambda+36\right)(\lambda+4.8)=\lambda^{3}+14.4 \lambda^{2}+82.1 \lambda+172.8 .
$$

Comparing Equations (11.6) and (11.7) yields the three equations

$$
\begin{aligned}
& 5+k_{3}=14.4 \\
& 3+k_{2}=82.1 \\
& 2+k_{1}=172.8
\end{aligned}
$$

Therefore, we require that $k_{3}=9.4, k_{2}=79.1$, and $k_{1}=170.8$. The step response has no overshoot and a settling time of 1 second, as desired.

\section{EXAMPLE 11.6 Inverted pendulum control}

Consider the control of an unstable inverted pendulum balanced on a moving cart. We measure and utilize the state variables of the system in order to control the pendulum. Thus, if we want to measure the angle from vertical, $\theta(t)$, we could use a potentiometer connected to the shaft of the pendulum hinge. Similarly, we could measure the rate of change of the angle $\dot{\theta}(t)$ by using a tachometer generator. If the state variables are all measured, then they can be used in a feedback controller so that $u(t)=-\mathbf{K} \mathbf{x}(t)$, where $\mathbf{K}$ is the feedback matrix. The state vector $\mathbf{x}(t)$ represents the state of the system; therefore, knowledge of $\mathrm{x}(t)$ and the equations describing the system dynamics provide sufficient information for control and stabilization of a system $[4,5,7]$.

To illustrate the use of state variable feedback, consider the unstable inverted pendulum and design a suitable state variable feedback control system. If we assume that the control input, $u(t)$, is an acceleration signal, we can focus on the unstable dynamics of the pendulum. The equation of motion describing the angle, $\dot{\theta}(t)$, from the vertical, is

$$
\ddot{\theta}(t)=\frac{g}{l} \theta(t)-\frac{1}{l} u(t)
$$

Let the state vector be $\left(x_{1}(t), x_{2}(t)\right)=(\theta(t), \dot{\theta}(t))$. The state vector differential equation is

$$
\frac{d}{d t}\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)=\left[\begin{array}{cc}
0 & 1 \\
g / l & 0
\end{array}\right]\left(\begin{array}{l}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)+\left[\begin{array}{c}
0 \\
-1 / l
\end{array}\right] u(t)
$$

The A matrix of Equation (11.8) has the characteristic equation $\lambda^{2}-g / l=0$ with one root in the right-hand $s$-plane. To stabilize the system, we generate a control signal that is a function of the two state variables, $x_{1}(t)$ and $x_{2}(t)$. Then we have

$$
u(t)=-\mathbf{K x}(t)=-\left[\begin{array}{ll}
k_{1} & k_{2}
\end{array}\right]\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)=-k_{1} x_{1}(t)-k_{2} x_{2}(t) .
$$

Substituting this control signal relationship into Equation (11.8), we have

$$
\left(\begin{array}{c}
\dot{x}_{1}(t) \\
\dot{x}_{2}(t)
\end{array}\right)=\left[\begin{array}{cc}
0 & 1 \\
g / l & 0
\end{array}\right]\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)+\left[\begin{array}{c}
0 \\
(1 / l)\left(k_{1} x_{1}+k_{2} x_{2}\right)
\end{array}\right] .
$$

Combining the two additive terms on the right side of the equation, we find that

$$
\left(\begin{array}{c}
\dot{x}_{1}(t) \\
\dot{x}_{2}(t)
\end{array}\right)=\left[\begin{array}{cc}
0 & 1 \\
\left(g+k_{1}\right) / l & k_{2} / l
\end{array}\right]\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t)
\end{array}\right) .
$$

Obtaining the characteristic equation, we have

$$
\begin{aligned}
{\left[\begin{array}{cc}
\lambda & -1 \\
-\left(g+k_{1}\right) / l & \lambda-k_{2} / l
\end{array}\right] } & =\lambda\left(\lambda-\frac{k_{2}}{l}\right)-\frac{g+k_{1}}{l} \\
& =\lambda^{2}-\left(\frac{k_{2}}{l}\right) \lambda+\frac{g+k_{1}}{l} .
\end{aligned}
$$

Thus, for the system to be stable, we require that $k_{2} / l<0$ and $k_{1}>-g$. Hence, we have stabilized an unstable system by measuring the state variables $x_{1}$ and $x_{2}$ and using the control function $u(t)=-\mathbf{K} \mathbf{x}(t)$ to obtain a stable system. If we wish to achieve a rapid response with modest overshoot, we select $\omega_{n}=10$ and $\zeta=0.8$. Then we require

$$
\frac{k_{2}}{l}=-16 \text { and } \frac{k_{1}+g}{l}=100 .
$$

The step response would have a percent overshoot of $P . O .=1.5 \%$ and a settling time of $T_{s}=0.5 \mathrm{~s}$.

Thus far, we have established an approach for the design of a feedback control system by using the state variables as the feedback variables in order to increase the stability of the system and obtain the desired system response. Now we face the task of computing the gain matrix $\mathbf{K}$ to place the poles at desired locations. For a single-input, single-output system, Ackermann's formula is useful for determining the state variable feedback matrix

$$
\mathbf{K}=\left[\begin{array}{lll}
k_{1} & k_{2} & \ldots \\
k_{n}
\end{array}\right],
$$

where

$$
u(t)=-\mathbf{K x}(t)
$$

Given the desired characteristic equation

$$
q(\lambda)=\lambda^{n}+\alpha_{n-1} \lambda^{n-1}+\cdots+\alpha_{o},
$$

the state feedback gain matrix is

$$
\mathbf{K}=\left[\begin{array}{lllll}
0 & 0 & \ldots 0 & 1
\end{array}\right] \mathbf{P}_{c}^{-1} q(\mathbf{A}),
$$

where

$$
q(\mathbf{A})=\mathbf{A}^{n}+\alpha_{n-1} \mathbf{A}^{n-1}+\cdots \alpha_{1} \mathbf{A}+\alpha_{0} \mathbf{I},
$$

and $\mathbf{P}_{c}$ is the controllability matrix of Equation (11.2).

\section{EXAMPLE 11.7 Second-order system}

Consider the system

$$
\frac{Y(s)}{U(s)}=G(s)=\frac{1}{s^{2}}
$$

and determine the feedback gain to place the closed-loop poles at $s=-1 \pm j$. Therefore, we require that

$$
q(\lambda)=\lambda^{2}+2 \lambda+2
$$

and $\alpha_{1}=\alpha_{2}=2$. With $x_{1}(t)=y(t)$ and $x_{2}(t)=\dot{y}(t)$, the matrix equation for the system $G(s)$ is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) .
$$

The controllability matrix is

$$
\mathbf{P}_{c}=\left[\begin{array}{ll}
\mathbf{B} & \mathbf{A B}
\end{array}\right]=\left[\begin{array}{ll}
0 & 1 \\
1 & 0
\end{array}\right] .
$$

Thus, we obtain

$$
\mathbf{K}=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{P}_{c}^{-1} q(\mathbf{A}),
$$

where

$$
\mathbf{P}_{c}^{-1}=\frac{1}{-1}\left[\begin{array}{cc}
0 & -1 \\
-1 & 0
\end{array}\right]=\left[\begin{array}{ll}
0 & 1 \\
1 & 0
\end{array}\right]
$$

and

$$
q(\mathbf{A})=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right]^{2}+2\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right]+2\left[\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right]=\left[\begin{array}{ll}
2 & 2 \\
0 & 2
\end{array}\right]
$$

Then we have

$$
\mathbf{K}=\left[\begin{array}{ll}
0 & 1
\end{array}\right]\left[\begin{array}{ll}
0 & 1 \\
1 & 0
\end{array}\right]\left[\begin{array}{ll}
2 & 2 \\
0 & 2
\end{array}\right]=\left[\begin{array}{ll}
0 & 1
\end{array}\right]\left[\begin{array}{ll}
0 & 2 \\
2 & 2
\end{array}\right]=\left[\begin{array}{ll}
2 & 2
\end{array}\right]
$$

Note that computing the gain matrix K using Ackermann's formula requires the use of $\mathbf{P}_{c}^{-1}$. We see that complete controllability is essential because only then can we guarantee that the controllability matrix $\mathbf{P}_{c}$ has full rank and hence that $\mathbf{P}_{c}^{-1}$ exists. 

\subsection{OBSERVER DESIGN}

In the full-state feedback design procedure discussed in Section 11.3, it was assumed that all the states were available for feedback at all times. This is a good assumption for the control law design process. Only a subset of the states are typically measurable and available for feedback. Having all the states available for feedback implies that these states are measured with a sensor or sensor combinations. The cost and complexity of the control system increases as the number of required sensors increases. So, even in situations where extra sensors are available, it may not be cost effective to employ these extra sensors, if indeed, the control system design goals can be accomplished without them. Fortunately, if the system is completely observable with a given set of outputs, then it is possible to determine (or to estimate) the states that are not directly measured (or observed).

According to Luenberger [26], the full-state observer for the system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

is given by

$$
\dot{\hat{\mathbf{x}}}(t)=\mathbf{A} \hat{\mathbf{x}}(t)+\mathbf{B} u(t)+\mathbf{L}(y(t)-\mathbf{C} \hat{\mathbf{x}}(t))
$$

where $\hat{\mathbf{x}}(t)$ denotes the estimate of the state $\mathbf{x}(t)$. The matrix $\mathbf{L}$ is the observer gain matrix and is to be determined as part of the observer design procedure. The observer is depicted in Figure 11.6. The observer has two inputs, $u(\mathrm{t})$ and $y(\mathrm{t})$, and one output, $\hat{\mathbf{x}}(t)$.

The goal of the observer is to provide an estimate $\hat{\mathbf{x}}(t)$ so that $\hat{\mathbf{x}}(t) \rightarrow \mathbf{x}(t)$ as $t \rightarrow \infty$. Remember that we do not know $\mathbf{x}\left(t_{0}\right)$ precisely; therefore we must provide an initial estimate $\hat{\mathbf{x}}\left(t_{0}\right)$ to the observer. Define the observer estimation error as

$$
\mathbf{e}(t)=\mathbf{x}(t)-\hat{\mathbf{x}}(t)
$$

The observer design should produce an observer with the property that $\mathbf{e}(t) \rightarrow 0$ as $t \rightarrow \infty$. One of the main results of systems theory is that if the system is completely observable, we can always find $\mathbf{L}$ so that the tracking error is asymptotically stable, as desired.

Taking the time-derivative of the estimation error in Equation (11.12) yields

$$
\dot{\mathbf{e}}(t)=\dot{\mathbf{x}}(t)-\dot{\hat{\mathbf{x}}}(t)
$$

FIGURE 11.6

The full-state observer.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0826.jpg?height=348&width=781&top_left_y=1764&top_left_x=517)

and using the system model and the observer in Equation (11.11), we obtain

$$
\dot{\mathbf{e}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)-\mathbf{A} \hat{\mathbf{x}}(t)-\mathbf{B} u(t)-\mathbf{L}(y(t)-\mathbf{C} \hat{\mathbf{x}}(t))
$$

or

$$
\dot{\mathbf{e}}(t)=(\mathbf{A}-\mathbf{L C}) \mathbf{e}(t) .
$$

We can guarantee that $\mathbf{e}(t) \rightarrow 0$ as $t \rightarrow \infty$ for any initial tracking error $\mathbf{e}\left(t_{0}\right)$ if the characteristic equation

$$
\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L C}))=0
$$

has all its roots in the left half-plane. Therefore, the observer design process reduces to finding the matrix $\mathbf{L}$ such that the roots of the characteristic equation in Equation (11.14) lie in the left half-plane. This can always be accomplished if the system is completely observable; that is, if the observability matrix $\mathbf{P}_{o}$ has full rank (for a single-input, single-output system, full rank implies that $\mathbf{P}_{o}$ is invertible).

\section{EXAMPLE 11.8 Second-order system observer design}

Consider the second-order system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
2 & 3 \\
-1 & 4
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

In this example, we can only directly observe the state $y(t)=x_{1}(t)$. The observer will provide estimates of the second state $x_{2}(t)$.

We only consider full-state observers, which implies that the observer will provide estimates of all the states. We might be inclined to suppose that since some states are directly measured, it may be possible to design an observer that provides just the estimates of the states not directly measured. This is, in fact, possible, and the resulting observers are known as reduced-order observers [12, 18]. However, since sensors are not noise free, even states that are directly measured are generally estimated in an effort to reduce the effect of sensor noise on the state estimate. The Kalman filter (which is a time-varying optimal observer) solves the observer problem in the presence of measurement noise (and process noise as well) [33, 34].

The observer design begins by checking the system observability to verify that an observer can be constructed to guarantee the stability of the estimation error. From the system model, we find that

$$
\mathbf{A}=\left[\begin{array}{cc}
2 & 3 \\
-1 & 4
\end{array}\right] \text { and } \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right]
$$

The corresponding observability matrix is

$$
\mathbf{P}_{o}=\left[\begin{array}{c}
\mathbf{C} \\
\mathbf{C A}
\end{array}\right]=\left[\begin{array}{ll}
1 & 0 \\
2 & 3
\end{array}\right] \text {. }
$$

FIGURE 11.7

Second-order observer response to initial estimation errors.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0828.jpg?height=722&width=892&top_left_y=156&top_left_x=523)

Since det $\mathbf{P}_{o}=3 \neq 0$, the system is completely observable. Suppose that the desired characteristic equation is given by

$$
\Delta_{d}(\lambda)=\lambda^{2}+2 \zeta \omega_{n} \lambda+\omega_{n}^{2} .
$$

We can select $\zeta=0.8$ and $\omega_{n}=10$, resulting in an expected settling time of less than 0.5 second. Computing the actual characteristic equation yields

$$
\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L} \mathbf{C}))=\lambda^{2}+\left(L_{1}-6\right) \lambda-4\left(L_{1}-2\right)+3\left(L_{2}+1\right),
$$

where $\mathbf{L}=\left[\begin{array}{ll}L_{1} & L_{2}\end{array}\right]^{T}$. Equating the coefficients in Equation (11.15) to those in Equation (11.16) yields the two equations

$$
\begin{aligned}
L_{1}-6 & =16 \\
-4\left(L_{1}-2\right)+3\left(L_{2}+1\right) & =100
\end{aligned}
$$

which, when solved, produces

$$
\mathbf{L}=\left[\begin{array}{l}
L_{1} \\
L_{2}
\end{array}\right]=\left[\begin{array}{l}
22 \\
59
\end{array}\right]
$$

The observer is thus given by

$$
\dot{\hat{\mathbf{x}}}(t)=\left[\begin{array}{cc}
2 & 3 \\
-1 & 4
\end{array}\right] \hat{\mathbf{x}}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t)+\left[\begin{array}{c}
22 \\
59
\end{array}\right]\left(y(t)-\hat{x}_{1}(t)\right) .
$$

The response of the estimation error to an initial error of

$$
\mathbf{e}\left(t_{0}\right)=\left[\begin{array}{c}
1 \\
-2
\end{array}\right]
$$

is shown in Figure 11.7. Ackermann's formula can also be employed to place the roots of the observer characteristic equation at the desired locations. Consider the observer gain matrix

$$
\mathbf{L}=\left[\begin{array}{llll}
L_{1} & L_{2} & \cdots & L_{n}
\end{array}\right]^{T}
$$

and the desired observer characteristic equation

$$
p(\lambda)=\lambda^{n}+\beta_{n-1} \lambda^{n-1}+\cdots+\beta_{1} \lambda+\beta_{0} .
$$

The $\beta^{\prime}$ s are selected to meet given performance specifications for the observer. The observer gain matrix is then computed via

$$
\mathbf{L}=p(\mathbf{A}) \mathbf{P}_{o}^{-1}\left[\begin{array}{lll}
0 & \cdots 0 & 1
\end{array}\right]^{T}
$$

where $\mathbf{P}_{O}$ is the observability matrix given in Equation (11.3) and

$$
p(\mathbf{A})=\mathbf{A}^{n}+\beta_{n-1} \mathbf{A}^{n-1}+\cdots+\beta_{1} \mathbf{A}+\beta_{0} \mathbf{I}
$$

\section{EXAMPLE 11.9 Second-order system observer design using Ackermann's formula}

Consider the second-order system in Example 11.8. The desired characteristic equation was given as

$$
p(\lambda)=\lambda^{2}+2 \zeta \omega_{n} \lambda+\omega_{n}^{2}
$$

where $\zeta=0.8$ and $\omega_{n}=10$; hence, $\beta_{1}=16$ and $\beta_{2}=100$. Computing $p(\mathbf{A})$ yields

$$
p(\mathbf{A})=\left[\begin{array}{cc}
2 & 3 \\
-1 & 4
\end{array}\right]+16\left[\begin{array}{cc}
2 & 3 \\
-1 & 4
\end{array}\right]+100\left[\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right]=\left[\begin{array}{cc}
133 & 66 \\
-22 & 177
\end{array}\right]
$$

and from Example 11.8, we have the observability matrix

$$
\mathbf{P}_{o}=\left[\begin{array}{ll}
1 & 0 \\
2 & 3
\end{array}\right]
$$

which implies that

$$
\mathbf{P}_{o}^{-1}=\left[\begin{array}{cc}
1 & 0 \\
-2 / 3 & 1 / 3
\end{array}\right]
$$

Using Ackermann's formula in Equation (11.17) yields the observer gain matrix

$$
\mathbf{L}=p(\mathbf{A}) \mathbf{P}_{o}{ }^{-1}\left[\begin{array}{llll}
0 & \cdots & 0 & 1
\end{array}\right]^{T}=\left[\begin{array}{cc}
133 & 66 \\
-22 & 177
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 \\
-2 / 3 & 1 / 3
\end{array}\right]\left[\begin{array}{l}
0 \\
1
\end{array}\right]=\left[\begin{array}{l}
22 \\
59
\end{array}\right]
$$

This is the identical result obtained in Example 11.8 using other methods. 

\subsection{INTEGRATED FULL-STATE FEEDBACK AND OBSERVER}

The state variable compensator is constructed by appropriately connecting the fullstate feedback control law (see Section 11.3) to the observer (see Section 11.4). The compensator is shown in Figure 11.1 (as discussed in Section 11.1). Our strategy was to design the state feedback control law as $u(t)=-\mathbf{K} \mathbf{x}(t)$, where we assumed that we had access to the complete state $\mathbf{x}(t)$. Then we designed an observer to provide an estimate of the state $\hat{\mathbf{x}}(t)$. It seems reasonable that we can employ the state estimate in the feedback control law in place of $\mathbf{x}(t)$. In other words, we can consider the feedback law

$$
u(t)=-\mathbf{K} \hat{\mathbf{x}}(t) .
$$

But is this a good strategy? The feedback gain matrix $\mathbf{K}$ was designed to guarantee stability of the closed-loop system; that is, the roots of the characteristic equation

$$
\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=0
$$

are in the left half-plane. Under the assumption that the complete state $\mathbf{x}(t)$ is available for feedback, the feedback control law (with properly designed gain matrix $\mathbf{K}$ ) leads to the desired result that $\mathbf{x}(t) \rightarrow 0$ as $t \rightarrow \infty$ for any initial condition $\mathbf{x}\left(t_{0}\right)$. We need to verify that, when using the feedback control law in Equation (11.18), we retain the stability of the closed-loop system.

Consider the observer (from Section 11.4)

$$
\dot{\hat{\mathbf{x}}}(t)=\mathbf{A} \hat{\mathbf{x}}(t)+\mathbf{B} u(t)+\mathbf{L}(y(t)-\mathbf{C} \hat{\mathbf{x}}(t)) .
$$

Substituting the feedback law in Equation (11.18) and rearranging terms in the observer yields the compensator system

$$
\begin{aligned}
\dot{\hat{\mathbf{x}}}(t) & =(\mathbf{A}-\mathbf{B K}-\mathbf{L C}) \hat{\mathbf{x}}(t)+\mathbf{L} y(t) \\
u(t) & =-\mathbf{K} \hat{\mathbf{x}}(t) .
\end{aligned}
$$

Notice that the system in Equation (11.19) has the form of a state variable model with input $y(t)$ and output $u(t)$, as illustrated in Figure 11.8.

FIGURE 11.8

State variable compensator with integrated full-state feedback and observer.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0830.jpg?height=392&width=1227&top_left_y=1728&top_left_x=504)

Computing the estimation error using the compensator in Equation (11.19) yields

$$
\dot{\mathbf{e}}(t)=\dot{\mathbf{x}}(t)-\dot{\hat{\mathbf{x}}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)-\mathbf{A} \hat{\mathbf{x}}(t)-\mathbf{B} u(t)-\mathbf{L} y(t)+\mathbf{L C} \hat{\mathbf{x}}(t),
$$

or

$$
\dot{\mathbf{e}}(t)=(\mathbf{A}-\mathbf{L C}) \mathbf{e}(t) .
$$

This is the same result as we obtained for the estimation error in Section 11.4. The estimation error does not depend on the input as seen in Equation (11.20), where the input terms cancel. Recall that the underlying system model is given by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t) .
\end{aligned}
$$

Substituting the feedback law $u(t)=-\mathbf{K} \hat{\mathbf{x}}(t)$ into the system model yields

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)=\mathbf{A x}(t)-\mathbf{B K} \hat{\mathbf{x}}(t),
$$

and with $\hat{\mathbf{x}}(t)=\mathbf{x}(t)-\mathbf{e}(t)$, we obtain

$$
\dot{\mathbf{x}}(t)=(\mathbf{A}-\mathbf{B K}) \mathbf{x}(t)+\mathbf{B K e}(t) .
$$

Writing Equations (11.20) and (11.21) in matrix form, we have

$$
\left(\begin{array}{c}
\dot{\boldsymbol{x}}(t) \\
\dot{\mathbf{e}}(t)
\end{array}\right)=\left[\begin{array}{cc}
\mathbf{A}-\mathbf{B K} & \mathbf{B K} \\
\mathbf{0} & \mathbf{A}-\mathbf{L C}
\end{array}\right]\left(\begin{array}{c}
\mathbf{x}(t) \\
\mathbf{e}(t)
\end{array}\right) .
$$

Recall that our goal is to verify that, with $u(t)=-\mathbf{K} \hat{\mathbf{x}}(t)$, we retain stability of the closed-loop system and the observer. The characteristic equation associated with Equation (11.22) is

$$
\Delta(\lambda)=\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K})) \operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L C})) .
$$

So if the roots of $\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=0$ lie in the left half-plane (which they do by design of the full-state feedback law), and if the roots of $\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L C}))=0$ lie in the left half-plane (which they do by design of the observer), then the overall system is stable. Therefore, employing the strategy of using the state estimates for the feedback is in fact a good strategy.

In other words, when we use $u(t)=-\mathbf{K} \hat{\mathbf{x}}(t)$ where $\mathbf{K}$ is designed using the methods proposed in Section 11.3 and $\hat{\mathbf{x}}(t)$ is derived from the observer discussed in Section 11.4, then $\mathbf{x}(t) \rightarrow 0$ as $t \rightarrow \infty$ for any initial condition $\mathbf{x}\left(t_{0}\right)$ and $\mathbf{e}(t) \rightarrow 0$ as $t \rightarrow \infty$ for any initial estimation error $\mathbf{e}\left(t_{0}\right)$. The fact that the full-state feedback law and the observer can be designed independently is an illustration of the separation principle.

The design procedure is summarized as follows:

1. Determine $\mathbf{K}$ such that $\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=0$ has roots in the left half-plane and place the poles appropriately to meet the control system design specifications. The ability to place the poles arbitrarily in the complex plane is guaranteed if the system is completely controllable. 2. Determine $\mathbf{L}$ such that $\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L C}))=0$ has roots in the left half-plane and place the poles to achieve acceptable observer performance. The ability to place the observer poles arbitrarily in the complex plane is guaranteed if the system is completely observable.

3. Connect the observer to the full-state feedback law using

$$
u(t)=-\mathbf{K} \hat{\mathbf{x}}(t) .
$$

Compensator Transfer Function. The compensator given in Equation (11.19) can be given equivalently in transfer function form with input $Y(s)$ and output $U(s)$. Taking the Laplace transform (with zero initial conditions) of the compensator yields

$$
\begin{aligned}
s \hat{\mathbf{X}}(s) & =(\mathbf{A}-\mathbf{B K}-\mathbf{L C}) \hat{\mathbf{X}}(s)+\mathbf{L} Y(s) \\
U(s) & =-\mathbf{K} \hat{\mathbf{X}}(s),
\end{aligned}
$$

and rearranging and solving for $U(s)$, we obtain the transfer function

$$
U(s)=\left[-\mathbf{K}(s \mathbf{I}-(\mathbf{A}-\mathbf{B K}-\mathbf{L C}))^{-1} \mathbf{L}\right] Y(s)
$$

Note that the compensator transfer function itself (when viewed as a system) may or may not be stable. Even though $\mathbf{A}-\mathbf{B K}$ is stable and $\mathbf{A}-\mathbf{L C}$ is stable, it does not necessarily follow that $\mathbf{A}-\mathbf{B K}-\mathbf{L C}$ is stable. However, the overall closedloop system is stable (as we proved in the previous discussions). The controller in Equation (11.23) is commonly referred to as a stabilizing controller.

\section{EXAMPLE 11.10 Compensator design for the inverted pendulum}

The state variable model representing the inverted pendulum atop a moving cart is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cccc}
0 & 1 & 0 & 0 \\
0 & 0 & \frac{-m g}{M} & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & \frac{g}{l} & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
\frac{1}{M} \\
0 \\
\frac{-1}{M l}
\end{array}\right] u(t),
$$

where $\mathbf{x}(t)=\left(x_{1}(t), x_{2}(t), x_{3}(t), x_{4}(t)\right)^{T}, x_{1}(t)$ is the cart position, $x_{2}(t)$ is the cart velocity, $x_{3}(t)$ is the pendulum angular position (measured from the vertical), $x_{4}(t)$ is the pendulum angular rate, and $u(t)$ is the input applied to the cart. Typically, we can measure the state variable $x_{3}(t)=\theta$ using a potentiometer attached to the shaft, or measure $x_{4}(t)=\dot{\theta}(t)$ using a tachometer generator. However, suppose that we have a sensor available to measure the position of the cart. Is it possible to hold the angular position of the pendulum at the desired value $\left(\theta(t)=0^{\circ}\right)$ when only the output $y(t)=x_{1}(t)$ (the cart position) is available? In this case, we have the output equation

$$
y(t)=\left[\begin{array}{llll}
1 & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)
$$

Let the system parameters be $l=0.098 \mathrm{~m}, g=9.8 \mathrm{~m} / \mathrm{s}^{2}, m=0.825 \mathrm{~kg}$ and $M=8.085 \mathrm{~kg}$. Therefore, using the parameter values, the system state and input matrices are

$$
\mathbf{A}=\left[\begin{array}{cccc}
0 & 1 & 0 & 0 \\
0 & 0 & -1 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 100 & 0
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{c}
0 \\
0.1237 \\
0 \\
-1.2621
\end{array}\right]
$$

Checking controllability yields the controllability matrix

$$
\mathbf{P}_{c}=\left[\begin{array}{cccc}
0 & 0.1237 & 0 & 1.2621 \\
0.1237 & 0 & 1.2621 & 0 \\
0 & -1.2621 & 0 & -126.21 \\
-1.2621 & 0 & -126.21 & 0
\end{array}\right]
$$

Computing det $\mathbf{P}_{c}=196.49 \neq 0$; hence, the system is completely controllable. Likewise, computing the observability matrix yields

$$
\mathbf{P}_{o}=\left[\begin{array}{cccc}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & -1 & 0 \\
0 & 0 & 0 & -1
\end{array}\right]
$$

and det $\mathbf{P}_{o}=1 \neq 0$; hence, the system is completely observable. We can now proceed with the three-step design procedure knowing that we can determine a control gain matrix $\mathbf{K}$ and observer gain matrix $\mathbf{L}$ to place all the closed-loop system poles at desired locations.

\section{STEP 1: Design the Full-State Feedback Control Law}

The open-loop system poles are located at $\lambda=0,0,-10$, and 10 , hence the openloop system is unstable (there is a pole in the right half-plane). Suppose that the desired closed-loop system characteristic equation is given by

$$
q(\lambda)=\left(\lambda^{2}+2 \zeta \omega_{n} \lambda+\omega_{n}^{2}\right)\left(\lambda^{2}+a \lambda+b\right)
$$

where we choose (1) the pair $\left(\zeta, \omega_{n}\right)$ so that these poles are the dominant poles, and (2) the pair $(a, b)$ farther in the left half-plane so as not to dominate the response. To obtain a settling time less than 10 seconds with low overshoot, we can select $\left(\zeta, \omega_{n}\right)=(0.8,0.5)$. Then, we choose a separation factor of 20 between the dominant poles and the remaining poles, from which it follows that $(a, b)=(16,100)$. Figure 11.9 shows the pole zero map for the system design. The separation factor between the dominant and nondominant poles is a FIGURE 11.9

System pole map: open-loop poles, desired closed-loop poles, and observer poles.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0834.jpg?height=727&width=911&top_left_y=154&top_left_x=523)

parameter that can be varied as part of the design process. The larger the separation selected, the further left in the left half-plane the nondominant poles will be placed, and hence the larger the required control law gains. The desired roots are then specified to be

$$
\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{B K}))=(\lambda+8 \pm j 6)(\lambda+0.4 \pm j 0.3) .
$$

The poles at $\lambda=-0.4 \pm 0.3 j$ are the dominant poles. Using Ackermann's formula yields the feedback gain matrix

$$
\mathbf{K}=\left[\begin{array}{llll}
-2.2509 & -7.5631 & -169.0265 & -14.0523
\end{array}\right] .
$$

\section{STEP 2: Observer Design}

The observer needs to provide an estimate of the states that cannot be directly observed. The goal is to achieve an accurate estimate as fast as possible without resulting in too large a gain matrix $\mathbf{L}$. How large is too large depends on the problem under consideration. In particular, if there are significant levels of measurement noise (this is sensor dependent), then the magnitude of the observer matrix should be kept correspondingly low to avoid amplifying the measurement noise. The trade-off between the time required to obtain accurate observer performance and the amount of noise amplification is a primary design issue. For design purposes, we will attempt to insure a separation of the desired closedloop system poles and the observer poles on the order of 2 to 10 (as illustrated in Figure 11.9). The desired observer characteristic equation is selected to be of the form

$$
p(\lambda)=\left(\lambda^{2}+c_{1} \lambda+c_{2}\right)^{2},
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0835.jpg?height=595&width=722&top_left_y=154&top_left_x=91)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0835.jpg?height=583&width=751&top_left_y=167&top_left_x=864)

(b)

FIGURE 11.10 (a) Pendulum performance under full-state feedback control with the observer in the loop, (b) Observer performance.

where the constants $c_{1}$ and $c_{2}$ are appropriately chosen. As a first attempt, we select $c_{1}=32$ and $c_{2}=711.11$. These values should produce a response to an initial state estimation error that settles in less than 0.5 second with minimal percent overshoot. Using Ackermann's formula from Section 11.3, we determine that the observer gain that achieves the desired observer pole locations $\operatorname{det}(\lambda \mathbf{I}-(\mathbf{A}-\mathbf{L C}))=((\lambda+16+j 21.3)(\lambda+16-j 21.3))^{2}$ is

$$
\mathbf{L}=\left[\begin{array}{c}
64.0 \\
2546.22 \\
-5.1911 \mathrm{E} 04 \\
-7.6030 \mathrm{E} 05
\end{array}\right]
$$

\section{STEP 3: Compensator Design}

The final step in the design is to connect the observer to the full-state feedback control law via $u(t)=-\mathbf{K} \hat{\mathbf{x}}(t)$. As proved earlier, the closed-loop system will remain stable; however, we should not expect the closed-loop performance to be as good when using the state estimate from the observer. This makes sense, since it takes a finite amount of time for the observer to provide accurate state estimates. The response of the inverted pendulum design is shown in Figure 11.10. The pendulum is initially stationary at $\theta\left(t_{0}\right)=5.72^{\circ}$, and the cart is initially not moving. The initial state estimate in the observer is set to zero.

In Figure 11.10(a), we see that, indeed, the pendulum is balanced to the vertical in under 4 seconds. The response of the compensator (with the observer) is more oscillatory than without the observer in the loop-but this difference in performance is expected, since it takes about 0.4 second for the observer to converge to a minimal state tracking error, as seen in Figure 11.10(b). 

\subsection{REFERENCE INPUTS}

The feedback strategies discussed in the previous sections (and illustrated in Figure 11.1) were constructed without consideration of reference inputs. We referred to the design of state variable feedback compensators without reference inputs (i.e., $r(t)=0$ ) as regulators. Since command following is also an important aspect of feedback design, it is important to consider how we can introduce a reference signal into the state variable feedback compensator. There are, in fact, many different techniques that can be employed to permit the tracking of a reference input. Two of the more common methods are discussed in this section.

The general form of the state variable feedback compensator is

$$
\begin{aligned}
\dot{\hat{\mathbf{x}}}(t) & =\mathbf{A} \hat{\mathbf{x}}(t)+\mathbf{B} \tilde{u}(t)+\mathbf{L} \tilde{y}(t)+\mathbf{M} r(t) \\
u(t) & =\tilde{u}(t)+N r(t)=-\mathbf{K} \hat{\mathbf{x}}(t)+N r(t),
\end{aligned}
$$

where $\tilde{y}=y(t)-\mathbf{C} \hat{\mathbf{x}}(t)$ and $\tilde{u}(t)=-\mathbf{K} \hat{\mathbf{x}}(t)$. The state variable compensator with the reference input is illustrated in Figure 11.11. Notice that when $\mathbf{M}=0$ and $N=0$, the compensator in Equation (11.24) reduces to the regulator described in Section 11.5 and illustrated in Figure 11.1.

The compensator key design parameters required to implement the command tracking of the reference input are $\mathbf{M}$ and $N$. When the reference input is a scalar signal (i.e., a single input), the parameter $\mathbf{M}$ is a column vector of length $n$, where $n$ is the length of the state vector, $\mathbf{x}(t)$ and $N$ is a scalar. Here, we consider two possibilities for selecting $\mathbf{M}$ and $N$. In the first case, we select $\mathbf{M}$ and $N$ so that the estimation error $\mathbf{e}(t)$ is independent of the reference input $r(t)$. In the second case, we select $\mathbf{M}$ and $N$ so that the tracking error $y(t)-r(t)$ is used as an input to the compensator. These two cases will result in implementations wherein the compensator is in the feedback loop in the first case and in the forward loop in the second case.

Employing the generalized compensator in Equation (11.24), the estimation error is found to be described by the differential equation

$$
\dot{\mathbf{e}}(t)=\dot{\mathbf{x}}(t)-\dot{\hat{\mathbf{x}}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)-\mathbf{A} \hat{\mathbf{x}}(t)-\mathbf{B} \tilde{u}(t)-\mathbf{L} \tilde{y}(t)-\mathbf{M} r(t),
$$

FIGURE

11.11

State variable compensator with a reference input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0836.jpg?height=593&width=1343&top_left_y=1526&top_left_x=443)

FIGURE 11.12

State variable compensator with reference input and $\mathbf{M}=\mathbf{B} N$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0837.jpg?height=454&width=1117&top_left_y=168&top_left_x=368)

or

$$
\dot{\mathbf{e}}(t)=(\mathbf{A}-\mathbf{L C}) \mathbf{e}(t)+(\mathbf{B} N-\mathbf{M}) r(t) .
$$

Suppose that we select

$$
\mathbf{M}=\mathbf{B} N .
$$

Then the corresponding estimation error is given by

$$
\dot{\mathbf{e}}(t)=(\mathbf{A}-\mathbf{L C}) \mathbf{e}(t) .
$$

In this case, the estimation error is independent of the reference input $r(t)$. This is the identical result found in Section 11.4, where we considered the observer design assuming no reference inputs. The remaining task is to determine a suitable value of $N$, since the value of $\mathbf{M}$ follows from Equation (11.25). For example, we might choose $N$ to obtain a zero steady-state tracking error to a step input $r(t)$.

With $\mathbf{M}=\mathbf{B} N$, we find that the compensator is given by

$$
\begin{aligned}
\dot{\hat{\mathbf{x}}}(t) & =\mathbf{A} \hat{\mathbf{x}}(t)+\mathbf{B} u(t)+\mathbf{L} \tilde{y}(t) \\
u(t) & =-\mathbf{K} \hat{\mathbf{x}}(t)+N r(t) .
\end{aligned}
$$

This implementation of the state variable compensator is illustrated in Figure 11.12.

As an alternative approach, suppose that we select $N=0$ and $\mathbf{M}=-\mathrm{L}$. Then, the compensator in Equation (11.24) is given by

$$
\begin{aligned}
\dot{\hat{\mathbf{x}}}(t) & =\mathbf{A} \hat{\mathbf{x}}(t)+\mathbf{B} u(t)+\mathbf{L} \tilde{y}(t)-\mathbf{L} r(t) \\
u(t) & =-\mathbf{K} \hat{\mathbf{x}}(t),
\end{aligned}
$$

which can be rewritten as

$$
\begin{aligned}
\dot{\hat{\mathbf{x}}}(t) & =(\mathbf{A}-\mathbf{B K}-\mathbf{L C}) \hat{\mathbf{x}}(t)+\mathbf{L}(y(t)-r(t)) \\
u(t) & =-\mathbf{K} \hat{\mathbf{x}}(t) .
\end{aligned}
$$

In this formulation, the observer is driven by the tracking error $y(t)-r(t)$. The reference input tracking implementation is illustrated in Figure 11.13.

Notice that in the first implementation (with $\mathbf{M}=\mathbf{B} N$ ) the compensator is in the feedback loop, whereas in the second implementation $(N=0$ and $\mathbf{M}=-\mathbf{L})$ FIGURE 11.13

State variable compensator with reference

input and $N=0$ and $\mathbf{M}=-\mathbf{L}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0838.jpg?height=318&width=1322&top_left_y=149&top_left_x=466)

the compensator is in the forward path. These two implementations are representative of the possibilities open to control system designers when considering reference inputs.

Depending on the choice of $N$ and $\mathbf{M}$, other implementations are possible. For example, Section 11.8 presents a method of tracking reference inputs with guaranteed steady-state tracking errors using internal model design techniques.

\subsection{OPTIMAL CONTROL SYSTEMS}

The design of optimal control systems is an important function of control engineering. The purpose of design is to realize a system with practical components that will provide the desired performance. The desired performance can be readily stated in terms of time-domain performance indices, such as the integral performance measures. The design of a system can be based on minimizing a performance index, such as the integral of the squared error (ISE). Systems that are adjusted to provide a minimum performance index are called optimal control systems. In this section, we consider the design of an optimal control system that is described by a state variable formulation.

The performance of a control system, written in terms of the state variables of a system, can be expressed as

$$
J=\int_{0}^{\infty} g(\mathbf{x}, \mathbf{u}, t) d t,
$$

where $\mathbf{x}(t)$ is the state vector, and $\mathbf{u}(t)$ is the control vector. In this section, we consider the design of optimal control systems using state variable feedback and error-squared performance indices [1-3].

Consider the system

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B u}(t) .
$$

We will select a feedback controller as

$$
u(t)=-\mathbf{K} \mathbf{x}(t),
$$

where $\mathbf{K}$ is an $1 \times n$ matrix.

Substituting Equation (11.28) into Equation (11.27) yields

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)-\mathbf{B K} \mathbf{x}(t)=\mathbf{H} \mathbf{x}(t),
$$

where $\mathbf{H}$ is the $n \times n$ matrix resulting from the addition of the elements of $\mathbf{A}$ and - BK. The error-squared performance index for a single state variable, $x_{1}(t)$, is written as

$$
J=\int_{0}^{\infty} x_{1}^{2}(t) d t
$$

A performance index written in terms of two state variables would then be

$$
J=\int_{0}^{\infty}\left(x_{1}^{2}(t)+x_{2}^{2}(t)\right) d t
$$

Since we wish to define the performance index in terms of an integral of the sum of the state variables squared, we will use the matrix operation

$$
\begin{aligned}
\mathbf{x}^{T}(t) \mathbf{x}(t) & =\left(x_{1}(t), x_{2}(t), x_{3}(t), \ldots x_{n}(t)\right)\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t) \\
\vdots \\
x_{n}(t),
\end{array}\right) \\
& =x_{1}^{2}(t)+x_{2}^{2}(t)+x_{3}^{2}(t)+\ldots+x_{n}^{2}(t),
\end{aligned}
$$

where $\mathbf{x}^{T}(t)$ indicates the transpose of $\mathbf{x}(t) .^{\dagger}$ Then the specific form of the performance index, in terms of the state vector, is

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t .
$$

The general form of the performance index (Equation 11.26) incorporates a term with $u(t)$ that we have not included at this point, but we will do so later in this section.

To obtain the minimum value of $J$, we postulate the existence of an exact differential so that

$$
\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P} \mathbf{x}(t)\right)=-\mathbf{x}^{T}(t) \mathbf{x}(t)
$$

where $\mathbf{P}$ is to be determined. A symmetric $\mathbf{P}$ matrix will be used to simplify the algebra without any loss of generality. Then, for a symmetric $\mathbf{P}$ matrix, $p_{i j}=p_{j i}$. Completing the differentiation indicated on the left-hand side of Equation (11.34), we have

$$
\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P x}(t)\right)=\dot{\mathbf{x}}^{T}(t) \mathbf{P x}(t)+\mathbf{x}^{T}(t) \mathbf{P} \dot{\mathbf{x}}(t) .
$$

Substituting Equation (11.29) into Equation (11.35), we obtain

$$
\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P x}(t)\right)=\mathbf{x}^{T}(t)\left(\mathbf{H}^{T} \mathbf{P}+\mathbf{P H}\right) \mathbf{x}(t)
$$

If we let

$$
\mathbf{H}^{T} \mathbf{P}+\mathbf{P H}=-\mathbf{I},
$$

\footnotetext{
${ }^{\dagger}$ Matrix operations are discussed on the MCS website.
} then Equation (11.36) becomes

$$
\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P} \mathbf{x}(t)\right)=-\mathbf{x}^{T}(t) \mathbf{x}(t)
$$

which is the exact differential we are seeking. Substituting Equation (11.38) into Equation (11.33), we obtain

$$
J=\int_{0}^{\infty}-\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P} \mathbf{x}(t)\right) d t=-\left.\mathbf{x}^{T}(t) \mathbf{P x}(t)\right|_{0} ^{\infty}=\mathbf{x}^{T}(0) \mathbf{P x}(0) .
$$

In the evaluation of the limit at $t=\infty$, we have assumed that the system is stable, and hence $\mathbf{x}(\infty)=0$, as desired. Therefore, to minimize the performance index $J$, we consider the two equations

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t=\mathbf{x}^{T}(0) \mathbf{P} \mathbf{x}(0)
$$

and

$$
\mathbf{H}^{T} \mathbf{P}+\mathbf{P H}=-\mathbf{I} .
$$

The design steps are then as follows:

1. Determine the matrix $\mathbf{P}$ that satisfies Equation (11.41), where $\mathbf{H}$ is known.

2. Minimize $J$ by determining the minimum of Equation (11.40) by adjusting one or more unspecified system parameters.

\section{EXAMPLE 11.11 State variable feedback}

Consider the open-loop control system shown in Figure 11.14. The state variables are identified as $x_{1}(t)$ and $x_{2}(t)$. The performance of this system is quite unsatisfactory because an undamped response results for a step input. The vector differential equation of this system is

$$
\frac{d}{d t}\left(\begin{array}{l}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right]\left(\begin{array}{l}
x_{1}(t) \\
x_{2}(t)
\end{array}\right)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) .
$$

We choose a feedback control system so that

$$
u(t)=-k_{1} x_{1}(t)-k_{2} x_{2}(t),
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0840.jpg?height=122&width=588&top_left_y=1995&top_left_x=508)

and therefore the control signal is a linear function of the two state variables. Then Equation (11.42) becomes

$$
\begin{aligned}
& \dot{x}_{1}(t)=x_{2}(t), \\
& \dot{x}_{2}(t)=-k_{1} x_{1}(t)-k_{2} x_{2}(t) .
\end{aligned}
$$

In matrix form, we have

$$
\dot{\mathbf{x}}(t)=\mathbf{H x}(t)=\left[\begin{array}{cc}
0 & 1 \\
-k_{1} & -k_{2}
\end{array}\right] \mathbf{x}(t) .
$$

Let $k_{1}=1$ and determine a suitable value for $k_{2}$ so that the performance index is minimized. From Equation (11.41), it follows that

$$
\left[\begin{array}{cc}
0 & -1 \\
1 & -k_{2}
\end{array}\right]\left[\begin{array}{ll}
p_{11} & p_{12} \\
p_{12} & p_{22}
\end{array}\right]+\left[\begin{array}{ll}
p_{11} & p_{12} \\
p_{12} & p_{22}
\end{array}\right]\left[\begin{array}{cc}
-0 & 1 \\
-1 & -k_{2}
\end{array}\right]=\left[\begin{array}{cc}
-1 & 0 \\
0 & -1
\end{array}\right] .
$$

Completing the matrix multiplication and addition yields

$$
\begin{aligned}
-p_{12}-p_{12} & =-1, \\
p_{11}-k_{2} p_{12}-p_{22} & =0, \\
p_{12}-k_{2} p_{22}+p_{12}-k_{2} p_{22} & =-1 .
\end{aligned}
$$

Solving these simultaneous equations, we obtain

$$
p_{12}=\frac{1}{2}, \quad p_{22}=\frac{1}{k_{2}}, \quad p_{11}=\frac{k_{2}^{2}+2}{2 k_{2}} .
$$

The integral performance index is then

$$
J=\mathbf{x}^{T}(0) \mathbf{P x}(0),
$$

and we will consider the case where each state is initially displaced one unit from equilibrium so that $\mathbf{x}^{T}(0)=(1,1)$. Therefore Equation (11.48) becomes

$$
J=\left[\begin{array}{ll}
1 & 1
\end{array}\right]\left[\begin{array}{ll}
p_{11} & p_{12} \\
p_{12} & p_{22}
\end{array}\right]\left[\begin{array}{l}
1 \\
1
\end{array}\right]=p_{11}+2 p_{12}+p_{22}
$$

Substituting the values of the elements of $\mathbf{P}$, we have

$$
J=\frac{k_{2}^{2}+2}{2 k_{2}}+1+\frac{1}{k_{2}}=\frac{k_{2}^{2}+2 k_{2}+4}{2 k_{2}} .
$$

To minimize as a function of $k_{2}$, we take the derivative with respect to $k_{2}$ and set it equal to zero yielding

$$
\frac{d J}{d k_{2}}=\frac{2 k_{2}\left(2 k_{2}+2\right)-2\left(k_{2}^{2}+2 k_{2}+4\right)}{\left(2 k_{2}\right)^{2}}=0
$$

Therefore, $k_{2}^{2}=4$, and $k_{2}=2$ when $J$ is a minimum. The minimum value of $J$ is obtained by substituting $k_{2}=2$ into Equation (11.50). Thus, we obtain

$$
J_{\min }=3 .
$$

The system matrix $\mathbf{H}$, obtained for the compensated system, is then

$$
\mathbf{H}=\left[\begin{array}{cc}
0 & 1 \\
-1 & -2
\end{array}\right] .
$$

The characteristic equation of the compensated system is therefore

$$
\operatorname{det}[\lambda \mathbf{I}-\mathbf{H}]=\operatorname{det}\left[\begin{array}{cc}
\lambda & -1 \\
1 & \lambda+2
\end{array}\right]=\lambda^{2}+2 \lambda+1 .
$$

Because this is a second-order system, we note that the characteristic equation is of the form $s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=0$, and therefore the damping ratio of the compensated system is $\zeta=1.0$. This compensated system is considered to be an optimal system in that the compensated system results in a minimum value for the performance index when $k_{1}=1$ is fixed. Of course, we recognize that this system is optimal only for the specific set of initial conditions that were assumed. The compensated system is shown in Figure 11.15. A curve of the performance index as a function of $k_{2}$ is shown in Figure 11.16. It is clear that this system is not very sensitive to changes in $k_{2}$ and will maintain a near-minimum performance index if the $k_{2}$ is altered by some percentage. We define the sensitivity of an optimal system as

$$
S_{k}^{\mathrm{opt}}=\frac{\Delta J / J}{\Delta k / k}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0842.jpg?height=320&width=752&top_left_y=1597&top_left_x=506)

FIGURE 11.15 Compensated control system of Example 11.11.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0842.jpg?height=410&width=383&top_left_y=1486&top_left_x=1370)

FIGURE 11.16 Performance index versus the parameter $k_{2}$. where $k$ is the design parameter. Then, for this example, we have $k=k_{2}$, and considering $k_{2}=2.5$, for which $J=3.05$, we obtain

$$
S_{k_{2}}^{\mathrm{opt}} \approx \frac{0.05 / 3}{0.5 / 2}=0.07
$$

\section{EXAMPLE 11.12 Determination of an optimal system}

Now let us consider again the system of Example 11.11, where both the feedback gains, $k_{1}$ and $k_{2}$, are unspecified. To simplify the algebra without any loss in insight into the problem, let us set $k_{1}=k_{2}=k$. We can prove that if $k_{1}$ and $k_{2}$ are unspecified, then $k_{1}=k_{2}$ when the minimum of the performance index (Equation 11.40) is obtained. Then, for the system of Example 11.11, Equation (11.45) becomes

$$
\dot{\mathbf{x}}(t)=\mathbf{H x}(t)=\left[\begin{array}{cc}
0 & 1 \\
-k & -k
\end{array}\right] \mathbf{x}(t) .
$$

To determine the $\mathbf{P}$ matrix, we use Equation (11.41), yielding

$$
p_{12}=\frac{1}{2 k}, \quad p_{22}=\frac{k+1}{2 k^{2}}, \quad \text { and } \quad p_{11}=\frac{1+2 k}{2 k} .
$$

Let us consider the case where the system is initially displaced one unit from equilibrium so that $\mathbf{x}^{T}(0)=\left(\begin{array}{ll}1 & 0\end{array}\right)$. Then the performance index becomes

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t=\mathbf{x}^{T}(0) \mathbf{P x}(0)=p_{11} .
$$

Thus, the performance index to be minimized is

$$
J=p_{11}=\frac{1+2 k}{2 k}=1+\frac{1}{2 k} .
$$

The minimum value of $J$ is obtained when $k$ approaches infinity; the result is $J_{\min }=1$. A plot of $J$ versus $k$, shown in Figure 11.17, illustrates that the performance index approaches a minimum asymptotically as $k$ approaches an infinite value. Now, we recognize that, in providing a very large gain $k$, we can cause the feedback signal

$$
u(t)=-k\left(x_{1}(t)+x_{2}(t)\right)
$$

to be very large. However, we are restricted to realizable magnitudes of the control signal $u(t)$. Therefore, we should introduce a constraint on $u(t)$ so that the gain $k$ is not too large. Then, for example, if we establish a constraint on $u(t)$ so that

$$
|u(t)| \leq 50,
$$

FIGURE 11.17

Performance index versus the feedback gain $k$ for Example 11.12.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0844.jpg?height=487&width=586&top_left_y=152&top_left_x=507)

we require that the maximum acceptable value of $k$ in this case be

$$
k_{\max }=\frac{|u(t)|_{\max }}{x_{1}(0)}=50 .
$$

Then the minimum value of $J$ is

$$
J_{\min }=1+\frac{1}{2 k_{\max }}=1.01,
$$

which is sufficiently close to the absolute minimum of $J$ to satisfy our requirements.

Upon examining the performance index, we recognize that the reason the magnitude of the control signal is not accounted for in the original calculations is that $u(t)$ is not included within the expression for the performance index. However, in many cases, we have physical limits on the control magnitude. To account for the control magnitude, we can consider the performance index

$$
J=\int_{0}^{\infty}\left(\mathbf{x}^{T}(t) \mathbf{I} \mathbf{x}(t)+\lambda \mathbf{u}^{T}(t) \mathbf{u}(t)\right) d t
$$

where $\lambda$ is a scalar weighting factor and $\mathbf{I}=$ identity matrix. The weighting factor $\lambda$ will be chosen so that the relative importance of the state variable performance is contrasted with the importance of the control energy represented by $\mathbf{u}^{T}(t) \mathbf{u}(t)$. We represent the state variable feedback via

$$
u(t)=-\mathbf{K x}(t),
$$

and the system with this state variable feedback as

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)=\mathbf{H} \mathbf{x}(t) .
$$

Substituting Equation (11.64) into Equation (11.63) yields

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t)\left(\mathbf{I}+\lambda \mathbf{K}^{T} \mathbf{K}\right) \mathbf{x}(t) d t=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{Q} \mathbf{x}(t) d t,
$$

where $\mathbf{Q}=\mathbf{I}+\lambda \mathbf{K}^{T} \mathbf{K}$ is an $n \times n$ matrix. Following the development of Equations (11.33) through (11.39), we postulate the existence of an exact differential so that

$$
\frac{d}{d t}\left(\mathbf{x}^{T}(t) \mathbf{P} \mathbf{x}(t)\right)=-\mathbf{x}^{T}(t) \mathbf{Q} \mathbf{x}(t)
$$

Then, in this case, we require that

$$
\mathbf{H}^{T} \mathbf{P}+\mathbf{P H}=-\mathbf{Q}
$$

and thus, as before, we have

$$
J=\mathbf{x}^{T}(0) \mathbf{P x}(0)
$$

If $\lambda=0$, Equation (11.68) reduces to Equation (11.41). Now, let us consider again Example 11.11 when $\lambda$ is other than zero and account for the expenditure of control signal energy.

\section{EXAMPLE 11.13 Optimal system with control energy considerations}

Consider again the system of Example 11.11, which is shown in Figure 11.14. For this system, we use a state variable feedback so that

$$
u(t)=-\mathbf{K x}(t)=\left[\begin{array}{ll}
-k & -k
\end{array}\right]\left(\begin{array}{c}
x_{1}(t) \\
x_{2}(t)
\end{array}\right) .
$$

Therefore, the matrix

$$
\mathbf{Q}=\mathbf{I}+\lambda \mathbf{K}^{T} \mathbf{K}=\left[\begin{array}{ll}
1+\lambda k^{2} & \lambda k^{2} \\
\lambda k^{2} & 1+\lambda k^{2}
\end{array}\right] .
$$

As in Example 11.12, we will let $\mathbf{x}^{T}(0)=(1,0)$ so that $J=p_{11}$. We evaluate $p_{11}$ from Equation (11.68), yielding

$$
J=p_{11}=\left(1+\lambda k^{2}\right)\left(1+\frac{1}{2 k}\right)-\lambda k^{2} .
$$

The minimum of $J$ is found by taking the derivative of $J$, setting the result to zero, and solving for $k$, yielding

$$
\frac{d J}{d k}=\frac{1}{2}\left(\lambda-\frac{1}{k^{2}}\right)=0 .
$$

Therefore, the minimum of the performance index occurs when $k=k_{\min }=1 / \sqrt{\lambda}$, where $k_{\min }$ is the solution of Equation (11.73).

Let us complete this example for the case where the control energy and the state variables squared are equally important, so that $\lambda=1$. Then Equation (11.73) is satisfied when $k^{2}-1=0$, and we find that $k_{\min }=1.0$. The plot of $J$ versus $k$ for FIGURE 11.18

Performance index versus the feedback gain $k$ for Example 11.13.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0846.jpg?height=487&width=588&top_left_y=152&top_left_x=508)

this case is shown in Figure 11.18. The plot of $J$ versus $k$ for Example 11.12 is also shown for comparison in Figure 11.18.

The design of several parameters can be accomplished in a manner similar to that illustrated in the examples. Also, the design procedure can be carried out for higher-order systems. Consider the single-input, single-output system with

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

and feedback

$$
u(t)=-\mathbf{K x}(t)=-\left[\begin{array}{ll}
k_{1} & k_{2} \ldots k_{n}
\end{array}\right] \mathbf{x}(t) .
$$

We can consider the performance index

$$
J=\int_{0}^{\infty}\left(\mathbf{x}^{T}(t) \mathbf{Q} \mathbf{x}(t)+R u^{2}(t)\right) d t
$$

where $R>0$ is a scalar weighting factor. This index is minimized when

$$
\mathbf{K}=R^{-1} \mathbf{B}^{T} \mathbf{P} .
$$

The $n \times n$ matrix $\mathbf{P}$ is determined from the solution of the equation

$$
\mathbf{A}^{T} \mathbf{P}+\mathbf{P A}-\mathbf{P B} R^{-1} \mathbf{B}^{T} \mathbf{P}+\mathbf{Q}=\mathbf{0} .
$$

Equation (11.76) is often called the algebraic Riccati equation. This optimal control problem is called the linear quadratic regulator (LQR) $[12,19]$.

\subsection{INTERNAL MODEL DESIGN}

In this section, we consider the problem of designing a compensator that provides asymptotic tracking of a reference input with zero steady-state error. The reference inputs considered can include steps, ramps, and other persistent signals, such as sinusoids. For a step input, we know that zero steady-state tracking errors can be achieved with a type-one system. This idea is formalized here by introducing an internal model of the reference input in the compensator $[5,18]$. Consider a state variable model given by

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t), \quad y(t)=\mathbf{C x}(t) .
$$

We consider a reference input to be generated by a linear system of the form

$$
\dot{\mathbf{x}}_{r}(t)=\mathbf{A}_{r} \mathbf{x}_{r}(t), \quad r(t)=\mathbf{d}_{r} \mathbf{x}_{r}(t)
$$

with unknown initial conditions.

We begin by considering a familiar design problem, namely, the design of a controller to enable the tracking of a step reference input with zero steady-state error. In this case, the reference input is generated by

$$
\dot{x}_{r}(t)=0, \quad r(t)=x_{r}(t)
$$

or equivalently

$$
\dot{r}(t)=0,
$$

and the tracking error $e(t)$ is defined as

$$
e(t)=y(t)-r(t) .
$$

Taking the time derivative yields

$$
\dot{e}(t)=\dot{y}(t)=\mathbf{C} \dot{\mathbf{x}}(t) .
$$

If we define the two intermediate variables

$$
\mathbf{z}(t)=\dot{\mathbf{x}}(t) \quad \text { and } \quad w(t)=\dot{u}(t),
$$

we have

$$
\left(\begin{array}{c}
\dot{e}(t) \\
\dot{\mathbf{z}}(t)
\end{array}\right)=\left[\begin{array}{ll}
0 & \mathbf{C} \\
0 & \mathbf{A}
\end{array}\right]\left(\begin{array}{c}
e(t) \\
\mathbf{z}(t)
\end{array}\right)+\left[\begin{array}{c}
0 \\
\mathbf{B}
\end{array}\right] w(t) .
$$

If the system in Equation (11.81) is controllable, we can find a feedback of the form

$$
w(t)=-K_{1} e(t)-\mathbf{K}_{2} \mathbf{z}(t)
$$

such that Equation (11.81) is stable. This implies that the tracking error $e$ is stable; thus, we will have achieved the objective of asymptotic tracking with zero steadystate error. The control input, found by integrating Equation (11.82), is

$$
u(t)=-K_{1} \int_{0}^{t} e(\tau) d \tau-\mathbf{K}_{2} \mathbf{x}(t) .
$$

The corresponding block diagram is shown in Figure 11.19. We see that the compensator includes an internal model (that is, an integrator) of the reference step input.

FIGURE 11.19 Internal model design for a step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0847.jpg?height=315&width=1155&top_left_y=1825&top_left_x=370)



\section{EXAMPLE 11.14 Internal model design for a unit step input}

Consider a process given by

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-2 & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t), \quad y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
$$

We want to design a controller for this system to track a reference step input with zero steady-state error. From Equation (11.81), we have

$$
\left(\begin{array}{c}
\dot{e}(t) \\
\dot{\mathbf{z}}(t)
\end{array}\right)=\left[\begin{array}{ccc}
0 & 1 & 0 \\
0 & 0 & 1 \\
0 & -2 & -2
\end{array}\right]\left(\begin{array}{l}
e(t) \\
\mathbf{z}(t)
\end{array}\right]+\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right] w(t) .
$$

A check of controllability shows that the system described by Equation (11.84) is completely controllable. We use

$$
K_{1}=20, \quad \mathbf{K}_{2}=\left[\begin{array}{ll}
20 & 10
\end{array}\right],
$$

in order to locate the roots of the characteristic equation of Equation (11.84) at $s=-1 \pm j,-10$. With $w(t)$ given in Equation (11.82), Equation (11.84) is asymptotically stable. So, for any initial tracking error $e(0)$ we are guaranteed that $e(t) \rightarrow 0$ as $t \rightarrow \infty$.

Consider a block diagram where the process is represented by $G(s)$ and the cascade controller is $G_{c}(s)=K_{1} / s$. The internal model principle states that if $G(s) G_{c}(s)$ contains $R(s)$, then $y(t)$ will track $r(t)$ asymptotically. In this case $R(s)=1 / s$, which is contained in $G(s) G_{c}(s)$, as we expect.

Consider the problem of designing a controller to provide asymptotic tracking of a ramp input with zero steady-state error $r(t)=M t, t \geq 0$, where $M$ is the ramp magnitude. In this case, the reference input model is

$$
\begin{aligned}
\dot{\mathbf{x}}_{r}(t) & =\mathbf{A}_{r} \mathbf{x}_{r}(t)=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \mathbf{x}_{r}(t) \\
r(t) & =\mathbf{d}_{r} \mathbf{x}_{r}(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}_{r}(t) .
\end{aligned}
$$

In input-output form, the reference model in Equation (11.85) is given by

$$
\ddot{r}(t)=0 \text {. }
$$

Proceeding as before, we take the time-derivative of the tracking error twice yielding

$$
\ddot{e}(t)=\ddot{y}(t)=\mathbf{C} \ddot{\mathbf{x}}(t) \text {. }
$$

With the definitions

$$
\mathbf{z}(t)=\ddot{\mathbf{x}}(t), \quad w(t)=\ddot{u}(t),
$$

we have

$$
\left(\begin{array}{c}
\dot{e} \\
\ddot{e} \\
\dot{\mathbf{z}}
\end{array}\right)=\left[\begin{array}{lll}
0 & 1 & 0 \\
0 & 0 & \mathbf{C} \\
0 & 0 & \mathbf{A}
\end{array}\right]\left(\begin{array}{c}
e \\
\dot{e} \\
\mathbf{z}
\end{array}\right)+\left[\begin{array}{c}
0 \\
0 \\
\mathbf{B}
\end{array}\right] w .
$$

FIGURE 11.20 Internal model design for a ramp input. Note that $G(s) G_{c}(s)$ contains $1 / s^{2}$, the reference input $R(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0849.jpg?height=317&width=1329&top_left_y=152&top_left_x=309)

So if the system of Equation (11.86) is controllable, then we can compute the gains $K_{1}, K_{2}$, and $\mathbf{K}_{3}$ such that with

$$
w(t)=-\left[\begin{array}{lll}
K_{1} & K_{2} & \mathbf{K}_{3}
\end{array}\right]\left(\begin{array}{c}
e(t) \\
\dot{e}(t) \\
\mathbf{z}(t)
\end{array}\right),
$$

the system represented by Equation (11.86) is asymptotically stable; hence, the tracking error $e(t) \rightarrow 0$ as $t \rightarrow \infty$, as desired. The control, $u(t)$, is found by integrating Equation (11.87) twice. In Figure 11.20, we see that the resulting controller has a double integrator, which is the internal model of the reference ramp input.

The internal model approach can be extended to other reference inputs by following the same general procedure outlined for the step and ramp inputs. In addition, the internal model design can be used to reject persistent disturbances by including models of the disturbances in the compensator.

\subsection{DESIGN EXAMPLES}

In this section we present a control system designed to manage the speed of the electric motor shaft of a diesel electric locomotive. The design process focuses on the design of a full-state feedback control system using pole-placement methods.

\section{EXAMPLE 11.15 Diesel electric locomotive control}

The diesel electric locomotive is depicted in Figure 11.21. The efficiency of the diesel engine is very sensitive to the speed of rotation of the motors. We want to design a control system that drives the electric motors of a diesel electric locomotive for use on railroad trains. The locomotive is driven by DC motors located on each of the axles. The throttle position is set by moving the input potentiometers. The elements of the design process emphasized in this example are highlighted in Figure 11.22.

The control objective is to regulate the shaft rotation speed $\omega_{o}(t)$ to the desired value $\omega_{r}(t)$.

\section{Control Goal}

Regulate the shaft rotation speed to the desired value in the presence of external load torque disturbances.

The corresponding variable to be controlled is the shaft rotation speed $\omega_{o}(t)$. FIGURE 11.21

Diesel electric locomotive system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0850.jpg?height=894&width=1249&top_left_y=155&top_left_x=519)

Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0850.jpg?height=1061&width=1178&top_left_y=1123&top_left_x=580)

If the performance does not meet the specifications, then iterate the configuration.
If the performance meets the specifications, then finalize the design.
FIGURE 11.22

Elements of the control system design process emphasized in this diesel electric locomotive example.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0850.jpg?height=1075&width=49&top_left_y=1082&top_left_x=426)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0850.jpg?height=1009&width=228&top_left_y=1142&top_left_x=220)



\section{Variable to Be Controlled}

Shaft rotation speed $\omega_{o}(t)$.

The controlled speed $\omega_{o}(t)$ is sensed by a tachometer, which supplies a feedback voltage $v_{o}(t)$. The electronic amplifier amplifies the error signal, $v_{r}(t)-v_{o}(t)$, between the reference and feedback voltage signals and provides a voltage $v_{f}(t)$ that is supplied to the field winding of a DC generator.

The generator is run at a constant speed $\omega_{d}$ by the diesel engine and generates a voltage $v_{g}$ that is supplied to the armature of a DC motor. The motor is armature controlled, with a fixed current supplied to its field. As a result, the motor produces a torque $T$ and drives the load connected to its shaft so that the controlled speed $\omega_{o}(t)$ tends to equal the command speed $\omega_{r}(t)$.

A block diagram and signal flow graph of the system are shown in Figure 11.23. In Figure 11.23 we use $L_{t}$ and $R_{t}$, which are defined as

$$
\begin{aligned}
& L_{t}=L_{a}+L_{g}, \\
& R_{t}=R_{a}+R_{g} .
\end{aligned}
$$

Values for the parameters of the diesel electric locomotive are given in Table 11.1.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0851.jpg?height=400&width=1232&top_left_y=1016&top_left_x=254)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0851.jpg?height=456&width=1515&top_left_y=1522&top_left_x=108)

(b)

FIGURE 11.23 Signal flow graph of the diesel electric locomotive. (a) Signal flow graph. (b) Block diagram controller feedback loops are shown in green. 

\section{Table 11.1 Parameter Values for the Diesel Electric Locomotive}

\begin{tabular}{cccccccccccccc}
$K_{m}$ & $K_{g}$ & $K_{b}$ & $J$ & $b$ & $L_{a}$ & $R_{a}$ & $R_{f}$ & $L_{f}$ & $K_{t}$ & $K_{p o t}$ & $L_{g}$ & $R_{g}$ \\
\hline 10 & 100 & 0.62 & 1 & 1 & 0.2 & 1 & 1 & 0.1 & 1 & 1 & 0.1 & 1 \\
\hline
\end{tabular}

Notice that the system has a feedback loop; we use the tachometer voltage $v_{o}(t)$ as a feedback signal to form an error signal $v_{r}(t)-v_{o}(t)$. Without additional state feedback, the only tuning parameter is the amplifier gain $K$. As a first step, we can investigate the system performance with tachometer voltage feedback only.

The key tuning parameters are given by

\section{Select Key Tuning Parameters}

$K$ and $\mathbf{K}$

The matrix $\mathbf{K}$ is the state feedback gain matrix. The design specifications are

\section{Design Specifications}

DS1 Steady-state tracking $e_{s s} \leq 2 \%$ to a unit step input.

DS2 Percent overshoot of $\omega_{O}(t)$ of P.O. $\leq 10 \%$ to a unit step input $\omega_{r}(s)=1 / \mathrm{s}$.

DS3 Settling time of $T_{s} \leq 1 \mathrm{~s}$ to a unit step input.

The first step in the development of the vector differential equation that accurately describes the system is to choose a set of state variables. In practice the selection of state variables can be a difficult process, especially for complex systems. The state variables must be sufficient in number to determine the future behavior of the system when the present state and all future inputs are known. The selection of state variables is related to the issue of complexity.

The diesel electric locomotive system has three major components: two electrical circuits and one mechanical system. It seems logical that the state vector will include state variables from both electrical circuits and from the mechanical system. One reasonable choice of state variables is $x_{1}(t)=\omega_{o}(t), x_{2}(t)=i_{a}(t)$, and $x_{3}(t)=i_{f}(t)$. This state variable selection is not unique. With the state variables defined above, the state variable model is

$$
\begin{aligned}
& \dot{x}_{1}(t)=-\frac{b}{J} x_{1}(t)+\frac{K_{m}}{J} x_{2}(t)-\frac{1}{J} T_{d}(t), \\
& \dot{x}_{2}(t)=-\frac{K_{b}}{L_{t}} x_{1}(t)-\frac{R_{t}}{L_{t}} x_{2}(t)+\frac{K_{g}}{L_{t}} x_{3}(t), \\
& \dot{x}_{3}(t)=-\frac{R_{f}}{L_{f}} x_{3}(t)+\frac{1}{L_{f}} u(t),
\end{aligned}
$$

where

$$
u(t)=K K_{\text {pot }} \omega_{r}(t)
$$

In matrix form (with $\left.T_{d}(t)=0\right)$, we have

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t), \\
y(t)=\mathbf{C x}(t)+\mathbf{D} u(t),
\end{gathered}
$$

where

$$
\mathbf{A}=\left[\begin{array}{ccc}
-\frac{b}{J} & \frac{K_{m}}{J} & 0 \\
-\frac{K_{b}}{L_{t}} & -\frac{R_{t}}{L_{t}} & \frac{K_{g}}{L_{t}} \\
0 & 0 & -\frac{R_{f}}{L_{f}}
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{c} 
\\
0 \\
0 \\
\frac{1}{L_{f}}
\end{array}\right], \text { and }
$$

The corresponding transfer function is

$$
G(s)=\mathbf{C}(s \mathbf{I}-\mathbf{A})^{-1} \mathbf{B}=\frac{K_{g} K_{m}}{\left(R_{f}+L_{f} s\right)\left[\left(R_{t}+L_{t} s\right)\left(J_{s}+b\right)+K_{m} K_{b}\right]} .
$$

Assume the tachometer feedback is available, that is, that $K_{t}$ is in the loop. If we take advantage of the fact that

$$
K_{\mathrm{pot}}=K_{t}=1
$$

then (from an input-output perspective) the system has the feedback configuration shown in Figure 11.24.

Using the parameter values given in Table 11.1 and computing the steady-state tracking error for a unit step input yields

$$
e_{\mathrm{ss}}=\frac{1}{1+K G(0)}=\frac{1}{1+121.95 K} .
$$

Using the Routh-Hurwitz method, we also find that the closed-loop system is stable for

$$
-0.008<K<0.0468 \text {. }
$$

The smallest steady-state tracking error is achieved for the largest value of $K$. At best we can obtain a $15 \%$ tracking error, which does not meet the design specification DS1. Also, as $K$ gets larger, the response becomes unacceptably oscillatory.

We now consider a full state feedback controller design. The feedback loops are shown in Figure 11.23, which shows that $\omega_{0}(t), i_{a}(t)$, and $i_{f}(t)$ are available for feedback. Without any loss of generality, we set $K=1$. Any value of $K>0$ would work as well.

FIGURE 11.24 Block diagram representation of the diesel electric locomotive.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0853.jpg?height=297&width=928&top_left_y=1820&top_left_x=371)

The control input is

$$
u(t)=K_{\text {pot }} \omega_{r}(t)-K_{t} x_{1}(t)-K_{2} x_{2}(t)-K_{3} x_{3}(t) .
$$

The feedback gains to be determined are $K_{t}, K_{2}$, and $K_{3}$. The tachometer gain, $K_{t}$, is now a key parameter of the design process. Also $K_{\text {pot }}$ is a key variable for tuning. By adjusting the parameter $K_{\text {pot }}$, we have the freedom to scale the input $\omega_{r}(t)$. When we define

$$
\mathbf{K}=\left[\begin{array}{lll}
K_{t} & K_{2} & K_{3}
\end{array}\right],
$$

then

$$
u(t)=-\mathbf{K x}(t)+K_{\mathrm{pot}} \omega_{r}(t) .
$$

The closed-loop system with state feedback is

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =(\mathbf{A}-\mathbf{B K}) \mathbf{x}(t)+\mathbf{B} v(t), \\
y(t) & =\mathbf{C x}(t),
\end{aligned}
$$

where

$$
v(t)=K_{\text {pot }} \omega_{r}(t) .
$$

We will use pole-placement methods to determine $\mathbf{K}$ such that the eigenvalues of $\mathbf{A}-\mathbf{B K}$ are in the desired locations. First we make sure the system is controllable. When $n=3$ the controllability matrix is

$$
\mathbf{P}_{c}=\left[\begin{array}{lll}
\mathbf{B} & \mathbf{A B} & \mathbf{A}^{2} \mathbf{B}
\end{array}\right] .
$$

Computing the determinant of $\mathbf{P}_{c}$ yields

$$
\operatorname{det} \mathbf{P}_{c}=-\frac{K_{g}^{2} K_{m}}{J L_{f}^{3} L_{t}^{2}} .
$$

Since $K_{g} \neq 0$ and $K_{m} \neq 0$ and $J L_{f}^{3} L_{t}^{2}$ is nonzero, we determine that

$$
\operatorname{det} \mathbf{P}_{c} \neq 0 \text {. }
$$

Thus the system is controllable. We can place all the poles of the system appropriately to satisfy DS2 and DS3.

The desired region to place the eigenvalues of $\mathbf{A}-\mathbf{B K}$ is illustrated in Figure 11.25. The specific pole locations are selected to be

$$
\begin{aligned}
& p_{1}=-50, \\
& p_{2}=-4+3 j, \\
& p_{3}=-4-3 j .
\end{aligned}
$$

Selecting $p_{1}=-50$ allows for a good second-order response governed by $p_{2}$ and $p_{3}$. The gain matrix $\mathbf{K}$ that achieves the desired closed-loop poles is

$$
\mathbf{K}=\left[\begin{array}{lll}
-0.0041 & 0.0035 & 4.0333
\end{array}\right] \text {. }
$$

To select the gain $K_{\text {pot }}$, we first compute the DC gain of the closed-loop transfer function. With the state feedback in place, the closed-loop transfer function is

$$
T(s)=\mathbf{C}(s \mathbf{I}-\mathbf{A}+\mathbf{B K})^{-1} \mathbf{B} .
$$

FIGURE 11.25

Desired location of the closed-loop poles (that is, the eigenvalues of A - BK).
FIGURE 11.26

Closed-loop step response of the diesel electric locomotive.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0855.jpg?height=1438&width=1096&top_left_y=168&top_left_x=374)

Then

$$
K_{\mathrm{pot}}=\frac{1}{T(0)} \text {. }
$$

Using the gain $K_{\text {pot }}$ in this manner effectively scales the closed-loop transfer function so that the DC gain is equal to 1 . We then expect that a unit step input representing a $1 \%$ s step command results in a $1 \%$ s steady-state output at $\omega_{o}$.

The step response of the system is shown in Figure 11.26. We can see that all the design specifications are satisfied. 

\subsection{STATE VARIABLE DESIGN USING CONTROL DESIGN SOFTWARE}

Controllability and observability of a system in state variable feedback form can be checked using the functions ctrb and obsv, respectively. The inputs to the ctrb function, shown in Figure 11.27, are the system matrix $\mathbf{A}$ and the input matrix $\mathbf{B}$; the output of ctrb is the controllability matrix $\mathbf{P}_{c}$. Similarly, the input to the obsv function, shown in Figure 11.27, is the system matrix $\mathbf{A}$ and the output matrix $\mathbf{C}$; the output of obsv is the observability matrix $\mathbf{P}_{o}$.

Notice that the controllability matrix $\mathbf{P}_{c}$ is a function only of $\mathbf{A}$ and $\mathbf{B}$, while the observability matrix $\mathrm{P}_{o}$ is a function only of $\mathbf{A}$ and $\mathbf{C}$.

\section{EXAMPLE 11.16 Satellite trajectory control}

Let us consider a satellite in a circular, equatorial orbit at an altitude of 250 nautical miles above the Earth, as illustrated in Figure 11.28 [14, 24]. The satellite motion (in the orbit plane) is described by the normalized state variable model

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cccc}
0 & 1 & 0 & 0 \\
3 \omega^{2} & 0 & 0 & 2 \omega \\
0 & 0 & 0 & 1 \\
0 & -2 \omega & 0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1 \\
0 \\
0
\end{array}\right] u_{r}(t)+\left[\begin{array}{l}
0 \\
0 \\
0 \\
1
\end{array}\right] u_{t}(t)
$$

where the state vector $\mathbf{x}(t)$ represents normalized perturbations from the circular, equatorial orbit; $u_{r}(t)$ is the input from a radial thruster; $u_{t}(t)$ is the input from a tangential thruster; and $\omega=0.0011 \mathrm{rad} / \mathrm{s}$ (approximately one orbit of 90 minutes) is the orbital rate for the satellite at the specific altitude. In the absence of perturbations, the satellite will remain in the nominal circular equatorial orbit. However, disturbances such as aerodynamic drag can cause the satellite to deviate from its nominal path. The problem is to design a controller that commands the satellite thrusters in

Controllability $\dot{\mathbf{x}}=\mathbf{A x}+\mathbf{B} u$ matrix $\quad y=\mathbf{C x}+\mathbf{D} u$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0856.jpg?height=102&width=297&top_left_y=1680&top_left_x=310)

$\mathrm{Pc}=\mathrm{ctrb}(\mathrm{A}, \mathrm{B})$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0856.jpg?height=224&width=378&top_left_y=1826&top_left_x=225)

FIGURE 11.27 The ctrb and obsv functions.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0856.jpg?height=729&width=1101&top_left_y=1371&top_left_x=654)

FIGURE 11.28 The satellite in an equatorial circular orbit. FIGURE 11.29

Controllability with radial thrusters only: (a) $m$-file script, (b) output. radial.m

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0857.jpg?height=463&width=725&top_left_y=210&top_left_x=384)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0857.jpg?height=169&width=1226&top_left_y=788&top_left_x=375)

(b)

such a manner that the actual orbit remains near the desired circular orbit. Before commencing with the design, we check controllability. In this case, we investigate controllability using the radial and tangential thrusters independently.

Suppose the tangential thruster fails (i.e., $u_{t}(t)=0$ ), and only the radial thruster is operational. Is the satellite controllable from $u_{r}(t)$ only? We answer this question by using an m-file script to determine the controllability. Using the script shown in Figure 11.29, we find that the determinant $\mathbf{P}_{c}$ is zero; thus, the satellite is not completely controllable when the tangential thruster fails.

Suppose now that the radial thruster fails (i.e., $\left.u_{r}(t)=0\right)$ and that the tangential thruster is functioning properly. Is the satellite controllable from $u_{t}$ only? Using the script in Figure 11.30, we find that the satellite is completely controllable using the tangential thruster only.

We conclude this section with a controller design for a third-order system using state variable models. The design approach utilizes root locus methods and incorporates $\mathrm{m}$-file scripts to assist in the procedure.

\section{EXAMPLE 11.17 Third-order system}

Consider a system with the state-space representation

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t),
$$

where

$$
\mathbf{A}=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & -1 & 1 \\
0 & 0 & -5
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{c}
0 \\
0 \\
K
\end{array}\right]
$$

FIGURE 11.30

Controllability with tangential thrusters only: (a) m-file script, (b) output. tangent.m

$\%$ This script computes the satellite controllability

$\%$ with a tangential thruster only (i.e. failed radial thruster)

$\%$

$\mathrm{W}=0.0011$;

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0858.jpg?height=35&width=558&top_left_y=359&top_left_x=549)

b2 $=[0 ; 0 ; 0 ; 1]$;

$\mathrm{Pc}=\mathrm{ctrb}(\mathrm{A}, \mathrm{b} 2)$;

$\mathrm{n}=\operatorname{det}(\mathrm{Pc})$;

if $\operatorname{abs}(\mathrm{n})<\mathrm{eps}$

disp('Satellite is uncontrollable with tangential thruster only!')

else

disp('Satellite is controllable with tangential thruster only!')

end

(a)

>>tangent

Satellite is controllable with tangential thruster only!

Input matrix associated with tangential thruster

Compute controllability matrix $n=$ determinant of controllability matrix FIGURE 11.31

(a) Root locus.

(b) m-file script.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0859.jpg?height=652&width=762&top_left_y=156&top_left_x=376)

(a)

$\%$ Root locus script

$\%$ Including performance specs regions

num=[1 8 20]; den=[1 $\left.6 \begin{array}{lll}1 & 5 & 0\end{array}\right]$; sys=tf(num,den);

clf; rlocus(sys); hold on $4-\quad$ Hold plot to add $\%$

zeta $=0.72 ; w n=2.8$;

stability regions

$x=\left[-10: 0.1:-z^{*}{ }^{*} w n\right] ; y=-\left(\operatorname{sqrt}\left(1-\text { zeta}^{\wedge} 2\right) / \text { zeta }\right)^{\star} x ;$

$x c=\left[-10: 0.1:-z^{*} a^{*} w n\right] ; c=s q r t\left(w n^{\wedge} 2-x c .^{\wedge} 2\right)$

$\operatorname{plot}\left(x, y,,^{\prime}: ', x,-y,{ }^{\prime}: ', x c, c,,^{\prime \prime}, x c,-c, '^{\prime}: '\right)$

(b)

where $\mathbf{H}=\mathbf{A}-\mathbf{B K}$. The characteristic equation associated with Equation (11.93) can be obtained by evaluating $\operatorname{det}(s \mathbf{I}-\mathbf{H})=0$, resulting in

$$
s(s+1)(s+5)+K K_{3}\left(s^{2}+\frac{K_{3}+K_{2}}{K_{3}} s+\frac{K_{1}}{K_{3}}\right)=0 .
$$

If we view $K K_{3}$ as a parameter and let $K_{1}=1$, then we can write Equation (11.94) as

$$
1+K K_{3} \frac{s^{2}+\frac{K_{3}+K_{2}}{K_{3}} s+\frac{1}{K_{3}}}{s(s+1)(s+5)}=0 .
$$

We place the zeros at $s=-4 \pm 2 j$ in order to pull the locus to the left in the $s$-plane. Thus, our desired numerator polynomial is $s^{2}+8 s+20$. Comparing corresponding coefficients leads to

$$
\frac{K_{3}+K_{2}}{K_{3}}=8 \text { and } \frac{1}{K_{3}}=20 .
$$

FIGURE 11.32 Step response.

FIGURE 11.33 The acker function.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0860.jpg?height=910&width=990&top_left_y=154&top_left_x=521)

Therefore, $K_{2}=0.35$ and $K_{3}=0.05$. We can now plot a root locus with $K K_{3}$ as the parameter, as shown in Figure 11.31.

The characteristic equation, Equation (11.94), is

$$
1+K K_{3} \frac{s^{2}+8 s+20}{s(s+1)(s+5)}=0 .
$$

The roots for the selected gain, $K K_{3}=12$, lie in the performance region, as shown in Figure 11.31. The rlocfind function is used to determine the value of $K K_{3}$ at the selected point. The final gains are $K=240.00, K_{1}=1.00, K_{2}=0.35$, and $K_{3}=0.05$. The controller design results in a settling time of about 1.8 seconds and an overshoot of $3 \%$, as shown in Figure 11.32.

In Section 11.4, we discussed Ackermann's formula to place the poles of the system at desired locations. The function acker calculates the gain matrix $\mathbf{K}$ to place the closed-loop poles at the desired locations. The acker function is illustrated in Figure 11.33.

\section{EXAMPLE 11.18 Second-order system design using the acker function}

Consider again the second-order system in Example 11.7. The system model is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) .
$$

FIGURE 11.34

Using acker to compute $\mathrm{K}$ to place the poles at $\mathbf{P}=\left[\begin{array}{cc}-1+j & -1-j\end{array}\right]^{T}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0861.jpg?height=366&width=454&top_left_y=169&top_left_x=410)

The desired closed-loop pole locations are $s_{1,2}=-1 \pm j$. To apply Ackermann's formula using the acker function, form the vector

Then, with

$$
\mathbf{P}=\left[\begin{array}{c}
-1+j \\
-1-j
\end{array}\right]
$$

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right]
$$

the acker function, illustrated in Figure 11.34, determines that the gain matrix that achieves the desired pole locations is

$$
\mathbf{K}=\left[\begin{array}{ll}
2 & 2
\end{array}\right] .
$$

This confirms the result in Example 11.7.

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this chapter, we will design a state variable feedback system that will achieve the desired system response. The specifications for the system are given in Table 11.2. The second-order open-loop model is shown in Figure 11.35. We will design the system for this second-order model and then test the system response for both the second-order and third-order models.

First, we select the two state variables as $x_{1}(t)=y(t)$ and $x_{2}(t)=d y(t) / d t=$ $d x_{1}(t) / d t$, as shown in Figure 11.36. It is practical to measure these variables as the position and velocity of the reader head. We then add the state variable feedback, as shown in Figure 11.36. We choose $K_{1}=1$, since our goal is for $y(t)$ to closely and accurately follow the command $r(t)$. The state variable differential equation for the open-loop system is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
0 & -20
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
5 K_{a}
\end{array}\right] r(t) .
$$

The closed-loop state variable differential equation obtained from Figure 11.36 is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-5 K_{1} K_{a} & -\left(20+5 K_{2} K_{a}\right)
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
5 K_{a}
\end{array}\right] r(t) .
$$

FIGURE 11.35

Open-loop model of head control system.
FIGURE 11.36

Closed-loop system with feedback of the two state variables.
Table 11.2 Disk Drive Control System Specifications and Actual Performance

\begin{tabular}{llll}
$\begin{array}{l}\text { Performance } \\
\text { Measure }\end{array}$ & $\begin{array}{l}\text { Desired } \\
\text { Value }\end{array}$ & $\begin{array}{l}\text { Response for } \\
\text { Second-Order } \\
\text { Model }\end{array}$ & $\begin{array}{l}\text { Response for } \\
\text { Third-Order } \\
\text { Model }\end{array}$ \\
\hline Percent overshoot & $<5 \%$ & $<1 \%$ & $0 \%$ \\
$\begin{array}{l}\text { Settling time } \\
\begin{array}{l}\text { Maximum response for a } \\
\text { unit step disturbance }\end{array}\end{array}$ & $<50 \mathrm{~ms}$ & $34.3 \mathrm{~ms}$ & $34.2 \mathrm{~ms}$ \\
\hline
\end{tabular}
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0862.jpg?height=718&width=1270&top_left_y=618&top_left_x=506)

The characteristic equation of the closed-loop system is

$$
s^{2}+\left(20+5 K_{2} K_{a}\right) s+5 K_{a}=0
$$

since $K_{1}=1$. In order to achieve the specifications, we select $\zeta=0.90$ and $\zeta \omega_{n}=125$. Then the desired closed-loop characteristic equation is

$$
s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}=s^{2}+250 s+19290=0 .
$$

Therefore, we require that $5 K_{a}=19290$ or $K_{a}=3858$. Furthermore, we require that

$$
20+5 K_{2} K_{a}=250
$$

or $K_{2}=0.012$.

The system with the second-order model has the desired response and meets all the specifications, as shown in Table 11.2. If we add the field inductance $L=1 \mathrm{mH}$, we have a third-order model with

$$
G_{1}(s)=\frac{5000}{s+1000}
$$

Using this model, which incorporates the field inductance, we test the response of the system with the feedback gains selected for the second-order model. The results are provided in Table 11.2, illustrating that the second-order model is a very good model of the system. The actual results of the third-order system meet the specifications.

\subsection{SUMMARY}

In this chapter, the design of control systems in the time domain was examined. The three-step design procedure for constructing state variable compensators was presented. The optimal design of a system using state variable feedback and an integral performance index was considered. Also, the $s$-plane design of systems utilizing state variable feedback was examined. Finally, internal model design was discussed.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 11.37 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0863.jpg?height=196&width=845&top_left_y=1031&top_left_x=603)

FIGURE 11.37 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. A system is said to be controllable on the interval $\left[t_{0}, t_{f}\right]$ if there exists a continuous input $u(t)$ such that any initial state $\mathbf{x}\left(t_{0}\right)$ can be transformed to any arbitrary state $\mathbf{x}\left(t_{f}\right)$ in a finite interval $t_{f}-t_{0}>0$. True or False

2. The poles of a system can be arbitrarily assigned through full-state feedback if and only if the system is completely controllable and observable.

True or False

3. The problem of designing a compensator that provides asymptotic tracking of a reference input with zero steady-state error is called state-variable feedback.

True or False

4. Optimal control systems are systems whose parameters are adjusted so that the performance index reaches an extremum value.

True or False

5. Ackerman's formula is used to check observability of a system.

True or False

6. Consider the system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{cc}
0 & 1 \\
0 & -4
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
2
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
0 & 2
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

The system is:

a. Controllable, observable

b. Not controllable, not observable

c. Controllable, not observable

d. Not controllable, observable

7. Consider the system

$$
G(s)=\frac{10}{s^{2}(s+2)\left(s^{2}+2 s+5\right)} .
$$

This system is:

a. Controllable, observable

b. Not controllable, not observable

c. Controllable, not observable

d. Not controllable, observable

8. A system has the state variable representation

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{ccc}
-1 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & -5
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
1 \\
1
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ccc}
1 & 2 & -1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine the associated transfer function model $G(s)=\frac{Y(s)}{U(s)}$.
a. $G(s)=\frac{5 s^{2}+32 s+35}{s^{3}+9 s^{2}+23 s+15}$
b. $G(s)=\frac{5 s^{2}+32 s+35}{s^{4}+9 s^{3}+23 s+15}$
c. $G(s)=\frac{2 s^{2}+16 s+22}{s^{3}+9 s^{2}+23 s+15}$
d. $G(s)=\frac{5 s+32}{s^{2}+32 s+9}$

9. Consider the closed-loop system in Figure 11.37, where

$$
\mathbf{A}=\left[\begin{array}{ccc}
-12 & -10 & -5 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
1 \\
0 \\
0
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ccc}
3 & 5 & -5
\end{array}\right] .
$$

Determine the state-variable feedback control gain matrix $\mathbf{K}$ so that the closed-loop system poles are $s=-3,-4$, and -6 .
a. $\mathbf{K}=\left[\begin{array}{lll}1 & 44 & 67\end{array}\right]$
b. $\mathbf{K}=\left[\begin{array}{lll}10 & 44 & 67\end{array}\right]$
c. $\mathbf{K}=\left[\begin{array}{lll}44 & 1 & 1\end{array}\right]$
d. $\mathbf{K}=\left[\begin{array}{lll}1 & 67 & 44\end{array}\right]$

10. Consider the system depicted in the block diagram in Figure 11.38.

This system is:

a. Controllable, observable

b. Not controllable, not observable c. Controllable, not observable

d. Not controllable, observable

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0865.jpg?height=320&width=1061&top_left_y=296&top_left_x=448)

FIGURE 11.38 Two-loop feedback control system.

11. A system has the transfer function

$$
T(s)=\frac{s+a}{s^{4}+6 s^{3}+12 s^{2}+12 s+6} .
$$

Determine the values of $a$ that render the system unobservable.

a. $a=1.30$ or $a=-1.44$

b. $a=3.30$ or $a=1.44$

c. $a=-3.30$ or $a=-1.44$

d. $a=-5.7$ or $a=-2.04$

12. Consider the closed-loop system in Figure 11.37, where

$$
\mathbf{A}=\left[\begin{array}{cc}
-7 & -10 \\
1 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
1 \\
0
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}
0 & 1
\end{array}\right]
$$

Determine the state variable feedback control gain matrix $\mathrm{K}$ for a zero steady-state tracking error to a step input.
a. $\mathbf{K}=\left[\begin{array}{ll}3 & -9\end{array}\right]$
b. $\mathbf{K}=\left[\begin{array}{ll}3 & -6\end{array}\right]$
c. $\mathbf{K}=\left[\begin{array}{ll}-3 & 2\end{array}\right]$
d. $\mathbf{K}=\left[\begin{array}{ll}-1 & 4\end{array}\right]$

13. Consider the system where

$$
\mathbf{A}=\left[\begin{array}{cc}
-3 & 0 \\
1 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
1 \\
0
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}
0 & 1
\end{array}\right] .
$$

It is desired to place the observer poles at $s_{1,2}=-3 \pm j 3$. Determine the appropriate state-variable feedback control gain matrix $\mathbf{L}$.
a. $\mathbf{L}=\left[\begin{array}{c}-9 \\ 3\end{array}\right]$
b. $\mathbf{L}=\left[\begin{array}{l}9 \\ 3\end{array}\right]$
c. $\mathbf{L}=\left[\begin{array}{l}3 \\ 9\end{array}\right]$
d. None of the above 14. A feedback system has a state-space representation

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
-75 & 0 \\
1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & 3600
\end{array}\right] \mathbf{x}(t),
\end{aligned}
$$

where the feedback is $u(t)=-\mathbf{K x}+r(t)$. The control system design specifications are: (i) the overshoot to a step input approximately P.O. $\approx 6 \%$, and (ii) the settling time $T_{s} \approx 0.1 \mathrm{~s}$. A state variable feedback gain matrix which satisfies the specifications is:
a. $\mathbf{K}=\left[\begin{array}{ll}10 & 200\end{array}\right]$
b. $\mathbf{K}=\left[\begin{array}{ll}6 & 3600\end{array}\right]$
c. $\mathbf{K}=\left[\begin{array}{ll}3600 & 10\end{array}\right]$
d. $\mathbf{K}=\left[\begin{array}{ll}100 & 40\end{array}\right]$

15. Consider the system

$$
Y(s)=G(s) U(s)=\left[\frac{1}{s^{2}}\right] U(s) .
$$

Determine the eigenvalues of the closed-loop system when utilizing state variable feedback, where $u(t)=-2 x_{2}(t)-2 x_{1}(t)+r(t)$. We define $x_{1}(t)=y(t), x_{2}(t)=\dot{x}_{1}(t)$, and $r(t)$ is a reference input.
a. $s_{1}=-1+j 1 \quad s_{2}=-1-j 1$
b. $s_{1}=-2+j 2 \quad s_{2}=-2-j 2$
c. $s_{1}=-1+j 2 \quad s_{2}=-1-j 2$
d. $s_{1}=-1 \quad s_{2}=-1$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Stabilizing controller Occurs when the control signal for the process is a direct function of all the state variables.

b. Controllability matrix

c. Stabilizable

d. Command following

e. State variable feedback

f. Full-state feedback control law

g. Observer

h. Linear quadratic regulator

i. Optimal control system
A system in which any initial state $\mathbf{x}\left(t_{0}\right)$ is uniquely determined by observing the output $y(t)$ on the interval $\left[t_{0}, t_{f}\right]$.

A system in which there exists a continuous input $u(t)$ such that any initial state $\mathbf{x}\left(t_{0}\right)$ can be driven to any arbitrary trial state $\mathbf{x}\left(t_{f}\right)$ in a finite time interval $t_{f}-t_{0}>0$.

A system whose parameters are adjusted so that the performance index reaches an extremum value.

An important aspect of control system design wherein a nonzero reference input is tracked.

A linear system is (completely) controllable if and only if this matrix has full rank.

A system in which the states that are unobservable are naturally stable.

The difference between the actual state and the estimated state.

A control law of the form $u(t)=-\mathbf{K x}(t)$ where $\mathbf{x}(t)$ is the state of the system assumed known at all times. j. Detectable

k. Controllable system

I. Pole placement

m. Estimation error

n. Kalman state-space decomposition

o. Observable system

p. Separation principle

q. Observability matrix
A partition of the state space that illuminates the states that are controllable and unobservable, uncontrollable and unobservable, controllable and observable, and uncontrollable and observable.

An optimal controller designed to minimize a quadratic performance index.

A linear system is (completely) observable if and only if this matrix has full rank.

A dynamic system used to estimate the state of another dynamic system given knowledge of the system inputs and measurements of the system outputs.

A design methodology wherein the objective is to place the eigenvalues of the closed-loop system in desired regions of the complex plane.

The principle that states that the full-state feedback law and the observer can be designed independently and when connected will function as an integrated control system in the desired manner (that is, stable).

A system in which the states that are not controllable are naturally stable.

A controller that stabilizes the closed-loop system.

\section{EXERCISES}

E11.1 The ability to balance actively is a key ingredient in the mobility of a device that hops and runs on one springy leg, as shown in Figure E11.1 [8]. The control of the attitude of the device uses a gyroscope and a feedback such that $u(t)=\mathbf{K} \mathbf{x}(t)$, where

$$
\mathbf{K}=\left[\begin{array}{cc}
-k & 0 \\
0 & -3 k
\end{array}\right] \text {, }
$$

and

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-2 & 0
\end{array}\right] \text { and } \mathbf{B}=\mathbf{I} \text {. }
$$

Determine a value for $k$ so that the response of each hop is critically damped.

E11.2 A magnetically suspended steel ball can be described by the linear equation

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & 1 \\
9 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0867.jpg?height=804&width=515&top_left_y=1247&top_left_x=975)

FIGURE E11.1 Single-leg control. The state variables are $x_{1}(t)=$ position and $x_{2}(t)=$ velocity. Select a feedback so that the settling time (with a $2 \%$ criterion) is $T_{s}=4 \mathrm{~s}$ and $P . O . \leq 10 \%$ to a unit step input. Choose the feedback in the form

$$
u(t)=-k_{1} x_{1}(t)-k_{2} x_{2}(t)+r(t)
$$

where $r(t)$ is the reference input and the gains $k_{1}$ and $k_{2}$ are to be determined.

E11.3 A system is described by the matrix equations

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & -1 \\
-4 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
2 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine whether the system is controllable and observable.

Answer: controllable and observable

E11.4 A system is described by the matrix equations

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
2 & 0 \\
0 & 1
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine whether the system is controllable and observable.

E11.5 A system is described by the matrix equations

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-1 & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}
-2 \\
1
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine whether the system is controllable and observable.

E11.6 A system is described by the matrix equations

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rr}
4 & 5 \\
0 & -7
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine whether the system is controllable and observable.

Answer: uncontrollable and unobservable

E11.7 Consider the system represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A} \mathbf{x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{rr}
-5 & -8 \\
1 & 0
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
2 \\
0
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{ll}
-1 & 3
\end{array}\right], \quad \text { and } \quad \mathbf{D}=[0] .
\end{aligned}
$$

Sketch a block diagram model of the system.

E11.8 Consider the third-order system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rrr}
0 & 0 & 1 \\
1 & 0 & 0 \\
-7 & -1 & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}
4 \\
-1 \\
9
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{lll}
12 & 4 & 3
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Sketch a block diagram model of the system.

E11.9 Consider the second-order system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
1 & -3 \\
-4 & 1
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
k_{1} \\
k_{2}
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

For what values of $k_{1}$ and $k_{2}$ is the system completely controllable?

E11.10 Consider the block diagram model in Figure E11.10. Write the corresponding state variable model in the form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C} \mathbf{x}(t)+\mathbf{D} u(t) .
\end{aligned}
$$

FIGURE E11.10

State variable block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0868.jpg?height=536&width=1120&top_left_y=1581&top_left_x=517)

E11.11 Consider the system shown in block diagram form in Figure E11.11. Obtain a state variable representation of the system. Determine if the system is controllable and observable.

E11.12 Consider a single-input, single-output system that is described by

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t),
\end{gathered}
$$

where

$$
\mathbf{A}=\left[\begin{array}{rr}
0 & 1 \\
-8 & -6
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
2
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right]
$$

Compute the corresponding transfer function representation of the system. If the initial conditions are zero (i.e., $x_{1}(0)=0$ and $\left.x_{2}(0)=0\right)$, determine the response when $u(t)$ is a unit step input for $t \geq 0$.
FIGURE E11.11

State variable block diagram with a

feedforward term.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0869.jpg?height=470&width=1019&top_left_y=541&top_left_x=375)

\section{PROBLEMS}

P11.1 A first-order system is represented by the time-domain differential equation

$$
\dot{x}(t)=x(t)+u(t) .
$$

A feedback controller is to be designed such that

$$
u(t)=-2 k x(t),
$$

and the desired equilibrium condition is $x(t)=0$ as $t \rightarrow \infty$. The performance integral is defined as

$$
J=\int_{0}^{\infty} x^{2} d t,
$$

and the initial value of the state variable is $x(0)=3$. Obtain the value of $k$ in order to make $J$ a minimum. Is this $k$ physically realizable? Select a practical value for the gain $k$, and evaluate the performance index with that gain. Is the system stable without the feedback due to $u(t)$ ?

P11.2 To account for the expenditure of energy and resources, the control signal is often included in the performance integral. Then the operation will not involve an unlimited control signal $u(t)$. One suitable performance index, which includes the effect of the magnitude of the control signal, is

$$
J=\int_{0}^{\infty}\left(x^{2}(t)+\lambda u^{2}(t)\right) d t .
$$

a. Repeat Problem P11.1 for the performance index.

b. If $\lambda=0.5$, obtain the value of $k$ that minimizes the performance index. Calculate the resulting minimum value of $J$.

P11.3 An unstable robot system is described by the vector differential equation [9]

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
1 & 0 \\
0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t),
$$

where $\mathbf{x}(t)=\left(x_{1}(t)=x_{2}(t)\right)^{T}$. Both state variables are measurable, and so the control signal is set as $u(t)=$ $-k\left(x_{1}(t)+x_{2}(t)\right)$. Design the gain $k$ so that the performance index

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t
$$

is minimized. Evaluate the minimum value of the performance index. Determine the sensitivity of the performance to a change in $k$. Assume that the initial conditions are

$$
\mathbf{x}(0)=\left(\begin{array}{l}
0 \\
1
\end{array}\right) .
$$

Is the system stable without the feedback signals due to $u(t)$ ? P11.4 Consider the system

$$
\dot{\mathbf{x}}(t)=[\mathbf{A}-\mathbf{B K}] \mathbf{x}(t)=\mathbf{H} \mathbf{x}(t),
$$

where $\mathbf{H}=\left[\begin{array}{cc}0 & 1 \\ -k & -k\end{array}\right]$. Determine the feedback gain $k$ that minimizes the performance index

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t
$$

when $\mathbf{x}^{T}(0)=\left[\begin{array}{ll}2, & -1\end{array}\right]$. Plot the performance index $J$ versus the gain $k$.

P11.5 Consider the system described by

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t),
$$

where $\mathbf{x}(t)=\left(x_{1}(t), x_{2}(t)\right)^{T}$,

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right]
$$

The state feedback of the system is $u(t)=-k_{1} x_{1}(t)$ $-k_{2} x_{2}(t)$, where $k_{1}=3 k$ and $k_{2}=k, k>0$. Given the initial condition $\mathbf{x}(0)=(0,1)^{T}$, and determine the gain $k$ to minimize the performance index

$$
J=\int_{0}^{\infty}\left(\mathbf{x}^{T}(t) \mathbf{x}(t)+u^{T}(t) u(t)\right) d t .
$$

Plot the function $J(k)$.

P11.6 For the solutions of Problems P11.3, P11.4, and P11.5, determine the roots of the closed-loop optimal control system. Note that the resulting closed-loop roots depend on the performance index selected.

P11.7 A system has the vector differential equation

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

where

$$
\mathbf{A}=\left[\begin{array}{ll}
0 & 1 \\
0 & 0
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right]
$$

We want both state variables to be used in the feedback so that $u(t)=-k_{1} x_{1}(t)+k_{2} x_{2}(t)$. Also, we desire to have a natural frequency $\omega_{n}=3$. Find a set of gains $k_{1}$ and $k_{2}$ in order to achieve an optimal system when $J$ is given by

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t)+u^{T}(t) u(t) d t .
$$

Assume $\mathbf{x}^{T}(0)=\left[\begin{array}{ll}1, & 0\end{array}\right]$.

P11.8 For the system of P11.7, determine the optimum value for $k_{2}$ when $k_{1}=0.25$, and $\mathbf{x}^{T}(0)=\left[\begin{array}{ll}1, & 0\end{array}\right]$.

P11.9 An interesting mechanical system with a challenging control problem is the ball and beam, shown in Figure P11.9(a) [10]. It consists of a rigid beam that is free to rotate in the plane of the paper around a center pivot, with a solid ball rolling along a groove in the top of the beam. The control problem is to position the ball at a desired point on the beam using a torque applied to the beam as a control input at the pivot.

A linear model of the system with a measured value of the angle $\phi(t)$ and its angular velocity $\phi=\omega(t)$ is available. Select a feedback scheme so that the response of the closed-loop system has a percent overshoot of P.O. $=5 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s}=1.5 \mathrm{~s}$ for a step input.

P11.10 The dynamics of a rocket are represented by

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{ll}
0 & 0 \\
1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t),
\end{aligned}
$$

and state variable feedback is used, where $u(t)=-7 x_{1}(t)-12 x_{2}(t)+r(t)$. Determine the roots of the characteristic equation of this system and the response of the system when the initial conditions are $x_{1}(0)=1$ and $x_{2}(0)=-1$. Assume the reference input $r(t)=0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0870.jpg?height=193&width=478&top_left_y=1491&top_left_x=782)

(a)

FIGURE P11.9

(a) Ball and beam.

(b) Model of the ball and beam.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0870.jpg?height=294&width=1018&top_left_y=1772&top_left_x=507)

(b) P11.11 The state variable model of a plant to be controlled is

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rr}
-7 & -1 \\
4 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0.2 \\
0
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
0 & 1
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

Use state variable feedback, and incorporate a command input $u(t)=-\mathbf{K x}(t)+\alpha r(t)$. Select the gains $\mathbf{K}$ and $\alpha$ so that the system has a rapid response with a percent overshoot of P.O. $=1 \%$, a settling time (with a $2 \%$ criterion) of $T_{s} \leq 1 \mathrm{~s}$, and a zero steadystate error to a unit step input.

P11.12 A voice-coil actuator-driven electromechanical system has the following state-space model:

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A} \mathbf{x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t),
\end{gathered}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{cccc}
-1.4890 & -0.7681 & -0.0945 & -0.0424 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0
\end{array}\right], \\
& \mathbf{B}=\left[\begin{array}{l}
1 \\
0 \\
0 \\
0
\end{array}\right], \text { and } \mathbf{C}=\left[\begin{array}{llll}
0 & 0 & 0 & 1
\end{array}\right] .
\end{aligned}
$$

Compute the transfer function and the poles of this system.

Determine whether it is controllable and observable.

P11.13 A feedback system has a plant transfer function

$$
\frac{Y(s)}{R(s)}=G(s)=\frac{45.78}{s(s+50)} .
$$

We want the percent overshoot to a step to be P.O. $\leq 10 \%$ and the settling time (with a $2 \%$ criterion) $T_{s} \leq 1 \mathrm{~s}$. Design an appropriate state variable feedback system for $r(t)=-k_{1} x_{1}(t)-k_{2} x_{2}(t)$.

P11.14 A process has the transfer function

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
-8 & 0 \\
1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
-1 & 1
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

Determine the state variable feedback gains to achieve a settling time (with a $2 \%$ criterion) of $T_{S}=1.5 \mathrm{~s}$ and a percent overshoot of P.O. $=8 \%$. Assume the complete state vector is available for feedback.
P11.15 A telerobot system has the matrix equations [16]

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
-5 & 1 & 0 \\
0 & -1 & 1 \\
0 & 0 & -6
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
1 \\
0
\end{array}\right] u(t) \\
y(t)=\left[\begin{array}{lll}
3 & 1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{gathered}
$$

(a) Determine the transfer function, $G(s)=Y(s) /$ $U(s)$. (b) Draw the block diagram indicating the state variables. (c) Determine whether the system is controllable. (d) Determine whether the system is observable.

P11.16 Hydraulic power actuators were used to drive the dinosaurs of the movie Jurassic Park [20]. The motions of the large monsters required high-power actuators requiring 1200 watts.

One specific limb motion has dynamics represented by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rr}
-3 & 0 \\
1 & -1
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
0
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

We want to place the closed-loop poles at $s=-5 \pm j$. Determine the required state variable feedback using Ackermann's formula. Assume that the complete state vector is available for feedback.

P11.17 A system has a transfer function

$$
\frac{Y(s)}{R(s)}=\frac{s^{2}+a s+b}{s^{4}+12 s^{3}+48 s^{2}+72 s+52} .
$$

Determine real values of $a$ and $b$ so that the system is either uncontrollable or unobservable.

P11.18 A system has a plant

$$
\frac{Y(s)}{U(s)}=G(s)=\frac{1}{(s+2)^{2}} .
$$

(a) Find the matrix differential equation to represent this system. Identify the state variables on a block diagram model. (b) Select a state variable feedback structure using $u(t)$, and select the feedback gains so that the response $y(t)$ of the unforced system is critically damped when the initial condition is $x_{1}(0)=1$ and $x_{2}(0)=0$, where $x_{1}=y(t)$. The repeated roots are at $s=-3$.

P11.19 The block diagram of a system is shown in Figure P11.19. Determine whether the system is controllable and observable.

P11.20 Consider the automatic ship-steering system. The state variable form of the system differential equation is

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{cccc}
-0.06 & -5 & 0 & 0 \\
-0.01 & -0.2 & 0 & 0 \\
1 & 0 & 0 & 10 \\
0 & 1 & 0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
-0.1 \\
0.05 \\
0 \\
0
\end{array}\right] \delta(t), \\
y(t) & =\left[\begin{array}{llll}
0 & 0 & 10 & 0
\end{array}\right] \mathbf{x}(t)
\end{aligned}
$$

FIGURE P11.19

Multiloop feedback control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0872.jpg?height=332&width=1066&top_left_y=154&top_left_x=516)

where $\mathbf{x}^{T}(t)=\left[\begin{array}{llll}v(t) & \omega_{s}(t) & y(t) & \theta(t)\end{array}\right]$. The state variables are $x_{1}(t)=v(t)=$ the transverse velocity; $x_{2}(t)=\omega_{s}(t)=$ angular rate of ship's coordinate frame relative to response frame; $x_{3}(t)=y(t)=$ deviation distance on an axis perpendicular to the track; $x_{4}(t)=\theta(t)=$ deviation angle. (a) Determine whether the system is stable. (b) Feedback can be added so that

$$
\delta(t)=-k_{1} x_{1}(t)-k_{3} x_{3}(t)+r(t) .
$$

Determine whether this system is stable for suitable values of $k_{1}$ and $k_{3}$. If so, determine $k_{1}$ and $k_{3}$ such that the percent overshoot P.O. $\leq 25 \%$ to a unit step, $R(s)=1 / \mathrm{s}$ and $T_{S} \leq 20 \mathrm{~s}$.

P11.21 An op-amp circuit is shown in Figure P11.21 with input $u(t)=v_{i}(t)$, and output $y(t)=v_{0}(t)$.

a. Determine the system transfer function.

b. Select the state variables, and write the state equations for this system.

c. Determine its observability, and find the condition when the system has a double root.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0872.jpg?height=640&width=513&top_left_y=1371&top_left_x=350)

FIGURE P11.21 An op-amp circuit.
P11.22 The speed control system of an electric car has a plant transfer function of

$$
G(s)=\frac{1}{s(0.2 s+1)}
$$

in the open loop and a negative feedback transfer function of $H(s)=k$ with a reference input of $r(t)$ and an output $y(t)$.

a. Represent the system in the block diagram for unity feedback systems by scaling the input, and write the corresponding vector differential equation for this system.

b. The system uses state variable feedback with a feedback signal from the output derivative $\dot{y}(t)$ with gain $b$. Design $k$ and $b$ so that the car speed has a settling time of $0.5 \mathrm{~s}$ and a percent overshoot of $10 \%$.

c. Plot the response of the state variable feedback system to a step input.

P11.23 Let

$$
\mathbf{A}=\left[\begin{array}{rr}
-1 & 2 \\
0 & 1
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{r}
-1 \\
1
\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right]
$$

and $\mathbf{D}=[0]$. Then design a controller using internal model methods so that the steady-state error for a step input is zero and the desired roots of the characteristic equation are $s=-2 \pm 2 j$ and $s=-20$.

P11.24 Let $\mathbf{A}=\left[\begin{array}{ll}0 & 1 \\ 0 & 0\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}0 \\ 1\end{array}\right], \quad \mathbf{C}=\left[\begin{array}{ll}1 & 0\end{array}\right]$ and $\mathbf{D}=[0]$. Then design a controller using internal model methods so that the steady-state error for a ramp input is zero and the roots of the characteristic equation are $s=-2 \pm j 2, s=-2$, and $s=-1$.

P11.25 Consider the system represented in state variable form

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t)+\mathbf{D} u(t),
\end{gathered}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{rr}
1 & 4 \\
-5 & 10
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{ll}
1 & -4
\end{array}\right] \text { and } \mathbf{D}=[0] .
\end{aligned}
$$

Verify that the system is observable. Then design a full-state observer by placing the observer poles at $s_{1,2}=-1$. Plot the response of the estimation error $\mathbf{e}(t)=\mathbf{x}(t)-\hat{\mathbf{x}}(t)$ with an initial estimation error of $\mathbf{e}(0)=[1,1]^{T}$.

P11.26 Consider the second-order system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-1 & -2 & -6
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
7
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{lll}
5 & -4 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t)
\end{aligned}
$$

Verify that the system is observable. If so, determine the observer gain matrix required to place the observer poles at $s_{1,2}=-2 \pm j 3$ and $s_{3}=-6$.

P11.27 Consider the second-order system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-5 & -9
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
4
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
2 & 1
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

Determine the observer gain matrix required to place the observer poles at $s_{1,2}=-1 \pm j 2$.

P11.28 Consider the single-input, single-output system is described by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-16 & -8
\end{array}\right], \mathbf{B}=\left[\begin{array}{c}
0 \\
K
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right]
$$

a. Determine the value of $K$ resulting in a zero steady-state tracking error when $u(t)$ is a unit step input for $t \geq 0$. The tracking error is defined here as $e(t)=u(t)-y(t)$.

b. Plot the response to a unit step input and verify that the tracking error is zero for the gain $K$ determined in part (a).

P11.29 The block diagram shown in Figure P11.29 is an example of an interacting system. Determine a state variable representation of the system in the form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t)
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0873.jpg?height=527&width=628&top_left_y=675&top_left_x=933)

FIGURE P11.29 Interacting feedback system.

\section{ADVANCED PROBLEMS}

AP11.1 A DC motor control system has the form shown in Figure AP11.1 [6]. The three state variables are available for measurement; the output position is $x_{1}(t)$. Select the feedback gains so that the system has a steady-state error equal to zero for a step input and a response with a percent overshoot of P.O. $\leq 4 \%$.
AP11.2 A system has the model

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
-5 & -2 & -1 \\
-1 & 0 & 0 \\
0 & 1 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
16 \\
0 \\
0
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{lll}
0 & 0 & 10
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Add state variable feedback so that the closed-loop poles are $s=-2 \pm 2 j$ and $s=-20$.
FIGURE AP11.1 Field-controlled DC motor.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0873.jpg?height=146&width=1228&top_left_y=1938&top_left_x=374)

AP11.3 A system has a matrix differential equation

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-2 & -3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
b_{1} \\
2 b_{2}
\end{array}\right] u(t) .
$$

What values for $b_{1}$ and $b_{2}$ are required so that the system is controllable?

AP11.4 The vector differential equation describing the inverted pendulum of Example 3.3 is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrrr}
0 & 1 & 0 & 0 \\
0 & 0 & -1 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 9.8 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}
0 \\
1 \\
0 \\
-1
\end{array}\right] u(t) .
$$

Assume that all state variables are available for measurement, and use state variable feedback. Place the system characteristic roots at $s=-5 \pm j 2,-3$, and -3 .

AP11.5 An automobile suspension system has three physical state variables, as shown in Figure AP11.5 [13]. The state variable feedback structure is shown in the figure, with $K_{1}=1$. Select $K_{2}$ and $K_{3}$ so that the roots of the characteristic equation are three real roots lying between $s=-3$ and $s=-6$. Also, select $K_{p}$ so that the steady-state error for a step input is equal to zero.

AP11.6 A system is represented by the differential equation

$$
\ddot{y}(t)+4 \dot{y}(t)+4 y(t)=\dot{u}(t)+2 u(t),
$$

where $y(t)=$ output and $u(t)=$ input.

(a) Define the state variables as $x_{1}(t)=y(t)$ and $x_{2}(t)$ $=\dot{y}(t)$. Develop a state variable representation and show that it is a controllable system. (b) Define the state variables as $x_{1}(t)=y(t)$ and $x_{2}(t)=\dot{y}(t)-u(t)$. Develop a state variable represetation and determine whether the system is controllable. (c) Explain why the system controllability differs in these two cases.

AP11.7 The Radisson Diamond uses pontoons and stabilizers to damp out the effect of waves hitting the ship, as shown in Figure AP11.7(a). The block diagram of the ship roll control system is shown in Figure AP11.7(b).
Determine the feedback gains $K_{2}$ and $K_{3}$ so that the characteristic roots are $s=-15$ and $s=-2 \pm j 2$. Plot the roll angle for a unit step disturbance.

AP11.8 Consider the system

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$

where

$$
\mathbf{A}=\left[\begin{array}{rcc}
-1 & 1.6 & 0 \\
0 & 0 & 1 \\
0 & 0 & -11.8
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{c}
0 \\
0 \\
8333.0
\end{array}\right]
$$

(a) Design a state variable controller using only $x_{1}(t)$ as the feedback variable, so that the step response has a percent overshoot of P.O. $\leq 10 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 5 \mathrm{~s}$. (b) Design a state variable controller feedback using two state variables, level $x_{1}(t)$ and shaft position $x_{2}(t)$, to satisfy the specifications of part (a). (c) Compare the results of parts (a) and (b).

AP11.9 The motion control of a lightweight hospital transport vehicle can be represented by a system of two masses, as shown in Figure AP11.9, where $m_{1}=m_{2}=1$ and $k_{1}=k_{2}=1$ [21]. (a) Determine the state vector differential equation. (b) Find the roots of the characteristic equation. (c) We wish to stabilize the system by letting $u(t)=-k x_{i}(t)$, where $u$ is the force on the lower mass, and $x_{i}(t)$ is one of the state variables. Select an appropriate state variable $x_{i}(t)$. (d) Choose a value for the gain $k$ and sketch the root locus as $k$ varies.

AP11.10 Consider the inverted pendulum mounted to a motor, as shown in Figure AP11.10. The motor and load are assumed to have no friction damping. The pendulum to be balanced is attached to the horizontal shaft of a servomotor. The servomotor carries a tachogenerator, so that a velocity signal is available, but there is no position signal. When the motor is unpowered, the pendulum will hang vertically downward and, if slightly disturbed, will perform oscillations. If lifted to the top of its arc,
FIGURE AP11.5

Automobile suspension system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0874.jpg?height=402&width=1282&top_left_y=1685&top_left_x=502)



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0875.jpg?height=341&width=1159&top_left_y=159&top_left_x=406)

(a)

FIGURE AP11.7

(a) Radisson

Diamond.

(b) Control system to reduce the effect of the disturbance.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0875.jpg?height=447&width=1230&top_left_y=600&top_left_x=373)

(b)

the pendulum is unstable in that position. Devise a feedback compensator using only the velocity signal from the tachometer.

AP11.11 Determine an internal model controller $G_{c}(s)$ for the system shown in Figure AP11.11. We want the steady-state error to a step input to be zero. We also want the settling time (with a $2 \%$ criterion) to be $T_{s} \leq 5 \mathrm{~s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0875.jpg?height=519&width=275&top_left_y=1514&top_left_x=333)

FIGURE AP11.10 Motor and inverted pendulum.

AP11.12 A fourth-order system has the model.

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C} \mathbf{x}(t),
\end{gathered}
$$

where

$$
\begin{aligned}
\mathbf{A} & =\left[\begin{array}{rrrr}
-2.4762 & 3.3755 & -0.0225 & -2.5811 \\
-0.9504 & -2.1473 & -2.1050 & -3.5917 \\
2.1847 & 1.0792 & -3.4821 & -0.1983 \\
3.5185 & 2.3825 & 1.2432 & -1.6509
\end{array}\right], \\
\mathbf{B} & =\left[\begin{array}{c}
0.2916 \\
0.1978 \\
0 \\
0
\end{array}\right], \quad \text { and } \mathbf{C}=\left[\begin{array}{llll}
0 & 0 & 0 & 1
\end{array}\right] .
\end{aligned}
$$

FIGURE AP11.9 Model of hospital vehicle. What are the poles of the open-loop system? By using the state variable feedback control $u(t)=-\mathbf{K x}(t)$, determine matrix $\mathbf{K}$ to place the closed-loop poles at $-1,-2,-4$, and -8 .

AP11.13 Consider the system represented in state variable form

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A} \mathbf{x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{rr}
1 & 7 \\
-6 & -3
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}
5 \\
1
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{ll}
8 & 1
\end{array}\right], \quad \text { and } \quad \mathbf{D}=[0] .
\end{aligned}
$$

Verify that the system is observable and controllable. If so, design a full-state feedback law and an observer by placing the closed-loop system poles at $s_{1,2}=-2 \pm j 2$ and the observer poles at $s_{1,2}=-13$.

AP11.14 Consider the third-order system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-10 & -2 & -2
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
0 \\
6
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{lll}
1 & -5 & 3
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

Verify that the system is observable and controllable. Then, design a full-state feedback law and an observer by placing the closed-loop system poles at $s_{1,2}=-4 \pm j 1, s_{3}=-5$ and the observer poles at $s_{1,2}=-10 \pm j 5, s_{3}=-25$.

AP11.15 Consider the system depicted in Figure AP11.15. Design a full-state observer for the system. Determine the observer gain matrix $\mathbf{L}$ to place the observer poles at $s_{1,2}=-10 \pm j 10$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0876.jpg?height=400&width=762&top_left_y=527&top_left_x=990)

FIGURE AP11.15 A second-order system block diagram.
FIGURE AP11.11

Internal model control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0876.jpg?height=371&width=1249&top_left_y=1235&top_left_x=519)

\section{DESIGN PROBLEMS}

CDP11.1 We wish to obtain a state variable feedback system for the capstan-slide the state variable model developed in CDP3.1 and determine the feedback system. The step response should have a percent overshoot of P.O. $\leq 2 \%$ and a settling time of $T_{s} \leq 250 \mathrm{~ms}$.

DP11.1 Consider the device for the magnetic levitation of a steel ball, as shown in Figures DP11.1(a) and (b). Design a feedback controller $i=-k_{1} x_{1}-k_{2} x_{2}+\beta r$ where $x_{1}(t)=y(t), x_{2}(t)=\dot{y}(t)$, and $\beta$ is selected to produce a zero steady-state error to a unit step. The goal for $y(t)$ is $P . O . \leq 10 \%$ for a unit step. Assume that $y(t)$ and $\dot{y}(t)$ are measurable.

DP11.2 The control of the fuel-to-air ratio in an automobile of prime importance as automakers work to reduce exhaust-pollution emissions. Thus, auto engine designers turned to the feedback control of the fuel-to-air ratio. A sensor was placed in the exhaust stream and used as an input to a controller. The 
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0877.jpg?height=446&width=492&top_left_y=155&top_left_x=238)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0877.jpg?height=138&width=562&top_left_y=693&top_left_x=189)

(b)

FIGURE DP11.1 (a) The levitation of a ball using an electromagnet. (b) The model of the electromagnet and the ball.

controller actually adjusts the orifice that controls the flow of fuel into the engine [3].

Select the devices and develop a linear model for the entire system. Assume that the sensor measures the actual fuel-to-air ratio with a negligible delay. With this model, determine the optimum controller when we desire a system with a zero steadystate error to a step input and a percent overshoot for a step command of P.O. $\leq 10 \%$.

DP11.3 Consider the feedback system depicted in Figure DP11.3. The system model is given by

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t) & =\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 1 \\
-10.5 & -11.3
\end{array}\right], \mathbf{B}=\left[\begin{array}{c}
0 \\
0.55
\end{array}\right], \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right] .
$$

Design the compensator to meet the following specifications:

1. The steady-state error to a unit step input is zero.

2. The settling time $T_{s}<1 \mathrm{~s}$ and the percent overshoot is P.O. $<5 \%$.

3. Select initial conditions $\mathrm{x}(0)$ and different initial conditions $\hat{\mathrm{x}}(0)$ and simulate the response of the closed-loop system to a unit step input.

DP11.4 A high-performance helicopter has a model shown in Figure DP11.4. The goal is to control the pitch angle $\theta(t)$ of the helicopter by adjusting the rotor thrust angle $\delta(t)$. The equations of motion of the helicopter are

$$
\begin{gathered}
\ddot{\theta}(t)=-\sigma_{1} \ddot{\theta}(t)-\alpha_{1} \dot{x}(t)+n \delta(t) \\
\ddot{x}(t)=g \theta(t)-\alpha_{2} \dot{\theta}(t)-\sigma_{2} \dot{x}(t)+g \delta(t),
\end{gathered}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0877.jpg?height=541&width=739&top_left_y=936&top_left_x=877)

FIGURE DP11.4 Helicopter pitch angle, $\theta$, control.
FIGURE DP11.3

Feedback system constructed to track a desired input $r(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0877.jpg?height=468&width=1075&top_left_y=1638&top_left_x=375)

where $x(t)$ is the translation in the horizontal direction. For a high-performance helicopter, we find that

$$
\begin{array}{rlrl}
\sigma_{1} & =0.415 & \alpha_{2} & =1.43 \\
\sigma_{2} & =0.0198 & n & =6.27 \\
\alpha_{1} & =0.0111 & g & =9.8
\end{array}
$$

all in appropriate SI units.

Find (a) a state variable representation of this system and (b) the transfer function representation for $\theta(s) / \delta(s)$. (c) Use state variable feedback to achieve adequate performances for the controlled system.

Desired specifications include (1) a steady-state for an input step command for $\theta_{d}(s)$, the desired pitch angle, less than $20 \%$ of the input step magnitude; (2) an overshoot for a step input command less than $20 \%$; and (3) a settling (with a $2 \%$ criterion) time for a step command of less than 1.5 seconds.

DP11.5 The headbox process is used in the manufacture of paper to transform the pulp slurry flow into a jet of $2 \mathrm{~cm}$ and then spread it onto a mesh belt [22]. To achieve desirable paper quality, the pulp slurry must be distributed as evenly as possible on the belt, and the relationship between the velocity of the jet and that of the belt, called the jet/belt ratio, must be maintained. One of the main control variables is the pressure in the headbox, which in turn controls the velocity of the slurry at the jet. The total pressure in the headbox is the sum of the liquid-level pressure and the air pressure that is pumped into the headbox. Because the pressurized headbox is a highly dynamic and coupled system, manual control would be difficult to maintain and could result in degradation in the sheet properties.

The state-space model of a typical headbox, linearized about a particular stationary point, is given by

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
-0.8 & 0.02 \\
-0.02 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0.05 \\
0.001
\end{array}\right] u(t)
$$

and $y(t)=\left[\begin{array}{ll}1, & 0\end{array}\right] \mathbf{x}(t)$.

The state variables are $x_{1}(t)=$ liquid level and $x_{2}(t)=$ pressure. The control variable is $u_{1}(t)=$ pump current. (a) Design a state variable feedback system that has a characteristic equation with real roots with a magnitude greater than five. (b) Design an observer with observer poles located at least ten times farther in the left half-plane than the state variable feedback system. (c) Connect the observer and full-state feedback system and sketch the block diagram of the integrated system.
DP11.6 A coupled-drive apparatus is shown in Figure DP11.6. The coupled drives consist of two pulleys connected via an elastic belt, which is tensioned by a third pulley mounted on springs providing an underdamped dynamic mode. One of the main pulleys, pulley $A$, is driven by an electric DC motor. Both pulleys $A$ and $B$ are fitted with tachometers that generate measurable voltages proportional to the rate of rotation of the pulley. When a voltage is applied to the DC motor, pulley $A$ will accelerate at a rate governed by the total inertia experienced by the system. Pulley $B$, at the other end of the elastic belt, will also accelerate owing to the applied voltage or torque, but with a lagging effect caused by the elasticity of the belt. Integration of the velocity signals measured at each pulley will provide an angular position estimate for the pulley [23].

The second-order model of a coupled-drive is

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-36 & -12
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
0 \\
1
\end{array}\right] u(t)
$$

and $y(t)=x_{1}(t)$.

(a) Design a state variable feedback controller that will yield a step response with deadbeat response and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 0.5 \mathrm{~s}$. (b) Design an observer for the system by placing the observer poles appropriately in the left half-plane. (c) Draw the block diagram of the system including the compensator with the observer and state feedback. (d) Simulate the response to an initial state at $\mathbf{x}(0)=\left[\begin{array}{ll}1 & 0\end{array}\right]^{T}$ and $\hat{\mathbf{x}}(0)=\left[\begin{array}{ll}0 & 0\end{array}\right]^{T}$.

DP11.7 A closed-loop feedback system is to be designed to track a reference input. The desired feedback block diagram is shown in Figure DP11.3. The system

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0878.jpg?height=586&width=367&top_left_y=1410&top_left_x=1197)

FIGURE DP11.6 FIGURE DP11.7

Feedback system constructed to track a desired input $r(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0879.jpg?height=440&width=1155&top_left_y=161&top_left_x=368)

model is given by

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
& y(t)=\mathbf{C x}(t)
\end{aligned}
$$

where

$$
\mathbf{A}=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-4 & -8 & -10
\end{array}\right], \mathbf{B}=\left[\begin{array}{l}
0 \\
0 \\
1
\end{array}\right], \mathbf{C}=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] .
$$

Design the observer and the control law to meet the following specifications:

1. The steady-state error of the closed-loop system to a unit step input is zero.

2. P.O. $\leq 20 \%$ to a unit step.

3. $T_{s} \leq 1$ s to a unit step.

4. Select initial conditions $\mathrm{x}(0)$ and different initial conditions $\hat{x}(0)$ and simulate the response of the closed-loop system to a unit step input. Verify that the tracking error is zero in the steady-state.

\section{COMPUTER PROBLEMS}

CP11.1 Consider the system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
5 & -2 & 0 \\
3 & 0 & 8 \\
-9 & 13 & 3
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}
12 \\
0 \\
-5
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{lll}
1 & 5 & 1
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Using the ctrb and obsv functions, show that the system is controllable and observable.

CP11.2 Consider the system

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-15 & -23
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{r}
0 \\
16
\end{array}\right] u(t), \\
& y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t) .
\end{aligned}
$$

Determine if the system is controllable and observable. Compute the transfer function from $u(t)$ to $y(t)$.

CP11.3 Find a gain matrix $\mathbf{K}$ so that the closed-loop poles of the system,

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\left[\begin{array}{rr}
0 & 1 \\
-6 & -5
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
1 \\
1
\end{array}\right] u(t) \\
& y(t)=\left[\begin{array}{ll}
1 & -1
\end{array}\right] \mathbf{x}(t),
\end{aligned}
$$

are $s_{1}=-2$ and $s_{2}=-5$. Use state feedback $u(t)=-\mathbf{K x}(t)$.
CP11.4 The following model has been proposed to describe the motion of a constant-velocity rocket:

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrrrr}
0 & 1 & 0 & 0 & 0 \\
-0.64 & -1.2 & 0 & 0 & 0 \\
0.6 & 0 & 0 & 0 & 0 \\
0 & 0 & 17.8 & 0 & 0 \\
0.5 & 1 & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
4.5 \\
0 \\
0 \\
0
\end{array}\right] u(t), \\
y(t)=\left[\begin{array}{lllll}
0 & 0 & 0 & 1 & 0
\end{array}\right] \mathbf{x}(t)
\end{gathered}
$$

a. Verify that the system is not controllable by analyzing the controllability matrix using the ctrb function.

b. Develop a controllable state variable model by first computing the transfer function from $u(t)$ to $y(t)$, then cancel any common factors in the numerator and denominator polynomials of the transfer function. With the modified transfer function just obtained, use the ss function to determine a modified state variable model for the system.

c. Verify that the modified state variable model in part (b) is controllable.

d. Is the constant velocity rocket stable?

e. Comment on the relationship between the controllability and the complexity of the state variable model (where complexity is measured by the number of state variables). CP11.5 A linearized model of a vertical takeoff and landing (VTOL) aircraft is [24]

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B}_{1} u_{1}(t)+\mathbf{B}_{2} u_{2}(t) .
$$

where

$$
\begin{gathered}
\mathbf{A}=\left[\begin{array}{rrrr}
-0.0523 & 0.0912 & -0.0291 & 0.3120 \\
0.0482 & -6.5100 & 0 & 5.1800 \\
0.2719 & -0.2512 & -0.7070 & 0.9170 \\
0 & 0 & 1.4200 & 0
\end{array}\right] \\
\mathbf{B}_{1}=\left[\begin{array}{r}
0.2412 \\
4.412 \\
-5.784 \\
0
\end{array}\right], \quad \mathbf{B}_{2}=\left[\begin{array}{r}
0.1571 \\
-2.212 \\
5.1200 \\
0
\end{array}\right] .
\end{gathered}
$$

The state vector components are: (i) $x_{1}(t)$ is the horizontal velocity (knots), (ii) $x_{2}(t)$ is the vertical velocity (knots), (iii) $x_{3}(t)$ is the pitch rate (degrees/second), and (iv) $x_{4}(t)$ is the pitch angle (degrees). The input $u_{1}(t)$ is used mainly to control the vertical motion, and $u_{2}(t)$ is used for the horizontal motion.

(a) Compute the eigenvalues of the system matrix A. Is the system stable? (b) Determine the characteristic polynomial associated with $\mathbf{A}$ using the poly function. Compute the roots of the characteristic equation, and compare them with the eigenvalues in part (a). (c) Is the system controllable from $u_{1}(t)$ alone? What about from $u_{2}(t)$ alone? Comment on the results.

CP11.6 In an effort to open up the far side of the Moon to exploration, studies have been conducted to determine the feasibility of operating a communication satellite around the translunar equilibrium point in the Earth-Sun-Moon system. The desired satellite orbit, known as a halo orbit, is shown in Figure CP11.6. The objective of the controller is to keep the satellite on a halo orbit trajectory that can be seen from the Earth so that the lines of communication are accessible at all times. The communication link is from the Earth to the satellite and then to the far side of the Moon.

The linearized (and normalized) equations of motion of the satellite around the translunar equilibrium point are [25]

$$
\dot{\mathbf{x}}(t)=\left[\begin{array}{cccccc}
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
7.3809 & 0 & 0 & 0 & 2 & 0 \\
0 & -2.1904 & 0 & -2 & 0 & 0 \\
0 & 0 & -3.1904 & 0 & 0 & 0
\end{array}\right] \mathbf{x}(t)
$$

$$
+\left[\begin{array}{l}
0 \\
0 \\
0 \\
1 \\
0 \\
0
\end{array}\right] u_{1}(t)+\left[\begin{array}{l}
0 \\
0 \\
0 \\
0 \\
1 \\
0
\end{array}\right] u_{2}(t)+\left[\begin{array}{l}
0 \\
0 \\
0 \\
0 \\
0 \\
1
\end{array}\right] u_{3}(t)
$$

The state vector $\mathbf{x}(t)$ is the satellite position and velocity, and the inputs $u_{i}(t), i=1,2,3$, are the engine thrust accelerations in the $\xi, \eta$, and $\zeta$ directions, respectively.

(a) Is the translunar equilibrium point a stable location? (b) Is the system controllable from $u_{1}(t)$ alone? (c) Repeat part (b) for $u_{2}(t)$. (d) Repeat part (b) for $u_{3}(t)$. (e) Suppose that we can observe the position in the $\eta$ direction. Determine the transfer function from $u_{2}(t)$ to $x_{2}(t)$. (Hint: Let $\left.y(t)=\left[\begin{array}{llllll}0 & 1 & 0 & 0 & 0 & 0\end{array}\right] \mathrm{x}(t).\right) \quad(\mathrm{f})$ Compute a state-space representation of the transfer function in part (e) using the ss function. Verify that the system is controllable. (g) Using state feedback

$$
u_{2}(t)=-\mathbf{K} \mathbf{x}(t),
$$

design a controller (i.e., find $\mathbf{K}$ ) for the system in part (f) such that the closed-loop system poles are at $s_{1,2}=-1 \pm j$ and $s_{3,4}=-10$.

CP11.7 Consider the system

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-2 & -4 & -6
\end{array}\right] \mathbf{x}(t), \\
y(t)=\left[\begin{array}{lll}
1 & 0 & 0
\end{array}\right] \mathbf{x}(t) .
\end{gathered}
$$

Suppose that we are given three observations $y\left(t_{i}\right), i=1,2,3$, as follows:

$$
\begin{aligned}
& y\left(t_{1}\right)=1 \text { at } t_{1}=0 \\
& y\left(t_{2}\right)=-0.0256 \text { at } t_{2}=2 \\
& y\left(t_{3}\right)=-0.2522 \text { at } t_{3}=4 \text {. }
\end{aligned}
$$

(a) Using the three observations, develop a method to determine the initial value of the state vector $\mathbf{x}\left(t_{0}\right)$ for the system in Equation CP11.1 that will reproduce the three observations when simulated using the Isim function. (b) With the observations given, compute $\mathbf{x}\left(t_{0}\right)$ and discuss the condition under which this problem can be solved in general. (c) Verify the result by simulating the system response to the computed initial condition. (Hint: Recall that $\mathbf{x}(t)=e^{\mathrm{A}\left(t-t_{0}\right)} \mathbf{x}\left(t_{0}\right)$ for the system in Equation CP11.1.)

CP11.8 Consider the system

$$
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t)
$$


![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0881.jpg?height=730&width=660&top_left_y=154&top_left_x=131)

FIGURE CP11.6 The translunar satellite halo orbit.

where

$$
\mathbf{A}=\left[\begin{array}{cc}
0 & 0 \\
-1 & 0
\end{array}\right] \text { and } \mathbf{B}=\left[\begin{array}{l}
0 \\
1
\end{array}\right]
$$

Let $u(t)=-\mathbf{K x}(t)$ and consider the performance index

$$
J=\int_{0}^{\infty} \mathbf{x}^{T}(t) \mathbf{x}(t) d t=\mathbf{x}^{T}(0) \mathbf{P} \mathbf{x}(0) .
$$

Determine the optimal system when $\mathbf{x}^{T}(0)=(1,0)$.

CP11.9 A first-order system is given by

$$
\dot{x}(t)=-x(t)+u(t)
$$

with the initial condition $x(0)=x_{0}$. We want to design a feedback controller

$$
u(t)=-k x(t)
$$

such that the performance index

$$
J=\int_{0}^{\infty}\left(x^{2}(t)+\lambda u^{2}(t)\right) d t
$$

is minimized.

(a) Let $\lambda=1$. Develop a formula for $J$ in terms of $k$, valid for any $x_{0}$, and use an m-file to plot $J / x_{0}^{2}$ versus $k$. From the plot, determine the approximate value of $k=k_{\min }$ that minimizes $J / x_{0}^{2}$. (b) Verify the result in part (a) analytically. (c) Using the procedure developed in part (a), obtain a plot of $k_{\min }$ versus $\lambda$, where $k_{\min }$ is the gain that minimizes the performance index.
CP11.10 Consider the system represented in state variable form

$$
\begin{aligned}
& \dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
& y(t)=\mathbf{C x}(t)+\mathbf{D} u(t),
\end{aligned}
$$

where

$$
\begin{aligned}
& \mathbf{A}=\left[\begin{array}{rr}
0 & 1 \\
-25.5 & -17.5
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{c}
8.8 \\
19.1
\end{array}\right], \\
& \mathbf{C}=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \text { and } \mathbf{D}=[0] .
\end{aligned}
$$

Using the acker function, determine a full-state feedback gain matrix and an observer gain matrix to place the closed-loop system poles at $s_{1,2}=-3$ and the observer poles at $s_{1,2}=-18 \pm j 5$.

CP11.11 Consider the third-order system

$$
\begin{aligned}
\dot{\mathbf{x}}(t) & =\left[\begin{array}{rrr}
0 & 1 & 0 \\
0 & 0 & 1 \\
-4.3 & -1.7 & -6.7
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{c}
0 \\
0 \\
0.35
\end{array}\right] u(t) \\
y(t) & =\left[\begin{array}{lll}
0 & 1 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{aligned}
$$

(a) Using the acker function, determine a fullstate feedback gain matrix and an observer gain matrix to place the closed-loop system poles at $s_{1,2}=-1.4 \pm j 1.4, s_{3}=-2$ and the observer poles at $s_{1,2}=-18 \pm j 5, s_{3}=-20$. (b) Construct the state variable compensator. (c) Simulate the closed-loop system with the state initial conditions $\mathbf{x}(0)=\left(\begin{array}{lll}1 & 0 & 0\end{array}\right)^{T}$ and initial state estimate of $\hat{\mathbf{x}}(0)=\left(\begin{array}{lll}0.5 & 0.1 & 0.1\end{array}\right)^{T}$.

CP11.12 Implement the system shown in Figure CP11.12 in an m-file. Obtain the step response of the system.

CP11.13 Consider the system in state variable form

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0881.jpg?height=654&width=773&top_left_y=1449&top_left_x=860)

FIGURE CP11.12 Control system for m-file implementation. Design a full-state feedback gain matrix and an observer gain matrix to place the closed-loop system poles at $s_{1,2}=-2 \pm j 2, s_{3,4}=-5 \pm j$ and the observer poles $s_{1,2}=-9 \pm j 2, s_{3,4}=-15$.
Construct the state variable compensator, and simulate the closed-loop system. Select several values of initial states and initial state estimates in the observer, and display the tracking results.

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) True; (5) False

Multiple Choice: (6) c; (7) a; (8) c; (9) a; (10) a; (11) b; (12) a; (13) b; (14) b; (15) a
Word Match (in order, top to bottom): e, o, k, i, d, b, j, m, f, n, h, q, g, l, p, c, a

\section{TERMS AND CONCEPTS}

Command following An important aspect of control system design wherein a nonzero reference input is tracked.

Controllability matrix A linear system is (completely) controllable if and only if the controllability matrix $\mathbf{P}_{c}=\left[\begin{array}{llll}\mathbf{B} & \mathbf{A B} & \mathbf{A}^{2} \mathbf{B} \ldots & \mathbf{A}^{n-1} \mathbf{B}\end{array}\right]$ has full rank, where $\mathbf{A}$ is an $n \times n$ matrix. For single-input, single-output linear systems, the system is controllable if and only if the determinant of the $n \times n$ controllability matrix $\mathbf{P}_{c}$ is nonzero.

Controllable system A system is controllable on the interval $\left[t_{0}, t_{f}\right]$ if there exists a continuous input $u(t)$ such that any initial state $\mathbf{x}\left(t_{0}\right)$ can be driven to any arbitrary trial state $\mathbf{x}\left(t_{f}\right)$ in a finite time interval $t_{f}-t_{0}>0$.

Detectable A system in which the states that are unobservable are naturally stable.

Estimation error The difference between the actual state and the estimated state $\mathbf{e}(t)=\mathbf{x}(t)-\hat{\mathbf{x}}(t)$.

Full-state feedback control law A control law of the form $\mathbf{u}=-\mathbf{K x}$ where $\mathbf{x}$ is the state of the system assumed known at all times.

Internal model design A method of tracking reference inputs with guaranteed steady-state tracking errors.

Kalman state-space decomposition A partition of the state space that illuminates the states that are controllable and unobservable, uncontrollable and unobservable, controllable and observable, and uncontrollable and observable.

Linear quadratic regulator An optimal controller designed to minimize the quadratic performance index $J=\int_{0}^{\infty}\left(\mathbf{x}^{T} \mathbf{Q} \mathbf{x}+\mathbf{u}^{T} \mathbf{R} \mathbf{u}\right) d t$, where $\mathbf{Q}$ and $\mathbf{R}$ are design parameters.

Observability matrix A linear system is (completely) observable if and only if the observability matrix
$\mathbf{P}_{o}=\left[\begin{array}{lll}\mathbf{C}^{T} & (\mathbf{C A})^{T} & \left(\mathbf{C A}^{2}\right)^{T} \ldots\left(\mathbf{C A}^{n-1}\right)^{T}\end{array}\right]^{T}$ has full rank, where $\mathbf{A}$ is an $n \times n$ matrix. For single-input, single-output linear systems, the system is observable if and only if the determinant of the $n \times n$ observability matrix $\mathbf{P}_{O}$ is nonzero.

Observable system A system is observable on the interval $\left[t_{0}, t_{f}\right]$ if any initial state $\mathbf{x}\left(t_{0}\right)$ is uniquely determined by observing the output $y(t)$ on the interval $\left[t_{0}, t_{f}\right]$.

Observer A dynamic system used to estimate the state of another dynamic system given knowledge of the system inputs and measurements of the system outputs.

Optimal control system A system whose parameters are adjusted so that the performance index reaches an extremum value.

Pole placement A design methodology wherein the objective is to place the eigenvalues of the closed-loop system in desired regions of the complex plane.

Regulator problem The control design problem when the reference input $r(t)=0$ for all $t \geq t_{0}$.

Separation principle The principle that states that the full-state feedback law and the observer can be designed independently and when connected will function as an integrated control system in the desired manner (i.e., stable).

Stabilizable A system in which the states that are not controllable are naturally stable.

Stabilizing controller A controller that stabilizes the closed-loop system.

State variable feedback Occurs when the control signal $u$ for the process is a direct function of all the state variables. 

\section{CHAPTER

\section{Robust Control Systems}

12.1 Introduction 883

12.2 Robust Control Systems and System Sensitivity 884

12.3 Analysis of Robustness 888

12.4 Systems with Uncertain Parameters 890

12.5 The Design of Robust Control Systems 892

12.6 The Design of Robust PID-Controlled Systems 896

12.7 The Robust Internal Model Control System 900

12.8 Design Examples 903

12.9 The Pseudo-Quantitative Feedback System 914

12.10 Robust Control Systems Using Control Design Software 916

12.11 Sequential Design Example: Disk Drive Read System 919

12.12 Summary 921

\section{PREVIEW}

Physical systems and the external environment in which they operate cannot be modeled precisely, may change in an unpredictable manner, and may be subject to significant disturbances. The design of control systems in the presence of significant uncertainty motivates the concept of robust control system design. Advances in robust control design methodologies can address stability robustness and performance robustness in the presence of uncertainty. In this chapter, we describe five methods for robust design, including root locus, frequency response, ITAE methods for a robust PID systems, internal model control, and pseudo-quantitative feedback methods. However, we should also realize that classical design techniques may also produce robust control systems. Control engineers who are aware of these issues can design robust PID controllers, robust lead-lag controllers, and so forth. The chapter concludes with a PID controller design for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 12, students should be able to:

$\square$ Describe the role of robustness in control system design.

$\square$ Identify uncertainty models, including additive uncertainty, multiplicative uncertainty, and parameter uncertainty.

$\square$ Explain the various methods of tackling the robust control design problem using root locus, frequency response, ITAE methods for PID control, internal model, and pseudoquantitative feedback methods. 

\subsection{INTRODUCTION}

A control system designed using the methods and concepts of the preceding chapters assumes knowledge of the model of the process and controller and constant parameters. The process model will be an inaccurate representation of the actual physical system due to

parameter changes

unmodeled dynamics

$\bigcirc$ unmodeled time delays

changes in equilibrium point (operating point)

○ sensor noise

unpredicted disturbance inputs.

The goal of robust control system design is to maintain acceptable closed-loop system performance in the presence of model inaccuracies and changes.

A robust control system maintains acceptable performance in the presence of significant model uncertainty, disturbances, and noise.

A system structure that incorporates system uncertainties is shown in Figure 12.1. This model includes the sensor noise $N(s)$, the disturbance input $T_{d}(s)$, and a process $G(s)$ with unmodeled dynamics or parameter changes. The

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0884.jpg?height=412&width=722&top_left_y=1182&top_left_x=768)

(a)

FIGURE 12.1

Closed-loop control system. (a) Signal flow graph.

(b) Block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0884.jpg?height=355&width=1218&top_left_y=1709&top_left_x=515)

(b) unmodeled dynamics and parameter changes may be significant, and for these systems the challenge is to create a design that retains the desired performance.

\subsection{ROBUST CONTROL SYSTEMS AND SYSTEM SENSITIVITY}

Designing highly accurate systems in the presence of significant plant uncertainty is a classical feedback design problem. The theoretical bases for the solution of this problem date back to the works of H. S. Black and H. W. Bode in the early 1930s, when this problem was referred to as the sensitivities design problem. A significant amount of literature has been published since then regarding the design of systems subject to large process uncertainty. The designer seeks to obtain a system that performs adequately over a large range of uncertain parameters. A system is said to be robust when it is durable, hardy, and resilient.

A control system is robust when (1) it has low sensitivities, (2) it is stable over the expected range of parameter variations, and (3) the performance continues to meet the specifications in the presence of a set of changes in the system parameters $[3,4]$. Robustness is the low sensitivity to effects that are not considered in the analysis and design phase - for example, disturbances, measurement noise, and unmodeled dynamics. The system should be able to withstand these neglected effects when performing the tasks for which it was designed.

For small-parameter perturbations, we may use, as a measure of robustness, the differential sensitivities discussed in Sections 4.3 (system sensitivity) and Section 7.5 (root sensitivity) [6]. The system sensitivity is defined as

$$
S_{\alpha}^{T}=\frac{\partial T / T}{\partial \alpha / \alpha},
$$

where $\alpha$ is the parameter and $T$ the transfer function. The root sensitivity is defined as

$$
S_{\alpha}^{r_{i}}=\frac{\partial r_{i}}{\partial \alpha / \alpha} \text {. }
$$

When the zeros of $T(s)$ are independent of the parameter $\alpha$, we showed that

$$
S_{\alpha}^{T}=-\sum_{i=1}^{n} S_{\alpha}^{r_{i}} \cdot \frac{1}{s+r_{i}},
$$

for an $n$ th-order system. For example, if we have a closed-loop system, as shown in Figure 12.2, where the variable parameter is $\alpha$, then $T(s)=1 /[s+(\alpha+1)]$, and

$$
S_{\alpha}^{T}=\frac{-\alpha}{s+\alpha+1} .
$$

This follows because $r_{1}=+(\alpha+1)$, and

$$
-S_{\alpha}^{r_{i}}=-\alpha .
$$

FIGURE 12.2

A first-order system.

FIGURE 12.3

A second-order system.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0886.jpg?height=424&width=530&top_left_y=153&top_left_x=507)

Therefore,

$$
S_{\alpha}^{T}=-S_{\alpha}^{r_{i}} \frac{1}{s+\alpha+1}=\frac{-\alpha}{s+\alpha+1} .
$$

Let us examine the sensitivity of the second-order system shown in Figure 12.3. The transfer function of the closed-loop system is

$$
T(s)=\frac{K}{s^{2}+s+K} .
$$

The system sensitivity for $K$ is

$$
S(s)=S_{K}^{T}=\frac{s(s+1)}{s^{2}+s+K} .
$$

A Bode plot of the asymptotes of $20 \log |T(j \omega)|$ and $20 \log |S(j \omega)|$ is shown in Figure 12.4 for $K=1 / 4$ (critical damping). Note that the sensitivity is small for lower frequencies, while the transfer function primarily passes low frequencies.

Of course, the sensitivity $S(s)$ only represents robustness for small changes in gain. If $K$ changes from $K=1 / 4$ within the range $K=1 / 16$ to $K=1$, the resulting range of step response is shown in Figure 12.5. This system, with an expected wide

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0886.jpg?height=524&width=698&top_left_y=1488&top_left_x=220)

FIGURE 12.4 Sensitivity and $20 \log |T(j \omega)|$ for the second-order system in Figure 12.3. The asymptotic approximations are shown for $K=1 / 4$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0886.jpg?height=475&width=691&top_left_y=1522&top_left_x=1063)

FIGURE 12.5 The step response for selected gain $K$. FIGURE 12.6

A system with a PD controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0887.jpg?height=233&width=762&top_left_y=156&top_left_x=372)

range of $K$, may not be considered adequately robust. A robust system would be expected to yield essentially the same (within an agreed-upon variation) response to a selected input.

\section{EXAMPLE 12.1 Sensitivity of a controlled system}

Consider the system shown in Figure 12.6, where $G(s)=1 / s^{2}$ and a PD controller $G_{c}(s)=K_{p}+K_{D} s$. Then the sensitivity with respect to changes in $G(s)$ is

$$
S_{G}^{T}=\frac{1}{1+G_{c}(s) G(s)}=\frac{s^{2}}{s^{2}+K_{D} s+K_{p}},
$$

and

$$
T(s)=\frac{K_{D} s+K_{p}}{s^{2}+K_{D} s+K_{p}} .
$$

Consider the nominal condition $\zeta=1$ and $\omega_{n}=\sqrt{K_{p}}$. Then, $K_{D}=2 \omega_{n}$ to achieve $\zeta=1$. Therefore, we may plot $20 \log |S|$ and $20 \log |T|$ on a Bode plot, as shown in Figure 12.7. Note that the frequency $\omega_{n}$ is an indicator on the boundary between the frequency region in which the sensitivity is the important design criterion and the region in which the stability margin is important. Thus, if we specify $\omega_{n}$ properly to take into consideration the extent of modeling error and the frequency of external disturbance, we can expect the system to have an acceptable amount of robustness.

\section{EXAMPLE 12.2 System with a right-hand-plane zero}

Consider the system shown in Figure 12.8, where the plant has a zero in the righthand plane. The closed-loop transfer function is

$$
T(s)=\frac{K(s-1)}{s^{2}+(2+K) s+(1-K)} .
$$

The system is stable for a gain $-2<K<1$. The steady-state error due to a negative unit step input $R(s)=-1 / s$ is

$$
e_{\mathrm{ss}}=\frac{1-2 K}{1-K}
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0888.jpg?height=508&width=722&top_left_y=165&top_left_x=225)

FIGURE 12.7 Sensitivity and $T(s)$ for the secondorder system in Figure 12.6.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0888.jpg?height=225&width=759&top_left_y=452&top_left_x=994)

FIGURE 12.8 A second-order system.
FIGURE 12.9

Step response of the system in Figure 12.8 with $K=1 / 2$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0888.jpg?height=600&width=853&top_left_y=848&top_left_x=519)

and $e_{\mathrm{ss}}=0$ when $K=1 / 2$. The response is shown in Figure 12.9. Note the initial undershoot at $t=1 \mathrm{~s}$. This system is sensitive to changes in $K$, as recorded in Table 12.1. The performance of this system might not be acceptable for a change of gain of only $\pm 10 \%$. Thus, this system would not be considered robust. The steadystate error of this system changes greatly as $K$ changes.

\section{Table 12.1 Results for Example 12.2}

\begin{tabular}{llllll}
$\boldsymbol{K}$ & 0.25 & 0.45 & 0.50 & 0.55 & 0.75 \\
$\left|e_{S S}\right|$ & 0.67 & 0.18 & 0 & 0.22 & 1.0 \\
Undershoot & $5 \%$ & $9 \%$ & $10 \%$ & $11 \%$ & $15 \%$ \\
Settling time (seconds) & 15 & 24 & 27 & 30 & 45 \\
\hline
\end{tabular}



\subsection{ANALYSIS OF ROBUSTNESS}

System goals include maintaining a small tracking error for an input $R(s)$ and keeping the output $Y(s)$ small for a disturbance $T_{d}(s)$. The sensitivity function is

$$
S(s)=\frac{1}{1+G_{c}(s) G(s)}
$$

and the complementary sensitivity function is

$$
C(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}
$$

We also have the relationship

$$
S(s)+C(s)=1 \text {. }
$$

For physically realizable systems, the loop gain $L(s)=G_{c}(s) G(s)$ is small for high frequencies. This means that $S(j \omega)$ approaches 1 at high frequencies.

Consider the closed-loop system shown in Figure 12.1. An additive perturbation characterizes the set of possible processes as follows:

$$
G_{a}(s)=G(s)+A(s),
$$

where $G(s)$ is the nominal process, and $A(s)$ is the perturbation that is bounded in magnitude. We assume that $G_{a}(s)$ and $G(s)$ have the same number of poles in the right-hand $s$-plane (if any) [32]. Then the system stability will not change if

$$
|A(j \omega)|<\left|1+G_{c}(j \omega) G(j \omega)\right| \quad \text { for all } \omega .
$$

This assures stability but not dynamic performance.

A multiplicative perturbation is modeled as

$$
G_{m}(s)=G(s)[1+M(s)] .
$$

The perturbation is bounded in magnitude, and it is again assumed that $G_{m}(s)$ and $G(s)$ have the same number of poles in the right-hand $s$-plane. Then the system stability will not change if

$$
|M(j \omega)|<\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right| \quad \text { for all } \omega .
$$

Equation (12.15) is called the robust stability criterion. This is a test for robustness with respect to a multiplicative perturbation. This form of perturbation is often used because it satisfies the intuitive properties of (1) being small at low frequencies, where the nominal process model is usually well known, and (2) being large at high frequencies, where the nominal model is always inexact.

\section{EXAMPLE 12.3 System with multiplicative perturbation}

Consider the system of Figure 12.1 with $G_{c}=K$, and

$$
G(s)=\frac{170000(s+0.1)}{s(s+3)\left(s^{2}+10 s+10000\right)}
$$

The system is unstable with $K=1$, but a reduction in gain to $K=0.5$ will stabilize it. Now, consider the effect of an unmodeled pole at $50 \mathrm{rad} / \mathrm{s}$. In this case, the multiplicative perturbation is determined from

$$
1+M(s)=\frac{50}{s+50},
$$

or $M(s)=-s /(s+50)$. The magnitude bound is then

$$
|M(j \omega)|=\left|\frac{-j \omega}{j \omega+50}\right| .
$$

$|M(j \omega)|$ and $|1+1 /(K G(j \omega))|$ are shown in Figure 12.10(a), where it is seen that the criterion of Equation (12.15) is not satisfied. Thus, the system may not be stable.

If we use a lag compensator

$$
G_{c}(s)=\frac{0.15(s+25)}{s+2.5},
$$

the loop transfer function is $L(s)=1+G_{c}(s) G(s)$. We reshape the function $G_{c}(j \omega) G(j \omega)$ in the frequency range $2<\omega<25$ and check the condition

$$
|M(j \omega)|<\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right|,
$$

as shown in Figure 12.10(b). Here the robustness inequality is satisfied, and the system is robustly stable.

The control objective is to design a compensator $G_{c}(s)$ so that the transient, steady-state, and frequency-domain specifications are achieved and the cost of feedback measured by the bandwidth of the compensator $G_{c}(j \omega)$ is sufficiently small. This bandwidth constraint is needed mainly because of measurement noise. In subsequent sections, we discuss including a pre-filter in a two-degree-of-freedom configuration to help achieve the design goals. FIGURE 12.10

The robust stability criterion for Example 12.3.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0891.jpg?height=567&width=835&top_left_y=168&top_left_x=373)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0891.jpg?height=583&width=835&top_left_y=826&top_left_x=373)

(b)

\subsection{SYSTEMS WITH UNCERTAIN PARAMETERS}

Many systems have several parameters that are constants but uncertain within a range. For example, consider a system with a characteristic equation

$$
s^{n}+a_{n-1} s^{n-1}+a_{n-2} s^{n-2}+\cdots+a_{0}=0
$$

with known coefficients within bounds

$$
\alpha_{i} \leq a_{i} \leq \beta_{i} \text { and } \mathrm{i}=0, \ldots, n,
$$

where $a_{n}=1$.

To ascertain the stability of the system, we might have to investigate all possible combinations of parameters. Fortunately, it is possible to investigate a limited number of worst-case polynomials [20]. The analysis of only four polynomials is sufficient, and they are readily defined for a third-order system with a characteristic equation

$$
s^{3}+a_{2} s^{2}+a_{1} s+a_{0}=0
$$

The four polynomials are

$$
\begin{aligned}
& q_{1}(s)=s^{3}+\alpha_{2} s^{2}+\beta_{1} s+\beta_{0}, \\
& q_{2}(s)=s^{3}+\beta_{2} s^{2}+\alpha_{1} s+\alpha_{0}, \\
& q_{3}(s)=s^{3}+\beta_{2} s^{2}+\beta_{1} s+\alpha_{0}, \\
& q_{4}(s)=s^{3}+\alpha_{2} s^{2}+\alpha_{1} s+\beta_{0} .
\end{aligned}
$$

One of the four polynomials represents the worst case and may indicate either unstable performance or at least the worst performance for the system in that case.

\section{EXAMPLE 12.4 Third-order system with uncertain parameters}

Consider a third-order system with uncertain coefficients such that

$$
\begin{gathered}
8 \leq a_{0} \leq 60 \Rightarrow \alpha_{0}=8, \beta_{0}=60 ; \\
12 \leq a_{1} \leq 100 \Rightarrow \alpha_{1}=12, \beta_{1}=100 ; \\
7 \leq a_{2} \leq 25 \Rightarrow \alpha_{2}=7, \beta_{2}=25 .
\end{gathered}
$$

The four polynomials are

$$
\begin{aligned}
& q_{1}(s)=s^{3}+7 s^{2}+100 s+60 \\
& q_{2}(s)=s^{3}+25 s^{2}+12 s+8, \\
& q_{3}(s)=s^{3}+25 s^{2}+100 s+8, \\
& q_{4}(s)=s^{3}+7 s^{2}+12 s+60 .
\end{aligned}
$$

We then proceed to check these four polynomials by means of the Routh-Hurwitz criterion, and determine that the system is stable for all the range of uncertain parameters.

\section{EXAMPLE 12.5 Stability of uncertain system}

Consider a unity feedback system with a process transfer function (under nominal conditions)

$$
G(s)=\frac{4.5}{s(s+1)(s+2)} .
$$

The nominal characteristic equation is then

$$
q(s)=s^{3}+3 s^{2}+2 s+4.5=0,
$$

where $a_{0}=4.5, a_{1}=2$, and $\mathrm{a}_{2}=3$. Using the Routh-Hurwitz criterion, we find that this system is nominally stable. However, if the system has uncertain coefficients such that

$$
\begin{aligned}
& 4 \leq a_{0} \leq 5 \Rightarrow \alpha_{0}=4, \quad \beta_{0}=5 \\
& 1 \leq a_{1} \leq 3 \Rightarrow \alpha_{1}=1, \quad \beta_{1}=3 \\
& 2 \leq a_{2} \leq 4 \Rightarrow \alpha_{2}=2, \quad \beta_{2}=4
\end{aligned}
$$

then we must examine the four polynomials:

$$
\begin{aligned}
& q_{1}(s)=s^{3}+2 s^{2}+3 s+5 \\
& q_{2}(s)=s^{3}+4 s^{2}+1 s+4 \\
& q_{3}(s)=s^{3}+4 s^{2}+3 s+4 \\
& q_{4}(s)=s^{3}+2 s^{2}+1 s+5
\end{aligned}
$$

Using the Routh-Hurwitz criterion, $q_{1}(s)$ and $q_{3}(s)$ are stable and $q_{2}(s)$ is marginally stable. For $q_{4}(s)$, we have

\begin{tabular}{c|cc}
$s^{3}$ & 1 & 1 \\
$s^{2}$ & 2 & 5 \\
$s^{1}$ & $-3 / 2$ & \\
$s^{0}$ & 5 &
\end{tabular}.

Therefore, the system is unstable for the worst case, where $\alpha_{2}=$ minimum, $\alpha_{1}=$ minimum, and $\beta_{0}=$ maximum. This occurs when the process has changed to

$$
G(s)=\frac{5}{s(s+1)(s+1)} .
$$

Note that the third pole has moved toward the $j \omega$-axis to its limit at $s=-1$ and that the gain has increased to its limit at $K=5$.

\subsection{THE DESIGN OF ROBUST CONTROL SYSTEMS}

The design of robust control systems involves determining the structure of the controller and adjusting the controller parameters to achieve acceptable performance in the presence of uncertainty. The structure of the controller is chosen such that the system response can meet certain performance criteria.

One possible objective in the design of a control system is that the controlled system output should very accurately track the input. That is, we want to minimize the tracking error. In an ideal setting, the Bode plot of the loop gain, $L(s)$, would be $0-\mathrm{dB}$ gain of infinite bandwidth and zero phase shift. In practice, this is not possible. One possible design objective is to maintain the magnitude response curve as flat and as close to unity for as large a bandwidth as possible for a given plant and controller combination [20].

Another important goal of a control system design is that the effect on the output of the system due to disturbances is minimized. Consider the control system shown in Figure 12.11, where $G(s)$ is the plant and $T_{d}(s)$ is the disturbance. We then have

$$
T(s)=\frac{Y(s)}{R(s)}=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)},
$$

FIGURE 12.11

A system with a disturbance.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0894.jpg?height=261&width=953&top_left_y=152&top_left_x=516)

and

$$
\frac{Y(s)}{T_{d}(s)}=\frac{G(s)}{1+G_{c}(s) G(s)} .
$$

Note that both the reference and disturbance transfer functions have the same denominator; in other words, they have the same characteristic equation-namely,

$$
1+G_{c}(s) G(s)=1+L(s)=0 .
$$

Recall that the sensitivity of $T(s)$ with respect to $G(s)$ is

$$
S_{G}^{T}=\frac{1}{1+G_{c}(s) G(s)} .
$$

Equation (12.21) shows that for low sensitivity, we desire a high value of loop gain $L(j \omega)$. But it is known that a high gain can lead to instability and amplification of the measurement noise. Thus, we seek the following:

1. $T(s)$ with wide bandwidth.

2. Large loop gain $L(s)$ at low frequencies.

3. Small loop gain $L(s)$ at high frequencies.

Setting the design of robust systems in frequency-domain terms, we scale a compensator $G_{c}(s)$ such that the closed-loop sensitivity is less than some tolerance value. But sensitivity minimization involves finding a compensator such that the closed-loop sensitivity is minimized.

The gain and phase margin problem is to find a compensator to achieve prescribed gain and phase margins. The disturbance rejection problem and measurement noise attenuation problem seeks a solution with high loop gain at low frequencies and low loop gain at high frequencies, respectively. For the frequency-domain specifications, we seek the following conditions for the Bode plot of $G_{c}(j \omega) G(j \omega)$, shown in Figure 12.12:

1. For relative stability, the loop gain must have not more than a $-20-\mathrm{dB} /$ decade slope at or near the crossover frequency $\omega_{c}$.

2. Steady-state accuracy and measurement noise rejection achieved by the low gain at high frequency.

3. Disturbance rejection by a high gain over low frequencies.

4. Accuracy over a bandwidth $\omega_{B}$, by maintaining the loop gain above a prescribed level. FIGURE 12.12

Bode plot for $20 \mathrm{log}$ $\left|G_{c}(j \omega) G(j \omega)\right|$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0895.jpg?height=484&width=1026&top_left_y=153&top_left_x=369)

Using the root sensitivity concept, we can state that $S_{a}^{r}$ must be minimized while attaining $T(s)$ with dominant roots that will provide the appropriate response and minimize the effect of $T_{d}(s)$. As an example, let $G_{c}(s)=K$ and $G(s)=1 /(s(s+1))$ for the system in Figure 12.11. This system has two roots, and we select a gain $K$ so that $Y(s) / T_{d}(s)$ is minimized, $S_{K}^{r}$ is minimized, and $T(s)$ has desirable dominant roots. The sensitivity is

$$
S_{K}^{r}=\frac{d r}{d K} \cdot \frac{K}{r}=\left.\frac{d s}{d K}\right|_{s=r} \cdot \frac{K}{r},
$$

and the characteristic equation is

$$
s(s+1)+K=0 .
$$

Therefore, $d K / d s=-(2 s+1)$, since $K=-s(s+1)$. We then obtain

$$
S_{K}^{r}=\left.\frac{-1}{2 s+1} \frac{-s(s+1)}{s}\right|_{s=r} .
$$

When $\zeta<1$, the roots are complex and $r=-0.5+j \frac{1}{2} \sqrt{4 K-1}$. Then,

$$
\left|S_{K}^{r}\right|=\left(\frac{K}{4 K-1}\right)^{1 / 2}
$$

The magnitude of the root sensitivity is shown in Figure 12.13 for $K=0.2$ to $K=5$. The percent overshoot to a step is also shown. As illustrated in Figure 12.13, select $K \approx 1.25$ yields a near minimum sensitivity while maintaining good performance for the step response. To reduce the root sensitivity while simultaneously minimizing the effect of disturbances, we can use the design procedure as follows:

1. Sketch the root locus of the compensated system with $G_{c}(s)$ chosen to attain the desired location for the dominant roots.

2. Maximize the gain of $G_{c}(s)$ to reduce the effect of the disturbance.

3. Determine $S_{K}^{r}$ and attain the minimum value of the root sensitivity consistent with the transient response required, as described in Step 1. FIGURE 12.13

Sensitivity and percent overshoot for a second-order system.
FIGURE 12.14

Bode plot for Example 12.6.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0896.jpg?height=576&width=739&top_left_y=152&top_left_x=522)

\section{EXAMPLE 12.6 Sensitivity and compensation}

Consider the system in Figure 12.11 when $G(s)=1 / s^{2}$ and $G_{c}(s)$ is to be selected by frequency response methods. Therefore, the compensator is to be selected to achieve an appropriate gain and phase margin while minimizing sensitivity and the effect of the disturbance. Thus, we choose

$$
G_{c}(s)=\frac{K(s / z+1)}{s / p+1} .
$$

Choose $K=10$ to reduce the effect of the disturbance. To attain a phase margin of $45^{\circ}$, select $z=2.0$ and $p=12.0$. The compensated diagram is shown in Figure 12.14. The closed-loop bandwidth is $\omega_{B}=1.6 \omega_{c}$. Thus, we will increase the bandwidth by using the compensator.

The sensitivity at $\omega_{c}$ is

$$
\left|S_{G}^{T}\left(j \omega_{c}\right)\right|=\left|\frac{1}{1+G_{c}(j \omega) G(j \omega)}\right|_{\omega=\omega_{c}} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0896.jpg?height=637&width=1273&top_left_y=1502&top_left_x=502)

To estimate $\left|S_{G}^{T}\right|$, we recall that the Nichols chart enables us to obtain

$$
|T(j \omega)|=\left|\frac{G_{c}(j \omega) G(j \omega)}{1+G_{c}(j \omega) G(j \omega)}\right| .
$$

We can plot points of $G_{c}(j \omega) G(j \omega)$ on the Nichols chart and then read $|T(j \omega)|$ from the chart. Then, we have

$$
\left|S_{G}^{T}\left(j \omega_{1}\right)\right|=\frac{\left|T\left(j \omega_{1}\right)\right|}{\left|G_{c}\left(j \omega_{1}\right) G\left(j \omega_{1}\right)\right|},
$$

where $\omega_{1}$ is chosen at a frequency below $\omega_{c}$. The Nichols chart for the compensated system is shown in Figure 12.15. For $\omega_{1}=\omega_{c} / 2.5=2$, we have $20 \log \left|T\left(j \omega_{1}\right)\right|=2.5 d B$ and $20 \log \left|G_{c}\left(j \omega_{1}\right) G\left(j \omega_{1}\right)\right|=9 \mathrm{~dB}$. Therefore,

$$
\left|S\left(j \omega_{1}\right)\right|=\frac{\left|T\left(j \omega_{1}\right)\right|}{\left|G_{c}\left(j \omega_{1}\right) G\left(j \omega_{1}\right)\right|}=\frac{1.33}{2.8}=0.47 .
$$

\subsection{THE DESIGN OF ROBUST PID-CONTROLLED SYSTEMS}

The PID controller has the transfer function

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s
$$

The popularity of PID controllers can be attributed partly to their robust performance over a wide range of operating conditions and partly to their functional simplicity, which allows engineers to operate them in a straightforward manner. To implement the PID controller, three parameters must be determined for the given process: proportional gain, integral gain, and derivative gain [31].

Consider the PID controller

$$
\begin{aligned}
G_{c}(s) & =K_{P}+\frac{K_{I}}{s}+K_{D} s=\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s} \\
& =\frac{K_{D}\left(s^{2}+a s+b\right)}{s}=\frac{K_{D}\left(s+z_{1}\right)\left(s+z_{2}\right)}{s},
\end{aligned}
$$

where $a=K_{P} / K_{D}$ and $b=K_{I} / K_{D}$ Therefore, a PID controller introduces a transfer function with one pole at the origin and two zeros.

Recall that a root locus begins at the poles and ends at the zeros. If we have a system as shown in Figure 12.16 with

$$
G(s)=\frac{1}{(s+2)(s+5)},
$$

and we use a PID controller with complex zeros, we can plot the root locus as shown in Figure 12.17. As the gain $K_{D}$ of the controller is increased, the complex roots approach the zeros. The closed-loop transfer function is FIGURE 12.15

Nichols chart for Example 12.7.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0898.jpg?height=1651&width=1193&top_left_y=155&top_left_x=523)

$$
\begin{aligned}
T(s) & =\frac{G(s) G_{c}(s) G_{p}(s)}{1+G(s) G_{c}(s)} \\
& =\frac{K_{D}\left(s+z_{1}\right)\left(s+\hat{z}_{1}\right)}{\left(s+r_{2}\right)\left(s+r_{1}\right)\left(s+\hat{r}_{1}\right)} G_{p}(s) \simeq \frac{K_{D} G_{p}(s)}{s+r_{2}},
\end{aligned}
$$

FIGURE 12.16

Feedback control system with a desired input $R(s)$ and an undesired input $T_{d}(s)$.
FIGURE 12.17

Root locus with $-z_{1}=-6+j 2$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0899.jpg?height=1002&width=1076&top_left_y=154&top_left_x=372)

because the zeros and the complex roots are approximately equal $\left(r_{1} \approx z_{1}\right)$. Setting $G_{p}(s)=1$, we have

$$
T(s)=\frac{K_{D}}{s+r_{2}} \approx \frac{K_{D}}{s+K_{D}}
$$

when $K_{D} \gg 1$. The only limiting factor is the allowable magnitude of $U(s)$ (Figure 12.16) when $K_{D}$ is large. If $K_{D}$ is 100 , the system has a fast response and zero steady-state error. Furthermore, the effect of the disturbance is reduced significantly.

In general, we note that PID controllers are particularly useful for reducing steady-state error and improving the transient response when $G(s)$ has one or two poles (or may be approximated by a second-order process).

The main problem in the selection of the three PID controller parameters is that these coefficients do not readily translate into the desired performance and robustness characteristics that the control system designer has in mind. Several rules and methods have been proposed to solve this problem. In this section, we consider several design methods using root locus and performance indices.

The first design method uses the ITAE performance index. Hence, we select the three PID coefficients to minimize the ITAE performance index, which produces an excellent transient response to a step or a ramp. The design procedure consists of three steps:

1. Select the $\omega_{n}$ of the closed-loop system by specifying the settling time.

2. Determine the three coefficients using the appropriate optimum equation (Table 5.3 and Table 5.4) and the $\omega_{n}$ of step 1 to obtain $G_{c}(s)$.

3. Determine a prefilter $G_{p}(s)$ so that the closed-loop system transfer function, $T(s)$, does not have any zeros.

\section{EXAMPLE 12.7 Robust control of temperature}

Consider a temperature controller with a control system as shown in Figure 12.16 and a process

$$
G(s)=\frac{1}{(s+1)^{2}} .
$$

If $G_{c}(s)=1$, the steady-state error is $e_{s s}=50 \%$, and the settling time (with a $2 \%$ criterion) is $T_{s}=3.2 \mathrm{~s}$ for a step input. We want to obtain an optimum ITAE performance for a step input and a settling time of $T_{s} \leq 0.5 \mathrm{~s}$. Using a PID controller, we have

$$
\begin{aligned}
T_{1}(s)=\frac{Y(s)}{R(s)} & =\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} \\
& =\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s^{3}+\left(2+K_{D}\right) s^{2}+\left(1+K_{P}\right) s+K_{I}},
\end{aligned}
$$

where $G_{p}(s)=1$. The optimum coefficients of the characteristic equation for ITAE are

$$
s^{3}+1.75 \omega_{n} s^{2}+2.15 \omega_{n}^{2} s+\omega_{n}^{3}=0 .
$$

We need to select $\omega_{n}$ in order to meet the settling time requirement. Since $T_{s}=4 /\left(\zeta \omega_{n}\right)$ and $\zeta$ is unknown but near 0.8 , we set $\omega_{n}=10$. Then, equating the denominator of Equation (12.34) to Equation (12.35), we obtain the three coefficients as $K_{P}=214, K_{D}=15.5$, and $K_{I}=1000$.

Then Equation (12.34) becomes

$$
\begin{aligned}
T_{1}(s) & =\frac{15.5 s^{2}+214 s+1000}{s^{3}+17.5 s^{2}+215 s+1000} \\
& =\frac{15.5(s+6.9+j 4.1)(s+6.9-j 4.1)}{s^{3}+17.5 s^{2}+215 s+1000} .
\end{aligned}
$$

The response of this system to a step input has a percent overshoot of P.O. $=33.9 \%$, as recorded in Table 12.2.

We select a prefilter $G_{p}(s)$ so that we achieve the desired ITAE response with

$$
T(s)=\frac{G_{c}(s) G(s) G_{p}(s)}{1+G_{c}(s) G(s)}=\frac{1000}{s^{3}+17.5 s^{2}+215 s+1000} .
$$

Table 12.2 Results for Example 12.7

\begin{tabular}{llll} 
Controller & $G_{c}(s)=\mathbf{1}$ & $\begin{array}{l}\mathrm{PID} \text { and } \\
G_{p}(\mathbf{s})=\mathbf{1}\end{array}$ & $\begin{array}{l}\text { PID with } \\
G_{p}(\mathbf{s}) \text { Prefilter }\end{array}$ \\
\hline Percent overshoot & $4.2 \%$ & $33.9 \%$ & $1.9 \%$ \\
Settling time (seconds) & 4.2 & 0.6 & 0.75 \\
Steady-state error & $50 \%$ & $0.0 \%$ & $0.0 \%$ \\
Disturbance error & $52 \%$ & $0.4 \%$ & $0.4 \%$ \\
\hline
\end{tabular}

Therefore, we require that

$$
G_{p}(s)=\frac{64.5}{s^{2}+13.8 s+64.5}
$$

in order to eliminate the zeros in Equation (12.36) and bring the overall numerator to 1000 . The response of the system $T(s)$ to a step input is indicated in Table 12.2. The system has a small percent overshoot, a settling time of $T_{s} \leq 0.5 \mathrm{~s}$, and zero steady-state error. Furthermore, for a disturbance $T_{d}(s)=1 / s$, the maximum value of $y(t)$ due to the disturbance is $0.4 \%$ of the magnitude of the disturbance. This is a very favorable design.

Let us consider the system when the plant varies significantly, so that

$$
G(s)=\frac{K}{(\tau s+1)^{2}},
$$

where $0.5 \leq \tau \leq 1$ and $1 \leq K \leq 2$. We want to investigate the behavior using the ITAE optimum system with the prefilter. The objective is to have an overshoot of P.O. $\leq 4 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 2 \mathrm{~s}$ while $G(s)$ can attain any value in the range indicated.

We then obtain the step response for the four conditions: $\tau=1, K=1 ; \tau=0.5$, $K=1 ; \tau=1, K=2 ;$ and $\tau=0.5, K=2$. The results are summarized in Figure 12.18. This is a very robust system.

The value of $\omega_{n}$ that can be chosen will be limited by considering the maximum allowable $u(t)$, where $u(t)$ is the output of the controller, as shown in Figure 12.16. As an example, consider the system in Figure 12.16 with a PID controller, $G(s)=1 /(s(s+1))$, and the necessary prefilter $G_{p}(s)$ to achieve ITAE performance. If we select $\omega_{n}=10,20$, and 40 , the maximum value of $u(t)$ is as recorded in Table 12.3. If we wish to limit $u(t)$, we need to limit $\omega_{n}$. Thus, we are limited in the settling time we can achieve.

\subsection{THE ROBUST INTERNAL MODEL CONTROL SYSTEM}

The internal model control system is shown in Figure 12.19. We now consider the use of the internal model design with special attention to robust system performance. The internal model principle states that if $G_{c}(s) G(s)$ contains $R(s)$ then $Y(s)$ will track $R(s)$ asymptotically (in the steady state), and the tracking is robust. FIGURE 12.18

Response of the closed loop system in the presence of uncertainty in $K$ and $\tau$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0902.jpg?height=842&width=1089&top_left_y=153&top_left_x=514)

Table 12.3 Maximum Value of Plant Input

$\begin{array}{llll}\omega_{n} & 10 & 20 & 40 \\ u(t) \text { maximum for } R(s)=1 / s & 35 & 135 & 550 \\ \text { Settling time (seconds) } & 0.9 & 0.5 & 0.3\end{array}$

Consider a simple system with $G(s)=1 / s$, for which we seek a ramp response with a steady-state error of zero. A PI controller is sufficient, and we let $\mathbf{K}=\mathbf{0}$ (no state variable feedback). Then we have

$$
G_{c}(s) G(s)=\left(K_{p}+\frac{K_{I}}{s}\right) \frac{1}{s}=\frac{K_{p} s+K_{I}}{s^{2}} .
$$

Note that for a ramp, $R(s)=1 / s^{2}$, which is contained as a factor of Equation (12.40), and the closed-loop transfer function is

$$
T(s)=\frac{K_{p} s+K_{I}}{s^{2}+K_{p} s+K_{I}} .
$$

FIGURE 12.19

The internal model control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0902.jpg?height=325&width=1098&top_left_y=1820&top_left_x=505)

Using the ITAE specifications for a ramp response, we require that

$$
T(s)=\frac{3.2 \omega_{n} s+\omega_{n}^{2}}{s^{2}+3.2 \omega_{n} s+\omega_{n}^{2}} .
$$

We select $\omega_{n}$ to satisfy a specification for the settling time. For a settling time (with a $2 \%$ criterion) of $T_{s}=1 \mathrm{~s}$, we select $\omega_{n}=5$. Then we require $K_{p}=16$ and $K_{I}=25$. The response of this system settles in $T_{s}=1 \mathrm{~s}$ and then tracks the ramp with zero steady-state error. If this system (designed for a ramp input) receives a step input, the response has a percent overshoot of P.O. $=5 \%$ and a settling time of $T_{s}=1.5 \mathrm{~s}$. This system is very robust to changes in the plant. For example, if $G(s)=K / s$ changes gain so that $K$ varies by $\pm 50 \%$, the change in the ramp response is insignificant.

\section{EXAMPLE 12.8 Design of an internal model control system}

Consider the system of Figure 12.20 with state variable feedback and a compensator $G_{c}(s)$. We wish to track a step input with zero steady-state error. Here, we select a PID controller for $G_{c}(s)$. We then have

$$
G_{c}(s)=\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s}
$$

and $G(s) G_{c}(s)$ will contain $R(s)=1 / s$, the input command. Note that we feed back both state variables and add these additional signals after $G_{c}(s)$ in order to retain the integrator in $G_{c}(s)$.

The goal is to achieve a settling time (to within $2 \%$ of the final value) of $T_{s} \leq 1$ second and a deadbeat response while retaining a robust response. Here, we assume that the two poles of $G(s)$ can change by $\pm 50 \%$. Then the worst-case condition is

$$
\hat{G}(s)=\frac{1}{(s+0.5)(s+1)} .
$$

One design approach is to design the control for this worst-case condition. Another approach, which we use here, is to design for the nominal $G(s)$ and one-half the desired settling time. Then we expect to meet the settling time requirement and attain a very fast, highly robust system. Note that the prefilter $G_{p}(s)$ is used to attain the desired form for $T(s)$.

FIGURE 12.20

An internal model control with state variable feedback and $G_{C}(s)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0903.jpg?height=338&width=1268&top_left_y=1762&top_left_x=349)

The response desired is deadbeat, so we use a third-order transfer function as

$$
T(s)=\frac{\omega_{n}^{3}}{s^{3}+1.9 \omega_{n} s^{2}+2.20 \omega_{n}^{2} s+\omega_{n}^{3}},
$$

and the settling time (with a $2 \%$ criterion) is $T_{s}=4 / \omega_{n}$. For a settling time of $\mathrm{T}=0.5 \mathrm{~s}$, we use $\omega_{n}=8$.

The closed-loop transfer function of the system of Figure 12.20 with the appropriate $G_{p}(s)$ is

$$
T(s)=\frac{K_{I}}{s^{3}+\left(3+K_{D}+K_{b}\right) s^{2}+\left(2+K_{P}+K_{a}+2 K_{b}\right) s+K_{I}} .
$$

We let $K_{a}=10, K_{b}=2, K_{P}=127.6, K_{I}=527.5$, and $K_{D}=10.35$. Note that $T(s)$ could be achieved with other gain combinations.

The step response of this system has a deadbeat response with a percent overshoot of P.O. $=1.65 \%$ and a settling time of $T_{s}=0.5 \mathrm{~s}$. When the poles of $G(s)$ change by $\pm 50 \%$, the percent overshoot changes to $P . O .=1.86 \%$, and the settling time is $T_{s}=0.95 \mathrm{~s}$. This is an outstanding design of a robust deadbeat response system.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. The first example illustrates the design of two degree-of-freedom controllers (that is, two separate controllers) for an ultra-precision diamond turning machine. In the second design example, we consider the practical problem of designing a controller in the presence of an uncertain time delay. The specific problem under investigation is a PID controller for a digital audio tape drive. The design process is highlighted with an emphasis on robustness.

\section{EXAMPLE 12.9 Ultra-precision diamond turning machine}

The design of an ultra-precision diamond turning machine has been studied at Lawrence Livermore National Laboratory. This machine shapes optical devices such as mirrors with ultra-high precision using a diamond tool as the cutting device. In this discussion, we will consider only the $z$-axis control. Using frequency response identification with sinusoidal input to the actuator we determined that

$$
G(s)=\frac{4500}{s+60}
$$

The system can accommodate high gains, since the input command is a series of step commands of very small magnitude (a fraction of a micron). The system has an outer loop for position feedback using a laser interferometer with an accuracy of 0.1 micron $\left(10^{-7} \mathrm{~m}\right)$. An inner feedback loop is also used for velocity feedback, as shown in Figure 12.21. FIGURE 12.21

Turning machine control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0905.jpg?height=487&width=1279&top_left_y=152&top_left_x=339)

We want to select the controllers, $G_{1}(s)$ and $G_{2}(s)$, to obtain an overdamped, highly robust, high-bandwidth system. The robust system must accommodate changes in $G(s)$ due to varying loads, materials, and cutting requirements. Thus, we seek a large phase margin and gain margin for the inner and outer loops, and low root sensitivity. The specifications are summarized in Table 12.4.

Since we want zero steady-state error for the velocity loop, we propose a velocity loop controller $G_{2}(s)=G_{3}(s) G_{4}(s)$, where $G_{3}(s)$ is a PI controller and $G_{4}(s)$ is a phase-lead compensator. Thus, we have

$$
G_{2}(s)=G_{3}(s) G_{4}(s)=\left(K_{p}+\frac{K_{I}}{s}\right) \cdot \frac{1+K_{4} s}{\alpha\left(1+\frac{K_{4}}{\alpha} s\right)}
$$

and choose $K_{P} / K_{I}=0.00532, K_{4}=0.00272$, and $\alpha=2.95$. We now have

$$
G_{2}(s)=K_{P} \frac{s+188}{s} \cdot \frac{s+368}{s+1085} .
$$

The root locus for $G_{2}(s) G(s)$ is shown in Figure 12.22. When $K_{P}=2$, we have the velocity closed-loop transfer function given by

$$
T_{2}(s)=\frac{V(s)}{U(s)}=\frac{9000(s+188)(s+368)}{(s+205)(s+305)\left(s+10^{4}\right)} \approx \frac{10^{4}}{\left(s+10^{4}\right)},
$$

\begin{tabular}{|c|c|c|}
\hline \multirow[b]{2}{*}{ Specification } & \multicolumn{2}{|c|}{ Transfer Function } \\
\hline & Velocity, $V(s) / U(s)$ & Position $Y(s) / R(s)$ \\
\hline Minimum bandwidth & $950 \mathrm{rad} / \mathrm{s}$ & $95 \mathrm{rad} / \mathrm{s}$ \\
\hline Steady-state error to a step & 0 & 0 \\
\hline Minimum damping ratio $\zeta$ & 0.8 & 0.9 \\
\hline Maximum root sensitivity $\mid S_{K}^{r}$ & 1.0 & 1.5 \\
\hline Minimum phase margin & $90^{\circ}$ & $75^{\circ}$ \\
\hline Minimum gain margin & $40 \mathrm{~dB}$ & $60 \mathrm{~dB}$ \\
\hline
\end{tabular}

\section{Table 12.4 Specifications for Turning Machine Control System}

FIGURE 12.22

Root locus for velocity loop as $K_{p}$ varies.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0906.jpg?height=595&width=750&top_left_y=152&top_left_x=453)

Table 12.5 Design Results for Turning Machine Control System
Achieved Result

Velocity Position

Transfer

Closed-loop bandwidth

Steady-state error

Damping ratio, $\zeta$

Root sensitivity, $\left|S_{K}^{r}\right|$

Phase margin

Gain margin
$4000 \mathrm{rad} / \mathrm{s}$

0

1.0

0.92

$93^{\circ}$

Infinite
Position Transfer Function

$1000 \mathrm{rad} / \mathrm{s}$

0

1.0

1.2

$85^{\circ}$

$76 \mathrm{~dB}$ which is a large-bandwidth system. The actual bandwidth and root sensitivity are summarized in Table 12.5. Note that we have exceeded the specifications for the velocity transfer function.

We propose a phase-lead compensator for the position loop of the form

$$
G_{1}(s)=K_{1} \frac{1+K_{5} s}{\alpha\left(1+\frac{K_{5}}{\alpha} s\right)},
$$

and we choose $\alpha=2.0$ and $K_{5}=0.0185$ so that

$$
G_{1}(s)=\frac{K_{1}(s+54)}{s+108} \text {. }
$$

We then plot the root locus for the loop transfer function

$$
L(s)=G_{1}(s) \cdot T_{2}(s) \cdot \frac{1}{s} .
$$

If we use the approximate $T_{2}(s)$ of Equation (12.46), we have the root locus of Figure 12.23(a). Using the actual $T_{2}(s)$, we get the close-up of the root locus shown in Figure 12.23(b). We select $K_{P}=1000$ and achieve the actual results for the total system transfer function as recorded in Table 12.5. The total system has a high phase margin, has a low sensitivity, and is overdamped with a large bandwidth. This system is very robust. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0907.jpg?height=605&width=720&top_left_y=163&top_left_x=395)

(a)

FIGURE 12.23

The root locus for $K_{1}>0$ for (a) overview and (b) close-up near origin of the s-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0907.jpg?height=696&width=701&top_left_y=868&top_left_x=374)

(b)

\section{EXAMPLE 12.10 Digital audio tape controller}

Consider the feedback control system shown in Figure 12.24, where

$$
G_{d}(s)=e^{-T s} .
$$

The exact value of the time delay is uncertain, but is known to lie in the interval $T_{1} \leq T \leq T_{2}$. Define

$$
G_{m}(s)=e^{-T s} G(s) .
$$

Then

$$
G_{m}(s)-G(s)=e^{-T s} G(s)-G(s)=\left(e^{-T s}-1\right) G(s),
$$

FIGURE 12.24

A feedback system with a time delay in the loop.
FIGURE 12.25

Multiplicative uncertainty representation.

FIGURE 12.26

Equivalent block diagram depiction of the multiplicative uncertainty.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0908.jpg?height=259&width=1025&top_left_y=153&top_left_x=520)

or

$$
\frac{G_{m}(s)}{G(s)}-1=e^{-T s}-1 .
$$

If we define

$$
M(s)=e^{-T s}-1,
$$

then we have

$$
G_{m}(s)=(1+M(s)) G(s) .
$$

In the development of a robust stability controller, we would like to represent the time-delay uncertainty in the form shown in Figure 12.25 where we need to determine a function $M(s)$ that approximately models the time delay. This will lead to the establishment of a straightforward method of testing the system for stability robustness in the presence of the uncertain time-delay. The uncertainty model is known as a multiplicative uncertainty representation.

Since we are concerned with stability, we can consider $R(s)=0$. Then we can manipulate the block diagram in Figure 12.25 to obtain the form shown in Figure 12.26. Using the small gain theorem, we have the condition that the closed-loop system is stable if

$$
|M(j \omega)|<\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right| \text { for all } \omega
$$
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0908.jpg?height=628&width=1096&top_left_y=1478&top_left_x=506)The challenge is that the time delay $T$ is not known exactly. One approach to solving the problem is to find a weighting function, denoted by $W(s)$, such that

$$
\left|e^{-j \omega T}-1\right|<|W(j \omega)| \quad \text { for all } \omega \text { and } \mathrm{T}_{1} \leq T \leq T_{2} \text {. }
$$

If $W(s)$ satisfies the inequality in Equation (12.48), it follows that

$$
|M(j \omega)|<|W(j \omega)| \text {. }
$$

Therefore, the robust stability condition can be satisfied by

$$
|W(j \omega)|<\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right| \text { for all } \omega .
$$

This is a conservative bound. If the condition in Equation (12.49) is satisfied, then stability is guaranteed in the presence of any time delay in the range $T_{1} \leq T \leq T_{2}$ [5,32]. If the condition is not satisfied, the system may or may not be stable.

Suppose we have an uncertain time delay that is known to lie in the range $0.1 \leq T \leq 1$. We can determine a suitable weighting function $W(s)$ by plotting the magnitude of $e^{-j \omega T}-1$, as shown in Figure 12.27 for various values of $T$ in the range $T_{1} \leq T \leq T_{2}$. A reasonable weighting function obtained by trial and error is

$$
W(s)=\frac{2.5 s}{1.2 s+1}
$$

FIGURE 12.27 Magnitude plot of $\left|e^{-j \omega T}-1\right|$ for $T=0.1,0.5$, and 1.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0909.jpg?height=937&width=1178&top_left_y=1185&top_left_x=425)

FIGURE 12.28 Digital audio tape driver mechanism.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0910.jpg?height=557&width=868&top_left_y=159&top_left_x=507)

This function satisfies the condition

$$
\left|e^{-j \omega T}-1\right|<|W(j \omega)| \text {. }
$$

Keep in mind that the selection of the weighting function is not unique.

A digital audio tape (DAT) stores 1.3 gigabytes of data in a package the size of a credit card-roughly nine times more than a half-inch-wide reel-to-reel tape or quarter-inch-wide cartridge tape. A DAT sells for about the same amount as a floppy disk, even though it can store 1000 times more data. A DAT can record for two hours (longer than either reel-to-reel or cartridge tape), which means that it can run longer unattended and requires fewer changes and hence fewer interruptions of data transfer. DAT gives access to a given data file within 20 seconds, on the average, compared with several minutes for either cartridge or reel-to-reel tape [2].

The tape drive electronically controls the relative speeds of the drum and tape so that the heads follow the tracks on the tape, as shown in Figure 12.28. The control system is complex because motors have to be accurately controlled: capstan, take-up and supply reels, drum, and tension control. The elements of the design process emphasized in this example are highlighted in Figure 12.29.

Consider the speed control system shown in Figure 12.30. The motor and load transfer function varies because the tape moves from one reel to the other. The transfer function is

$$
G(s)=\frac{K_{m}}{\left(s+p_{1}\right)\left(s+p_{2}\right)},
$$

where nominal values are $K_{m}=4, p_{1}=1$, and $p_{2}=4$. However, the range of variation is $3 \leq K_{m} \leq 5,0.5 \leq p_{1} \leq 1.5$, and $3.5 \leq p_{2} \leq 4.5$. Thus, the process belongs to a family of processes, where each member corresponds to different values of $K_{m}, p_{1}$, and $p_{2}$. The design goal is

\section{Design Goal}

Control the DAT speed to the desired value in the presence of significant process uncertainties. FIGURE 12.30 Block diagram of the digital audio tape speed control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0911.jpg?height=1052&width=1190&top_left_y=208&top_left_x=419)

FIGURE 12.29 Elements of the control system design process emphasized in this digital audio tape speed control design.
If the performance does not meet the specifications, then iterate the configuration.
If the performance meets the specifications, then finalize the design.
Control the DAT speed e presence of significant plant uncertainties.

Ppecilcations: $T_{s}<2 s$ DS2: Robust stability

See Figures 12.28 and 12.30

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0911.jpg?height=259&width=866&top_left_y=1390&top_left_x=374)

Associated with the design goal we have the variable to be controlled defined as

Variable to Be Controlled

DAT speed $Y(s)$.

The design specifications are

\section{Design Specifications}

DS1 Percent overshoot of P.O. $\leq 13 \%$ and settling time of $T_{s} \leq 2 \mathrm{~s}$ for a unit step input.

DS2 Robust stability in the presence of a time delay at the plant input. The time delay value is uncertain but known to be in the range $0 \leq T \leq 0.1$. Design specification DS1 must be satisfied for the entire family of plants. Design specification DS2 must be satisfied by the nominal process $\left(K_{m}=4, p_{1}=1, p_{2}=4\right)$.

The following constraints on the design are given:

$\square \quad$ Fast peak time requires that an overdamped condition is not acceptable.

$\square \quad$ Use a PID controller:

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s
$$

$\square \quad K_{m} K_{D} \leq 20$ when $K_{m}=4$.

The key tuning parameters are the PID gains:

\section{Select Key Tuning Parameters}

$$
K_{P}, K_{I} \text {, and } K_{D} \text {. }
$$

Since we are constrained to have $K_{m} K_{D} \leq 20$ when $K_{m}=4$, we must select $K_{D} \leq 5$. We will design the PID controller using nominal values for $K_{m}, p_{1}$, and $p_{2}$. We then analyze the performance of the controlled system for the various values of the process parameters, using a simulation to check that DS1 is satisfied. The nominal process is given by

$$
G(s)=\frac{4}{(s+1)(s+4)} .
$$

The closed-loop transfer function is

$$
T(s)=\frac{4 K_{D} s^{2}+4 K_{P} s+4 K_{I}}{s^{3}+\left(5+4 K_{D}\right) s^{2}+\left(4+4 K_{P}\right) s+4 K_{I}} .
$$

If we choose $K_{D}=5$, then we write the characteristic equation as

$$
s^{3}+25 s^{2}+4 s+4\left(K_{P} s+K_{I}\right)=0,
$$

or

$$
1+\frac{4 K_{P}\left(s+K_{I} / K_{P}\right)}{s\left(s^{2}+25 s+4\right)}=0 .
$$

Per specifications, we try to place the dominant poles in the region defined by $\zeta \omega_{n}>2$ and $\zeta>0.55$. We need to select a value of $\tau=K_{I} / K_{P}$, and then we can plot the root locus with the gain $4 K_{P}$ as the varying parameter. After several iterations, we choose a reasonable value of $\tau=3$. The root locus is shown in Figure 12.31. We determine that $4 K_{P}=120$ represents a valid selection since the roots lie inside the desired performance region. We obtain $K_{P}=30$, and $K_{I}=\tau K_{P}=90$. The PID controller is then given by

$$
G_{c}(s)=30+\frac{90}{s}+5 s .
$$

The step response (for the process with nominal parameter values) is shown in Figure 12.32. A family of responses is shown in Figure 12.33 for various values of Robust Control Systems

FIGURE 12.31

Root locus for the DAT system with $K_{D}=5$ and $\tau=K_{l} / K_{P}=3$.

FIGURE 12.32

Unit step response for the DAT system with $K_{P}=30, K_{D}=5$, and $K_{l}=90$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0913.jpg?height=1910&width=1184&top_left_y=152&top_left_x=374)FIGURE 12.33

A family of step responses for the DAT system for various values of the process parameters $K_{m}, p_{1}$, and $p_{2}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0914.jpg?height=875&width=1115&top_left_y=153&top_left_x=506)

$K_{m}, p_{1}$, and $p_{2}$. None of the responses suggests a percent overshoot over the specified value of $P . O .=13 \%$, and the settling times are all under the $T_{s} \leq 2 \mathrm{~s} \mathrm{spec}-$ ification as well. As we can see in Figure 12.33, all of the tested processes in the family are adequately controlled by the single PID controller in Equation (12.52). Therefore DS1 is satisfied for all processes in the family.

Suppose the system has a time delay at the input to the process. The actual time delay is uncertain but known to be in the range $0 \leq T \leq 0.1 \mathrm{~s}$. Following the method discussed previously, we determine that a reasonable function $W(s)$ which bounds the plots of $\left|e^{-j \omega T}-1\right|$ for various values of $T$ is

$$
W(s)=\frac{0.29 s}{0.28 s+1} .
$$

To check the stability robustness property, we need to verify that

$$
|W(j \omega)|<\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right| \text { for all } \omega .
$$

The plot of both $|W(j \omega)|$ and $\left|1+\frac{1}{G_{c}(j \omega) G(j \omega)}\right|$ is shown in Figure 12.34. It can be seen that the condition in Equation (12.53) is indeed satisfied. Therefore, we expect that the nominal system will remain stable in the presence of time-delays up to 0.1 seconds. FIGURE 12.34

Stability robustness to a time delay of uncertain magnitude.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0915.jpg?height=885&width=1098&top_left_y=164&top_left_x=373)

\subsection{THE PSEUDO-QUANTITATIVE FEEDBACK SYSTEM}

Quantitative feedback theory (QFT) uses a controller, as shown in Figure 12.35, to achieve robust performance. The goal is to achieve a wide bandwidth for the closedloop transfer function with a high loop gain $K$. Typical QFT design methods use graphical and numerical methods in conjunction with the Nichols chart. Generally, QFT design seeks a high loop gain and large phase margin so that robust performance is achieved [24-26, 28].

In this section, we pursue a simple method of achieving the goals of QFT with an $s$-plane, root locus approach to the selection of the gain $K$ and the compensator $G_{c}(s)$. This approach, dubbed pseudo-QFT, follows these steps:

1. Place the $n$ poles and $m$ zeros of $G(s)$ on the $s$-plane for the $n$th order $G(s)$. Also, add any poles of $G_{c}(s)$.

2. Starting near the origin, place the zeros of $G_{c}(s)$ immediately to the left of each of the $(n-1)$ poles on the left-hand $s$-plane. This leaves one pole far to the left of the lefthand side of the $s$-plane.

3. Increase the gain $K$ so that the roots of the characteristic equation (poles of the closedloop transfer function) are close to the zeros of $G_{c}(s) G(s)$.

This method introduces zeros so that all but one of the root loci end on finite zeros. If the gain $K$ is sufficiently large, then the poles of $T(s)$ are almost equal to the zeros of $G_{c}(s) G(s)$. This leaves one pole of $T(s)$ with a significant partial fraction residue and the system with a phase margin of approximately $90^{\circ}$ (actually about $85^{\circ}$ ). FIGURE 12.35

Feedback system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0916.jpg?height=165&width=1082&top_left_y=153&top_left_x=520)

EXAMPLE 12.11 Design using the pseudo-QFT method

Consider the system of Figure 12.35 with

$$
G(s)=\frac{1}{\left(s+p_{1}\right)\left(s+p_{2}\right)},
$$

where the nominal case is $p_{1}=1$ and $p_{2}=2$, with $\pm 50 \%$ variation. The worst case is with $p_{1}=0.5$ and $p_{2}=1$. We wish to design the system for zero steady-state error for a step input, so we use the PID controller

$$
G_{c}(s)=\frac{\left(s+z_{1}\right)\left(s+z_{2}\right)}{s} .
$$

We then invoke the internal model principle, with $R(s)=1 / s$ incorporated within $G_{c}(s) G(s)$. Using Step 1, we place the poles of on the $s$-plane, as shown in Figure 12.36. There are three poles (at $s=0,-1$, and -2 ), as shown. Step 2 calls for placing a zero to the left of the pole at the origin and at the pole at $s=-1$, as shown in Figure 12.36.

The compensator is thus

$$
G_{c}(s)=\frac{(s+0.8)(s+1.8)}{s} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0916.jpg?height=813&width=772&top_left_y=1301&top_left_x=508)

We select $K=100$, so that the roots of the characteristic equation are close to the zeros. The closed-loop transfer function is

$$
T(s)=\frac{100(s+0.80)(s+1.80)}{(s+0.798)(s+1.797)(s+100.4)} \approx \frac{100}{s+100} .
$$

This closed-loop system provides a fast response and possesses a phase margin of P.M. $=85^{\circ}$. When the worst-case conditions are realized $\left(p_{1}=0.5\right.$ and $\left.p_{2}=1\right)$, the performance remains essentially unchanged. Pseudo-QFT design results in very robust systems.

\subsection{ROBUST CONTROL SYSTEMS USING CONTROL DESIGN SOFTWARE}

In this section, we investigate robust control systems using control design software. In particular, we will consider the commonly used PID controller in the feedback control system shown in Figure 12.16. Note that the system has a prefilter $G_{p}(s)$.

The objective is to choose the PID parameters $K_{P}, K_{I}$, and $K_{D}$ to meet the performance specifications and have desirable robustness properties. Unfortunately, it is not immediately clear how to choose the parameters in the PID controller to obtain certain robustness characteristics. An illustrative example will show that it is possible to choose the parameters iteratively and verify the robustness by simulation. Using the computer helps in this process, because the entire design and simulation can be automated using scripts and can easily be executed repeatedly.

\section{EXAMPLE 12.12 Robust control of temperature}

Consider the feedback control system in Figure 12.16, where

$$
G(s)=\frac{1}{\left(s+c_{0}\right)^{2}},
$$

and the nominal value is $c_{0}=1$, and $G_{p}(s)=1$. We can design a compensator based on $c_{0}=1$ and check robustness by simulation. Our design specifications are

1. A settling time (with a $2 \%$ criterion) $T_{S} \leq 0.5 \mathrm{~s}$, and

2. An optimum ITAE performance for a step input.

For this design, we will not use a prefilter to meet specification (2), but will instead show that acceptable performance (i.e., low percent overshoot) can be obtained by increasing a cascade gain.

The closed-loop transfer function is

$$
T(s)=\frac{K_{D} s^{2}+K_{P} s+K_{I}}{s^{3}+\left(2+K_{D}\right) s^{2}+\left(1+K_{P}\right) s+K_{I}} .
$$

FIGURE 12.37

Root locus for the PID-compensated temperature controller as $\hat{K}$ varies.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0918.jpg?height=522&width=703&top_left_y=155&top_left_x=540)

$>>a=16 ; b=70 ;$ num=[1 a b]; den=[1 100 0 $]$; sys=tf(num,den); $>$ rlocus(sys)

$>$ rlocfind(sys)

The associated root locus equation is

$$
1+\hat{K}\left(\frac{s^{2}+a s+b}{s^{3}}\right)=0
$$

where

$$
\hat{K}=K_{D}+2, \quad a=\frac{1+K_{P}}{2+K_{D}}, \quad \text { and } \quad b=\frac{K_{I}}{2+K_{D}} .
$$

The settling time requirement $T_{s}<0.5 \mathrm{~s}$ leads us to choose the roots of $s^{2}+a s+b$ to the left of the $s=-\zeta \omega_{n}=-8$ line in the $s$-plane, as shown in Figure 12.37, to ensure that the locus travels into the required $s$-plane region. We have chosen $a=16$ and $b=70$ to ensure the locus travels past the $s=-8$ line. We select a point on the root locus in the performance region, and using the rlocfind function, we find the associated gain $\hat{K}$ and the associated value of $\omega_{n}$. For our chosen point, we find that

$$
\hat{K}=118 \text {. }
$$

Then, with $\hat{K}, a$, and $b$, we can solve for the PID coefficients as follows:

$$
\begin{aligned}
K_{D} & =\hat{K}-2=116, \\
K_{P} & =a\left(2+K_{D}\right)-1=1887, \\
K_{I} & =b\left(2+K_{D}\right)=8260 .
\end{aligned}
$$

To meet the overshoot performance requirements for a step input, we will use a cascade gain $K$ that will be chosen by iterative methods using the step function, as illustrated in Figure 12.38. The step response corresponding to $K=5$ has an FIGURE 12.38

Step response of the PID temperature controller.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0919.jpg?height=1088&width=890&top_left_y=154&top_left_x=392)

acceptable percent overshoot of $P . O .=2 \%$. With the addition of the gain $K=5$, the final PID controller is

$$
G_{c}(s)=K \frac{K_{D} s^{2}+K_{P} s+K_{I}}{s}=5 \frac{116 s^{2}+1887 s+8260}{s} .
$$

We do not use the prefilter. Instead, we increase the cascade gain $K$ to obtain satisfactory transient response. Now we can consider the question of robustness to changes in the plant parameter $c_{0}$.

The investigation into the robustness of the design consists of a step response analysis using the PID controller given in Equation (12.57) for a range of plant parameter variations of $0.1 \leq c_{0} \leq 10$. The results are displayed in Figure 12.39. The script is written to compute the step response for a given $c_{0}$. It can be convenient to place the input of $c_{0}$ at the command prompt level to make the script more interactive.

The simulation results indicate that the PID design is robust with respect to changes in $c_{0}$. The differences in the step responses for $0.1 \leq c_{0} \leq 10$ are barely discernible on the plot. If the results showed otherwise, it would be possible to iterate on the design until an acceptable performance was achieved. The interactive capability of the m-file allows us to check the robustness by simulation. FIGURE 12.39

Robust PID

controller analysis

with variations in $c_{0}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0920.jpg?height=671&width=781&top_left_y=149&top_left_x=520)

$\mathrm{c} 0=10$ Specify process parameter.

numg=[1]; deng=[1 $\left.2^{*} \mathrm{CO} \mathrm{cO}^{\wedge} 2\right]$;

numgc $=5^{\star}[1161887$ 8260]; dengc $=[10]$;

sysg=tf(numg,deng);

sysgc=tf(numgc, dengc);

$\%$

syso=series(sysgc,sysg);

$\%$

sys=feedback(syso,[1]);

$\%$

step(sys)

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this section, we design a PID controller to achieve the desired system response. Many disk drive head control systems use a PID controller and use a command signal $r(t)$ that utilizes an ideal velocity profile at the maximum allowable velocity until the head arrives near the desired track, when $r(t)$ is switched to a step-type input. Thus, we want zero steady-state error for a ramp (velocity) signal and a step signal. Examining the system shown in Figure 12.40, we note that the forward path possesses two pure integrations, and we expect zero steady-state error for a velocity input $r(t)=A t, t>0$.

The PID controller is

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s=\frac{K_{D}\left(s+z_{1}\right)\left(s+\hat{z}_{1}\right)}{s} .
$$

The motor field transfer function is

$$
G_{1}(s)=\frac{5000}{(s+1000)} \approx 5 .
$$

FIGURE 12.41

A sketch of a root locus at $K_{D}$ increases for estimated root locations with a desirable system response.

FIGURE 12.40 Disk drive feedback system with a PID controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0921.jpg?height=854&width=1171&top_left_y=533&top_left_x=372)

The second-order model uses $G_{1}(s)=5$, and the design is determined for this model.

We use the second-order model and the PID controller for the $s$-plane design technique illustrated in Section 12.6. The poles and zeros of the system are shown in the $s$-plane in Figure 12.41 for the second-order model and $G_{1}(s)=5$. Then we have the loop transfer function

$$
L(s)=G_{c}(s) G_{1}(s) G_{2}(s)=\frac{5 K_{D}\left(s+z_{1}\right)\left(s+\hat{z}_{1}\right)}{s^{2}(s+20)} .
$$

We select $-z_{1}=-120+j 40$ and determine $5 K_{D}$ so that the roots are to the left of the line $s=-100$. If we achieve that requirement, then

$$
T_{s}<\frac{4}{100}
$$

and the percent overshoot to a step input is (ideally) P.O. $\leq 2 \%$ since $\zeta$ of the complex roots is approximately 0.8 . Of course, this sketch is only a first step. As a FIGURE 12.42

Actual root locus for the secondorder model.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0922.jpg?height=687&width=953&top_left_y=153&top_left_x=521)

Table 12.6 Disk Drive Control System Specifications and Actual Performance

\begin{tabular}{lll}
$\begin{array}{ll}\text { Performance } \\
\text { Measure }\end{array}$ & $\begin{array}{l}\text { Desired } \\
\text { Value }\end{array}$ & $\begin{array}{l}\text { Response for } \\
\text { Second-Order } \\
\text { Model }\end{array}$ \\
\hline $\begin{array}{ll}\text { Percent overshoot } \\
\begin{array}{l}\text { Settling time for } \\
\text { step input }\end{array}\end{array}$ & $<5 \%$ & $4.5 \%$ \\
$\begin{array}{l}\text { Maximum response for } \\
\text { a unit step disturbance }\end{array}$ & $<50 \mathrm{~ms}$ & $6 \mathrm{~ms}$ \\
\hline
\end{tabular}

second step, we determine $K_{D}$. We then obtain the actual root locus as shown in Figure 12.42 with $K_{D}=800$. The system response is recorded in Table 12.6. The system meets all the specifications.

\subsection{SUMMARY}

The design of highly accurate control systems in the presence of significant plant uncertainty requires the designer to seek a robust control system. A robust control system exhibits low sensitivities to parameter change and is stable over a wide range of parameter variations.

The PID controller was considered as a compensator to aid in the design of robust control systems. The design issue for a PID controller is the selection of the gain and two zeros of the controller transfer function. We used three design methods for the selection of the controller: the root locus method, the frequency response method, and the ITAE performance index method. An operational amplifier circuit used for a PID controller is shown in Figure 12.43. In general, the use of a PID controller will enable the designer to attain a robust control system. FIGURE 12.43

Operational amplifier circuit used for PID controller.

$$
G_{c}(s)=\frac{V_{0}(s)}{V_{1}(s)}=\frac{R_{4} R_{2}\left(R_{1} C_{1} s+1\right)\left(R_{2} C_{2} s+1\right)}{R_{3} R_{1}\left(R_{2} C_{2} s\right)}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0923.jpg?height=388&width=1056&top_left_y=279&top_left_x=375)

The internal model control system with state variable feedback and a controller $G_{c}(s)$ was used to obtain a robust control system. Finally, the robust nature of a pseudo-QFT control system was demonstrated.

A robust control system provides stable, consistent performance as specified by the designer in spite of the wide variation of plant parameters and disturbances. It also provides a highly robust response to command inputs and a steady-state tracking error equal to zero.

For systems with uncertain parameters, the need for robust systems will require the incorporation of advanced machine intelligence, as shown in Figure 12.44.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0923.jpg?height=863&width=927&top_left_y=1262&top_left_x=374)

FIGURE 12.44 Intelligence required versus uncertainty for modern control systems. 

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 12.45 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0924.jpg?height=219&width=1056&top_left_y=450&top_left_x=559)

FIGURE 12.45 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. A robust control system exhibits the desired performance in the presence of significant plant uncertainty.

True or False

2. For physically realizable systems, the loop gain $L(s)=G_{c}(s) G(s)$

must be large for high frequencies.

True or False

3. The PID controller consists of three terms in which the output is the sum of a proportional term, an integrating term, and a differentiating term, with an adjustable gain for each term.

True or False

4. A plant model will always be an inaccurate representation of the actual physical system.

True or False

5. Control system designers seek small loop gain $L(s)$ in order to minimize the sensitivity $S(s)$.

True or False

6. A closed-loop feedback system has the third-order characteristic equation

$$
q(s)=s^{3}+a_{2} s^{2}+a_{1} s+a_{0}=0,
$$

where the nominal values of the coefficients are $a_{2}=3, a_{1}=6$, and $a_{0}=11$. The uncertainty in the coefficients is such that the actual values of the coefficients can lie in the intervals

$$
2 \leq a_{2} \leq 4, \quad 4 \leq a_{1} \leq 9, \quad 6 \leq a_{0} \leq 17 .
$$

Considering all possible combinations of coefficients in the given intervals, the system is:

a. Stable for all combinations of coefficients.

b. Unstable for some combinations of coefficients.

c. Marginally stable for all combinations of coefficients.

d. Unstable for all combinations of coefficients.

In Problems 7 and 8, consider the unity feedback system in Figure 12.45, where

$$
G(s)=\frac{2}{(s+3)} \text {. }
$$

7. Assume that the prefilter is $G_{p}(s)=1$. The proportional-plus-integral (PI) controller, $G_{c}(s)$, that provides optimum coefficients of the characteristic equation for ITAE (assuming $\omega_{n}=12$ and a step input) is which of the following:
a. $G_{c}(s)=72+\frac{6.9}{s}$
b. $G_{c}(s)=6.9+\frac{72}{s}$
c. $G_{c}(s)=1+\frac{1}{s}$
d. $G_{c}(s)=14+10 s$

8. Considering the same PI controller as in Problem 7, a suitable prefilter, $G_{p}(s)$, which provides optimum ITAE response to a step input is:
a. $G_{p}(s)=\frac{10.43}{s+12.5}$
b. $G_{p}(s)=\frac{12.5}{s+12.5}$
c. $G_{p}(s)=\frac{10.43}{s+10.43}$
d. $G_{p}(s)=\frac{143}{s+143}$

9. Consider the closed-loop system block-diagram in Figure 12.45, where

$$
G(s)=\frac{1}{s\left(s^{2}+8 s\right)} \text { and } \quad G_{p}(s)=1 .
$$

Determine which of the following PID controllers results in a closed-loop system possessing two pairs of equal roots.
a. $G_{c}(s)=\frac{22.5(s+1.11)^{2}}{s}$
b. $G_{c}(s)=\frac{10.5(s+1.11)^{2}}{s}$
c. $G_{c}(s)=\frac{2.5(s+2.3)^{2}}{s}$
d. None of the above

10. Consider the system in Figure 12.45 with $G_{p}(s)=1$,

$$
G(s)=\frac{b}{s^{2}+a s+b},
$$

and $1 \leq a \leq 3$ and $7 \leq b \leq 11$. Which of the following PID controllers yields a robustly stable system?
a. $G_{c}(s)=\frac{13.5(s+1.2)^{2}}{s}$
b. $G_{c}(s)=\frac{2(s+40)^{2}}{s}$ c. $G_{c}(s)=\frac{0.1(s+10)^{2}}{s}$

d. None of the above

11. Consider the system in Figure 12.45 with $G_{p}(s)=1$ and loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+5)} .
$$

The sensitivity of the closed-loop system with respect to variations in the parameter $K$ is
a. $S_{K}^{T}=\frac{s(s+3)}{s^{2}+3 s+K}$
b. $S_{K}^{T}=\frac{s+5}{s^{2}+5 s+K}$
c. $S_{K}^{T}=\frac{s}{s^{2}+5 s+K}$
d. $S_{K}^{T}=\frac{s(s+5)}{s^{2}+5 s+K}$

12. Consider the feedback control system in Figure 12.45 with plant

$$
G(s)=\frac{1}{s+2} \text {. }
$$

A proportional-plus-integral (PI) controller and prefilter pair that results in a settling time $T_{s}<1.8 \mathrm{~s}$ and an optimum ITAE step response are which of the following:
a. $G_{c}(s)=3.2+\frac{13.8}{s}$ and $G_{p}(s)=\frac{13.8}{3.2 s+13.8}$
b. $G_{c}(s)=10+\frac{10}{s}$ and $G_{p}(s)=\frac{1}{s+1}$
c. $G_{c}(s)=1+\frac{5}{s}$ and $G_{p}(s)=\frac{5}{s+5}$
d. $G_{c}(s)=12.5+\frac{500}{s}$ and $G_{p}(s)=\frac{500}{12.5 s+500}$

13. Consider a unity negative feedback system with a loop transfer function (with nominal values)

$$
L(s)=G_{c}(s) G(s)=\frac{K}{s(s+a)(s+b)}=\frac{4.5}{s(s+1)(s+2)} .
$$

Using the Routh-Hurwitz stability analysis, it can be shown that the closed-loop system is nominally stable. However, if the system has uncertain coefficients such that

$$
0.25 \leq a \leq 2, \quad 1 \leq b \leq 4, \text { and } \quad 4 \leq K \leq 5,
$$

the closed-loop system may exhibit instability. Which of the following situations is true:

a. Unstable for $a=1, b=2$, and $K=4$.

b. Unstable for $a=2, b=4$, and $K=4.5$.

c. Unstable for $a=0.25, b=3$, and $K=5$.

d. Stable for all $a, b$, and $K$ in the given intervals. 14. Consider the feedback control system in Figure 12.45 with $G_{p}(s)=1$ and $G(s)=\frac{1}{J s^{2}}$.

The nominal value of $J=5$, but it is known to change with time. It is thus necessary to design controller with sufficient phase margin to retain stability as $J$ changes. A suitable PID controller such that the phase margin is greater than P.M. $>40^{\circ}$ and bandwidth $\omega_{b}<20 \mathrm{rad} / \mathrm{s}$ is which of the following:
a. $G_{c}(s)=\frac{50\left(s^{2}+10 s+26\right)}{s}$
b. $G_{c}(s)=\frac{5\left(s^{2}+2 s+2\right)}{s}$
c. $G_{c}(s)=\frac{60\left(s^{2}+20 s+200\right)}{s}$

d. None of the above

15. A feedback control system has the nominal characteristic equation

$$
q(s)=s^{3}+a_{2} s^{2}+a_{1} s+a_{0}=s^{3}+3 s^{2}+2 s+3=0 .
$$

The process varies such that

$$
2 \leq a_{2} \leq 4, \quad 1 \leq a_{1} \leq 3, \quad 1 \leq a_{0} \leq 5 .
$$

Considering all possible combinations of coefficients $a_{2}, a_{1}$, and $a_{0}$ in the given intervals, the system is:

a. Stable for all combinations of coefficients.

b. Unstable for some combinations of coefficients.

c. Marginally stable for all combinations of coefficients.

d. Unstable for all combinations of coefficients.

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Root sensitivity

b. Additive perturbation

c. Complementary sensitivity function

d. Robust control system

e. System sensitivity

f. Multiplicative perturbation
A system that exhibits the desired performance in the presence of significant plant uncertainty.

A controller with three terms in which the output is the sum of a proportional term, an integrating term, and a differentiating term, with an adjustable gain for each term.

A transfer function that filters the input signal prior to the calculation of the error signal.

A system perturbation model expressed in the additive form $G_{C}(s)=G(s)+A(s)$ where $G(s)$ is the nominal plant, $A(s)$ is the perturbation that is bounded in magnitude, and $G_{c}(s)$ is the family of perturbed plants.

The function $G(s)=G_{c}(s) G(s)\left[1+G_{c}(s) G_{c}(s)\right]^{-1}$ that satisfies the relationship $C(s)+S(s)=1$, where $S(s)$ is the sensitivity function.

The principle that states that if $G_{c}(s) G(s)$ contains the input $R(s)$, then the output $y(t)$ will track the input asymptotically (in the steady state) and the tracking is robust. g. PID controller

h. Robust stability criterion

i. Prefilter

j. Sensitivity function

k. Internal model principle
A system perturbation model expressed in the multiplicative form $G_{m}(s)=G(s)[1+M(s)]$ where $G(s)$ is the nominal plant, $M(s)$ is the perturbation that is bounded in magnitude, and $G_{m}(s)$ is the family of perturbed plants.

A test for robustness with respect to multiplicative perturbations.

A measure of the sensitivity of the roots (that is, the poles and zeros) of the system to changes in a parameter.

The function that $S(s)=\left[1+G_{c}(s) G(s)\right]^{-1}$ that satisfies the relationship $C(s)+S(s)=1$, where $C(s)$ is the complementary sensitivity function.

A measure of the system sensitivity to changes in a parameter.

\section{EXERCISES}

E12.1 Consider a system of the form shown in Figure E12.1, where

$$
G(s)=\frac{5}{(s+5)} .
$$

Using the ITAE performance method for a step input, determine the required $G_{c}(s)$. Assume $\omega_{n}=25$ for
Table 5.6. Determine the step response with and without a prefilter $G_{p}(s)$.

E12.2 For the ITAE design obtained in Exercise E12.1, determine the response due to a disturbance $T_{d}(s)=0.5 / s$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0928.jpg?height=404&width=720&top_left_y=1254&top_left_x=783)

(a)

FIGURE E12.1

Closed-loop control system. (a) Signal flow graph.

(b) block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0928.jpg?height=355&width=1221&top_left_y=1770&top_left_x=528)

(b) E12.3 A closed-loop unity feedback system has the loop transfer function

$$
L=G_{c}(s) G(s)=\frac{22}{s(s+b)} .
$$

where $b$ is normally equal to 4 . Determine $S_{b}^{T}$, and plot $20 \log 10|T(j \omega)|$ and $20 \log 10|S(j \omega)|$ on a Bode plot.

Answer: $S_{b}^{T}=\frac{-b s}{s^{2}+b s+22}$

E12.4 A PID controller is used in a unity feedback system where

$$
G(s)=\frac{1}{(s+10)(s+25)} .
$$

The gain $K_{D}$ of the controller

$$
G_{c}(s)=K_{p}+K_{D} s+\frac{K_{I}}{s}
$$

is limited to 500. Select a set of compensator zeros so that the pair of closed-loop roots is approximately equal to the zeros. Find the step response for the approximation

$$
T(s) \cong \frac{K_{D}}{s+K_{D}}
$$

and the actual response, and compare them.

E12.5 A system has a process function

$$
G(s)=\frac{K}{s(s+4)(s+7)}
$$

with $K=50$ and unity feedback with a PD compensator

$$
G_{c}(s)=K_{p}+K_{D} s .
$$

The objective is to design $G_{c}(s)$ so that the percent overshoot to a step is P.O. $\leq 10 \%$, and the settling time (with a $2 \%$ criterion) is $T_{s} \leq 3 \mathrm{~s}$. Find a suitable $G_{c}(s)$. What is the effect of decreasing process gain from $K=50$ to $K=25$ on the percent overshoot and settling time?

E12.6 Consider the control system shown in Figure E12.6 when $G(s)=2 /(s+3)^{2}$, and select a PID controller so that the settling time (with a $2 \%$ criterion) is less than 1.5 second for an ITAE step response. Plot $y(t)$ for a step input $r(t)$ with and without a prefilter. Determine and plot $y(t)$ for a step disturbance. Discuss the effectiveness of the system.

Answer: One possible controller is

$$
G_{c}(s)=\frac{2.25 s^{2}+34.2 s+108}{s} .
$$

E12.7 For the control system of Figure E12.6 with $G(s)=1 /(s+6)^{2}$, select a PID controller to achieve a settling time (with a $2 \%$ criterion) of less than 1.0 second for an ITAE step response. Plot $y(t)$ for a step input $r(t)$ with and without a prefilter. Determine and plot $y(t)$ for a step disturbance. Discuss the effectiveness of the system.

E12.8 Repeat Exercise 12.6, striving to achieve a minimum settling time while adding the constraint that $|u(t)|<20$ for $t>0$ for a unit step input, $r(t)=1, t \geq 1$.

Answer: $G_{c}(s)=\frac{20 s+16}{s}$

E12.9 A system has the form shown in Figure E12.6 with

$$
G(s)=\frac{K}{s(s+5)(s+8)},
$$

where $K=1$. Design a PD controller such that the dominant closed-loop poles possess a damping ratio of $\zeta=0.6$. Determine the step response of the system. Predict the effect of a change in $K$ of $\pm 50 \%$, on the percent overshoot. Estimate the step response of the worst-case system.

E12.10 A system has the form shown in Figure E12.6 with

$$
G(s)=\frac{K}{s(s+2)(s+7)},
$$

where $K=1$. Design a PI controller so that the dominant roots have a damping ratio $\zeta=0.65$. Determine the step response of the system. Predict the effect of a change in $K$ of $\pm 50 \%$ on the percent overshoot. Estimate the step response of the worstcase system.
FIGURE E12.6

System with controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0929.jpg?height=287&width=1079&top_left_y=1823&top_left_x=373)

E12.11 Consider a second-order system with the following state space representation

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t),
\end{gathered}
$$

where $\mathbf{A}=\left[\begin{array}{cc}0 & 1 \\ -p & -k\end{array}\right], p>0, k>0, \mathbf{B}=\left[\begin{array}{l}0 \\ 1\end{array}\right]$, and $\mathbf{C}=\left[\begin{array}{ll}1 & 0\end{array}\right]$.

a. What are the system's natural frequency $\omega_{n}$ and damping ratio $\zeta$ as functions of system parameters $p$ and $k$ ?

b. Given the parameter values of $p$ and $k$ vary in intervals of $5 \leq p \leq 50$ and $1 \leq k \leq 10$, what will be the ranges of variation of $\omega_{n}$ and $\zeta$ ?
For a nominal value of $p=20$, what is the range of the system damping ratio? Plot the root locus with variation of $k$. If the system is required to have a percent overshoot of less than $10 \%$, a controller is added to improve damping capability by increasing parameter $k$. What is the minimum value of $k$ to maintain the required percent overshoot?

E12.12 Consider the second-order system

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\left[\begin{array}{cc}
0 & 1 \\
-a & -b
\end{array}\right] \mathbf{x}(t)+\left[\begin{array}{l}
c_{1} \\
c_{2}
\end{array}\right] u(t) \\
y(t)=\left[\begin{array}{ll}
1 & 0
\end{array}\right] \mathbf{x}(t)+[0] u(t) .
\end{gathered}
$$

The parameters $a, b, c_{1}$, and $c_{2}$ are unknown $a$ priori. Under what conditions is the system completely controllable? Select valid values of $a, b, c_{1}$, and $c_{2}$ to ensure controllability and plot the step response.

\section{PROBLEMS}

P12.1 Consider the uncrewed underwater vehicle (UUV) problem. The control system is shown in Figure P12.1, where $R(s)=0$, the desired roll angle, and $T_{d}(s)=1 / s$. (a) Plot $20 \log |T(j \omega)|$ and $20 \log \left|S_{K}^{T}(j \omega)\right|$. (b) Evaluate $\left|S_{K}^{T}(j \omega)\right|$ at $\omega_{B}, \omega_{B / 2}$, and $\omega_{B / 4}$.

P12.2 Consider the control system is shown in Figure P12.2, where $\tau_{1}=10 \mathrm{~ms}$ and $\tau_{2}=1 \mathrm{~ms}$.

(a) Select $K$ so that $M_{p \omega}=1.39$. (b) Plot $20 \log |T(j \omega)|$ and $20 \log \left|S_{K}^{T}(j \omega)\right|$ on one Bode plot.

(c) Evaluate $\left|S_{K}^{T}(j \omega)\right|$ at $\omega_{B}, \omega_{B / 2}$, and $\omega_{B / 4}$. (d) Let $R(s)=0$, and determine the effect of $T_{d}(s)=1 / s$ for the gain $K$ of part (a) by plotting $y(t)$.

P12.3 Magnetic levitation (maglev) trains may replace airplanes on routes shorter than 200 miles. The maglev train developed by a German firm uses electromagnetic attraction to propel and levitate heavy vehicles, carrying up to 400 passengers at $300-\mathrm{mph}$ speeds. But the $\frac{1}{4}$-inch gap between car and track is difficult to maintain $[7,12,17]$.

The block diagram of the air-gap control system is shown in Figure P12.3. The compensator is

$$
G_{c}(s)=\frac{K(s-3)}{(s+0.06)} .
$$

(a) Find the range of $K$ for a stable system. (b) Select a gain so that the steady-state error of the system is less than 0.2 for a step input command. (c) Find $y(t)$ for the gain of part (b). (d) Find $y(t)$ when $K$ varies $\pm 15 \%$ from the gain of part (b).
FIGURE P12.1

Control of an underwater vehicle [13].
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0930.jpg?height=536&width=1092&top_left_y=1578&top_left_x=508)

FIGURE P12.2

Remote-controlled TV camera. FIGURE P12.3

Maglev train

control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0931.jpg?height=275&width=999&top_left_y=152&top_left_x=373)

P12.4 An automatically guided vehicle is shown in Figure P12.4(a) and its control system is shown in Figure P12.4(b). The goal is to track the guide wire accurately, to be insensitive to changes in the gain $K_{1}$, and to reduce the effect of the disturbance $[15,22]$. The gain $K_{1}$ is normally equal to 1 and $\tau=1 / 10$.

a. Select a compensator $G_{c}(s)$ so that the percent overshoot to a step input is $P . O$. $\leq 15 \%$, and the settling time (with a $2 \%$ criterion) is $T_{S} \leq 0.5 \mathrm{~s}$.

b. For the compensator selected in part (a), determine the sensitivity of the system to small changes in $K_{1}$ by determining $S_{K_{1}}^{T}$.

c. If $K_{1}$ changes to 2 while $G_{c}(s)$ of part (a) remains unchanged, find the step response of the system and compare selected performance figures with those obtained in part (a).

p. Determine the effect of $T_{d}(s)=1 / s$ by plotting $y(t)$ when $R(s)=0$.

P12.5 A roll-wrapping machine (RWM) receives, wraps, and labels large paper rolls produced in a paper mill $[9,16]$. The RWM consists of several major stations: positioning station, waiting station, wrapping station, and so forth. We will focus on the positioning station shown in Figure P12.5(a). The positioning station is the first station that sees a paper roll. This station is responsible for receiving and weighing the roll, measuring its diameter and width, determining the desired wrap for the roll, positioning it for downstream processing, and finally ejecting it from the station.

Functionally, the RWM can be categorized as a complex operation because each functional step (e.g., measuring the width) involves a large number of field device actions and relies upon a number of accompanying sensors.

The control system for accurately positioning the width-measuring arm is shown in Figure P12.5(b). The pole $p$ of the positioning arm is normally equal to 2 , but it is subject to change because of loading and misalignment of the machine. (a) For $p=2$, design a compensator so that the P.O. $\leq 20 \%$ and $T_{s} \leq 1 \mathrm{~s}$ to a unit step input. (b) Plot $y(t)$ for a step input $R(s)=1 / s$. (c) Plot $y(t)$ for a disturbance
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0931.jpg?height=416&width=1114&top_left_y=1280&top_left_x=372)

(a)

FIGURE P12.4

Automatically guided vehicle.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0931.jpg?height=280&width=1115&top_left_y=1789&top_left_x=393)

(b) FIGURE P12.5

Roll-wrapping machine control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0932.jpg?height=398&width=835&top_left_y=154&top_left_x=542)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0932.jpg?height=285&width=853&top_left_y=650&top_left_x=519)

(b)
$T_{d}(s)=1 / s$, with $R(s)=0$. (d) Repeat parts (b) and (c) when $p$ changes to 1 and $G_{c}(s)$ remains as designed in part (a) and compare.

P12.6 The function of a steel plate mill is to roll reheated slabs into plates of scheduled thickness and dimension $[5,10]$. The final products are of rectangular plane view shapes having a width of up to $3300 \mathrm{~mm}$ and a thickness of $180 \mathrm{~mm}$.

A schematic layout of the mill is shown in Figure P12.6(a). The mill has two major rolling stands, denoted No. 1 and No. 2. These are equipped with large rolls (up to $508 \mathrm{~mm}$ in diameter), which are driven by high-power electric motors (up to $4470 \mathrm{~kW}$ ). Roll gaps and forces are maintained by large hydraulic cylinders.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0932.jpg?height=190&width=1001&top_left_y=1556&top_left_x=598)

(a)

FIGURE P12.6

Steel-rolling mill control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0932.jpg?height=252&width=1214&top_left_y=1838&top_left_x=517)

(b)
Typical operation of the mill can be described as follows. Slabs coming from the reheating furnace initially go through the No. 1 stand, whose function is to reduce the slabs to the required width. The slabs proceed through the No. 2 stand, where finishing passes are carried out to produce the required slab thickness. Finally, they go through the hot plate leveller, which gives each plate a smooth finish.

One of the key systems controls the thickness of the plates by adjusting the rolls. The block diagram of this control system is shown in Figure P12.6(b).

The controller is a PID with two equal real zeros. (a) Select the PID zeros and the gains so that the closed-loop system has two pairs of equal roots. 

\section{FIGURE P12.7}

PID controller for the motor and load system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0933.jpg?height=277&width=1230&top_left_y=153&top_left_x=373)

(b) For the design of part (a), obtain the step response without a prefilter $\left(G_{p}(s)=1\right)$. (c) Repeat part (b) for an appropriate prefilter. (d) For the system, determine the effect of a unit step disturbance by evaluating $y(t)$ with $r(t)=0$.

P12.7 A motor and load with negligible friction and a voltage-to-current amplifier $K_{a}$ is used in the feedback control system, shown in Figure P12.7. A designer selects a PID controller

$$
G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s,
$$

where $K_{P}=5, K_{I}=500$, and $K_{D}=0.0475$.

(a) Determine the appropriate value of $K_{a}$ so that the phase margin of the system is $P . M .=30^{\circ}$. (b) For the gain $K_{a}$, plot the root locus of the system and determine the roots of the system for the $K_{a}$ of part (a). (c) Determine the maximum value of $y(t)$ when $T_{d}(s)=1 / s$ and $R(s)=0$ for the $K_{a}$ of part (a). (d) Determine the response to a step input $r(t)$, with and without a prefilter.

P12.8 A unity feedback system has a nominal characteristic equation

$$
q(s)=s^{3}+2 s^{2}+4 s+5=0 .
$$

The coefficients vary as follows:

$$
1 \leq a_{2} \leq 3, \quad 2 \leq a_{1} \leq 5, \quad 4 \leq a_{0} \leq 6 .
$$

Determine whether the system is stable for these uncertain coefficients.

P12.9 Future astronauts may drive on the Moon in a pressurized vehicle, shown in Figure P12.9(a), that would have a long range and could be used for missions of up to six months. Engineers first analyzed the Apolloera Lunar Roving Vehicle, then designed the new vehicle, incorporating improvements in radiation and thermal protection, shock and vibration control, and lubrication and sealants.

The steering control of the moon buggy is shown in Figure P12.9(b). The objective of the control design is to achieve a step response to a steering command with zero steady-state error, a percent overshoot of P.O. $\leq 20 \%$, and a peak time of $T_{P} \leq 1 \mathrm{~s}$. It is also necessary to determine the effect of a step disturbance $T_{d}(s)=1 / s$ when $R(s)=0$, in order to ensure the reduction of moon surface effects. Using (a) a PI controller and (b) a PID controller, design an acceptable controller. Record the results for each design in a table. Compare the performance of each design.

P12.10 A satellite system can be modeled as a double integrator with a plant transfer function $G(s)=\frac{10}{s^{2}}$. We want to use a PID controller and a prefilter with unity feedback for the system to achieve the requirements of P.O. $=2 \%$ and settling time $T_{S}=2 \mathrm{sec}$. The desired characteristic poles for third-order systems as per ITAE and Bessel polynomials normalized at $\omega_{n}=1 \mathrm{rad} / \mathrm{s}$ are given as:

\section{ITAE:}

$(s+0.7081)(s+0.5210+j 1.0681)(s+0.5210-j 1.0681)$

Bessel:

$(s+0.9420)(s+0.7455+j 0.7112)(s+0.7455-j 0.7112)$.

Design the PID and the prefilter. Plot the step response of the system.

P12.11 Consider the three dimensional cam shown in Figure P12.11 [18]. The control of $x$ may be achieved with a DC motor and position feedback of the form shown in Figure P12.11.

Assume $1 \leq K \leq 5$ and $2 \leq p \leq 5$. Normally $K=1$ and $p=3$. Design a PID controller so that the settling time response to a step input is $T_{s} \leq 3 \mathrm{~s}$ for all $p$ and $K$ in the ranges given.

P12.12 Consider a control system with the plant's model

$$
\begin{gathered}
\dot{\mathbf{x}}(t)=\mathbf{A x}(t)+\mathbf{B} u(t) \\
y(t)=\mathbf{C x}(t),
\end{gathered}
$$

$\begin{aligned} \text { where } \mathbf{A} & =\left[\begin{array}{rrr}0 & 1 & 0 \\ 0 & 0 & 1 \\ -9 & -6 & -4\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{l}0 \\ 0 \\ 1\end{array}\right], \quad \text { and } \\ \mathbf{C} & =\left[\begin{array}{lll}0 & 1 & 0\end{array}\right] .\end{aligned}$

The system uses output feedback $u(t)=r(t)-K y(t)$, where $r(t)$ is the reference input. Plot the root locus. Derive the transfer function of the closed-loop system and its sensitivity to variations in parameter $K$. FIGURE P12.9

(a) A moon vehicle.

(b) Steering control for the moon vehicle.

FIGURE P12.11

An $x$-axis control system of a three dimensional cam.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0934.jpg?height=828&width=833&top_left_y=153&top_left_x=543)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0934.jpg?height=287&width=1054&top_left_y=1084&top_left_x=508)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0934.jpg?height=169&width=840&top_left_y=1484&top_left_x=521)

\section{ADVANCED PROBLEMS}

AP12.1 To minimize vibrational effects, a telescope is magnetically levitated. This method also eliminates friction in the azimuth magnetic drive system. The photodetectors for the sensing system require electrical connections. The system block diagram is shown in Figure AP12.1. Design a PID controller so that the maximum percent overshoot for a step input is P.O. $\leq 20 \%$ and the $T_{s} \leq 1 \mathrm{~s}$.
AP12.2 One promising solution to traffic gridlock is a magnetic levitation (maglev) system. Vehicles are suspended on a guideway above the highway and guided by magnetic forces instead of relying on wheels or aerodynamic forces. Magnets provide the propulsion for the vehicles $[7,12,17]$. Ideally, maglev can offer the environmental and safety advantages of a high-speed train, the speed and low friction of an airplane, and FIGURE AP12.1

Magnetically levitated telescope position control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0935.jpg?height=281&width=869&top_left_y=151&top_left_x=372)

the convenience of an automobile. All these shared attributes notwithstanding, the maglev system is truly a new mode of travel and will enhance the other modes of travel by relieving congestion and providing connections among them. Maglev travel would be fast, operating at 150 to 300 miles per hour.

The tilt control of a maglev vehicle is illustrated in Figures AP12.2(a) and (b). The dynamics of the plant $G(s)$ are subject to variation so that the poles will lie within the boxes shown in Figure AP12.2(c), and $1 \leq K \leq 2$.

The objective is to achieve a robust system with a step response possessing a percent overshoot of P.O. $\leq 10 \%$, as well as a settling time (with a $2 \%$ criterion) of $T_{s} \leq 2 \mathrm{~s}$ when $|u(t)| \leq 100$. Obtain a design with a PI, PD, and PID controller and compare the results. Use a prefilter $G_{p}(s)$ if necessary.

AP12.3 Antiskid braking systems present a challenging control problem, since brake/automotive system parameter variations can vary significantly (e.g., due to the brake-pad coefficient of friction changes or road slope variations) and environmental influences (e.g., due to adverse road conditions). The objective of the antiskid system is to regulate wheel slip to maximize the coefficient of friction between the tire and road for any given road surface [8]. As we expect, the braking coefficient of friction is greatest for dry asphalt, slightly reduced for wet asphalt, and greatly reduced for ice.

A unity feedback simplified model of the braking system is represented by a plant transfer function $G(s)$ with

$$
G(s)=\frac{Y(s)}{U(s)}=\frac{1}{(s+a)(s+b)},
$$

where normally $a=1$ and $b=4$.

a. Using a PID controller, design a very robust system where, for a step input, the percent overshoot is $P . O . \leq 4 \%$ and the settling time (with a $2 \%$ criterion) is $T_{s} \leq 1 \mathrm{~s}$. The steady-state error must be less than $1 \%$ for a step. We expect $a$ and $b$ to vary by $\pm 50 \%$.

b. Design a system to yield the specifications of part (a) using an ITAE performance index. Predict the percent overshoot and settling time for this design.
AP12.4 A robot has been designed to aid in hipreplacement surgery. The device, called RoBoDoc, is used to precisely orient and mill the femoral cavity for acceptance of the prosthetic hip implant. Clearly, we want a very robust surgical tool control, because there is no opportunity to redrill a bone $[21,27]$. The unity feedback control system has

$$
G(s)=\frac{b}{s^{2}+a s+b},
$$

where $1 \leq a \leq 2$, and $4 \leq b \leq 12$.

Select a PID controller so that the system is robust. Use the $s$-plane root locus method. Select the appropriate $G_{p}(s)$ and plot the response to a step input.

AP12.5 The plant of a driverless car is modeled as $G(s)=\frac{K}{s(s+10)}$, where $K=1$ under nominal conditions. The system has unity feedback with a controller $G_{c}(s)$. To increase the system's robustness, a phase margin of P.M. $=50^{\circ}$ is required. Design a PID controller for $G_{c}(s)$, and determine the effect of parameter variations when the system gain $K$ changes by $\pm 50 \%$. Plot the step response of the controlled system.

AP12.6 Consider a unity feedback system with

$$
G(s)=\frac{K_{1}}{s(\tau s+1)},
$$

where $K_{1}=1.5$ and $\tau=0.001$ s. Select a PID controller so that the settling time (with a $2 \%$ criterion) for a step input is $T_{s} \leq 1 \mathrm{~s}$ and the percent overshoot is P.O. $\leq 10 \%$. Also, the effect of a disturbance at the output must be reduced to less than $5 \%$ of the magnitude of the disturbance.

AP12.7 Consider a unity feedback system with

$$
G(s)=\frac{1}{s} .
$$

The goal is to select a PI controller using the ITAE design criterion while constraining the control signal as $|u(t)| \leq 1$ for a unit step input. Determine the appropriate PI controller and the settling time (with a $2 \%$ criterion) for a step input. Use a prefilter, if necessary. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0936.jpg?height=945&width=917&top_left_y=165&top_left_x=652)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0936.jpg?height=263&width=1133&top_left_y=1202&top_left_x=520)

(b)

FIGURE AP12.2

(a) and (b) tilt control for a maglev vehicle. (c) plant dynamics.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0936.jpg?height=428&width=451&top_left_y=1562&top_left_x=866)

(c) 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0937.jpg?height=604&width=1214&top_left_y=159&top_left_x=374)

FIGURE AP12.8

A machine tool control system.

AP12.8 A machine tool control system is shown in Figure AP12.8. The transfer function of the power amplifier, prime mover, moving carriage, and tool bit is

$$
G(s)=\frac{50}{s(s+1)(s+4)(s+5)} .
$$

The goal is to have a percent overshoot of P.O. $\leq 25 \%$ for a step input while achieving a peak time of $T_{p} \leq 3 \mathrm{~s}$. Determine a suitable controller using (a) PD control, (b) PI control, and (c) PID control. (d) Then select the best controller.

AP12.9 The position control of a suspension system can be represented by a unity feedback system with controller $G_{c}(s)$. The plant has a gain $K$ and viscous friction coefficient $b, G(s)=\frac{K}{s^{2}+b s+K}$. The system has its gain varying in a large range, $4 \leq K \leq 25$, with low damping, $0.5 \leq b \leq 2$. The desired $2 \%$ criterion applies to this system with a settling time $T_{s} \leq 0.5 \mathrm{~s}$ as per an ITAE index. Design a PID controller for $G_{c}(s)$ so that in the worst case, the system still maintains the control performance. At the smallest damping coefficient, $b=0.5$, plot the root locus for the controlled system with the obtained PID controller, and comment on its performance.

AP12.10 A system of the form shown in Figure 12.1 has

$$
G(s)=\frac{s+r}{(s+p)(s+q)},
$$

where $3 \leq p \leq 5,0 \leq q \leq 1$, and $1 \leq r \leq 2$. We will use a compensator

$$
G_{c}(s)=\frac{K\left(s+z_{1}\right)\left(s+z_{2}\right)}{\left(s+p_{1}\right)\left(s+p_{2}\right)},
$$

with all real poles and zeros. Select an appropriate compensator to achieve robust performance.

AP12.11 A unity feedback system has a plant

$$
G(s)=\frac{1}{(s+2)(s+4)(s+6)} .
$$

We want to attain a steady-state error for a step input. Select a compensator $G_{c}(s)$ using the pseudo-QFT method, and determine the performance of the system when all the poles of $G(s)$ change by $-50 \%$. Describe the robust nature of the system.

\section{DESIGN PROBLEMS}

CDP12.1 Design a PID controller for the capstan-slide system of Figure CDP4.1. The percent overshoot should be $P . O . \leq 3 \%$ and the settling time should be (with a $2 \%$ criterion) $T_{s} \leq 250 \mathrm{~ms}$ for a step input $r(t)$. Determine the response to a disturbance for the designed system.
DP12.1 A position control system for a large turntable is shown in Figure DP12.1(a), and the block diagram of the system is shown in Figure DP12.1(b) $[11,14]$. This system uses a large torque motor with $K_{m}=15$. The objective is to reduce the steady-state effect of a step change in the load disturbance to $5 \%$ of the magnitude of the step disturbance while maintaining 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0938.jpg?height=365&width=1197&top_left_y=154&top_left_x=556)

(a)

FIGURE DP12.1

Turntable control.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0938.jpg?height=360&width=1230&top_left_y=620&top_left_x=523)

(h)

a fast response to a step input command $R(s)$, DP12.3 Many university and government laboratories with $P . O . \leq 5 \%$. Select $K_{1}$ and the compensator when (a) $G_{c}(s)=K$ and (b) $G_{c}(s)=K_{P}+K_{D} s$. Plot the step response for the disturbance and the input for both compensators. Determine whether a prefilter is required to meet the percent overshoot requirement.

DP12.2 Consider the closed-loop system depicted in Figure DP12.2. The process has a parameter $K$ that is nominally $K=1$. Design a controller that results in a percent overshoot P.O. $\leq 20 \%$ for a unit step input for all $K$ in the range $1 \leq K \leq 4$. have constructed robot hands capable of grasping and manipulating objects. But teaching the artificial devices to perform even simple tasks required formidable computer programming. However, a special hand device can be worn over a human hand to record the side-toside and bending motions of finger joints. Each joint is fitted with a sensor that changes its signal depending on position. The signals from all the sensors are translated into computer data and used to operate robot hands [1].

The joint angle control system is shown in part Figure DP12.3. The normal value of $K_{m}$ is 1.0. The goal is to design a PID controller so that the

FIGURE DP12.2 A unity feedback system with a process with varying parameter K.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0938.jpg?height=233&width=847&top_left_y=1558&top_left_x=508)

FIGURE DP12.3 Special hand device to train robot hands.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0938.jpg?height=277&width=1248&top_left_y=1842&top_left_x=505)

steady-state error for a ramp input is zero. Also, the settling time (with a $2 \%$ criterion) must be $T_{s} \leq 3 \mathrm{~s}$ for the ramp input. We want the controller to be

$$
G_{c}(s)=\frac{K_{D}\left(s^{2}+6 s+18\right)}{s} .
$$

(a) Select $K_{D}$ and obtain the ramp response. Plot the root locus as $K_{D}$ varies. (b) If $K_{m}$ changes to one-half of its normal value and $G_{c}(s)$ remains as designed in part (a), obtain the ramp response of the system. Compare the results of parts (a) and (b) and discuss the robustness of the system.

DP12.4 Objects smaller than the wavelengths of visible light are a staple of contemporary science and technology. Biologists study single molecules of protein or DNA; materials scientists examine atomic-scale flaws in crystals; microelectronics engineers lay out circuit patterns only a few tenths of atoms thick. Until recently, this minute world could be seen only by cumbersome, often destructive methods, such as electron microscopy and X-ray diffraction. It lay beyond the reach of any instrument as simple and direct as the familiar light microscope. New microscopes, typified by the scanning tunneling microscope (STM), are now available [3].

The precision of position control required is in the order of nanometers. The STM relies on piezoelectric sensors that change size when an electric voltage across the material is changed. The "aperture" in the STM is a tiny tungsten probe, its tip ground so fine that it may consist of only a single atom and measure just 0.2 nanometer in width. Piezoelectric controls maneuver the tip to within a nanometer or two of the surface of a conducting specimen-so close that the electron clouds of the atom at the probe tip and of the nearest atom of the specimen overlap. A feedback mechanism senses the variations in tunneling current and varies the voltage applied to a third, $z$-axis, control. The $z$-axis piezoelectric moves the probe vertically to stabilize the current and to maintain a constant gap between the microscope's tip and the surface. The control system is shown in Figure DP12.4(a), and the block diagram is shown in Figure DP12.4(b).

(a) Use the ITAE design method to determine $G_{c}(s)$. (b) Determine the step response of the system with and without a prefilter $G_{p}(s)$. (c) Determine the response of the system to a disturbance when $T_{d}(s)=1 / s$. (d) Using the prefilter and of $G_{c}(s)$ parts (a) and (b), determine the actual response when the process changes to

$$
G(s)=\frac{16000}{s\left(s^{2}+40 s+1600\right)} .
$$

DP12.5 The system described in DP12.4 is to be designed using the frequency response techniques. Select

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0939.jpg?height=562&width=830&top_left_y=1144&top_left_x=505)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0939.jpg?height=280&width=1402&top_left_y=1798&top_left_x=216)

the coefficients of $G_{c}(s)$ so that the phase margin is $P . M .=45^{\circ}$. Obtain the step response of the system with and without a prefilter $G_{p}(s)$.

DP12.6 The use of control theory to provide insight into neurophysiology has a long history. As early as the beginning of the last century, many investigators described a muscle control phenomenon caused by the feedback action of muscle spindles and by sensors based on a combination of muscle length and rate of change of muscle length.

This analysis of muscle regulation has been based on the theory of single-input, single-output control systems. An example is a proposal that the stretch reflex is an experimental observation of a motor control strategy, namely, control of individual muscle length by the spindles. Others later proposed the regulation of individual muscle stiffness (by sensors of both length and force) as the motor control strategy [30].

One model of the human standing-balance mechanism is shown in Figure DP12.6. Consider the case of a paraplegic who has lost control of his standing mechanism. We propose to add an artificial controller to enable the person to stand and move his legs. (a) Design a controller when the normal values of the parameters are $K=10, a=12$, and $b=100$, in order to achieve a step response with percent overshoot of P.O. $\leq 10 \%$, steady-state error of $e_{s s} \leq 5 \%$, and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 2 \mathrm{~s}$. Try a controller with proportional gain, PI, PD, and PID. (b) When the person is fatigued, the parameters may change to $K=15, a=8$, and $b=144$. Examine the performance of this system with the controllers of part (a). Prepare a table contrasting the results of parts (a) and (b).

P12.7 The goal is to design an elevator control system so that the elevator will move from floor to floor rapidly and stop accurately at the selected floor (Figure DP12.7). The elevator will contain from one to three occupants. However, the weight of the elevator should be greater than the weight of the occupants; you may assume that the elevator weighs 1000 pounds and each occupant weighs 150 pounds. Design a system to accurately control the elevator to within one centimeter. Assume that the large DC motor is field-controlled. Also, assume that the time constant of the motor and load is one second, the time constant of the power amplifier driving the motor is one-half
FIGURE DP12.6

Artificial control of standing and leg articulation.
FIGURE DP12.7

Elevator position control.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0940.jpg?height=1110&width=1266&top_left_y=1000&top_left_x=486)FIGURE DP12.8

Feedback control system for an electric ventricular assist device.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0941.jpg?height=282&width=1271&top_left_y=151&top_left_x=350)

second, and the time constant of the field is negligible. We seek a percent overshoot of P.O. $\leq 6 \%$ and a settling time (with a $2 \%$ criterion) of $T_{S} \leq 4 \mathrm{~s}$.

DP12.8 A model of the feedback control system is shown in Figure DP12.8 for an electric ventricular assist device. This problem was introduced in AP9.11. The motor, pump, and blood sac can be modeled by a time delay with $T=1 \mathrm{~s}$. The goal is to achieve a step response with less than 5\% steady-state error and P.O. $\leq 10 \%$. Furthermore, to prolong the batteries, the voltage is limited to $30 \mathrm{~V}$ [26]. Design a controller using (a) $G_{c}(s)=K / s$, (b) a PI controller, and (c) a PID controller. In each case, also design the pre-filter. Compare the results for the three controllers by recording in a table the percent overshoot, peak time, settling time (with $2 \%$ criterion) and the maximum value of $v(t)$.

DP12.9 One arm of a space robot is shown in Figure DP12.9(a). The block diagram for the control of the arm is shown in Figure DP12.9(b).

(a) If $G_{c}(s)=K$, determine the gain necessary for a percent overshoot of P.O. $=4.5 \%$, and plot the step response. (b) Design a proportional plus derivative (PD) controller using the ITAE method and $\omega_{n}=10$. Determine the required prefilter $G_{p}(s)$. (c) Design a PI controller and a prefilter using the ITAE method. (d) Design a PID controller and a prefilter using the ITAE method with $\omega_{n}=10$. (e) Determine the effect of a unit step disturbance for each design. Record the maximum value of $y(t)$ and the final value of $y(t)$ for the disturbance input. (f) Determine the overshoot, peak time, and settling time (with a $2 \%$ criterion) step $R(s)$ for each design above. ( $\mathrm{g}$ ) The process is subject to variation due to load changes. Find the magnitude of the sensitivity at $\omega=5,\left|S_{G}^{T}(j 5)\right|$, where

$$
T(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)} .
$$

(h) Based on the results of parts (e), (f), and (g), select the best controller.

DP12.10 A photovoltaic system is mounted on a space station in order to develop the power for the station. The photovoltaic panels should follow the Sun with

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0941.jpg?height=442&width=572&top_left_y=1324&top_left_x=561)

FIGURE DP12.9

Space robot control. (a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0941.jpg?height=238&width=966&top_left_y=1852&top_left_x=373)

(b) good accuracy in order to maximize the energy from the panels. The unity feedback control system uses a DC motor, so that the transfer function of the panel mount and the motor is

$$
G(s)=\frac{1}{s(s+b)},
$$

where $b=10$. Design a controller $G_{c}(s)$ assuming that an optical sensor is available to accurately track the sun's position.

The goal is to design $G_{c}(s)$ so that (1) the percent overshoot to a unit step is $P . O . \leq 15 \%$ and (2) the settling time is $T_{s} \leq 0.75 \mathrm{~s}$. Examine the robustness of the system when $b$ varies by $\pm 10 \%$.

DP12.11 Electromagnetic suspension systems for aircushioned trains are known as magnetic levitation (maglev) trains. One maglev train uses a superconducting magnet system [17]. It uses superconducting coils, and the levitation distance $x(t)$ is inherently unstable. The model of the levitation is

$$
G(s)=\frac{X(s)}{V(s)}=\frac{K}{\left(s \tau_{1}+1\right)\left(s^{2}-\omega_{1}^{2}\right)},
$$

FIGURE DP12.12

Two-mass cart system. where $V(s)$ is the coil voltage; $\tau_{1}$ is the magnet time constant; and $\omega_{1}$ is the natural frequency. The system uses a position sensor with a negligible time constant. A train traveling at $250 \mathrm{~km} / \mathrm{hr}$ would have $\tau_{1}=0.75 \mathrm{~s}$ and $\omega_{1}=75 \mathrm{rad} / \mathrm{s}$. Determine a controller in a unity feedback system that can maintain steady, accurate levitation when disturbances occur along the railway.

DP12.12 A benchmark problem consists of the massspring system shown in Figure DP12.12, which represents a flexible structure. Let $m_{1}=m_{2}=1$ and $0.5 \leq k \leq 2.0$ [29]. It is possible to measure $x_{1}(t)$ and $x_{2}(t)$ and use a controller prior to $u(t)$. Obtain the system description, choose a control structure, and design a robust system. Determine the response of the system to a unit step disturbance. Assume that the output $x_{2}(t)$ is the variable to be controlled.

\section{COMPUTER PROBLEMS}

CP12.1 A closed-loop feedback system is shown in Figure CP12.1. Use an m-file to obtain a plot of $\left|S_{K}^{T}(j \omega)\right|$ versus $\omega$. Plot $|T(j \omega)|$ versus $\omega$, where $T(s)$ is the closedloop transfer function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0942.jpg?height=230&width=772&top_left_y=1621&top_left_x=223)

FIGURE CP12.1 Closed-loop feedback system with gain $K$.

CP12.2 An aircraft aileron can be modeled as a first-order system

$$
G(s)=\frac{p}{s+p}
$$

where $p$ depends on the aircraft. Obtain a family of step responses for the aileron system in the feedback configuration shown in Figure CP12.2.

The nominal value of $p=15$. Compute reasonable values of $K_{p}$ and $K_{I}$ so that the step response (with $p=15)$ has $P . O . \leq 20 \%$ and $T_{s} \leq 0.5$ s. Then, use an m-file to obtain the step responses for $12<p<18$ with the controller as determined above. Plot the settling time as a function of $p$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0942.jpg?height=223&width=719&top_left_y=1803&top_left_x=1033)

FIGURE CP12.2 Closed-loop control system for the aircraft aileron. CP12.3 Consider the control system in Figure CP12.3. The value of $J$ is known to change slowly with time, although, for design purposes, the nominal value is chosen to be $J=28$.

(a) Design a PID controller (denoted by $G_{c}(s)$ ) to achieve a phase margin $P . M . \geq 45^{\circ}$ and a bandwidth $\omega_{B} \leq 4 \mathrm{rad} / \mathrm{s}$. (b) Using the PID controller designed in part (a), develop an m-file script to generate a plot of the phase margin as $J$ varies from 10 to 40 . At what $J$ is the closed-loop system unstable.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0943.jpg?height=167&width=684&top_left_y=533&top_left_x=86)

FIGURE CP12.3 A feedback control system with compensation.

CP12.4 Consider the feedback control system in Figure CP12.4. The exact value of parameter $b$ is unknown; however, for design purposes, the nominal value is taken to be $b=4$. The value of $a=8$ is known very precisely.

a. Design the proportional controller $K$ so that the closed-loop system response to a unit step input has a settling time (with a $2 \%$ criterion) of $T_{s} \leq 5$ s and a percent overshoot of P.O. $\leq 10 \%$. Use the nominal value of $b$ in the design.

b. Investigate the effects of variations in the parameter $b$ on the closed-loop system unit step response. Let $b=0,1,4$, and 40, and co-plot the step response associated with each value of $b$. In all cases, use the proportional controller from part (a). Discuss the results.

CP12.5 A model of a flexible structure is given by

$$
G(s)=\frac{\left(1+k \omega_{n}^{2}\right) s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}}{s^{2}\left(s^{2}+2 \zeta \omega_{n} s+\omega_{n}^{2}\right)},
$$

where $\omega_{n}$ is the natural frequency of the flexible mode, and $\zeta$ is the corresponding damping ratio. In general, it is difficult to know the structural damping precisely, while the natural frequency can be predicted more accurately using well-established modeling techniques. Assume the nominal values of $\omega_{n}=2 \mathrm{rad} / \mathrm{s}, \zeta=0.005$, and $k=0.1$.

a. Design a lead compensator to meet the following specifications: (1) a closed-loop system response to a unit step input with a settling time (with a $2 \%$ criterion) $T_{s} \leq 200 \mathrm{~s}$ and (2) a percent overshoot of P.O. $\leq 50 \%$.

b. With the controller from part (a), investigate the closed-loop system unit step response with $\zeta=0,0.005,0.1$, and 1. Co-plot the various unit step responses and discuss the results.

c. From a control system point of view, is it preferable to have the actual flexible structure damping less than or greater than the design value? Explain.

CP12.6 The industrial process shown in Figure CP12.6 is known to have a time delay in the loop. In practice, it is often the case that the magnitude of system time delays cannot be precisely determined. The magnitude of the time delay may change in an unpredictable manner depending on the process environment. A robust control system should be able to operate satisfactorily in the presence of the system time delays.

a. Develop an m-file script to compute and plot the phase margin for the industrial process in Figure CP12.6 when the time delay, $T$, varies between 0 and 5 seconds. Use the pade function with a second-order approximation to approximate the time delay. Plot the phase margin as a function of the time delay.

b. Determine the maximum time delay allowable for system stability. Use the plot generated in part (a) to compute the maximum time delay approximately.
FIGURE CP12.4

A feedback control system with uncertain parameter $b$.

FIGURE CP12.6 An industrial controlled process with a time delay in the loop.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0943.jpg?height=516&width=1058&top_left_y=1596&top_left_x=374)CP12.7 A unity feedback control system has the loop transfer function

$$
L(s)=G_{c}(s) G(s)=\frac{a(s+0.5)}{s^{2}+0.15 s} .
$$

We know from the underlying physics of the problem that the parameter $a$ can vary only between $0<a<1$. Develop an m-file script to generate the following plots:

a. The unit step response for the range of $a$ given.

b. The percent overshoot, P.O., due to the unit step input versus parameter $a$.

c. The gain margin versus the parameter $a$.

d. Based on the results in parts (a)-(c), comment on the robustness of the system to changes in parameter $a$ in terms of stability and transient time response.

CP12.8 The Gamma-Ray Imaging Device (GRID) is a NASA experiment to be flown on a long-duration, high-altitude balloon during the coming solar maximum. The GRID on a balloon is an instrument that will qualitatively improve hard X-ray imaging and carry out the first gamma-ray imaging for the study of solar high-energy phenomena in the next phase of peak solar activity. From its long-duration balloon platform, GRID will observe numerous hard X-ray bursts, coronal hard X-ray sources, "superhot" thermal events, and microflares [2]. Figure CP12.8(a) depicts the GRID payload attached to the balloon. The major components of the GRID experiment consist of a 5.2-meter canister and mounting gondola, a high-altitude balloon, and a cable connecting the gondola and balloon. The instrument-sun pointing requirements of the experiment are 0.1 degree pointing accuracy and 0.2 arcsecond per $4 \mathrm{~ms}$ pointing stability.

An optical sun sensor provides a measure of the sun-instrument angle and is modeled as a first-order system with a DC gain and a pole at $s=-500$. A torque motor actuates the canister/gondola assembly. The azimuth angle control system is shown in Figure CP12.8(b). The PID controller is selected by the design team so that

$$
G_{c}(s)=\frac{K_{D}\left(s^{2}+a s+b\right)}{s},
$$

where $a$ and $b$ are to be selected. A prefilter is used as shown in Figure CP12.8(b). Determine the value of $K_{D}, a$, and $b$ so that the dominant roots have a damping ratio $\zeta=0.8$ and the percent overshoot to a step input is $P . O . \leq 3 \%$. Develop a simulation to study the control system performance. Use a step response to confirm the percent overshoot meets the specification.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0944.jpg?height=454&width=564&top_left_y=1198&top_left_x=828)

(a)

FIGURE CP12.8 The GRID device.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0944.jpg?height=301&width=1253&top_left_y=1748&top_left_x=500)

(b) 

\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) False; (3) True; (4) True; (5) Word Match (in order, top to bottom): d, g, i, b, c, k, f, h, False

Multiple Choice: (6) b; (7) b; (8) c; (9) d; (10) a; (11) d; $\mathrm{a}, \mathrm{j}, \mathrm{e}$

(12) a; (13) c; (14) a; (15) b

\section{TERMS AND CONCEPTS}

Additive perturbation A system perturbation model ex- Process controller See PID controller. pressed in the additive form $G_{a}(s)=G(s)+A(s)$, where $G(s)$ is the nominal process function, $A(s)$ is the perturbation that is bounded in magnitude, and $G_{a}(s)$ is the family of perturbed process functions.

Complementary sensitivity function The function $C(s)=\frac{G_{c}(s) G(s)}{1+G_{c}(s) G(s)}$ that satisfies the relationship $S(s)+C(s)=1$, where $S(s)$ is the sensitivity function.

Internal model principle The principle that states that if $G_{c}(s) G(s)$ contains the input $R(s)$, then the output $y(t)$ will track $R(s)$ asymptotically (in the steadystate) and the tracking is robust.

Multiplicative perturbation A system perturbation model expressed in the multiplicative form $G_{m}(s)=G(s)(1+M(s))$, where $G(s)$ is the nominal process function, $M(s)$ is the perturbation that is bounded in magnitude, and $G_{m}(s)$ is the family of perturbed process functions.

PID controller A controller with three terms in which the output is the sum of a proportional term, an integrating term, and a differentiating term, with an adjustable gain for each term.

Prefilter A transfer function $G_{p}(s)$ that filters the input signal $R(s)$ prior to the calculation of the error signal.
Robust control system A system that maintains acceptable performance in the presence of significant model uncertainty, disturbances, and noise.

Robust stability criterion A test for robustness with respect to multiplicative perturbations in which stability is guaranteed if $|M(j \omega)|<\left|1+\frac{1}{G(j \omega)}\right|$, for all $\omega$, where $M(s)$ is the multiplicative perturbation.

Root sensitivity A measure of the sensitivity of the roots (i.e., the poles and zeros) of the system to changes in a parameter defined by $S_{\alpha}^{r_{i}}=\frac{\partial r_{i}}{\partial \alpha / \alpha}$, where $\alpha$ is the parameter and $r_{i}$ is the root.

Sensitivity function The function $S(s)=\left[1+G_{c}(s) G(s)\right]^{-1}$ that satisfies the relationship $S(s)+C(s)=1$, where $C(s)$ is the complementary sensitivity function.

System sensitivity A measure of the system sensitivity to changes in a parameter defined by $S_{\alpha}^{T}=\frac{\partial T / T}{\partial \alpha / \alpha}$, where $\alpha$ is the parameter and $T$ is the system transfer function. 

\section{CHAPTER}

\section{Digital Control Systems}

13.1 Introduction 946

13.2 Digital Computer Control System Applications 946

13.3 Sampled-Data Systems 948

13.4 The $z$-Transform 951

13.5 Closed-Loop Feedback Sampled-Data Systems 955

13.6 Performance of a Sampled-Data, Second-Order System 959

13.7 Closed-Loop Systems with Digital Computer Compensation 961

13.8 The Root Locus of Digital Control Systems 964

13.9 Implementation of Digital Controllers 968

13.10 Design Examples 968

13.11 Digital Control Systems Using Control Design Software 977

13.12 Sequential Design Example: Disk Drive Read System 982

13.13 Summary 984

\section{PREVIEW}

A digital computer often hosts the controller algorithm in a feedback control system. Since the computer receives data only at specific intervals, it is necessary to develop a method for describing and analyzing the performance of computer control systems. In this chapter, we provide an introduction to the topic of digital control systems. The notion of a sampled-data system is presented followed by a discussion of the $z$-transform. We may use the $z$-transform of a transfer function to analyze the stability and transient response of a system. The basics of closedloop stability with a digital controller in the loop are covered with a short presentation on the role of root locus in the design process. This chapter concludes with the design of a digital controller for the Sequential Design Example: Disk Drive Read System.

\section{DESIRED OUTCOMES}

Upon completion of Chapter 13, students should be able to:

$\square \quad$ Explain the role of digital computers in control system design and application.

$\square \quad$ Describe the $z$-transform and sampled-data systems.

$\square \quad$ Design digital controllers using root locus methods.

$\square \quad$ Identify the potential issues of implementing digital controllers. 

\subsection{INTRODUCTION}

The use of digital computer compensator (controller) devices continues to increase as the price and reliability of digital computers improves [1,2]. A block diagram of a single-loop digital control system is shown in Figure 13.1. The digital computer in this system configuration receives the error in digital form and performs calculations in order to provide an output in digital form. The computer may be programmed to provide an output so that the performance of the process is near or equal to the desired performance. Many computers are able to receive and manipulate several inputs, so a digital computer control system can often be a multivariable system.

A digital computer receives and operates on signals in digital (numerical) form, as contrasted to continuous signals [3]. A digital control system uses digital signals and a digital computer to control a process. The measurement data are converted from analog form to digital form by means of the analog-to-digital converter shown in Figure 13.1. After processing the inputs, the digital computer provides an output in digital form. This output is then converted to analog form by the digital-to-analog converter shown in Figure 13.1.

\subsection{DIGITAL COMPUTER CONTROL SYSTEM APPLICATIONS}

A digital computer consists of a central processing unit (CPU), input-output units, and a memory unit. The size and power of a computer will vary according to the size, speed, and power of the CPU, as well as the size, speed, and organization of the memory unit. Powerful but inexpensive computers, called microcomputers are everywhere. These systems use a microprocessor as a CPU. Therefore, the nature of the control task, the extent of the data required in memory, and the speed of calculation required will dictate the selection of the computer within the range of available computers.

The size of computers and the cost for the active logic devices used to construct them have both declined exponentially. The active components per cubic centimeter have increased so that the actual computer can be reduced in size to the point where relatively inexpensive, powerful laptop computers are providing mobile high-performance computational capability to students and professionals alike, and are, in many instances, replacing traditional desktop microcomputers. The speed of computers has also increased exponentially. The transistor density (a measure of computational performance) on microprocessor integrated circuits has increased exponentially over the last 40 years, as illustrated in Figure 13.2. In fact, according to "Moore's law," the transistor density doubles every year, and will probably

FIGURE 13.1

A block diagram of a computer control system, including the signal converters. The signal is indicated as digital or analog.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0947.jpg?height=331&width=1263&top_left_y=1789&top_left_x=370)

FIGURE 13.2

The development of microprocessors measured in millions of transistors.

FIGURE 13.3

The flight deck of the Boeing 787 Dreamliner features digital control electronics. The aircraft is equipped with a complete suite of navigation and communication avionics. (Courtesy of Craig F. Walker/ Getty Images.)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0948.jpg?height=1372&width=962&top_left_y=152&top_left_x=507)

continue to do so. Significant progress in computation capability has been and will continue to be made. Clearly, improvements in computational capability have revolutionized the application of control theory and design in the modern era.

Digital control systems are used in many applications: for machine tools, metal-working processes, biomedical, environmental, chemical processes, aircraft control, and automobile traffic control, and many others [4-8]. An example of a computer control system used in the aircraft industry is shown in Figure 13.3. Automatic computer-controlled systems are used for purposes as diverse as measuring the objective refraction of the human eye and controlling the engine spark timing or air-fuel ratio of automobile engines.

The advantages of using digital control include improved measurement sensitivity; the use of digitally coded signals, digital sensors and transducers, and microprocessors; reduced sensitivity to signal noise; and the capability to easily reconfigure FIGURE 13.4

A digital control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0949.jpg?height=301&width=1100&top_left_y=153&top_left_x=372)

the control algorithm in software. Improved sensitivity results from the low-energy signals required by digital sensors and devices. The use of digitally coded signals permits the wide application of digital devices and communications. Digital sensors and transducers can effectively measure, transmit, and couple signals and devices. In addition, many systems are inherently digital because they send out pulse signals.

\subsection{SAMPLED-DATA SYSTEMS}

Computers used in control systems are interconnected to the actuator and the process by means of signal converters. The output of the computer is processed by a digital-to-analog converter. We will assume that all the numbers that enter or leave the computer do so at the same fixed period $T$, called the sampling period. Thus, for example, the reference input shown in Figure 13.4 is a sequence of sample values $r(k T)$. The variables $r(k T), m(k T)$, and $u(k T)$ are discrete signals in contrast to $m(t)$ and $y(t)$, which are continuous functions of time.

\section{Sampled data (or a discrete signal) are data obtained for the system variables only at discrete intervals and are denoted as $x(k T)$.}

A system where part of the system acts on sampled data is called a sampled-data system. A sampler is basically a switch that closes every $T$ seconds for one instant of time. Consider an ideal sampler, as shown in Figure 13.5. The input is $r(t)$, and the output is $r^{*}(t)$, where $n T$ is the current sample time, and the current value of $r^{*}(t)$ is $r(n T)$. We then have $r^{*}(t)=r(n T) \delta(t-n T)$, where $\delta$ is the impulse function.

Let us assume that we sample a signal $r(t)$, as shown in Figure 13.5, and obtain $r^{*}(t)$. Then, we portray the series for $r^{*}(t)$ as a string of impulses starting at $t=0$, spaced at $T$ seconds, and of amplitude $r(k T)$. For example, consider the input signal $r(t)$ shown in Figure 13.6(a). The sampled signal is shown in Figure 13.6(b) with an impulse represented by a vertical arrow of magnitude $r(k T)$.

A digital-to-analog converter serves as a device that converts the sampled signal $r^{*}(t)$ to a continuous signal $p(t)$. The digital-to-analog converter can usually be

FIGURE 13.5

An ideal sampler with an input $r(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0949.jpg?height=184&width=518&top_left_y=1940&top_left_x=369)

FIGURE 13.6

(a) An input signal $r(t)$.

(b) The sampled signal $r^{*}(t)=$ $\Sigma_{k=0}^{x} r(k T) \delta(t-k T)$.

The vertical arrow represents an impulse.

FIGURE 13.7 A sampler and zero-order hold circuit.

FIGURE 13.8

The response of a zero-order hold to an impulse input $r(k T)$, which equals unity when $k=0$ and equals zero when $k \neq 0$, so that $r^{*}(t)=r(0) \delta(t)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0950.jpg?height=294&width=544&top_left_y=152&top_left_x=537)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0950.jpg?height=296&width=569&top_left_y=539&top_left_x=508)

(b)
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0950.jpg?height=648&width=660&top_left_y=981&top_left_x=505)

represented by a zero-order hold circuit, as shown in Figure 13.7. The zero-order hold takes the value $r(k T)$ and holds it constant for $k T \leq t<(k+1) T$, as shown in Figure 13.8 for $k=0$. Thus, we use $r(k T)$ during the sampling period.

A sampler and zero-order hold can accurately follow the input signal if $T$ is small compared to the transient changes in the signal. The response of a sampler and zero-order hold for a ramp input is shown in Figure 13.9. Finally, the response of a sampler and zero-order hold for an exponentially decaying signal is shown in Figure 13.10 for two values of the sampling period. Clearly, the output $p(t)$ will approach the input $r(t)$ as $T$ approaches zero, meaning that we sample frequently. FIGURE 13.9

The response of a sampler and zero-order hold for a ramp input $r(t)=t$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0951.jpg?height=1048&width=788&top_left_y=152&top_left_x=375)

(a) $T=0.5 \mathrm{~s}$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0951.jpg?height=464&width=793&top_left_y=1311&top_left_x=375)

(b) $T=0.2 \mathrm{~s}$
FIGURE 13.10 The response of a sampler and zero-order hold to an input $r(t)=e^{-t}$ for two values of sampling period $T$. The precision of the digital computer and the associated signal converters is limited. Precision is the degree of exactness or discrimination with which a quantity is stated. The precision of the computer is limited by a finite word length. The precision of the analog-to-digital converter is limited by an ability to store its output only in digital logic composed of a finite number of binary digits. The converted signal $m(k T)$ is then said to include an amplitude quantization error. When the quantization error and the error due to the computer finite word size are small relative to the amplitude of the signal $[13,16]$, the system is sufficiently precise, and the precision limitations can be neglected.

\subsection{THE $z$-TRANSFORM}

Because the output of the ideal sampler, $r^{*}(t)$, is a series of impulses with values $r(k T)$, we have

$$
r^{*}(t)=\sum_{k=0}^{\infty} r(k T) \delta(t-k T),
$$

for a signal for $t>0$. Using the Laplace transform, we have

$$
\mathscr{L}\left\{r^{*}(t)\right\}=\sum_{k=0}^{\infty} r(k T) e^{-k s T} .
$$

We now have an infinite series that involves multiples of $e^{s T}$ and its powers. We define

$$
z=e^{s T}
$$

where this relationship involves a conformal mapping from the $s$-plane to the $z$-plane. We then define a new transform, called the $z$-transform, so that

$$
Z\{r(t)\}=Z\left\{r^{*}(t)\right\}=\sum_{k=0}^{\infty} r(k T) z^{-k}
$$

As an example, let us determine the $z$-transform of the unit step function $u(t)$ (not to be confused with the control signal $u(t))$. We obtain

$$
Z\{u(t)\}=\sum_{k=0}^{\infty} u(k T) z^{-k}=\sum_{k=0}^{\infty} z^{-k},
$$

since $u(k T)=1$ for $k \geq 0$. This series can be written in closed form as ${ }^{1}$

$$
U(z)=\frac{1}{1-z^{-1}}=\frac{z}{z-1} .
$$

In general, we will define the $z$-transform of a function $f(t)$ as

$$
Z\{f(t)\}=F(z)=\sum_{k=0}^{\infty} f(k T) z^{-k} .
$$

${ }^{1}$ Recall that the infinite geometric series may be written $(1-b x)^{-1}=1+b x+(b x)^{2}+(b x)^{3}+\ldots$, if $|b x|<1$. 

\section{EXAMPLE 13.1 Transform of an exponential}

Let us determine the $z$-transform of $f(t)=e^{-a t}$ for $t \geq 0$. Then

$$
Z\left\{e^{-a t}\right\}=F(z)=\sum_{k=0}^{\infty} e^{-a k T} z^{-k}=\sum_{k=0}^{\infty}\left(z e^{+a T}\right)^{-k} .
$$

Again, this series can be written in closed form as

$$
F(z)=\frac{1}{1-\left(z e^{a T}\right)^{-1}}=\frac{z}{z-e^{-a T}} .
$$

In general, we may show that

$$
Z\left\{e^{-a t} f(t)\right\}=F\left(e^{a T} z\right)
$$

\section{EXAMPLE 13.2 Transform of a sinusoid}

Let us determine the $z$-transform of $f(t)=\sin (\omega t)$ for $t \geq 0$. We can write $\sin (\omega t)$ as

$$
\sin (\omega t)=\frac{e^{j \omega T}}{2 j}-\frac{e^{-j \omega T}}{2 j} .
$$

Then, it follows that

$$
\begin{aligned}
F(z) & =\frac{1}{2 j}\left(\frac{z}{z-e^{j \omega T}}-\frac{z}{z-e^{-j \omega T}}\right)=\frac{1}{2 j}\left(\frac{z\left(e^{j \omega T}-e^{-j \omega T}\right)}{z^{2}-z\left(e^{j \omega T}+e^{-j \omega T}\right)+1}\right) \\
& =\frac{z \sin (\omega T)}{z^{2}-2 z \cos (\omega T)+1} .
\end{aligned}
$$

A table of $z$-transforms is given in Table 13.1 and at the MCS website. Note that we use the same letter to denote both the Laplace and $z$-transforms, distinguishing them by the argument $s$ or $z$. A table of properties of the $z$-transform is given in Table 13.2. As in the case of Laplace transforms, we are ultimately interested in the output $y(t)$ of the system. Therefore, we must use an inverse transform to obtain $y(t)$ from $Y(z)$. We may obtain the output by (1) expanding $Y(z)$ in a power series, (2) expanding $Y(z)$ into partial fractions and using Table 13.1 to obtain the inverse of each term, or (3) obtaining the inverse $z$-transform by an inversion integral. We will limit our methods to (1) and (2) in this limited discussion.

\section{EXAMPLE 13.3 Transfer function of an open-loop system}

Consider the system shown in Figure 13.11 for $T=1$. The transfer function of the zero-order hold is

$$
G_{0}(s)=\frac{1-e^{-s T}}{s} .
$$

Therefore, the transfer function $Y(s) / R^{*}(s)$ is

$$
\frac{Y(s)}{R^{*}(s)}=G_{0}(s) G_{p}(s)=G(s)=\frac{1-e^{-s T}}{s^{2}(s+1)} .
$$



\section{Table $13.1 \quad z$-Transforms}

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0954.jpg?height=1470&width=1525&top_left_y=211&top_left_x=223)

Expanding into partial fractions, we have

$$
G(s)=\left(1-e^{-s T}\right)\left(\frac{1}{s^{2}}-\frac{1}{s}+\frac{1}{s+1}\right),
$$

and the $z$-transform is

$$
G(z)=Z\{G(s)\}=\left(1-z^{-1}\right) Z\left(\frac{1}{s^{2}}-\frac{1}{s}+\frac{1}{s+1}\right) .
$$

FIGURE 13.11

An open-loop, sampled-data system (without feedback).
Table 13.2 Properties of the z-Transform

\begin{tabular}{ll}
\multicolumn{1}{c}{$\boldsymbol{x}(\boldsymbol{t})$} & $\boldsymbol{X}(\boldsymbol{z})$ \\
\hline 1. $k x(t)$ & $k X(z)$ \\
2. $x_{1}(t)+x_{2}(t)$ & $X_{1}(z)+X_{2}(z)$ \\
3. $x(t+T)$ & $z X(z)-z x(0)$ \\
4. $t x(t)$ & $-T z \frac{d X(z)}{d z}$
\end{tabular}

5. $e^{-a t} x(t)$ $X\left(z e^{a T}\right)$

6. $x(0)$, initial value $\lim _{z \rightarrow \infty} X(z)$ if the limit exists

7. $x(\infty)$, final value $\lim _{z \rightarrow 1}(z-1) X(z)$ if the limit exists and the system is stable; that is, if all poles of $(z-1) X(z)$ are inside the unit circle $|z|=1$ on $z$-plane.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0955.jpg?height=221&width=870&top_left_y=835&top_left_x=353)

Using the entries of Table 13.1 to convert from the Laplace transform to the corresponding $z$-transform of each term, we have

$$
\begin{aligned}
G(z) & =\left(1-z^{-1}\right)\left[\frac{T z}{(z-1)^{2}}-\frac{z}{z-1}+\frac{z}{z-e^{-T}}\right] \\
& =\frac{\left(z e^{-T}-z+T z\right)+\left(1-e^{-T}-T e^{-T}\right)}{(z-1)\left(z-e^{-T}\right)} .
\end{aligned}
$$

When $T=1$, we obtain

$$
G(z)=\frac{z e^{-1}+1-2 e^{-1}}{(z-1)\left(z-e^{-1}\right)}=\frac{0.3678 z+0.2644}{z^{2}-1.3678 z+0.3678} .
$$

The response of this system to a unit impulse is obtained for $R(z)=1$ so that $Y(z)=G(z) \cdot 1$. We obtain $Y(z)$ by dividing the denominator into the numerator:

$$
\begin{aligned}
& 0.3678 z^{-1}+0.7675 z^{-2}+0.9145 z^{-3}+\ldots=Y(z) \\
& z ^ { 2 } - 1 . 3 6 7 8 z + 0 . 3 6 7 8 \longdiv { 0 . 3 6 7 8 z + 0 . 2 6 4 4 } \\
& \frac{0.3678 z-0.5031+0.1353 z^{-1}}{+0.7675-0.1353 z^{-1}} \\
&+0.7675-1.0497 z^{-1}+0.2823 z^{-2} \\
& \hline
\end{aligned}
$$

FIGURE 13.12

System with sampled output.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0956.jpg?height=122&width=724&top_left_y=153&top_left_x=506)

FIGURE 13.13

The $z$-transform transfer function in block diagram form.

This calculation yields the response at the sampling instants and can be carried as far as is needed for $Y(z)$. From Equation (13.5), we have

$$
Y(z)=\sum_{k=0}^{\infty} y(k T) z^{-k} .
$$

In this case, we have obtained $y(k T)$ as follows: $y(0)=0, y(T)=0.3678, y(2 T)=$ 0.7675 , and $y(3 T)=0.9145$. Note that $y(k T)$ provides the values of $y(t)$ at $t=k T$.

We have determined $Y(z)$, the $z$-transform of the output sampled signal. The $z$-transform of the input sampled signal is $R(z)$. The transfer function in the $z$-domain is

$$
\frac{Y(z)}{R(z)}=G(z)
$$

Since we determined the sampled output, we can use an output sampler to depict this condition, as shown in Figure 13.12; this represents the system of Figure 13.11 with the sampled input passing to the process. We assume that both samplers have the same sampling period and operate synchronously. Then

$$
Y(z)=G(z) R(z)
$$

as required. We may represent Equation (13.19), which is a $z$-transform equation, by the block diagram of Figure 13.13.

\subsection{CLOSED-LOOP FEEDBACK SAMPLED-DATA SYSTEMS}

In this section, we consider closed-loop, sampled-data control systems. Consider the system shown in Figure 13.14(a). The sampled-data $z$-transform model of this figure with a sampled-output signal $Y(z)$ is shown in Figure 13.14(b). The closed-loop transfer function (using block diagram reduction) is

$$
\frac{Y(z)}{R(z)}=T(z)=\frac{G(z)}{1+G(z)} .
$$

Here, we assume that the $G(z)$ is the $z$-transform of $G(s)=G_{0}(s) G_{p}(s)$, where $G_{0}(s)$ is the zero-order hold, and $G_{p}(s)$ is the process transfer function. FIGURE 13.14

Feedback control system with unity feedback. $G(z)$ is the $z$-transform corresponding to $G(s)$, which represents the process and the zero-order hold.

FIGURE 13.15

(a) Feedback control system with a digital controller. (b) Block diagram model. Note that $G(z)=$ $Z\left\{G_{0}(s) G_{p}(s)\right\}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0957.jpg?height=203&width=1055&top_left_y=157&top_left_x=376)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0957.jpg?height=167&width=724&top_left_y=448&top_left_x=539)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0957.jpg?height=249&width=1021&top_left_y=800&top_left_x=374)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0957.jpg?height=160&width=755&top_left_y=1131&top_left_x=507)

(b)

A digital control system with a digital controller is shown in Figure 13.15(a). The $z$-transform block diagram model is shown in Figure 13.15(b). The closed-loop transfer function is

$$
\frac{Y(z)}{R(z)}=T(z)=\frac{G(z) D(z)}{1+G(z) D(z)}
$$

\section{EXAMPLE 13.4 Response of a closed-loop system}

Consider the closed-loop system shown in Figure 13.16. We have obtained the $z$-transform model of this system, as shown in Figure 13.14. Therefore, we have

$$
\frac{Y(z)}{R(z)}=\frac{G(z)}{1+G(z)}
$$

FIGURE 13.16 A closed-loop, sampled-data system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0958.jpg?height=275&width=1042&top_left_y=154&top_left_x=523)

In Example 13.3, we obtained $G(z)$ as Equation (13.16) when $T=1 \mathrm{~s}$. Substituting $G(z)$ into Equation (13.22), we obtain

$$
\frac{Y(z)}{R(z)}=\frac{0.3678 z+0.2644}{z^{2}-z+0.6322}
$$

Since the input is a unit step,

$$
R(z)=\frac{z}{z-1}
$$

it follows that

$$
Y(z)=\frac{z(0.3678 z+0.2644)}{(z-1)\left(z^{2}-z+0.6322\right)}=\frac{0.3678 z^{2}+0.2644 z}{z^{3}-2 z^{2}+1.6322 z-0.6322}
$$

Completing the division, we have

$$
Y(z)=0.3678 z^{-1}+z^{-2}+1.4 z^{-3}+1.4 z^{-4}+1.147 z^{-5} \ldots
$$

The values of $y(k T)$ are shown in Figure 13.17, using the symbol $\square$. The complete response of the sampled-data, closed-loop system is shown and contrasted to the response of a continuous system (when $T=0$ ). The overshoot of the sampled system is $45 \%$, in contrast to $17 \%$ for the continuous system. Furthermore, the settling time of the sampled system is twice as long as that of the continuous system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0958.jpg?height=545&width=908&top_left_y=1574&top_left_x=506)
of the sampled system is twice as long as that of the continuous system.$$
\text { Time (s) }
$$

FIGURE 13.17

The response of a secondorder system: (a) continuous $(T=0)$, not sampled; (b) sampled system, $T=1 \mathrm{~s}$. A linear continuous feedback control system is stable if all poles of the closed-loop transfer function $T(s)$ lie in the left half of the $s$-plane. The $z$-plane is related to the $s$-plane by the transformation

$$
z=e^{s T}=e^{(\sigma+j \omega) T} .
$$

We may also write this relationship as

$$
|z|=e^{\sigma T}
$$

and

$$
\angle z=\omega T \text {. }
$$

In the left-hand $s$-plane, $\sigma<0$; therefore, the related magnitude of $z$ varies between 0 and 1 . Thus, the imaginary axis of the $s$-plane corresponds to the unit circle in the $z$-plane, and the inside of the unit circle corresponds to the left half of the $s$-plane [14].

Therefore, we can state that the stability of a sampled-data system exists if all the poles of the closed-loop transfer function $T(z)$ lie within the unit circle of the $z$-plane.

\section{EXAMPLE 13.5 Stability of a closed-loop system}

Let us consider the system shown in Figure 13.18 when $T=1$ and

$$
G_{p}(s)=\frac{K}{s(s+1)} .
$$

Recalling Equation (13.16), we note that

$$
G(z)=\frac{K(0.3678 z+0.2644)}{z^{2}-1.3678 z+0.3678}=\frac{K(a z+b)}{z^{2}-(1+a) z+a},
$$

where $a=0.3678$ and $b=0.2644$.

The poles of the closed-loop transfer function $T(z)$ are the roots of the equation $1+G(z)=0$. We call $q(z)=1+G(z)=0$ the characteristic equation. Therefore, we obtain

$$
q(z)=1+G(z)=z^{2}-(1+a) z+a+K a z+K b=0 .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0959.jpg?height=277&width=1057&top_left_y=1837&top_left_x=370)

When $K=1$, we have

$$
\begin{aligned}
q(z) & =z^{2}-z+0.6322 \\
& =(z-0.50+j 0.6182)(z-0.50-j 0.6182)=0 .
\end{aligned}
$$

Therefore, the system is stable because the roots lie within the unit circle. When $K=10$, we have

$$
\begin{aligned}
q(z) & =z^{2}+2.310 z+3.012 \\
& =(z+1.155+j 1.295)(z+1.155-j 1.295),
\end{aligned}
$$

and the system is unstable because both roots lie outside the unit circle. This system is stable for $0<K<2.39$. The locus of the roots as $K$ varies is discussed in Section 13.8.

We notice that a second-order sampled system can be unstable with increasing gain where a second-order continuous system is stable for all values of gain (assuming both the poles of the open-loop system lie in the left half $s$-plane).

\subsection{PERFORMANCE OF A SAMPLED-DATA, SECOND-ORDER SYSTEM}

Consider the performance of a sampled second-order system with a zero-order hold, as shown in Figure 13.18, when the process is

$$
G_{p}(s)=\frac{K}{s(\tau s+1)} .
$$

We then obtain $G(z)$ for the sampling period $T$ as

$$
G(z)=\frac{K\left\{(z-E)[T-\tau(z-1)]+\tau(z-1)^{2}\right\}}{(z-1)(z-E)},
$$

where $E=e^{-T / \tau}$. The stability of the system is analyzed by considering the characteristic equation

$$
q(z)=z^{2}+z\{K[T-\tau(1-E)]-(1+E)\}+K[\tau(1-E)-T E]+E=0 .
$$

Because the polynomial $q(z)$ is a quadratic and has real coefficients, the necessary and sufficient conditions for $q(z)$ to have all its roots within the unit circle are

$$
|q(0)|<1, \quad q(1)>0, \text { and } q(-1)>0 .
$$

These stability conditions for a second-order system can be established by mapping the $z$-plane characteristic equation into the $s$-plane and checking for positive coefficients of $q(s)$. Using these conditions, we establish the necessary conditions from Equation (13.35) as

$$
K \tau<\frac{1-E}{1-E-(T / \tau) E}
$$

FIGURE 13.19

The maximum percent overshoot for a second-order sampled system for a unit step input.

FIGURE 13.20 The loci of integral squared error for a second-order sampled system for constant values of $I$.
Table 13.3 Maximum Gain for a Second-Order Sampled System

\begin{tabular}{lllllll} 
& $T / \tau$ & 0 & 0.1 & 0.5 & 1 & 2 \\
\hline \multirow{2}{*}{ Maximum } & $K \tau$ & $\infty$ & 20.4 & 4.0 & 2.32 & 1.45 \\
\hline
\end{tabular}

$$
K \tau<\frac{2(1+E)}{(T / \tau)(1+E)-2(1-E)},
$$

and $K>0, T>0$. For this system, we can calculate the maximum gain permissible for a stable system. The maximum gain allowable is given in Table 13.3 for several values of $T / \tau$. It is possible to set $T / \tau=0.1$ and vary $K$ to obtain system characteristics approaching those of a continuous (nonsampled) system. The maximum percent overshoot of the second-order system for a unit step input is shown in Figure 13.19.

The integral squared error performance criterion can be written as

$$
I=\frac{1}{\tau} \int_{0}^{\infty} e^{2}(t) d t
$$

The loci of this criterion are given in Figure 13.20 for constant values of $I$. For a given value of $T / \tau$, we can determine the minimum value of $I$ and the required
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0961.jpg?height=1126&width=856&top_left_y=990&top_left_x=370)FIGURE 13.21

The steadystate error of a second-order sampled system for a unit ramp input $r(t)=t, t>0$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0962.jpg?height=536&width=856&top_left_y=167&top_left_x=515)

value of $K \tau$. The optimal curve shown in Figure 13.20 indicates the required $K \tau$ for a specified $T / \tau$ that minimizes $I$. For example, when $T / \tau=0.75$, we require $K \tau=1$ in order to minimize the performance criterion $I$.

The steady-state error for a unit ramp input $r(t)=t$ is shown in Figure 13.21. For a given $T / \tau$, we can reduce the steady-state error, but then the system yields a greater overshoot and settling time for a step input.

\section{EXAMPLE 13.6 Design of a sampled system}

Consider a closed-loop sampled system as shown in Figure 13.18 when

$$
G_{p}(s)=\frac{K}{s(0.1 s+1)} .
$$

We seek to select $T$ and $K$ for suitable performance. We use Figures 13.19-13.21 to select $K$ and $T$ for $\tau=0.1$. Limiting the percent overshoot to P.O. $=30 \%$ for the step input, we select $T / \tau=0.25$, yielding $K \tau=1.4$. For these values, the steadystate error for a unit ramp input is approximately $e_{s s}=0.6$ (see Figure 13.21).

Because $\tau=0.1$, we then set $T=0.025 \mathrm{~s}$ and $K=14$. The sampling rate is 40 samples per second. The percent overshoot to the step input and the steady-state error for a ramp input may be reduced if we set $T / \tau$ to 0.1 . The percent overshoot to a step input will be P.O. $=25 \%$ for $K \tau=1.6$. Using Figure 13.21, we estimate that the steady-state error for a unit ramp input is $e_{s s}=0.55$ for $K \tau=1.6$.

\subsection{CLOSED-LOOP SYSTEMS WITH DIGITAL COMPUTER COMPENSATION}

A closed-loop, sampled system with a digital computer used to improve the performance is shown in Figure 13.15. The closed-loop transfer function is

$$
\frac{Y(z)}{R(z)}=T(z)=\frac{G(z) D(z)}{1+G(z) D(z)} .
$$

The transfer function of the computer is represented by

$$
D(z)=\frac{U(z)}{E(z)} .
$$

In our prior examples, $D(z)$ was represented by a gain $K$. As an illustration of the power of the computer as a compensator, we consider again the second-order system with a zero-order hold and process

$$
G_{p}(s)=\frac{1}{s(s+1)} \text { when } T=1 .
$$

Then (see Equation 13.16)

$$
G(z)=\frac{0.3678(z+0.7189)}{(z-1)(z-0.3678)} .
$$

If we select

$$
D(z)=\frac{K(z-0.3678)}{z+r}
$$

we cancel the pole of $G(z)$ at $z=0.3678$ and have to set two parameters, $r$ and $K$. If we select

$$
D(z)=\frac{1.359(z-0.3678)}{z+0.240}
$$

we have

$$
G(z) D(z)=\frac{0.50(z+0.7189)}{(z-1)(z+0.240)}
$$

If we calculate the response of the system to a unit step, we find that the output is equal to the input at the fourth sampling instant and thereafter. The responses for both the uncompensated and the compensated system are shown in Figure 13.22. The overshoot of the compensated system is $4 \%$, whereas the percent overshoot of the uncompensated system is $P . O .=45 \%$. It is beyond the objective of this book

FIGURE 13.22

The response of a sampled-data second-order system to a unit step input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0963.jpg?height=504&width=868&top_left_y=1618&top_left_x=375)

FIGURE 13.23

The continuous system model of a sampled system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0964.jpg?height=233&width=849&top_left_y=156&top_left_x=507)

to discuss all the extensive methods for the analytical selection of the parameters of $D(z)$; other texts [2-4] can provide further information. However, we will consider two methods of compensator design: (1) the $G_{c}(s)$-to- $D(z)$ conversion method (in the following paragraphs) and (2) the root locus $z$-plane method (in Section 13.8).

One method for determining $D(z)$ first determines a controller $G_{c}(s)$ for a given process $G_{p}(s)$ for the system shown in Figure 13.23. Then, the controller is converted to $D(z)$ for the given sampling period $T$. This design method is called the $G_{c}(s)$-to- $D(z)$ conversion method. It converts the $G_{c}(s)$ of Figure 13.23 to $D(z)$ of Figure 13.15 [7].

We consider a first-order compensator

$$
G_{c}(s)=K \frac{s+a}{s+b}
$$

and a digital controller

$$
D(z)=C \frac{z-A}{z-B}
$$

We determine the $z$-transform corresponding to $G_{c}(s)$ and set it equal to $D(z)$ as

$$
Z\left\{G_{c}(s)\right\}=D(z) \text {. }
$$

Then the relationship between the two transfer functions is $A=e^{-a T}, B=e^{-b T}$, and when $s=0$, we require that

$$
C \frac{1-A}{1-B}=K \frac{a}{b}
$$

\section{EXAMPLE 13.7 Design to meet a phase margin specification}

Consider a system with a process

$$
G_{p}(s)=\frac{1740}{s(0.25 s+1)}
$$

We will design $G_{c}(s)$ so that we achieve a phase margin of $P . M .=45^{\circ}$ with a crossover frequency $\omega_{c}=125 \mathrm{rad} / \mathrm{s}$. Using the Bode plot of $G_{p}(s)$, we find that the phase margin is $P . M .=2^{\circ}$. Consider the phase-lead compensator

$$
G_{c}(s)=\frac{K(s+50)}{s+275}
$$

We select $K$ in order to yield $20 \log _{10}\left|G_{c}(j \omega) G(j \omega)\right|=0$ when $\omega=\omega_{c}=125 \mathrm{rad} / \mathrm{s}$ yielding $K=5.0$. The compensator $G_{c}(s)$ is to be realized by $D(z)$, so we solve the relationships with a selected sampling period. Setting $T=0.003 \mathrm{~s}$, we have

$$
A=e^{-0.15}=0.86, \quad B=e^{-0.827}=0.44, \quad \text { and } \quad C=3.66 .
$$

Then we have

$$
D(z)=\frac{3.66(z-0.86)}{z-0.44} .
$$

Of course, if we select another value for the sampling period, then the coefficients of $D(z)$ would differ.

In general, we select a small sampling period so that the design based on the continuous system will accurately carry over to the $z$-plane. However, we should not select too small a $T$, or the computation requirements may be more than necessary. In general, we use a sampling period $T \approx 1 /\left(10 f_{B}\right)$, where $f_{B}=\omega_{B} /(2 \pi)$, and $\omega_{B}$ is the bandwidth of the closed-loop continuous system. The bandwidth of the system designed in Example 13.7 is $\omega_{B}=208 \mathrm{rad} / \mathrm{s}$ or $f_{B}=33.2 \mathrm{~Hz}$. Thus, we select a period $T=0.003 \mathrm{~s}$.

\subsection{THE ROOT LOCUS OF DIGITAL CONTROL SYSTEMS}

Consider the transfer function of the system shown in Figure 13.24. Recall that $G(s)=G_{0}(s) G_{p}(s)$. The closed-loop transfer function is

$$
\frac{Y(z)}{R(z)}=\frac{K G(z) D(z)}{1+K G(z) D(z)} .
$$

The characteristic equation is

$$
1+K G(z) D(z)=0 .
$$

Thus, we can plot the root locus for the characteristic equation of the sampled system as $K$ varies. The rules for obtaining the root locus are summarized in Table 13.4.

\section{EXAMPLE 13.8 Root locus of a second-order system}

Consider the system shown in Figure 13.24 with $D(z)=1$ and $G_{p}(s)=1 / s^{2}$. Then we obtain

FIGURE 13.24

Closed-loop system with a digital controller.

$$
K G(z)=\frac{T^{2}}{2} \frac{K(z+1)}{(z-1)^{2}}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0965.jpg?height=214&width=1190&top_left_y=1897&top_left_x=374)



\section{Table 13.4 Root Locus in the z-Plane}

1. The root locus starts at the poles and progresses to the zeros.

2. The root locus lies on a section of the real axis to the left of an odd number of poles and zeros.

3. The root locus is symmetrical with respect to the horizontal real axis.

4. The root locus may break away from the real axis and may reenter the real axis. The breakaway and entry points are determined from the equation

$$
K=-\frac{N(z)}{D(z)}=F(z)
$$

with $z=\sigma$. Then obtain the solution of $\frac{d F(\sigma)}{d \sigma}=0$.

5. Plot the locus of roots that satisfy

$$
1+K G(z) D(z)=0
$$

or

$$
|K G(z) D(z)|=1
$$

and

$$
\angle G(z) D(z)=180^{\circ} \pm k 360^{\circ}, \quad k=0,1,2, \cdots
$$

Let $T=\sqrt{2}$ and plot the root locus. We now have

$$
K G(z)=\frac{K(z+1)}{(z-1)^{2}},
$$

and the poles and zeros are shown on the $z$-plane in Figure 13.25. The characteristic equation is

$$
1+K G(z)=1+\frac{K(z+1)}{(z-1)^{2}}=0 .
$$

Let $z=\sigma$ and solve for $K$ to obtain

$$
K=-\frac{(\sigma-1)^{2}}{\sigma+1}=F(\sigma) .
$$

Then obtain the derivative $d F(\sigma) / d \sigma=0$ and calculate the roots as $\sigma_{1}=-3$ and $\sigma_{2}=1$. The locus leaves the two poles at $\sigma_{2}=1$ and reenters at $\sigma_{1}=-3$, as shown in Figure 13.25. The unit circle is also shown in Figure 13.25. The system always has two roots outside the unit circle and is always unstable for all $K>0$.

We now turn to the design of a digital controller $D(z)$ to achieve a specified response utilizing a root locus method. We will select a controller

$$
D(z)=\frac{z-a}{z-b}
$$

FIGURE 13.25

Root locus for Example 13.8.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0967.jpg?height=633&width=854&top_left_y=154&top_left_x=373)

We then use $z-a$ to cancel one pole at $G(z)$ that lies on the positive real axis of the $z$-plane. Then we select $z-b$ so that the locus of the compensated system will give a set of complex roots at a desired point within the unit circle on the $z$-plane.

\section{EXAMPLE 13.9 Design of a digital compensator}

Let us design a compensator $D(z)$ that will result in a stable system when $G_{p}(s)$ is as described in Example 13.8. With $D(z)=1$, we have an unstable system. Select

$$
D(z)=\frac{z-a}{z-b}
$$

so that

$$
K G(z) D(z)=\frac{K(z+1)(z-a)}{(z-1)^{2}(z-b)} .
$$

If we set $a=1$ and $b=0.2$, we have

$$
K G(z) D(z)=\frac{K(z+1)}{(z-1)(z-0.2)} .
$$

Using the equation for $F(\sigma)$, we obtain the entry point as $z=-2.56$, as shown in Figure 13.26. The root locus is on the unit circle at $K=0.8$. Thus, the system is stable for $K<0.8$. If we select $K=0.25$, we find that the step response has a percent overshoot of $P . O .=20 \%$ and a settling time (with a $2 \%$ criterion) $T_{s}=8.5 \mathrm{~s}$.

We can draw lines of constant $\zeta$ on the $z$-plane. The mapping between the $s$-plane and the $z$-plane is obtained by the relation $z=e^{s T}$. The lines of constant $\zeta$ on the $s$-plane are radial lines with

$$
\frac{\sigma}{\omega}=-\tan \theta=-\tan \left(\sin ^{-1} \zeta\right)=-\frac{\zeta}{\sqrt{1-\zeta^{2}}} .
$$

FIGURE 13.26

Root locus for Example 13.9.

FIGURE 13.27 Curves of constant $\zeta$ on the $z$-plane.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0968.jpg?height=1486&width=1110&top_left_y=154&top_left_x=506)

Since $s=\sigma+j \omega$, we have

where

$$
z=e^{\sigma T} e^{j \omega T}
$$

$$
\sigma=-\frac{\zeta}{\sqrt{1-\zeta^{2}}} \omega .
$$

The plot of these lines for constant $\zeta$ is shown in Figure 13.27 for a range of T. A common value of $\zeta$ for many design specifications is $\zeta=1 / \sqrt{2}$. Then we have $\sigma=-\omega$ and

$$
z=e^{-\omega T} e^{j \omega T}=e^{-\omega T} \underline{\theta},
$$

where $\theta=\omega T$. 

\subsection{IMPLEMENTATION OF DIGITAL CONTROLLERS}

Consider the PID controller with an $s$-domain transfer function

$$
\frac{U(s)}{X(s)}=G_{c}(s)=K_{P}+\frac{K_{I}}{s}+K_{D} s .
$$

We can determine a digital implementation of this controller using a discrete approximation for the derivative and integration. For the time derivative, we use the backward difference rule

$$
u(k T)=\left.\frac{d x}{d t}\right|_{t=k T}=\frac{1}{T}(x(k T)-x((k-1) T)) .
$$

The $z$-transform of Equation (13.55) is then

$$
U(z)=\frac{1-z^{-1}}{T} X(z)=\frac{z-1}{T z} X(z) .
$$

The integration of $x(t)$ can be represented by the forward rectangular integration at $t=k T$ as

$$
u(k T)=u((k-1) T)+T x(k T),
$$

where $u(k T)$ is the output of the integrator at $t=k T$. The $z$-transform of Equation (13.56) is

$$
U(z)=z^{-1} U(z)+T X(z),
$$

and the transfer function is then

$$
\frac{U(z)}{X(z)}=\frac{T z}{z-1} .
$$

Hence, the $z$-domain transfer function of the PID controller is

$$
G_{c}(z)=K_{P}+\frac{K_{I} T z}{z-1}+K_{D} \frac{z-1}{T z} .
$$

The complete difference equation algorithm that provides the PID controller is obtained by adding the three terms to obtain [we use $x(k T)=x(k)$ ]

$$
\begin{aligned}
u(k) & =K_{P} x(k)+K_{I}[u(k-1)+T x(k)]+\left(K_{D} / T\right)[x(k)-x(k-1)] \\
& =\left[K_{P}+K_{I} T+\left(K_{D} / T\right)\right] x(k)-K_{D} T x(k-1)+K_{I} u(k-1) .
\end{aligned}
$$

Equation (13.58) can be implemented using a digital computer or microprocessor. Of course, we can obtain a PI or PD controller by setting an appropriate gain equal to zero.

\subsection{DESIGN EXAMPLES}

In this section we present two illustrative examples. In the first example, two controllers are designed to control the motor and lead screw of a movable worktable. Using a zero-order hold formulation, a proportional controller and a lead compensator FIGURE 13.28

A table motion control system: (a) actuator and table; (b) block diagram.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0970.jpg?height=307&width=1271&top_left_y=150&top_left_x=484)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0970.jpg?height=273&width=1249&top_left_y=569&top_left_x=500)

(b)

are obtained and their performance compared. In the second example, a control system is designed to control an aircraft control surface as part of a fly-by-wire system. Using root locus methods, the design process focuses on the design of a digital controller to meet settling time and percent overshoot performance specifications.

\section{EXAMPLE 13.10 Worktable motion control system}

An important positioning system in manufacturing systems is a worktable motion control system. The system controls the motion of a worktable at a certain location [18]. We assume that the table is activated in each axis by a motor and lead screw, as shown in Figure 13.28(a). We consider the $x$-axis and examine the motion control for a feedback system, as shown in Figure 13.28(b). The goal is to obtain a fast response with a rapid rise time and settling time to a step command while not exceeding a percent overshoot of P.O. $=5 \%$.

The specifications are then (1) a percent overshoot equal to P.O. $=5 \%$ and (2) a minimum settling time (with a $2 \%$ criterion) and rise time.

To configure the system, we choose a power amplifier and motor so that the system is described by Figure 13.29. Obtaining the transfer function of the motor and power amplifier, we have

$$
G_{p}(s)=\frac{1}{s(s+10)(s+20)} .
$$

We will initially use a continuous system and design $G_{c}(s)$ as described in Section 13.8. We then obtain $D(z)$ from $G_{c}(s)$. Consider the controller

$$
G_{c}(s)=\frac{K(s+a)}{s+b} .
$$

FIGURE 13.29 Model of the wheel control for a work table.
FIGURE 13.30

Root locus for $L(s)=$ $K G_{c}(s) G_{P}(s)$ where $G_{c}(s)=K(s+a) /$ $(s+b), a=30$ and $b=25$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0971.jpg?height=1288&width=1290&top_left_y=148&top_left_x=370)

The root locus is shown in Figure 13.30 when $a=30$ and $b=25$. In Figure 13.30, the desired region for the pole placement is shown consistent with a targeted percent overshoot P.O. $\leq 5 \%$ (corresponding to $\zeta \geq 0.69$ ). The selected point corresponds to $K=545$. The actual percent overshoot is $P . O .=5 \%$, the settling time is $T_{s}=1.18 \mathrm{~s}$, and the rise time $T_{r}=0.4 \mathrm{~s}$, therefore, the performance specifications are satisfied. The final controller design is

$$
G_{c}(s)=\frac{545(s+30)}{s+25} .
$$

The closed-loop system bandwidth is $\omega_{B}=5.3 \mathrm{rad} / \mathrm{s}$ ( or $f_{B}=0.85 \mathrm{~Hz}$ ). Hence, the sampling frequency is selected to be $T=1 /\left(10 f_{B}\right)=0.12 \mathrm{~s}$. Following the design strategy in Section 13.7, we determine that

$$
A=e^{-a T}=0.03, B=e^{-b T}=0.05, \text { and } C=K \frac{a}{b} \frac{(1-B)}{(1-A)}=638 .
$$

The digital controller is then given by

$$
D(z)=638 \frac{z-0.03}{z-0.05} .
$$

Using this $D(z)$, we expect a response very similar to that obtained for the continuous system model.

\section{EXAMPLE 13.11 Fly-by-wire aircraft control surface}

Increasing constraints on weight, performance, fuel consumption, and reliability created a need for the flight control system known as fly-by-wire. This approach implies that particular system components are interconnected electrically rather than mechanically and that they operate under the supervision of a computer responsible for monitoring, controlling, and coordinating the tasks. The fly-by-wire principle allows for the implementation of totally digital and highly redundant control systems reaching a remarkable level of reliability and performance [19].

Operational characteristics of a flight control system depend on the dynamic stiffness of an actuator, which represents its ability to maintain the position of the control surface in spite of the disturbing effects of random external forces. One flight actuator system consists of a special type of DC motor, driven by a power amplifier, which drives a hydraulic pump that is connected to either side of a hydraulic cylinder. The piston of the hydraulic cylinder is directly connected to a control surface of an aircraft through some appropriate mechanical linkage, as shown in Figure 13.31. The elements of the design process emphasized in this example are highlighted in Figure 13.32.

The process model is given by

$$
G_{p}(s)=\frac{1}{s(s+1)} .
$$

The zero-order hold is modeled by

$$
G_{o}(s)=\frac{1-e^{-s T}}{s} .
$$

Combining the process and the zero-order hold in series yields

$$
G(s)=G_{o}(s) G_{p}(s)=\frac{1-e^{-s T}}{s^{2}(s+1)} .
$$

The control goal is to design a compensator, $D(z)$, so that the control surface angle $Y(s)=\theta(s)$ tracks the desired angle, denoted by $R(s)$. We state the control goal as

\section{Control Goal}

Design a controller $D(z)$ so that the control surface angle tracks the desired angle.

The variable to be controlled is the control surface angle $\theta(t)$ :

\section{Variable to Be Controlled}

Control surface angle $\theta(t)$. FIGURE 13.31

(a) Fly-by-wire aircraft control surface system and (b) block diagram. The sampling period is 0.1 second.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0973.jpg?height=696&width=1136&top_left_y=153&top_left_x=387)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0973.jpg?height=289&width=1282&top_left_y=940&top_left_x=335)

(b)

The design specifications are as follows:

\section{Design Specifications}

DS1 Percent overshoot of P.O. $\leq 5 \%$ to a unit step input.

DS2 Settling time of $T_{S} \leq 1 \mathrm{~s}$ to a unit step input.

We begin the design process by determining $G(z)$ from $G(s)$. Expanding $G(s)$ in Equation (13.63) in partial fractions yields

$$
G(s)=\left(1-e^{-s T}\right)\left(\frac{1}{s^{2}}-\frac{1}{s}+\frac{1}{s+1}\right)
$$

and

$$
G(z)=Z\{G(s)\}=\frac{z e^{-T}-z+T z+1-e^{-T}-T e^{-T}}{(z-1)\left(z-e^{-T}\right)},
$$

where $Z\{\cdot\}$ represents the $z$-transform. Choosing $T=0.1$, we have

$$
G(z)=\frac{0.004837 z+0.004679}{(z-1)(z-0.9048)} \text {. }
$$

FIGURE 13.32 Elements of the control system design process emphasized in this fly-by-wire aircraft control surface example.
Topics emphasized in this example

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0974.jpg?height=1033&width=1227&top_left_y=222&top_left_x=525)

For a simple compensator, $D(z)=K$, the root locus is shown in Figure 13.33. For stability we require $K<21$. Using an iterative approach we discover that as $K \rightarrow 21$, the step response is very oscillatory, and the percent overshoot is too large; conversely, as $K$ gets smaller, the settling time gets too long, although the percent overshoot decreases. In any case the design specifications cannot be satisfied with a simple proportional controller, $D(z)=K$. We need to utilize a more sophisticated controller.

We have the freedom to select the controller type. As with control design for continuous-time systems, the choice of compensator is always a challenge and problem-dependent. Here we choose a compensator with the general structure

$$
D(z)=K \frac{z-a}{z-b} .
$$

Therefore, the key tuning parameters are the compensation parameters:

\section{Select Key Tuning Parameters}

$K, a$, and $b$. FIGURE 13.33

Root locus for $D(z)=K$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0975.jpg?height=806&width=1174&top_left_y=157&top_left_x=375)

For continuous systems we know that a design rule-of-thumb formula for the settling time is

$$
T_{s}=\frac{4}{\zeta \omega_{n}},
$$

where we use a $2 \%$ bound to define settling. This design rule-of-thumb is valid for second-order systems with no zeros. So to meet the $T_{s}$ requirement, we want

$$
-\operatorname{Re}\left(s_{i}\right)=\zeta \omega_{n}>\frac{4}{T_{s}},
$$

where $s_{i}, i=1,2$ are the dominant complex-conjugate poles. In the definition of the desired region of the $z$-plane for placing the dominant poles, we use the transform

$$
z=e^{s_{i} T}=e^{\left(-\zeta \omega_{n} \pm j \omega_{n} \sqrt{\left(1-\zeta^{2}\right)}\right) T}=e^{-\zeta \omega_{n} T} e^{ \pm j \omega_{n} T \sqrt{\left(1-\zeta^{2}\right)}} .
$$

Computing the magnitude of $z$ yields

$$
r_{o}=|z|=e^{-\zeta \omega_{n} T} .
$$

To meet the settling time specification, we need the $z$-plane poles to be inside the circle defined by

$$
r_{o}=e^{-4 T / T_{s}},
$$

where we have used the result in Equation (13.66).

Consider the settling time requirement $T_{s}<1 \mathrm{~s}$. In our case $T=0.1 \mathrm{~s}$. From Equation (13.67) we determine that the dominant $z$-plane poles should lie inside the circle defined by

$$
r_{o}=e^{-0.4 / 1}=0.67
$$

FIGURE 13.34

Root locus for $D(z)=K$ with the stability and performance regions shown.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0976.jpg?height=818&width=1059&top_left_y=153&top_left_x=522)

As shown previously we can draw lines of constant $\zeta$ on the $z$-plane. The lines of constant $\zeta$ on the $s$-plane are radial lines with

$$
\sigma=-\omega \tan \left(\sin ^{-1} \zeta\right)=-\frac{\zeta}{\sqrt{1-\zeta^{2}}} \omega
$$

Then, with $s=\sigma+j \omega$ and using the transform $z=e^{s T}$, we have

$$
z=e^{-\sigma \omega T} e^{j \omega T} .
$$

For a given $\zeta$, we can plot $\operatorname{Re}(z)$ vs $\operatorname{Im}(z)$ for $z$ given in Equation (13.68).

If we were working with a second-order transfer function in the $s$-domain, we would need to have the damping ratio associated with the dominant roots be greater than $\zeta \geq 0.69$. When $\zeta \geq 0.69$, the percent overshoot for a second-order system (with no zeros) will be P.O. $\leq 5 \%$. The curves of constant $\zeta$ on the $z$-plane will define the region in the $z$-plane where we need to place the dominant $z$-plane poles to meet the percent overshoot specification.

The root locus in Figure 13.33 is repeated in Figure 13.34 with the stability and desired performance regions included. We can see that the root locus does not lie in the intersection of the stability and performance regions. The question is how to select the controller parameters $K, a$, and $b$ so that the root locus lies in the desired regions.

One approach to the design is to choose $a$ such that the pole of $G(z)$ at $z=0.9048$ is cancelled. Then we must select $b$ so that the root locus lies in the desired region. For example, when $a=-0.9048$ and $b=0.25$, the compensated root locus appears as shown in Figure 13.35. The root locus lies inside the performance region, as desired. FIGURE 13.35

Compensated root locus.

FIGURE 13.36

Closed-loop system step response.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0977.jpg?height=1626&width=1068&top_left_y=153&top_left_x=374)

A valid value of $K$ is $K=70$. Thus the compensator is

$$
D(z)=70 \frac{s-0.9048}{s+0.25} .
$$

The closed-loop step response is shown in Figure 13.36. Notice that the percent overshoot specification $(P . O . \leq 5 \%)$ is satisfied, and the system response settles in less than 10 samples $(10$ samples $=1$ second because the sampling time is $T=0.1 \mathrm{~s}$ ). 

\subsection{DIGITAL CONTROL SYSTEMS USING CONTROL DESIGN SOFTWARE}

The process of designing and analyzing sampled-data systems is enhanced with the use of interactive computer tools. Many of the control design functions for continuous-time control design have equivalent counterparts for sampled-data systems. Discrete-time transfer function model objects are obtained with the tf function. Figure 13.37 illustrates the use of tf. Model conversion can be accomplished with the functions c2d and d2c, shown in Figure 13.37. The function c2d converts continuous-time systems to discrete-time systems; the function d2c converts discrete-time systems to continuous-time systems. For example, consider the process transfer function

$$
G_{p}(s)=\frac{1}{s(s+1)} .
$$

For a sampling period of $T=1 \mathrm{~s}$, we have

$$
G(z)=\frac{0.3678(z+0.7189)}{(z-1)(z-0.3680)}=\frac{0.3679 z+0.2644}{z^{2}-1.368 z+0.3680} .
$$

We can use an m-file script to obtain the $G(z)$, as shown in Figure 13.38.

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0978.jpg?height=301&width=1091&top_left_y=1103&top_left_x=562)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0978.jpg?height=306&width=1054&top_left_y=1444&top_left_x=583)

FIGURE 13.37

(a) The tf function.

(b) The c2d

function. (c) The

d2c function.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0978.jpg?height=318&width=1078&top_left_y=1791&top_left_x=564)

FIGURE 13.38

Using the c2d function to convert $G(s)=G_{0}(s) G_{p}(s)$ to $G(z)$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0979.jpg?height=470&width=852&top_left_y=167&top_left_x=388)

Transfer function:

$$
\frac{0.3679 z+0.2642}{z^{\wedge} 2-1.368 z+0.3679}
$$

Sampling time: 1

The functions step, impulse, and Isim are used for simulation of sampled-data systems. The unit step response is generated by step. The step function format is shown in Figure 13.39. The unit impulse response is generated by the function impulse, and the response to an arbitrary input is obtained by the Isim function. The impulse and Isim functions are shown in Figures 13.40 and 13.41, respectively. These sampled-data system simulation functions operate in essentially the same manner as their counterparts for continuous-time (unsampled) systems. The output is $y(k T)$ and is shown as $y(k T)$ held constant for the period $T$.

\section{EXAMPLE 13.12 Unit step response}

In Example 13.4, we considered the problem of computing the step response of a closed-loop sampled-data system. In that example, the response, $y(k T)$, was
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0979.jpg?height=514&width=924&top_left_y=1531&top_left_x=413)

FIGURE 13.39 The step function generates the output $y(k T)$ for a step input. FIGURE 13.40

The impulse function generates the output $y(t)$ for an impulse input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0980.jpg?height=162&width=779&top_left_y=152&top_left_x=615)

$y=$ output response

$T=$ simulation time vector

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0980.jpg?height=115&width=172&top_left_y=488&top_left_x=657)

Gys

$T$ should be in the form $0: T_{s}: T_{f}$, where $T_{s}$ is the sample time.
FIGURE 13.41

The Isim function generates the output $y(k T)$ for an arbitrary input.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0980.jpg?height=153&width=908&top_left_y=808&top_left_x=539)

$y=$ output response

$T=$ simulation time vector

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0980.jpg?height=122&width=205&top_left_y=1002&top_left_x=829)

$u$ : input should be sampled at the same rate as sys

computed using long division. We can compute the response $y(k T)$ using the step function, shown in Figure 13.39. With the closed-loop transfer function given by

$$
\frac{Y(z)}{R(z)}=\frac{0.3678 z+0.2644}{z^{2}-z+0.6322},
$$

the associated closed-loop step response is shown in Figure 13.42. The discrete step response shown in this figure is also shown in Figure 13.17. To determine the actual continuous response $y(t)$, we use the m-file script as shown in Figure 13.43. The zero-order hold is modeled by the transfer function

$$
G_{0}(s)=\frac{1-e^{-s T}}{s} .
$$

In the m-file script in Figure 13.43, we approximate the $e^{-s T}$ term using the pade function with a second-order approximation and a sampling time of $T=1 \mathrm{~s}$. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0981.jpg?height=1004&width=1032&top_left_y=161&top_left_x=413)

FIGURE 13.42 The discrete response, $y(k T)$, of a sampled second-order system to a unit step.

We then compute an approximation for $G_{0}(s)$ based on the Padé approximation of $e^{-s T}$.

The subject of digital computer compensation was discussed in Section 13.7. In the next example, we consider again the subject utilizing control design software.

\section{EXAMPLE 13.13 Root locus of a digital control system}

Consider

$$
G(z)=\frac{0.3678(z+0.7189)}{(z-1)(z-0.3680)},
$$

and the compensator

$$
D(z)=\frac{K(z-0.3678)}{z+0.2400},
$$



![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0982.jpg?height=967&width=945&top_left_y=166&top_left_x=506)

FIGURE 13.43 The continuous response $y(t)$ to a unit step for the system of Figure 13.16.

with the parameter $K$ as a variable yet to be determined. The sampling time is $T=1 \mathrm{~s}$. When

$$
G(z) D(z)=K \frac{0.3678(z+0.7189)}{(z-1)(z+0.2400)},
$$

we have the problem in a form for which the root locus method is directly applicable. The rlocus function works for discrete-time systems in the same way as for continuous-time systems. Using a m-file script, the root locus associated with Equation (13.70) is easily generated, as shown in Figure 13.44. Remember that the stability region is defined by the unit circle in the complex plane. The function rlocfind can be used with the discrete-time system root locus in exactly the same way as for continuous-time systems to determine the value of the system gain associated with any point on the locus. Using rlocfind, we determine that $K=4.639$ places the roots on the unit circle. FIGURE 13.44

The rlocus function for sampled-data systems.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0983.jpg?height=818&width=908&top_left_y=174&top_left_x=390)

>>rlocfind(sys)

Select a point in the graphics window

Determine $K$ at the unit circle

selected_point $=$ boundary

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0983.jpg?height=75&width=364&top_left_y=1235&top_left_x=406)

\subsection{SEQUENTIAL DESIGN EXAMPLE: DISK DRIVE READ SYSTEM}

In this chapter, we design a digital controller for the disk drive system. As the disk rotates, the sensor head reads the patterns used to provide the reference error information. This error information pattern is read intermittently as the head reads the stored data, and then the pattern in turn. Because the disk is rotating at a constant speed, the time $T$ between position-error readings is a constant. This sampling period is typically $100 \mu \mathrm{s}$ to $1 \mathrm{~ms}$ [20]. Thus, we have sampled error information. We may also use a digital controller, as shown in Figure 13.45, to achieve a satisfactory system response. In this section, we will design $D(z)$.

First, we determine

$$
G(z)=Z\left[G_{0}(s) G_{p}(s)\right] .
$$

Since

$$
G_{p}(s)=\frac{5}{s(s+20)},
$$

FIGURE 13.45

Feedback control system with a digital controller. Note that $G(z)=$ $Z\left[G_{0}(s) G_{p}(s)\right]$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0984.jpg?height=206&width=778&top_left_y=144&top_left_x=507)

we have

$$
G_{0}(s) G_{p}(s)=\frac{1-e^{-s T}}{s} \frac{5}{s(s+20)} .
$$

We note that for $s=20$ and $T=1 \mathrm{~ms}, e^{-s T}=0.98$. Then we see that the pole at $s=-20$ in Equation (13.71) has an insignificant effect. Therefore, we could approximate

$$
G_{p}(s) \approx \frac{0.25}{s}
$$

Then we need

$$
\begin{aligned}
G(z) & =Z\left[\frac{1-e^{-s T}}{s} \frac{0.25}{s}\right]=\left(1-z^{-1}\right)(0.25) Z\left[\frac{1}{s^{2}}\right] \\
& =\left(1-z^{-1}\right)(0.25) \frac{T z}{(z-1)^{2}}=\frac{0.25 T}{z-1}=\frac{0.25 \times 10^{-3}}{z-1} .
\end{aligned}
$$

We need to select the digital controller $D(z)$ so that the desired response is achieved for a step input. If we set $D(z)=K$, then we have

$$
D(z) G(z)=\frac{K\left(0.25 \times 10^{-3}\right)}{z-1} .
$$

The root locus for this system is shown in Figure 13.46. When $K=4000$,

$$
D(z) G(z)=\frac{1}{z-1} .
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0984.jpg?height=508&width=644&top_left_y=1606&top_left_x=520)

Therefore, the closed-loop transfer function is

$$
T(z)=\frac{D(z) G(z)}{1+D(z) G(z)}=\frac{1}{z} .
$$

We expect a rapid response for the system. The percent overshoot to a step input is P.O. $=0 \%$, and the settling time is $T_{s}=2 \mathrm{~ms}$.

\subsection{SUMMARY}

The use of a digital computer as the compensation device for a closed-loop control system has grown during the past two decades as the price and reliability of computers have improved dramatically. A computer can be used to complete many calculations during the sampling interval $T$ and to provide an output signal that is used to drive an actuator of a process. Computer control is used today for chemical processes, aircraft control, machine tools, and many common processes.

The $z$-transform can be used to analyze the stability and response of a sampled system and to design appropriate systems incorporating a computer. Computer control systems have become increasingly common as low-cost computers have become readily available.

\section{SKILLS CHECK}

In this section, we provide three sets of problems to test your knowledge: True or False, Multiple Choice, and Word Match. To obtain direct feedback, check your answers with the answer key provided at the conclusion of the end-of-chapter problems. Use the block diagram in Figure 13.47 as specified in the various problem statements.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0985.jpg?height=273&width=1061&top_left_y=1385&top_left_x=429)

FIGURE 13.47 Block diagram for the Skills Check.

In the following True or False and Multiple Choice problems, circle the correct answer.

1. A digital control system uses digital signals and a digital computer to control a process.

True or False

2. The sampled signal is available only with limited precision.

True or False

3. Root locus methods are not applicable to digital control system design and analysis.

True or False 4. A sampled system is stable if all the poles of the closed-loop transfer function lie outside the unit circle of the $z$-plane.

5. The $z$-transform is a conformal mapping from the $s$-plane to the $z$-plane by the relation $z=e^{s T}$.

True or False

6. Consider the function in the $s$-domain

$$
Y(s)=\frac{10}{s(s+2)(s+6)} .
$$

Let $T$ be the sampling time. Then, in the $z$-domain the function $Y(s)$ is
a. $Y(z)=\frac{5}{6} \frac{z}{z-1}-\frac{5}{4} \frac{z}{z-e^{-2 T}}+\frac{5}{12} \frac{z}{z-e^{-6 T}}$
b. $Y(z)=\frac{5}{6} \frac{z}{z-1}-\frac{5}{4} \frac{z}{z-e^{-6 T}}+\frac{5}{12} \frac{z}{z-e^{-T}}$
c. $Y(z)=\frac{5}{6} \frac{z}{z-1}-\frac{z}{z-e^{-6 T}}+\frac{5}{12} \frac{z}{z-e^{-2 T}}$
d. $Y(z)=\frac{1}{6} \frac{z}{z-1}-\frac{z}{1-e^{-2 T}}+\frac{5}{6} \frac{z}{1-e^{-6 T}}$

7. The impulse response of a system is given by

$$
Y(z)=\frac{z^{3}+2 z^{2}+2}{z^{3}-25 z^{2}+0.6 z} .
$$

Determine the values of $y(n T)$ at the first four sampling instants.

a. $y(0)=1, y(T)=27, y(2 T)=647, y(3 T)=660.05$

b. $y(0)=0, y(T)=27, y(2 T)=47, y(3 T)=60.05$

c. $y(0)=1, y(T)=27, y(2 T)=674.4, y(3 T)=16845.8$

d. $y(0)=1, y(T)=647, y(2 T)=47, y(3 T)=27$

8. Consider a sampled-data system with the closed-loop system transfer function

$$
T(z)=K \frac{z^{2}+2 z}{z^{2}+0.2 z-0.5} .
$$

This system is:

a. Stable for all finite $K$.

b. Stable for $-0.5<K<\infty$.

c. Unstable for all finite $K$.

d. Unstable for $-0.5<K<\infty$.

9. The characteristic equation of a sampled system is

$$
q(z)=z^{2}+(2 K-1.75) z+2.5=0,
$$

where $K>0$. The range of $K$ for a stable system is:
a. $0<K<2.63$
b. $K \geq 2.63$
c. The system is stable for all $K>0$.
d. The system is unstable for all $K>0$. 10. Consider the unity feedback system in Figure 13.47, where

$$
G_{p}(s)=\frac{K}{s(0.2 s+1)}
$$

with the sampling time $T=0.4 \mathrm{~s}$. The maximum value for $K$ for a stable closed-loop system is which of the following:

a. $K=7.27$

b. $K=10.5$

c. Closed-loop system is stable for all finite $K$.

d. Closed-loop system is unstable for all $K>0$.

In Problems 11 and 12, consider the sampled data system in Figure 13.47 where

$$
G_{p}(s)=\frac{225}{s^{2}+225} .
$$

11. The closed-loop transfer function $T(z)$ of this system with sampling at $T=1 \mathrm{~s}$ is
a. $T(z)=\frac{1.76 z+1.76}{z^{2}+3.279 z+2.76}$
b. $T(z)=\frac{z+1.76}{z^{2}+2.76}$
c. $T(z)=\frac{1.76 z+1.76}{z^{2}+1.519 z+1}$
d. $T(z)=\frac{z}{z^{2}+1}$

12. The unit step response of the closed-loop system is:
a. $Y(z)=\frac{1.76 z+1.76}{z^{2}+3.279 z+2.76}$
b. $Y(z)=\frac{1.76 z+1.76}{z^{3}+2.279 z^{2}-0.5194 z-2.76}$
c. $Y(z)=\frac{1.76 z^{2}+1.76 z}{z^{3}+2.279 z^{2}-0.5194 z-2.76}$
d. $Y(z)=\frac{1.76 z^{2}+1.76 z}{2.279 z^{2}-0.5194 z-2.76}$

In Problems 13 and 14, consider the sampled data system with a zero-order hold where

$$
G_{p}(s)=\frac{20}{s(s+9)} .
$$

13. The closed-loop transfer function $T(z)$ of this system using a sampling period of $T=0.5 \mathrm{~s}$ is which of the following:
a. $T(z)=\frac{1.76 z+1.76}{z^{2}+2.76}$
b. $T(z)=\frac{0.87 z+0.23}{z^{2}-0.14 z+0.24}$
c. $T(z)=\frac{0.87 z+0.23}{z^{2}-1.01 z+0.011}$
d. $T(z)=\frac{0.92 z+0.46}{z^{2}-1.01 z}$ 14. The range of the sampling period $T$ for which the closed-loop system is stable is:
a. $T \leq 1.12$
b. The system is stable for all $T>0$.
c. $1.12 \leq T \leq 10$
d. $T \leq 4.23$

15. Consider a continuous-time system with the closed-loop transfer function

$$
T(s)=\frac{s}{s^{2}+4 s+8} .
$$

Using a zero-order hold on the inputs and a sampling period of $T=0.02 \mathrm{~s}$, determine which of the following is the equivalent discrete-time closed-loop transfer function representation:
a. $T(z)=\frac{0.019 z-0.019}{z^{2}+2.76}$
b. $T(z)=\frac{0.87 z+0.23}{z^{2}-0.14 z+0.24}$
c. $T(z)=\frac{0.019 z-0.019}{z^{2}-1.9 z+0.9}$
d. $T(z)=\frac{0.043 z-0.02}{z^{2}+1.9231}$

In the following Word Match problems, match the term with the definition by writing the correct letter in the space provided.

a. Precision

b. Digital computer compensator

c. $z$-plane

d. Backward difference rule

e. Minicomputer

f. Sampled-data system

g. Sampled data

h. Digital control system

i. Microcomputer

j. Forward rectangular integration

k. Stability of a sampled-data system
A system where part of the system acts on sampled data (sampled variables).

The stable condition exists when all the poles of the closed-loop transfer function $T(z)$ are within the unit circle on the $z$-plane.

The plane with the vertical axis equal to the imaginary part of $z$ and the horizontal axis equal to the real part of $z$.

A control system using digital signals and a digital computer to control a process.

Data obtained for the system variables only at discrete intervals.

The period when all the numbers leave or enter the computer.

A conformal mapping from the $s$-plane to the $z$-plane by the relation $z=e^{s T}$.

The sampled signal available only with a limited precision.

A system that uses a digital computer as the compensator element.

A computational method of approximating the time derivative of a function.

A computational method of approximating the integration of a function. 
1. Amplitude quantization error
m. PID controller
n. $z$-transform
o. Sampling period
p. Zero-order hold

A small personal computer (PC) based on a microprocessor.

A stand-alone computer with size and performance between a microcomputer and a large mainframe.

A controller with three terms in which the output is the sum of a proportional term, an integral term, and a differentiating term.

The degree of exactness or discrimination with which a quantity is stated.

A mathematical model of a sample and data hold operation.

\section{EXERCISES}

E13.1 State whether the following signals are discrete or continuous:

(a) Elevation contours on a map.

(b) Temperature in a room.

(c) Digital clock display.

(d) The score of a soccer game.

(e) The output of a loudspeaker.

E13.2 (a) Find the values $y(k T)$ when

$$
Y(z)=\frac{2 z}{z^{2}-4 z+3}
$$

for $k=0$ to 3 .

(b) Obtain a closed form of solution for $y(k T)$ as a function of $k$.

Answer: $y(0)=0, y(T)=2, y(2 T)=8, y(3 T)=26$; $y(k T)=e^{k \operatorname{In} 3}-1$.

E13.3 Obtain the $z$-transform $Y(z)$ for the response $y(k T)=k T, k \geq 0$, where $T$ is the sampling time,

(a) by using the definition $X(z)=\sum_{k=0}^{\infty} x(k T) z^{-k}$,

(b) by applying the property of differentiation in $z$-domain, $Z\{t x(t)\}=-z T \frac{d X(z)}{d z}$, given that $Z\{u(t)\}=\frac{z}{z-1}$.

E13.4 We have a function

$$
Y(s)=\frac{1}{s(s+2)(s+3)} .
$$

Using a partial fraction expansion of $Y(s)$ and a table of $z$-transforms, find $Y(z)$ when $T=0.2 \mathrm{~s}$.

E13.5 The space shuttle, with its robotic arm, is shown in Figure E13.5(a). An astronaut controls the robotic arm and gripper by using a window and the TV cameras [9]. Discuss the use of digital control for this system and sketch a block diagram for the system, including a computer for display generation and control.
E13.6 Computer control of a robot to spraypaint an automobile is shown by the system in Figure E13.6(a) [1]. The system is of the type shown in Figure E13.6(b), where

$$
G_{p}(s)=\frac{1}{s(0.25 s+1)} .
$$

and we want a phase margin of $P . M .=45^{\circ}$. Using frequency response methods, a compensator was developed, given by $G_{c}(s)=\frac{0.508(s+0.15)}{s+0.015}$. Obtain the $D(z)$ required when $T=0.05 \mathrm{~s}$,

E13.7 Find the response for the first four sampling instants for

$$
Y(z)=\frac{z^{3}+2 z^{2}+1}{z^{3}-1.5 z^{2}+0.5 z} .
$$

Then, find $y(0), y(1), y(2)$, and $y(3)$.

E13.8 Determine whether the closed-loop system with $T(z)$ is stable when

$$
T(z)=\frac{z}{z^{2}+0.2 z-1.0} .
$$

Answer: unstable

E13.9 (a) Determine $y(k T)$ for $k=0$ to 3 when

$$
Y(z)=\frac{1.5 z^{2}+0.5 z}{z^{2}-1} .
$$

(b) Obtain a closed form solution for $y(k T)$ as a function of $k$.

E13.10 A system has

$$
G_{p}(s)=\frac{K}{s(\tau s+1)},
$$

with $T=0.01 \mathrm{~s}$ and $\tau=0.008 \mathrm{~s}$. (a) Find $K$ so that the percent overshoot is P.O. $\leq 40 \%$. (b) Determine the steady-state error in response to a unit ramp input. (c) Determine $K$ to minimize the integral squared error. 

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0990.jpg?height=525&width=541&top_left_y=156&top_left_x=630)

(a)

FIGURE E13.5

(a) Space shuttle and robotic arm.

(b) Astronaut

control of the arm.

FIGURE E13.6

(a) Automobile spraypaint system. (b) Closed-loop system with digital controller.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0990.jpg?height=442&width=762&top_left_y=776&top_left_x=522)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0990.jpg?height=466&width=1233&top_left_y=1336&top_left_x=522)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0990.jpg?height=224&width=1202&top_left_y=1861&top_left_x=509)

(b) FIGURE E13.10

A closed-loop sampled system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0991.jpg?height=275&width=1056&top_left_y=154&top_left_x=373)

E13.11 A system has a process transfer function

$$
G_{p}(s)=\frac{9}{s^{2}+9} .
$$

(a) Determine $G(z)$ for $G_{p}(s)$ preceded by a zeroorder hold with $T=0.15 \mathrm{~s}$. (b) Determine whether the digital system is stable. (c) Plot the impulse response of $G(z)$ for the first 15 samples. (d) Plot the first 30 samples of the output response of $G(z)$ when the input is a step of 0.5 unit.

E13.12 Find the $z$-transform of

$$
X(s)=\frac{s+1}{s^{2}+5 s+6}
$$

when the sampling period is $T=1 \mathrm{~s}$.

E13.13 The characteristic equation of a sampled system is

$$
z^{2}+(K-3) z+0.7=0 .
$$

Find the range of $K$ so that the system is stable.

Answer: $1.3<K<4.7$

E13.14 A unity feedback system, as shown in Figure E13.10, has a plant

$$
G_{p}(s)=\frac{K}{s(2 s+1)},
$$

with $T=0.5 \mathrm{~s}$. Determine whether the system is stable when $K=4$. Determine the maximum value of $K$ for stability.

E13.15 Consider the sampled-data system shown in Figure E13.15. Determine the transfer function $G(z)$ when the sampling time $T=1 \mathrm{~s}$.

E13.16 Consider the sampled-data system shown in Figure E13.16. Determine the transfer function $G(z)$ and when the sampling time $T=0.5 \mathrm{~s}$.
FIGURE E13.15

An open-loop sampled-data system with sampling time $T=1 \mathrm{~s}$.

FIGURE E13.16

An open-loop sampled-data system with sampling time $T=0.5 \mathrm{~s}$.
![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0991.jpg?height=462&width=926&top_left_y=1184&top_left_x=374)

\section{PROBLEMS}

P13.1 The input to a sampler is $r(t)=\sin (\omega t)$, where $\omega=1.5 \pi$. Plot the input to the sampler and the output $r^{*}(t)$ for the first 2 seconds when $T=0.25 \mathrm{~s}$.

P13.2 The input to a sampler is $r(t)=\sin (\omega t)$, where $\omega=2 \pi$. The output of the sampler enters a zeroorder hold. Plot the output of the zero-order hold $p(t)$ for the first 2 seconds when $T=0.125 \mathrm{~s}$.

P13.3 A unit ramp $r(t)=t, t>0$, is used as an input to a process where $G(s)=1 /(s+1)$, as shown in Figure
P13.3. Determine the output $y(k T)$ for the first four sampling instants.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0991.jpg?height=115&width=520&top_left_y=1951&top_left_x=916)

FIGURE P13.3 Sampling system. P13.4 A closed-loop system has a hold circuit and process as shown in Figure E13.10. Determine $G(z)$ when $T=0.5 \mathrm{~s}$ and

$$
G_{p}(s)=\frac{3}{s+3} .
$$

P13.5 For the system in Problem P13.4, let $r(t)$ be a unit step input and calculate the response of the system by synthetic division for five time steps.

P13.6 Consider the closed-loop system shown in Figure E13.10, where $G_{p}(s)=\frac{1}{(0.2 s+1)}$. Given the sampling period $T=0.05 \mathrm{~s}$, find the output $Y(z)$ to a unit step input. Find the initial and final value directly from $Y(z)$, and plot the unit step response.

P13.7 A closed-loop system is shown in Figure E13.10. This system represents the pitch control of an aircraft. The process transfer function is $G_{p}(s)=$ $K /[s(0.5 s+1)]$. Select a gain $K$ and sampling period $T$ so that the percent overshoot is limited to 0.3 for a unit step input and the steady-state error for a unit ramp input is less than 1.0.

P13.8 Consider the computer-compensated system shown in Figure E13.6(b) when $T=1 \mathrm{~s}$ and

$$
K G_{p}(s)=\frac{K}{s(s+10)} .
$$

Select the parameters $K$ and $r$ of $D(z)$ when

$$
D(z)=\frac{z-0.3678}{z+r} .
$$

Select within the range $1<K<2$ and $0<r<1$.

Determine the response of the compensated system and compare it with the uncompensated system.

P13.9 A suspended, mobile, remote-controlled system to bring three-dimensional mobility to professional NFL football is shown in Figure P13.9. The camera can be moved over the field as well as up and down. The motor control on each pulley is represented by Figure E13.10 with

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0992.jpg?height=503&width=720&top_left_y=1628&top_left_x=221)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0992.jpg?height=184&width=759&top_left_y=155&top_left_x=994)

FIGURE P13.10 Feedback control system with a digital controller.

We wish to achieve a phase margin of $P . M .=45^{\circ}$ using $G_{c}(s)$. Select a suitable crossover frequency and sampling period to obtain $D(z)$. Use the $G_{c}(s)$-to- $D(z)$ conversion method.

P13.10 Consider a system as shown in Figure P13.10 with a zero-order hold, a process

$$
G_{p}(s)=\frac{1}{s(s+10)},
$$

and $T=0.1$ s. Note that $G(z)=Z\left\{G_{0}(s) G_{p}(s)\right\}$.

(a) Let $D(z)=K$ and determine the transfer function $G(z) D(z)$. (b) Determine the characteristic equation of the closed-loop system. (c) Calculate the maximum value of $K$ for a stable system. (d) Determine $K$ such that the percent overshoot is P.O. $\leq 30 \%$. (e) Calculate the closed-loop transfer function $T(z)$ for $K$ of part (d) and plot the step response. (f) Determine the location of the closedloop roots and the percent overshoot if $K$ is one-half of the value determined in part (c). (g) Plot the step response for the $K$ of part (f).

P13.11 (a) For the system described in Problem P13.10, design a lag compensator $G_{c}(s)$ to achieve a percent overshoot P.O. $\leq 30 \%$ and a steady-state error of $e_{s s}=0.01$ for a ramp input. Assume a continuous nonsampled system with $G_{p}(s)$.

(b) Determine a suitable $D(z)$ to satisfy the requirements of part (a) with a sampling period $T=0.1 \mathrm{~s}$. Assume a zero-order hold and sampler, and use the $G_{c}(s)$-to- $D(z)$ conversion method.

(c) Plot the step response of the system with the continuous-time compensator $G_{c}(s)$ of part (a) and of the digital system with the $D(z)$ of part (b). Compare the results.

(d) Repeat part (b) for $T=0.01 \mathrm{~s}$ and then repeat part (c).

(e) Plot the ramp response for $D(z)$ with $T=0.1 \mathrm{~s}$ and compare it with the continuous-system response.

P13.12 The transfer function of a plant and a zero-order hold is

$$
G(z)=\frac{K(z+0.45)}{z(z-3)} .
$$

(a) Plot the root locus. (b) Determine the range of gain $K$ for a stable system.

FIGURE P13.9 Mobile camera for football field. P13.13 The azimuth control system of an aircraft has a transfer function $G_{p}(s)=\frac{(s+3)}{s(s+1)^{2}}$. It is implemented with a sampler and hold as shown in Figure E13.10.

(a) Find the transfer function of the plant and zero-order hold at a sampling rate $1 \mathrm{~Hz}$.

(b) Plot the root locus, and determine the value of $K$ so that the system is stable.

(c) Determine the value of $K$ so that the system has two equal roots, and calculate all the roots in this case.

P13.14 A sampled-data system with a sampling period $T=0.05 \mathrm{~s}$ is

$G(z)=\frac{K\left(z^{3}+10.3614 z^{2}+9.758 z+0.8353\right)}{z^{4}-3.7123 z^{3}+5.1644 z^{2}-3.195 z+0.7408}$.

(a) Plot the root locus. (b) Determine $K$ when the two real poles break away from the real axis. (c) Calculate the maximum $K$ for stability.

P13.15 A closed-loop system with a sampler and hold, as shown in Figure E13.10, has a process transfer function

$$
G_{p}(s)=\frac{17}{s-3} .
$$

Determine the first 6 samples of $y(k T)$ when $T=0.1 \mathrm{~s}$. The input signal is a unit step.
P13.16 A closed-loop system as shown in Figure E13.10 has

$$
G_{p}(s)=\frac{0.5}{s(s+5)} .
$$

Calculate and plot $y(k T)$ for $0 \leq k \leq 10$ when $T=1 \mathrm{~s}$, and the input is a unit step.

P13.17 A closed-loop system, as shown in Figure E13.10, has

$$
G_{p}(s)=\frac{K}{s(s+2.5)}
$$

and $T=1.5 \mathrm{~s}$. Plot the root locus for $K \geq 0$, and determine the gain $K$ that results in the two roots of the characteristic equation on the $z$-circle (at the stability limit).

P13.18 A unity feedback system, as shown in Figure E13.10, has

$$
G_{p}(s)=\frac{K}{s(s+1)} .
$$

If the system is continuous $(T=0)$, then $K=1$ yields a step response with a percent overshoot of P.O. $=16 \%$ and a settling time (with a $2 \%$ criterion) of $T_{S}=8 \mathrm{~s}$. Plot the response for $0 \leq T \leq 1.2$, varying $T$ by increments of 0.2 when $K=1$. Complete a table recording the percent overshoot and the settling time versus $T$.

\section{ADVANCED PROBLEMS}

AP13.1 A closed-loop system, as shown in Figure E13.16, has a process

$$
G_{p}(s)=\frac{K(1+a s)}{s^{2}},
$$

where $a$ is adjustable to achieve a suitable response. Plot the root locus when $a=6$. Determine the range of $K$ for stability when $T=0.5 \mathrm{~s}$.

AP13.2 A manufacturer uses an adhesive to form a seam along the edge of the material, as shown in Figure AP13.2. It is critical that the glue be applied evenly to avoid flaws; however, the speed at which the material passes beneath the dispensing head is not constant. The glue needs to be dispensed at a rate proportional to the varying speed of the material. The controller adjusts the valve that dispenses the glue [12].

The system can be represented by the block diagram shown in Figure P13.10, where $G_{p}(s)=5 /(0.04 s+1)$ with a zero-order hold $G_{0}(s)$. Use a controller

$$
D(z)=\frac{K T}{1-z^{-1}}=\frac{K T z}{z-1}
$$

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0993.jpg?height=682&width=774&top_left_y=1317&top_left_x=902)

FIGURE AP13.2 A glue control system. that represents an integral controller. Determine $G(z)$ $D(z)$ for $T=40 \mathrm{~ms}$, and plot the root locus. Select an appropriate gain $K$, and plot the step response.

AP13.3 A system of the form shown in Figure P13.10 has $D(z)=K$ and

$$
G_{p}(s)=\frac{10}{s(s+5)} .
$$

When $T=0.05 \mathrm{~s}$, find a suitable $K$ for a rapid step response with a percent overshoot of P.O. $\leq 10 \%$.
AP13.4 A system of the form shown in Figure E13.10 has

$$
G_{p}(s)=\frac{8}{s+2} .
$$

Determine the range of sampling period $T$ for which the system is stable. Select a sampling period $T$ so that the system is stable and provides a rapid response.

AP13.5 Consider the closed-loop sampled-data system shown in Figure AP13.5. Determine the acceptable range of the parameter $K$ for closed-loop stability.
FIGURE AP13.5

A closed-loop sampled-data system with sampling time $T=0.1 \mathrm{~s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0994.jpg?height=280&width=1076&top_left_y=566&top_left_x=504)

\section{DESIGN PROBLEMS}

CDP13.1 Design a digital controller for the system using the second-order model of the motor-capstan-slide as described in CDP2.1 and CDP4.1. Use a sampling period of $T=1 \mathrm{~ms}$ and select a suitable $D(z)$ for the system shown in Figure P13.10. Determine the response of the designed system to a step input $r(t)$.

DP13.1 A temperature system, as shown in Figure $\mathrm{P} 13.10$, has a process transfer function

$$
G_{p}(s)=\frac{0.8}{3 s+1}
$$

and a sampling period $T$ of $0.5 \mathrm{~s}$.

(a) Using $D(z)=K$, select a gain $K$ so that the system is stable. (b) The system may be slow and overdamped, and thus we seek to design a phase-lead compensator. Determine a suitable compensator $G_{c}(s)$ and then calculate $D(z)$. (c) Verify the design obtained in part (b) by plotting the step response of the system for the selected $D(z)$.

DP13.2 A disk drive read-write head-positioning system has a system as shown in Figure P13.10 [11]. The process transfer function is

$$
G_{p}(s)=\frac{9}{s^{2}+0.85 s+788} .
$$

Accurate control using a digital compensator is required. Let $T=10 \mathrm{~ms}$ and design a compensator, $D(z)$, using (a) the $G_{c}(s)-$ to $-D(z)$ conversion method and (b) the root locus method.

DP13.3 Vehicle traction control, which includes antiskid braking and antispin acceleration, can enhance vehicle performance and handling. The objective of this control is to maximize tire traction by preventing the wheels from locking during braking and from spinning during acceleration.

Wheel slip, the difference between the vehicle speed and the wheel speed (normalized by the vehicle speed for braking and the wheel speed for acceleration), is chosen as the controlled variable for most of the traction-control algorithm because of its strong influence on the tractive force between the tire and the road [17].

A model for one wheel is shown in Figure DP13.3 when $y$ is the wheel slip. The goal is to minimize the slip when a disturbance occurs due to road
FIGURE DP13.3

Vehicle fraction control system.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0994.jpg?height=303&width=1135&top_left_y=1815&top_left_x=505)

conditions. Design a controller $D(z)$ so that the damping ratio of the system $\zeta=1 / \sqrt{2}$, and determine the resulting $K$. Assume $T=0.1 \mathrm{~s}$. Plot the resulting step response, and find the percent overshoot and settling time (with a $2 \%$ criterion).

DP13.4 A machine-tool system has the form shown in Figure E13.6(b) with [10]

$$
K G_{p}(s)=\frac{0.2}{s(s+0.2)} .
$$

The sampling rate is chosen as $T=1 \mathrm{~s}$. We desire the step response to have a percent overshoot of P.O. $\leq 20 \%$ and a settling time (with a $2 \%$ criterion) of $T_{s} \leq 10 \mathrm{~s}$. Design a $D(z)$ to achieve these specifications.

DP13.5 Plastic extrusion is a well-established method widely used in the polymer processing industry [12]. Such extruders typically consist of a large barrel divided into several temperature zones, with a hopper at one end and a die at the other. Polymer is fed into the barrel in raw and solid form from the hopper and is pushed forward by a powerful screw. Simultaneously, it is gradually heated while passing through the various temperature zones set in gradually increasing temperatures. The heat produced by the heaters in the barrel, together with the heat released from the friction between the raw polymer and the surfaces of the barrel and the screw, eventually causes the melting of the polymer, which is then pushed by the screw out from the die, to be processed further for various purposes.

The output variables are the outflow from the die and the polymer temperature. The main controlling variable is the screw speed, since the response of the process to it is rapid.

The control system for the output polymer temperature is shown in Figure DP13.5. Select a gain $K$ and a sampling period $T$ to obtain a percent overshoot of P.O. $\leq 20 \%$ and $T_{s} \leq 10 \mathrm{~s}$ for a unit step input.

DP13.6 A sampled-data system closed-loop block diagram is shown in Figure DP13.6. Design $D(z)$ to such that the closed-loop system response to a unit step response has a percent overshoot P.O. $\leq 12 \%$ and a settling time $T_{s} \leq 20 \mathrm{~s}$.
FIGURE DP13.5

Control system for an extruder.

FIGURE DP13.6

A closed-loop sampled-data system with sampling time $T=1 \mathrm{~s}$.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0995.jpg?height=397&width=990&top_left_y=1034&top_left_x=427)

(a)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0995.jpg?height=172&width=1082&top_left_y=1523&top_left_x=374)

(b)

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0995.jpg?height=285&width=1192&top_left_y=1786&top_left_x=373)



\section{COMPUTER PROBLEMS}

CP13.1 Develop an $\mathrm{m}$-file to plot the unit step response of the system

$$
G(z)=\frac{0.575 z+0.025}{z^{2}-0.8 z+0.4} .
$$

Verify graphically that the steady-state value of the output is 1 .

CP13.2 Convert the following continuous-time transfer functions to sampled-data systems using the c2d function. Assume a sample period of 1 second and a zero-order hold $G_{0}(s)$.
(a) $G_{p}(s)=\frac{1}{s}$
(b) $G_{p}(s)=\frac{s}{s^{2}+2}$
(c) $G_{p}(s)=\frac{s+4}{s+3}$
(d) $G_{p}(s)=\frac{1}{s(s+8)}$

CP13.3 The closed-loop transfer function of a sampleddata system is given by

$$
T(z)=\frac{Y(z)}{R(z)}=\frac{0.684(z-0.4419)}{z^{2}-0.7524 z+0.0552} .
$$

(a) Compute the unit step response of the system using the dstep function, and assume a sampling period. of $T=0.1 \mathrm{~s}$. (b) Determine the continuous-time transfer function equivalent of $T(z)$ using the $\mathrm{d} 2 \mathrm{c}$ function, and assume a sampling period of $T=0.1 \mathrm{~s}$. (c) Compute the unit step response of the continuous (nonsampled) system using the step function, and compare the plot with part (a).

CP13.4 Plot the root locus for the system

$$
G(z) D(z)=K \frac{Z}{z^{2}-z+0.45} .
$$

Find the range of $K$ for stability.

FIGURE CP13.5

Control system with a digital controller.
CP13.5 Consider the feedback system in Figure CP13.5. Obtain the root locus, and determine the range of $K$ for stability.

CP13.6 Consider the sampled-data system with the loop transfer function

$$
G(z) D(z)=K \frac{z^{2}-z+1.5}{z^{2}-1.2 z+0.1} .
$$

(a) Plot the root locus using the rlocus function.

(b) From the root locus, determine the range of $K$ for stability.

CP13.7 An industrial grinding process is given by the transfer function [15]

$$
G_{p}(s)=\frac{10}{s(s+5)} .
$$

The objective is to use a digital computer to improve the performance, where the transfer function of the computer is represented by $D(z)$. The design specifications are (1) phase margin of $P . M . \geq 45^{\circ}$, and (2) settling time (with a $2 \%$ criterion) of $T_{s} \leq 1 \mathrm{~s}$.

(a) Design a controller

$$
G_{c}(s)=K \frac{s+a}{s+b}
$$

to meet the design specifications. (b) Assuming a sampling time of $T=0.02 \mathrm{~s}$, convert $G_{c}(s)$ to $D(z)$. (c) Simulate the continuous-time, closed-loop system with a unit step input. (d) Simulate the sampled-data, closed-loop system with a unit step input. (e) Compare the results in parts (c) and (d) and comment.

![](https://cdn.mathpix.com/cropped/2023_09_09_8e4139407e887870e81cg-0996.jpg?height=245&width=1150&top_left_y=1698&top_left_x=225)



\section{ANSWERS TO SKILLS CHECK}

True or False: (1) True; (2) True; (3) False; (4) False; (5) True

Multiple Choice: (6) a; (7) c; (8) a; (9) d; (10) a; (11) a; (12) c; (13) b; (14) a; (15) c
Word Match (in order, top to bottom): f, k, c, h, g, o, n, $\mathrm{l}, \mathrm{b}, \mathrm{d}, \mathrm{j}, \mathrm{i}, \mathrm{e}, \mathrm{m}, \mathrm{a}, \mathrm{p}$

\section{TERMS AND CONCEPTS}

Amplitude quantization error The sampled signal available only with a limited precision. The error between the actual signal and the sampled signal.

Backward difference rule A computational method of approximating the time derivative of a function given by $\dot{x}(k T) \approx \frac{x(k T)-x((k-1) T)}{T}$, where $t=k T, T$ is the sample time, and $k=1,2, \ldots$

Digital computer compensator A system that uses a digital computer as the compensator element.

Digital control system A control system using digital signals and a digital computer to control a process.

Forward rectangular integration A computational method of approximating the integration of a function given by $\quad x(k T) \approx x((k-1) T)+T \dot{x}((k-1) T), \quad$ where $t=k T, T$ is the sample time, and $k=1,2, \ldots$.

Microcomputer A small personal computer (PC) based on a microprocessor.

PID controller A controller with three terms in which the output is the sum of a proportional term, an integrating term, and a differentiating term, with an adjustable gain for each term, given by

$$
G_{c}(z)=K_{1}+\frac{K_{2} T s}{z-1}+K_{3} \frac{z-1}{T z} .
$$

Precision The degree of exactness or discrimination with which a quantity is stated.

Sampled data Data obtained for the system variables only at discrete intervals. Data obtained once every sampling period.

Sampled-data system A system where part of the system acts on sampled data (sampled variables).

Sampling period The period when all the numbers leave or enter the computer. The period for which the sampled variable is held constant.

Stability of a sampled-data system The stable condition exists when all the poles of the closed-loop transfer function $T(z)$ are within the unit circle on the $z$-plane.

$z$-plane The plane with the vertical axis equal to the imaginary part of $z$ and the horizontal axis equal to the real part of $z$.

$z$-transform A conformal mapping from the s-plane to the $z$-plane by the relation $z=e^{s T}$. A transform from the $s$-domain to the $z$-domain.

Zero-order hold A mathematical model of a sample and data hold operation whose input-output transfer function is represented by $G_{o}(s)=\frac{1-e^{-s T}}{s}$. 

\section{References}

\section{Chapter 1}

1. O. Mayr, The Origins of Feedback Control, MIT Press, Cambridge, Mass., 1970.

2. O. Mayr, "The Origins of Feedback Control," Scientific American, Vol. 223, No. 4, October 1970, pp. 110-118.

3. O. Mayr, Feedback Mechanisms in the Historical Collections of the National Museum of History and Technology, Smithsonian Institution Press, Washington, D. C., 1971.

4. E. P. Popov, The Dynamics of Automatic Control Systems, Gostekhizdat, Moscow, 1956; Addison-Wesley, Reading, Mass., 1962.

5. J. C. Maxwell, "On Governors," Proc. of the Royal Society of London, 16, 1868, in Selected Papers on Mathematical Trends in Control Theory, Dover, New York, 1964, pp. 270-283.

6. I. A. Vyshnegradskii, "On Controllers of Direct Action," Izv. SPB Tekhnolog. Inst., 1877.

7. H. W. Bode, "Feedback - The History of an Idea," in Selected Papers on Mathematical Trends in Control Theory, Dover, New York, 1964, pp. 106-123.

8. H. S. Black, "Inventing the Negative Feedback Amplifier," IEEE Spectrum, December 1977, pp. 55-60.

9. J. E. Brittain, Turning Points in American Electrical History, IEEE Press, New York, 1977, Sect. II-E.

10. W. S. Levine, The Control Handbook, CRC Press, Boca Raton, Fla., 1996.

11. G. Newton, L. Gould, and J. Kaiser, Analytical Design of Linear Feedback Controls, John Wiley \& Sons, New York, 1957.

12. M. D. Fagen, A History of Engineering and Science on the Bell Systems, Bell Telephone Laboratories, 1978, Chapter 3.

13. G. Zorpette, "Parkinson's Gun Director," IEEE Spectrum, April 1989, p. 43.
14. J. Höller, V. Tsiatsis, C. Mulligan, S. Karnouskos, S. Avesand, and D. Boyle, From Machine-to-Machine to the Internet of Things: Introduction to New Age of Intelligence, Elsevier, United Kingdom 2014.

15. S. Thrun, "Toward Robotic Cars," Communications of the ACM, Vol. 53, No. 4, April 2010.

16. M. M. Gupta, Intelligent Control, IEEE Press, Piscataway, N. J., 1995.

17. A. G. Ulsoy, "Control of Machining Processes," Journal of Dynamic Systems, ASME, June 1993, pp. 301-307.

18. M. P. Groover, Fundamentals of Modern Manufacturing, Prentice Hall, Englewood Cliffs, N. J., 1996.

19. Michelle Maisto, "Induct Now Selling Navia, First Self-Driving Commercial Vehicle," eWeek. 2014, http:/www.eweek.com/innovation/inductnow-selling-navia-first-self-driving-commercialvehicle.html.

20. Heather Kelly, "Self-Driving Cars Now Legal in California," CNN, 2013, http://www. cnn.com/2012/09/25/tech/innovation/selfdriving-car-california/index.html.

21. P. M. Moretti and L. V. Divone, "Modern Windmills," Scientific American, June 1986, pp. 110-118.

22. Amy Lunday, "Bringing a Human Touch to Modern Prosthetics," Johns Hopkins University, June 20, 2018, https://hub.jhu.edu/2018/06/20/edermis-prosthetic-sense-of-touch/

23. R. C. Dorf and J. Unmack, "A Time-Domain Model of the Heart Rate Control System," Proceedings of the San Diego Symposium for Biomedical Engineering, 1965, pp. 43-47.

24. Alex Wood, "The Internet of Things is Revolutionising Our Lives, But Standards Are a Must," published by theguardian.com, The Guardian, 2015. 25. R. C. Dorf, Introduction to Computers and Computer Science, 3rd ed., Boyd and Fraser, San Francisco, 1982, Chapters 13, 14.

26. K. Sutton, "Productivity," in Encyclopedia of Engineering, McGraw-Hill, New York, pp. 947-948.

27. Florian Michahelles, "The Internet of Things How It Has Started and What to Expect," Swiss Federal Institute of Technology, Zurich, 2010, http://www.im.ethz.ch/people/fmichahelles/talks/iotexpo_iothistory_fmichahelles. pdf.

28. R. C. Dorf, Robotics and Automated Manufacturing, Reston Publishing, Reston, Va., 1983.

29. S. S. Hacisalihzade, "Control Engineering and Therapeutic Drug Delivery," IEEE Control Systems, June 1989, pp. 44-46.

30. E. R. Carson and T. Deutsch, "A Spectrum of Approaches for Controlling Diabetes," IEEE Control Systems, December 1992, pp. 25-30.

31. J. R. Sankey and H. Kaufman, "Robust Considerations of a Drug Infusion System,' Proceedings of the American Control Conference, San Francisco, Calif., June 1993, pp. 1689-1695.

32. W. S. Levine, The Control Handbook, CRC Press, Boca Raton, Fla., 1996.

33. D. Auslander and C. J. Kempf, Mechatronics, Prentice Hall, Englewood Cliffs, N. J., 1996.

34. "Things that Go Bump in Your Flight," The Economist, July 3, 1999, pp. 69-70.

35. P. J. Brancazio, "Science and the Game of Baseball," Science Digest, July 1984, pp. 66-70.

36. C. Klomp, et al., "Development of an Autonomous Cow-Milking Robot Control System," IEEE Control Systems, October 1990, pp. 11-19.

37. M. B. Tischler et al., "Flight Control of a Helicopter," IEEE Control Systems, August 1999, pp. 22-32.

38. G. B. Gordon and J. C. Roark, "ORCA: An Optimized Robot for Chemical Analysis," Hewlett-Packard Journal, June 1993, pp. 6-19.

39. C. Lo, "The Magic Touch: Bringing Sensory Feedback to Brain-Controlled Prosthetics," January 21, 2019, https://www.medicaldevicenetwork.com/features/future-prosthetics/.
40. L. Scivicco and B. Siciliano, Modeling and Control of Robot Manipulators, McGrawHill, New York, 1996.

41. O. Mayr, "Adam Smith and the Concept of the Feedback System," Technology and Culture, Vol. 12, No. 1, January 1971, pp. 1-22.

42. A. Goldsmith, "Autofocus Cameras," Popular Science, March 1988, pp. 70-72.

43. R. Johansson, System Modeling and Identification, Prentice Hall, Englewood Cliffs, N. J., 1993.

44. M. DiChristina, "Telescope Tune-Up," Рориlar Science, September 1999, pp. 66-68.

45. K. Capek, Rossum's Universal Robots, English version by P. Selver and N. Playfair, Doubleday, Page, New York, 1923.

46. D. Hancock, "Prototyping the Hubble Fix," IEEE Spectrum, October 1993, pp. 34-39.

47. A. K. Naj, "Engineers Want New Buildings to Behave Like Human Beings," Wall Street Journal, January 20, 1994, p. B1.

48. E. H. Maslen, et al., "Feedback Control Applications in Artifical Hearts," IEEE Control Systems, December 1998, pp. 26-30.

49. M. DiChristina, "What's Next for Hubble?" Popular Science, March 1998, pp. 56-59.

50. Jack G. Arnold, "Technology Trends in Storage," IBM U.S. Federal, 2013, https:/www950.ibm.com/events/wwe/grp/grp017.nsf/ vLookupPDFs/StLouis Technology/\$file/StLouis Technology.pdf.

51. T. Brant, "SSD vs. HDD: What's the Difference?," January 24, 2019, https://www.pcmag .com/news/ssd-vs-hold-whats-the-difference.

52. R. Stone, "Putting a Human Face on a New Breed of Robot," Science, October 11,1996, p. 182.

53. P. I. Ro, "Nanometric Motion Control of a Traction Drive," ASME Dynamic Systems and Control, Vol. 55.2, 1994, pp. 879-883.

54. K. C. Cheok, "A Smart Automatic Windshield Wiper," IEEE Control Systems Magazine, December 1996, pp. 28-34.

55. D. Dooling, "Transportation," IEEE Spectrum, January 1996, pp. 82-86.

56. Y. Lu, Y. Pan, and Z. Xu, ed., Innovative Design of Manufacturing, Springer Tracts in Mechanical Engineering, Springer, 2020. 57. Trevor English, "Generative Design Utilizes AI to Provide You Practical Optimized Design Solutions," Interesting Engineering, February 17, 2020, https://interestingengineering.com/generative-design-proves-thatthe-future-is-now-for-engineers.

58. Douglas Heaven, "The Designer Changing the Way Aircraft are Built." $B B C$ Future: Machine Minds, November 29, 2018, https://www.bbc.com/future/article/ 20181129-the-ai-transforming-the-wayaircraft-are-built.

59. C. Rist, "Angling for Momentum," Discover, September 1999, p. 37.

60. S. J. Elliott, "Down With Noise," IEEE Spectrum, June 1999, pp. 54-62.

61. W. Ailor, "Controlling Space Traffic," AIAA Aerospace America, November 1999, pp. 34-38.

62. Willam Van Winkle, "The Death of Disk? HDDs Still have an Important Role to Play," September 2, 2019, VentureBeat, https:// venturebeat.com/2019/09/02/the-death-ofdisk-hdds-still-have-an-important-role-to-play/

63. G. F. Hughes, "Wise Drives," IEEE Spectrum, August 2002, pp. 37-41.

64. R. H. Bishop, The Mechatronics Handbook, 2nd ed., CRC Press, Inc., Boca Raton, Fla., 2007.

65. N. Kyura and H. Oho, "Mechatronics-An Industrial Perspective," IEEE/ASME Transactions on Mechatronics, Vol. 1, No. 1, 1996, pp. 10-15.

66. T. Mori, "Mecha-tronics," Yasakawa Internal Trademark Application Memo 21.131.01, July 12, 1969.

67. F. Harshama, M. Tomizuka, and T. Fukuda, "Mechatronics-What is it, Why, and How? - An Editorial," IEEE/ASME Transactions on Mechatronics, Vol. 1, No. 1, 1996, pp. $1-4$.

68. D. M. Auslander and C. J. Kempf, Mechatronics: Mechanical System Interfacing, Prentice Hall, Upper Saddle River, N. J., 1996.

69. D. Shetty and R. A. Kolk, Mechatronic System Design, PWS Publishing Company, Boston, Mass., 1997.
70. W. Bolton, Mechatronics: Electrical Control Systems in Mechanical and Electrical Engineering, 2nd ed., Addison Wesley Longman, Harlow, England, 1999.

71. D. Tomkinson and J. Horne, Mechatronics Engineering, McGraw-Hill, New York, 1996.

72. H. Kobayashi, Guest Editorial, IEEE/ASME Transactions on Mechatronics, Vol. 2, No. 4, 1997, p. 217.

73. D. S. Bernstein, "What Makes Some Control Problems Hard?" IEEE Control Systems Magazine, August 2002, pp. 8-19.

74. Lukas Schroth, "Drones and Artificial Intelligence," Drone Industry Insights, 28 August 2018, https://www.droneii.com/drones-andartifical-intelligence.

75. O. Zerbinati, "A Direct Methanol Fuel Cell," Journal of Chemical Education, Vol. 79, No. 7, July 2002, p. 829.

76. D. Basmadjian, Mathematical Modeling of Physical Systems: An Introduction, Oxford University Press, New York, N.Y., 2003.

77. D. W. Boyd, Systems Analysis and Modeling: A Macro-to-Micro Approach with Multidisciplinary Applications, Academic Press, San Diego, CA, 2001.

78. F. Bullo and A. D. Lewis, Geometric Control of Mechanical Systems: Modeling, Analysis, and Design for Simple Mechanical Control Systems, Springer Verlag, New York, N.Y., 2004.

79. P. D. Cha, J. J. Rosenberg, and C. L. Dym, Funda mentals of Modeling and Analyzing Engineering Systems, Cambridge University Press, Cambridge, United Kingdom, 2000.

80. P. H. Zipfel, Modeling and Simulation of Aerospace Vehicle Dynamics, AIAA Education Series, American Institute of Aeronautics \& Astronautics, Inc., Reston, Virginia, 2001.

81. D. Hristu-Varsakelis and W. S. Levin, eds., Hand book of Networked and Embedded Control Systems, Series: Control Engineering Series, Birkhäuser, Boston, MA, 2005.

82. See the website http://www.gps.gov.

83. B. W. Parkinson and J. J. Spilker, eds., Global Positioning System: Theory \& Applications, Vol. 1 \& 2, Progress in Astronautics and Aeronautics, AIAA, 1996.

84. E. D. Kaplan and C. Hegarty, eds., Understanding GPS: Principles and Applications, 2nd ed., Artech House Publishers, Norwood, Mass., 2005.

85. B. Hofmann-Wellenhof, H. Lichtenegger, and E. Wasle, GNSS-Global navigation Satellite Systems, Springer-Verlag, Vienna, Austria, 2008.

86. M. A. Abraham and N. Nguyen, "Green Engineering: Defining the Principles," Environmental Progress, Vol. 22, No. 4, American Institute of Chemical Engineers, 2003, pp. 233-236.

87. "National Electric Delivery Technologies Roadmap: Transforming the Grid to Revolutionize Electric Power in North America," U.S. Department of Energy, Office of Electric Transmission and Distribution, 2004.

88. D. T. Allen and D. R. Shonnard, Green Engineering: Environmentally Conscious Design of Chemical Processes, Prentice Hall, N. J., 2001.

89. "The Modern Grid Strategy: Moving Towards the Smart Grid," U.S. Department of Energy, Office of Electricity Delivery and Energy Reliability, http://www.netl.doe.gov/ moderngrid/.

90. "Smart Grid System Report," U.S. Department of Energy, July 2009, http://www. oe.energy.gov/ DocumentsandMedia/SGSRMain_090707_lowres.pdf.

91. Pacific Northwest National Laboratory (PNNL) report, "The Smart Grid: An Estimation of the Energy and CO2 Benefits," January 2010, https://www.pnnl.gov/news/ release. $\operatorname{aspx}$ ?id $=776$.

92. J. Machowski, J. Bialek, and J. Bumby, Power System Dynamics: Stability and Control, 2nd ed., John Wiley \& Sons, Ltd, West Sussex, United Kingdom, 2008.

93. R. H. Bishop, ed., Mechatronics Handbook, 2nd ed., CRC Press, 2007.

94. See http://www.burjdubai.com/.

95. R. Roberts, "Control of High-Rise HighSpeed Elevators," Proceedings of the American
Control Conference, Philadelphia, Pa., 1998, pp. 3440-3444.

96. N. L. Doh, C. Kim, and W. K. Chung, "A Practical Path Planner for the Robotic Vacuum Cleaner in Rectilinear Environments," IEEE Transactions on Consumer Electronics, Vol. 53, No. 2, 2007, pp. 519-527.

97. S. C. Lin and C. C. Tsai, "Development of a Self-Balancing Human Transportation Vehicle for the Teaching of Feedback Control," IEEE Transactions on Education, Vol. 52, No. 1, 2009, pp. 157-168.

98. K. Li, E. B. Kosmatopoulos, P. A. Ioannou, and H. Ryaciotaki-Boussalis, "Large Segmented Telescopes: Centralized, Decentralized and Overlapping Control Designs," IEEE Control Systems Magazine, October 2000.

99. A. Cavalcanti, "Assembly Automation with Evolutionary Nanorobots and Sensor-Based Control Applied to Nanomedicine," IEEE Transactions on Nanotechnology, Vol. 2, No. 2, 2003, pp. $82-87$.

100. C. J. Hegarty and E. D. Kaplan, ed., Understanding GPS/GNSS: Principles and Applications, 3rd ed., Artech House Publisher, 2017.

101. K. Yu, ed., Positioning and Navigation in Complex Environments, IGI Global, 2017.

102. P. Szeredi, G. Lukácsy, and B. Tamás, The Semantic Web Explained-the technology and mathematics behind Web 3.0, Cambridge University Press, 2014.

103. L. Yu, A Developer's Guide to the Semantic Web, 2nd ed., Springer-Verlag, Berlin Heidelberg, 2014.

104. J. Krumm, ed., Ubiquitous Computing Fundamentals, CRC Press, 2018.

105. Help Net Security, “41.6 Billion IoT Devices will be Generating 79.4 Zettabytes of Data in 2025," June 21, 2019, https: www. helpnetsecurity.com/2019/06/21/connnectediot-devices-forecast/.

106. W. Harris, "10 Hardest Things to Teach a Robot,"November 25,2013, HowStuffWorks. com, https://science.howstuffworks.com/ 10-hardest-things-to-teach-robot.htm 

\section{Chapter 2}

1. R. C. Dorf, Electric Circuits, 4th ed., John Wiley \& Sons, New York, 1999.

2. I. Cochin, Analysis and Design of Dynamic Systems, Addison-Wesley Publishing Co., Reading, Mass., 1997.

3. J.W.Nilsson, Electric Circuits, 5th ed.,AddisonWesley, Reading, Mass., 1996.

4. E. W. Kamen and B. S. Heck, Fundamentals of Signals and Systems Using MATLAB, Prentice Hall, Upper Saddle River, N. J., 1997.

5. F. Raven, Automatic Control Engineering, 3rd ed., McGraw-Hill, New York, 1994.

6. S. Y. Nof, Handbook of Industrial Robotics, John Wiley \& Sons, New York, 1999.

7. R. R. Kadiyala, "A Toolbox for Approximate Linearization of Nonlinear Systems," IEEE Control Systems, April 1993, pp. 47-56.

8. R. Smith and R. Dorf, Circuits, Devices and Systems, 5th ed., John Wiley \& Sons, New York, 1992.

9. Y. M. Pulyer, Electromagnetic Devices for Motion Control, Springer-Verlag, New York, 1992.

10. B. C. Kuo, Automatic Control Systems, 5th ed., Prentice Hall, Englewood Cliffs, N. J., 1996.

11. F. E. Udwadia, Analytical Dynamics, Cambridge Univ. Press, New York, 1996.

12. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

13. S. M. Ross, Simulation, 2nd ed., Academic Press, Orlando, Fla., 1996.

14. G. B. Gordon, "ORCA: Optimized Robot for Chemical Analysis," Hewlett-Packard Journal, June 1993, pp. 6-19.

15. P. E. Sarachik, Principles of Linear Systems, Cambridge Univ. Press, New York, 1997.

16. S. Bennett, "Nicholas Minorsky and the Automatic Steering of Ships," IEEE Control Systems, November 1984, pp. 10-15.

17. P. Gawthorp, Metamodeling: Bond Graphs and Dynamic Systems, Prentice Hall, Englewood Cliffs, N. J., 1996.

18. C. M. Close and D. K. Frederick, Modeling and Analysis of Dynamic Systems, 2nd ed., Houghton Mifflin, Boston, Mass., 1995.
19. H. S. Black, "Stabilized Feed-Back Amplifiers," Elec trical Engineering, 53, January 1934, pp. 114-120. Also in Turning Points in American History, J. E. Brittain, ed., IEEE Press, New York, 1977, pp. 359-361.

20. P. L. Corke, Visual Control of Robots, John Wiley \& Sons, New York, 1997.

21. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N. J., 1997.

22. S. Pannu and H. Kazerooni, "Control for a Walking Robot," IEEE Control Systems, February 1996, pp. 20-25.

23. K. Ogata, Modern Control Engineering, 3rd ed., Prentice Hall, Upper Saddle River, N. J., 1997.

24. S. P. Parker, Encyclopedia of Engineering, 2nd ed., McGraw-Hill, New York, 1993.

25. G. T. Pope, "Living-Room Levitation," Discover, June 1993, p. 24.

26. G. Rowell and D. Wormley, System Dynamics, Prentice Hall, Upper Saddle River, N. J., 1997.

27. R. H. Bishop, The Mechatronics Handbook, 2nd ed., CRC Press, Inc., Boca Raton, Fla., 2007.

28. C. N. Dorny, Understanding Dynamic Systems: Approaches to Modeling, Analysis, and Design, Prentice-Hall, Englewood Cliffs, New Jersey, 1993.

29. T. D. Burton, Introduction to Dynamic Systems Analysis, McGraw-Hill, Inc., New York, 1994.

30. K. Ogata, System Dynamics, 4th ed., Prentice-Hall, Englewood Cliffs, New Jersey, 2003.

31. J. D. Anderson, Fundamentals of Aerodynamics, 4th ed., McGraw-Hill, Inc., New York, 2005.

32. G. Emanuel, Gasdynamics Theory and Applications, AIAA Education Series, New York, 1986.

33. A. M. Kuethe and C-Y. Chow, Foundations of Aerodynamics: Bases of Aerodynamic Design, 5th ed., John Wiley \& Sons, New York, 1997.

34. M. A. S. Masoum, H. Dehbonei, and E. F. Fuchs, "Theoretical and Experimental Analyses of Photovoltaic Systems with Voltage- and Current-Based Maximum Power-Point Tracking," IEEE Transactions on Energy Conversion, Vol. 17, No. 4, 2002, pp. 514-522.

35. M. G. Wanzeller, R. N. C. Alves, J. V. da Fonseca Neto, and W. A. dos Santos Fonseca, "Current Control Loop for Tracking of Maximum Power Point Supplied for Photovoltaic Array," IEEE Transactions on Instrumentation And Measurement, Vol. 53, No. 4, 2004, pp. 1304-1310.

36. G. M. S. Azevedo, M. C. Cavalcanti, K. C. Oliveira, F. A. S. Neves, and Z. D. Lins, "Comparative Evaluation of Maximum Power Point Tracking Methods for Photovoltaic Systems," ASME Journal of Solar Energy Engineering, Vol. 131, 2009.

37. W. Xiao, W. G. Dunford, and A. Capel, "A Novel Modeling Method for Photovoltaic Cells," 35th Annual IEEE Power Electronics Specialists Conference, Aachen, Germany, 2004, pp. 1950-1956.

38. M. Uzunoglu, O.C. Onar, and M.S. Alam, "Modeling, Control and Simulation of a PV/ FC/UC Based Hybrid Power Generation System for Stand-Alone Applications," Renewable Energy, Vol. 34, Elsevier Ltd., 2009, pp. 509-520.

39. N. Hamrouni and A. Cherif, "Modelling and Control of a Grid Connected Photovoltaic System," International Journal of Electrical and Power Engineering, Vol. 1, No. 3, Medwell Journals, 2007, pp. 307-313.

40. N. Kakimoto, S. Takayama, H. Satoh, and K. Nakamura, "Power Modulation of Photovoltaic Generator for Frequency Control of Power System," IEEE Transactions on Energy Conversion, Vol. 24, No. 4, 2009, pp. 943-949.

41. S. J. Chiang, H.-J. Shieh, and M.-C. Chen, "Modeling and Control of PV Charger System with SEPIC Converter," IEEE Transactions on Industrial Electronics, Vol. 56, No. 11, 2009, pp. 4344-4353.

42. M. Castilla, J. Miret, J. Matas, L. G. de Vicuña, and J. M. Guerrero, "Control Design Guidelines for Single-Phase Grid-Connected Photovoltaic Inverters with Damped Resonant
Harmonic Compensators," IEEE Transactions on Industrial Electronics, Vol. 56, No. 11, 2009, pp. 4492-4501.

\section{Chapter 3}

1. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1997.

2. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N. J., 1996.

3. H. Kajiwara, et al., "LPV Techniques for Control of an Inverted Pendulum," IEEE Control Systems, February 1999, pp. 44-47.

4. R. C. Dorf, Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

5. A. V. Oppenheim, et al., Signals and Systems, Prentice Hall, Englewood Cliffs, N. J., 1996.

6. J. L. Stein, "Modeling and State Estimator Design Issues for Model Based Monitoring Systems," Journal of Dynamic Systems, ASME, June 1993, pp. 318-326.

7. I. Cochin, Analysis and Design of Dynamic Systems, Addison-Wesley, Reading, Mass., 1997.

8. R. C. Dorf, Electrical Engineering Handbook, CRC Press, Boca Raton, Fla., 1993.

9. Y. M. Pulyer, Electromagnetic Devices for Motion Control, Springer-Verlag, New York, 1992.

10. C. M. Close and D. K. Frederick, Modeling and Analysis of Dynamic Systems, 2nd ed., Houghton Mifflin, Boston, 1995.

11. R. C. Durbeck, "Computer Output Printer Technologies," in Electrical Engineering Handbook, R. C. Dorf, ed., CRC Press, Boca Raton, Fla., 1998, pp. 1958-1975.

12. B. Wie, et al., "New Approach to Attitude/ Momentum Control for the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 12, No. 5, 1989, pp. 714-722.

13. H. Ramirez, "Feedback Controlled Landing Maneuvers," IEEE Transactions on Automatic Control, April 1992, pp. 518-523.

14. C.A. Canudas De Wit, Theory of Robot Control, Springer-Verlag, New York, 1996.

15. R. R. Kadiyala, "A Toolbox for Approximate Linearization of Nonlinear Systems," IEEE Control Systems, April 1993, pp. 47-56. 16. B. C. Crandall, Nanotechnology, MIT Press, Cambridge, Mass., 1996.

17. W. Leventon, "Mountain Bike Suspension Allows Easy Adjustment," Design News, July 19, 1993, pp. 75-77.

18. A. Cavallo, et al., Using MATLAB, SIMULINK, and Control System Toolbox, Prentice Hall, Englewood Cliffs, N. J., 1996.

19. G. E. Carlson, Signal and Linear System Analysis, John Wiley \& Sons, New York, 1998.

20. D. Cho, "Magnetic Levitation Systems," IEEE Control Systems, February 1993, pp. $42-48$.

21. W. J. Palm, Modeling, Analysis, Control of Dynamic Systems, 2nd ed., John Wiley \& Sons, New York, 2000.

22. H. Kazerooni, "Human Extenders," Journal of Dynamic Systems, ASME, June 1993, pp. 281-290.

23. C. N. Dorny, Understanding Dynamic Systems, Prentice Hall, Englewood Cliffs, N. J., 1993.

24. C. Chen, Linear System Theory and Design, 3rd ed., Oxford Univ. Press, New York, 1998.

25. M. Kaplan, Modern Spacecraft Dynamics and Control, John Wiley and Sons, New York, 1976.

26. J. Wertz, ed., Spacecraft Attitude Determination and Control, Kluwer Academic Publishers, Dordrecht, The Netherlands, 1978 (reprinted in 1990).

27. W.E. Wiesel, Spaceflight Dynamics, McGrawHill, New York, 1989.

28. B. Wie, K. W. Byun, V. W. Warren, D. Geller, D. Long, and J. Sunkel, "New Approach to Attitude/Momentum Control for the Space Station," AIAA Journal Guidance, Control, and Dynamics, Vol. 12, No. 5, 1989, pp. 714-722.

29. L. R. Bishop, R. H. Bishop, and K. L. Lindsay, "Proposed CMG Momentum Management Scheme for Space Station," AIAA Guidance Navigation and Controls Conference Proceedings, Vol. 2, No. 87-2528, 1987, pp. 1229-1236.

30. H. H. Woo, H. D. Morgan, and E. T. Falangas, "Momentum Management and Attitude
Control Design for a Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 11, No. 1, 1988, pp. 19-25.

31. J. W. Sunkel and L. S. Shieh, "An Optimal Momentum Management Controller for the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 13, No. 4, 1990, pp. 659-668.

32. V.W.Warren, B. Wie, and D. Geller, "PeriodicDisturbance Accommodating Control of the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 13, No. 6, 1990, pp. 984-992.

33. B. Wie, A. Hu, and R. Singh, "Multi-Body Interaction Effects on Space Station Attitude Control and Momentum Management," AIAA Journal of Guidance, Control, and Dynamics, Vol. 13, No. 6, 1990, pp. 993-999.

34. J. W. Sunkel and L. S. Shieh, "Multistage Design of an Optimal Momentum Management Controller for the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 14, No. 3, 1991, pp. 492-502.

35. K. W. Byun, B. Wie, D. Geller, and J. Sunkel, "Robust $\mathrm{H}_{\infty}$ Control Design for the Space Station with Structured Parameter Uncertainty," AIAA Journal of Guidance, Control, and Dynamics, Vol. 14, No. 6, 1991, pp. 1115-1122.

36. E. Elgersma, G. Stein, M. Jackson, and J. Yeichner, "Robust Controllers for Space Station Momentum Management," IEEE Control Systems Magazine, Vol. 12, No. 2, October 1992, pp. 14-22.

37. G. J. Balas, A. K. Packard, and J. T. Harduvel, "Application of $\mu$-Synthesis Technique to Momentum Management and Attitude Control of the Space Station," Proceedings of 1991 AIAA Guidance, Navigation, and Control Conference, New Orleans, La., pp. 565-575.

38. Rhee and J. L. Speyer, "Robust Momentum Management and Attitude Control System for the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 15, No. 2, 1992, pp. 342-351.

39. T. F. Burns and H. Flashner, "Adaptive Control Applied to Momentum Unloading Using the Low Earth Orbital Environment," AIAA Journal of Guidance, Control, and Dynamics, Vol. 15, No. 2, 1992, pp. 325-333.

40. X. M. Zhao, L. S. Shieh, J. W. Sunkel, and Z. Z. Yuan, "Self-Tuning Control of Attitude and Momentum Management for the Space Station," AIAA Journal of Guidance, Control, and Dynamics, Vol. 15, No. 1, 1992, pp. 17-27.

41. G. Parlos and J. W. Sunkel, "Adaptive Attitude Control and Momentum Management for Large-Angle Spacecraft Maneuvers," AIAA Journal of Guidance, Control, and Dynamics, Vol. 15, No. 4, 1992, pp. 1018-1028.

42. R. H. Bishop, S. J. Paynter, and J. W. Sunkel, "Adaptive Control of Space Station with Control Moment Gyros," IEEE Control Systems Magazine, Vol. 12, No. 2, October 1992, pp. 23-28.

43. S. R. Vadali and H. S. Oh, "Space Station Attitude Control and Momentum Management: A Nonlinear Look," AIAA Journal of Guidance, Control, and Dynamics, Vol. 15, No. 3, 1992, pp. 577-586.

44. S. N. Singh and T. C. Bossart, "Feedback Linearization and Nonlinear Ultimate Boundedness Control of the Space Station Using CMG," AIAA Guidance Navigation and Controls Conference Proceedings, Vol. 1, No. 90-3354-CP, 1990, pp. 369-376.

45. S. N. Singh and T. C. Bossart, "Invertibility of Map, Zero Dynamics and Nonlinear Control of Space Station," AIAA Guidance Navigation and Controls Conference Proceedings, Vol.1, No. 91-2663-CP, 1991, pp. 576-584.

46. S. N. Singh and A. Iyer, "Nonlinear Regulation of Space Station: A Geometric Approach," AIAA Journal of Guidance, Control, and Dynamics, Vol. 17, No. 2, 1994, pp. 242-249.

47. J. J. Sheen and R. H. Bishop, "Spacecraft Nonlinear Control," The Journal of Astronautical Sciences, Vol. 42, No. 3, 1994, pp. 361-377.

48. J. Dzielski, E. Bergmann, J. Paradiso, D. Rowell, and D. Wormley, "Approach to Control Moment Gyroscope Steering Using Feedback Linearization," AIAA Journal of
Guidance, Control, and Dynamics, Vol. 14, No. 1, 1991, pp. 96-106.

49. J. J. Sheen and R. H. Bishop, "Adaptive Nonlinear Control of Spacecraft," The Journal of Astronautical Sciences, Vol. 42, No. 4, 1994, pp. 451-472.

50. S. N. Singh and T. C. Bossart, "Exact Feedback Linearization and Control of Space Station Using CMG," IEEE Transactions on Automatic Control, Vol. Ac-38, No. 1, 1993, pp. 184-187.

\section{Chapter 4}

1. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

2. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.

3. C. E. Rohrs, J. L. Melsa, and D. Schultz, Linear Control Systems, McGraw-Hill, New York, 1993.

4. P. E. Sarachik, Principles of Linear Systems, Cambridge Univ. Press, New York, 1997.

5. B. K. Bose, Power Electronics and Variable Frequency Drives, IEEE Press, Piscataway, N. J., 1997.

6. J. C. Nelson, Operational Amplifier Circuits, Butterworth, New York, 1995.

7. Motomatic Speed Control, Electro-Craft Corp., Hopkins, Minn., 1999.

8. M. W. Spong et al., Robot Control Dynamics, Motion Planning and Analysis, IEEE Press, New York, 1993.

9. R. C. Dorf, Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

10. D. J. Bak, "Dancer Arm Feedback Regulates Tension Control," Design News, April 6, 1987, pp. 132-133.

11. "The Smart Projector Demystified," Science Digest, May 1985, p. 76.

12. J. M. Maciejowski, Multivariable Feedback Design, Addison-Wesley, Wokingham, England, 1989.

13. L. Fortuna and G. Muscato, "A Roll Stabilization System for a Monohull Ship," IEEE Transactions on Control Systems Technology, January 1996, pp. 18-28. 14. C. N. Dorny, Understanding Dynamic Systems, Prentice Hall, Englewood Cliffs, N. J., 1993.

15. D. W. Clarke, "Sensor, Actuator, and Loop Validation," IEEE Control Systems, August 1995, pp. 39-45.

16. S. P. Parker, Encyclopedia of Engineering, 2nd ed., McGraw-Hill, New York, 1993.

17. M. S. Markow, "An Automated Laser System for Eye Surgery," IEEE Engineering in Medicine and Biology, December 1989, pp. 24-29.

18. M. Eslami, Theory of Sensitivity in Dynamic Systems, Springer-Verlag, New York, 1994.

19. Y. M. Pulyer, Electromagnetic Devices for Motion Control, Springer-Verlag, New York, 1992.

20. J. R. Layne, "Control for Cargo Ship Steering," IEEE Control Systems, December 1993, pp. 23-33.

21. S. Begley, "Greetings From Mars," Newsweek, July 14, 1997, pp. 23-29.

22. M. Carroll, "Assault on the Red Planet," Popular Science, January 1997, pp. 44-49.

23. The American Medical Association, Home Medical Encyclopedia, vol. 1, Random House, New York, 1989, pp. 104-106.

24. J. B. Slate, L. C. Sheppard, V. C. Rideout, and E. H. Blackstone, "Closed-loop Nitroprusside Infusion: Modeling and Control Theory for Clinical Applications," Proceedings IEEE International Symposium on Circuits and Systems, 1980, pp. 482-488.

25. B. C. McInnis and L. Z. Deng, "Automatic Control of Blood Pressures with Multiple Drug Inputs," Annals of Biomedical Engineering, vol. 13, 1985, pp. 217-225.

26. R. Meier, J. Nieuwland, A. M. Zbinden, and S. S. Hacisalihzade, "Fuzzy Logic Control of Blood Pressure During Anesthesia," IEEE Control Systems, December 1992, pp. 12-17.

27. L. C. Sheppard, "Computer Control of the Infusion of Vasoactive Drugs," Proceedings IEEE International Symposium on Circuits and Systems, 1980, pp. 469-473.

28. S. Lee, "Intelligent Sensing and Control for Advanced Teleoperation," IEEE Control Systems, June 1993, pp. 19-28.
29. L. L. Cone, "Skycam: An Aerial Robotic Camera System," Byte, October 1985, pp. 122-128.

\section{Chapter 5}

1. C. M. Close and D. K. Frederick, Modeling and Analysis of Dynamic Systems, 2nd ed., Houghton Mifflin, Boston, 1993.

2. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.

3. B. K. Bose, Power Electronics and Variable Frequency Drives, IEEE Press, Piscataway, N. J., 1997.

4. P. R. Clement, "A Note on Third-Order Linear Systems," IRE Transactions on Automatic Control, June 1960, p. 151.

5. R. N. Clark, Introduction to Automatic Control Systems, John Wiley \& Sons, New York, 1962, pp. 115-124.

6. D. Graham and R. C. Lathrop, "The Synthesis of Optimum Response: Criteria and Standard Forms, Part 2," Trans. of the AIEE 72, November 1953, pp. 273-288.

7. R. C. Dorf, Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

8. L. E. Ryan, "Control of an Impact Printer Hammer," ASME Journal of Dynamic Systems, March 1990, pp. 69-75.

9. E. J. Davison, "A Method for Simplifying Linear Dynamic Systems," IEEE Transactions on Automatic Control, January 1966, pp. 93-101.

10. R. C. Dorf, Electrical Engineering Handbook, CRC Press, Boca Raton, Fla., 1998.

11. A. G. Ulsoy, "Control of Machining Processes," ASME Journal of Dynamic Systems, June 1993, pp. 301-310.

12. I. Cochin, Analysis and Design of Dynamic Systems, Addison-Wesley, Reading, Mass., 1997.

13. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N.J., 1997.

14. W. J. Book, "Controlled Motion in an Elastic World," Journal of Dynamic Systems, June 1993, pp. 252-260.

15. C. E. Rohrs, J. L. Melsa, and D. Schultz, Linear Control Systems, McGraw-Hill, New York, 1993. 16. S. Lee, "Intelligent Sensing and Control for Advanced Teleoperation," IEEE Control Systems, June 1993, pp. 19-28.

17. Japan-Guide.com, "Shin Kansen," 2015, www. japan-guide.com/e/e2018.html.

18. M. DiChristina, "Telescope Tune-Up," Рориlar Science, September 1999, pp. 66-68.

19. M. Hutton and M. Rabins, "Simplification of Higher-Order Mechanical Systems Using the Routh Approximation," Journal of Dynamic Systems, ASME, December 1975, pp.383-392.

20. E. W. Kamen and B. S. Heck, Fundamentals of Signals and Systems Using MATLAB, Prentice Hall, Upper Saddle River, N. J., 1997.

21. M. DiChristina, "What's Next for Hubble?" Popular Science, March 1998, pp. 56-59.

22. A. Edsinger-Gonzales and J. Weber, "Domo: A Force Sensing Humanoid Robot for Manipulation Research," Proceedings of the IEEE/RSJ International Conference on Humanoid Robotics, 2004.

23. A. Edsinger-Gonzales, "Design of a Compliant and Force Sensing Hand for a Humanoid Robot," Proceedings of the International Conference on Intelligent Manipulation and Grasping, 2004.

24. B. L. Stevens and F. L. Lewis, Aircraft Control and Simulation, 2nd ed., John Wiley \& Sons, New York, 2003.

25. B. Etkin and L. D. Reid, Dynamics of Flight, 3rd ed., John Wiley \& Sons, New York, 1996.

26. G. E. Cooper and R. P. Harper, Jr., "The Use of Pilot Rating in the Evaluation of Aircraft Handling Qualities," NASA TN D-5153, 1969 (see also http://flighttest.navair.navy. $\mathrm{mil} /$ unrestricted/ch.pdf).

27. USAF, "Flying Qualities of Piloted Vehicles," USAF Spec., MIL-F-8785C, 1980.

28. H. Paraci and M. Jamshidi, Design and Implementation of Intelligent Manufacturing Systems, Prentice Hall, Upper Saddle River, N. J., 1997.

\section{Chapter 6}

1. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

2. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.
3. W. J. Palm, Modeling, Analysis and Control, 2nd ed., John Wiley \& Sons, New York, 2000.

4. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N. J., 1997.

5. B. Lendon, "Scientist: Tae Bo Workout Sent Skyscraper Shaking," CNN, 2011, http:// news.blogs.cnn.com/2011/07/19/scientisttae-bo-workout-sent-skyscraper-shaking/.

6. A. Hurwitz, "On the Conditions under which an Equation Has Only Roots with Negative Real Parts," Mathematische Annalen 46, 1895, pp. 273-284. Also in Selected Papers on Mathematical Trends in Control Theory, Dover, New York, 1964, pp. 70-82.

7. E. J. Routh, Dynamics of a System of Rigid Bodies, Macmillan, New York, 1892.

8. G. G. Wang, "Design of Turning Control for a Tracked Vehicle," IEEE Control Systems, April 1990, pp. 122-125.

9. N. Mohan, Power Electronics, John Wiley \& Sons, New York, 1995.

10. World Robotics 2014 Industrial Robots, IFR International Federation of Robotics, Frankfurt, Germany, 2014, http://www.ifr.org/ industrial-robots/statistics/.

11. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.

12. A. N. Michel, "Stability: The Common Thread in the Evolution of Control," IEEE Control Systems, June 1996, pp. 50-60.

13. S. P. Parker, Encyclopedia of Engineering, 2nd ed., McGraw-Hill, New York, 1933.

14. J. Levine, et al., "Control of Magnetic Bearings," IEEE Transactions on Control Systems Technology, September 1996, pp. 524-544.

15. F. S. Ho, "Traffic Flow Modeling and Control," IEEE Control Systems, October 1996, pp. 16-24.

16. D. W. Freeman, "Jump-Jet Airliner," Popular Mechanics, June 1993, pp. 38-40.

17. B. Sweetman, "Venture Star-21st-Century Space Shuttle," Popular Science, October 1996, pp. 43-47.

18. S. Lee, "Intelligent Sensing and Control for Advanced Teleoperation," IEEE Control Systems, June 1993, pp. 19-28. 19. "Uplifting," The Economist, July 10, 1993, p. 79.

20. R. N. Clark, "The Routh-Hurwitz Stability Criterion, Revisited," IEEE Control Systems, June 1992, pp. 119-120.

21. Gregory Mone, "5 Paths to the Walking, Talking, Pie-Baking Humanoid Robot," Popular Science, September 2006.

22. L. Hatvani, "Adaptive Control: Stabilization," Applied Control, edited by Spyros G.Tzafestas, Marcel Decker, New York, 1993, pp. 273-287.

23. H. Kazerooni, "Human Extenders," Journal of Dynamic Systems, ASME, 1993, pp. 281-290.

24. T. Koolen, J. Smith, G. Thomas, et al., "Summary of Team IHMC's Virtual Robotics Challenge Entry," Proceedings of the IEEERAS International Conference on Humanoid Robots, Atlanta, GA, 2013.

\section{Chapter 7}

1. W. R. Evans, "Graphical Analysis of Control Systems," Transactions of the AIEE, 67, 1948, pp. 547-551. Also in G. J. Thaler, ed., Automatic Control, Dowden, Hutchinson, and Ross, Stroudsburg, Pa., 1974, pp. 417-421.

2. W. R. Evans, "Control System Synthesis by Root Locus Method," Transactions of the AIEE, 69, 1950, pp. 1-4. Also in Automatic Control, G. J. Thaler, ed., Dowden, Hutchinson, and Ross, Stroudsburg, Pa., 1974, pp. 423-425.

3. W. R. Evans, Control System Dynamics, McGraw-Hill, New York, 1954.

4. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

5. J. G. Goldberg, Automatic Controls, Allyn and Bacon, Boston, 1965.

6. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

7. H. Ur, "Root Locus Properties and Sensitivity Relations in Control Systems," I.R.E. Trans. on Automatic Control, January 1960, pp. 57-65.

8. T. R. Kurfess and M. L. Nagurka, "Understanding the Root Locus Using Gain Plots," IEEE Control Systems, August 1991, pp. 37-40.
9. T. R. Kurfess and M. L. Nagurka, "Foundations of Classical Control Theory," The Franklin Institute, Vol. 330, No. 2, 1993, pp. 213-227.

10. "Webb Automatic Guided Carts," Jervis B. Webb Company, 2008, http://www.jervisbwebb.com/.

11. D. K. Lindner, Introduction to Signals and Systems, McGraw-Hill, New York, 1999.

12. S. Ashley, "Putting a Suspension through Its Paces," Mechanical Engineering, April 1993, pp. 56-57.

13. B. K. Bose, Modern Power Electronics, IEEE Press, New York, 1992.

14. P. Varaiya, "Smart Cars on Smart Roads," IEEE Transactions on Automatic Control, February 1993, pp. 195-207.

15. S. Bermana, E. Schechtmana, and Y. Edana, "Evaluation of Automatic Guided Vehicle Systems," Robotics and ComputerIntegrated Manufacturing, Vol. 25, No. 3, 2009, pp. 522-528.

16. B. Sweetman, "21st Century SST," Popular Science, April 1998, pp. 56-60.

17. L. V. Merritt, "Tape Transport Head Positioning Servo Using Positive Feedback," Motion, April 1993, pp. 19-22.

18. G. E. Young and K. N. Reid, "Control of Moving Webs," Journal of Dynamic Systems, ASME, June 1993, pp. 309-316.

19. S. P. Parker, Encyclopedia of Engineering, 2nd ed., McGraw-Hill, New York, 1993.

20. A. J. Calise and R. T. Rysdyk, "Nonlinear Adaptive Flight Control Using Neural Networks," IEEE Control Systems, December 1998, pp. 14-23.

21. T. B. Sheridan, Telerobotics, Automation and Control, MIT Press, Cambridge, Mass., 1992.

22. L. W. Couch, Digital and Analog Communication Systems, 5th ed., Macmillan, New York, 1997.

23. D. Hrovat, "Applications of Optimal Control to Automotive Suspension Design," Journal of Dynamic Systems, ASME, June 1993, pp. 328-342.

24. T. J. Lueck, "Amtrak Unveils Its Bullet to Boston," New York Times, March 10, 1999. 25. M. van de Panne, "A Controller for the Dynamic Walk of a Biped," Proceedings of the Conference on Decision and Control, IEEE, December 1992, pp. 2668-2673.

26. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.

27. S. Begley, "Mission to Mars," Newsweek, September 23, 1996, pp. 52-58.

28. W. J. Cook, "The International Space Station Takes Shape," US News and World Report, December 7, 1998, pp. 56-59.

29. "Batwings and Dragonfies," The Economist, July 2002, pp. 66-67.

30. "Global Automotive Electronics with Special Focus on OEMs Market," Business Wire, May 2013, http://www.researchandmarkets. com/research/j7t7g5/global_automotive.

31. F. Y. Wang, D. Zeng, and L. Yang, "Smart Cars on Smart Roads: An IEEE Intelligent Transportation Systems Society Update," Pervasive Computing, IEEE Computer Society, Vol. 5, No. 4, 2006, pp. 68-69.

32. M. B. Barron and W. F. Powers, "The Role of Electronic Controls for Future Automotive Mechatronic Systems," IEEE/ASME Transactions on Mechatronics, Vol. 1, No. 1, 1996, pp. 80-88.

33. Wind Energy-The Facts, European Wind Energy Association, 2009, http://windfacts.eu/.

34. P. D. Sclavounos, E. N. Wayman, S. Butterfield, J. Jonkman, and W. Musial, "Floating Wind Turbine Concepts," European Wind Energy Association Conference (EWAC), Athens, Greece, 2006.

35. I. Munteanu, A. I. Bratcu, N. A. Cutululis, and E. Ceanga, Optimal Control of Wind Energy Systems, Springer-Verlag, London, 2008.

36. F. G. Martin, The Art of Robotics, Prentice Hall, Upper Saddle River, N. J., 1999.

\section{Chapter 8}

1. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

2. I. Cochin and H. J. Plass, Analysis and Design of Dynamic Systems, John Wiley \& Sons, New York, 1997.

3. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.
4. H. W. Bode, "Relations Between Attenuation and Phase in Feedback Amplifier Design," Bell System Tech. J., July 1940, pp. 421-454. Also in Automatic Control: Classical Linear Theory, G. J. Thaler, ed., Dowden, Hutchinson, and Ross, Stroudsburg, Pa., 1974, pp. 145-178.

5. M. D. Fagen, A History of Engineering and Science in the Bell System, Bell Telephone Laboratories, Murray Hill, N.J., 1978, Chapter 3.

6. D. K. Lindner, Introduction to Signals and Systems, McGraw-Hill, New York., 1999.

7. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.

8. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

9. T. B. Sheridan, Telerobotics, Automation and Control, MIT Press, Cambridge, Mass., 1992.

10. J. L. Jones and A. M. Flynn, Mobile Robots, A. K. Peters Publishing, New York, 1993.

11. D. McLean, Automatic Flight Control Systems, Prentice Hall, Englewood Cliffs, N. J., 1990.

12. G. Leitman, "Aircraft Control Under Conditions of Windshear," Proceedings of IEEE Conference on Decision and Control, December 1990, pp. 747-749.

13. S. Lee, "Intelligent Sensing and Control for Advanced Teleoperation," IEEE Control Systems, June 1993, pp. 19-28.

14. R. A. Hess, "A Control Theoretic Model of Driver Steering Behavior," IEEE Control Systems, August 1990, pp. 3-8.

15. J. Winters, "Personal Trains," Discover, July 1999, pp. 32-33.

16. J. Ackermann and W. Sienel, "Robust Yaw Damping of Cars with Front and Rear Wheel Steering," IEEE Transactions on Control Systems Technology, March 1993, pp. 15-20.

17. L. V. Merritt, "Differential Drive Film Transport," Motion, June 1993, pp. 12-21.

18. S. Ashley, "Putting a Suspension through Its Paces," Mechanical Engineering, April 1993, pp. 56-57.

19. D. A. Linkens, "Anaesthesia Simulators," Computing and Control Engineering Journal, IEEE, April 1993, pp. 55-62. 20. J. R. Layne, "Control for Cargo Ship Steering," IEEE Control Systems, December 1993, pp. 58-64.

21. A. Titli, "Three Control Approaches for the Design of Car Semi-active Suspension," IEEE Proceedings of Conference on Decision and Control, December 1993, pp. 2962-2963.

22. H. H. Ottesen, "Future Servo Technologies for Hard Disk Drives," Journal of the Magnetics Society of Japan, Vol. 18, 1994, pp. 31-36.

23. D. Leonard, "Ambler Ramblin," Ad Astra,Vol. 2, No. 7, July-August 1990, pp. 7-9.

24. M. G. Wanzeller, R. N. C. Alves, J. V. da Fonseca Neto, and W. A. dos Santos Fonseca, "Current Control Loop for Tracking of Maximum Power Point Supplied for Photovoltaic Array," IEEE Transactions on Instrumentation And Measurement, Vol. 53, No. 4, 2004, pp. 1304-1310.

\section{Chapter 9}

1. H. Nyquist, "Regeneration Theory," Bell Systems Tech. J., January 1932, pp. 126-147. Also in Automatic Control: Classical Linear Theory, G. J. Thaler, ed., Dowden, Hutchinson, and Ross, Stroudsburg, Pa., 1932, pp. 105-126.

2. M. D. Fagen, A History of Engineering and Science in the Bell System, Bell Telephone Laboratories, Inc., Murray Hill, N. J., 1978, Chapter 5.

3. H. M. James, N. B. Nichols, and R. S. Phillips, Theory of Servomechanisms, McGraw-Hill, New York, 1947.

4. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N. J., 1996.

5. D. A. Linkens, CAD for Control Systems, Marcel Dekker, New York, 1993.

6. A. Cavallo, Using MATLAB, SIMULINK, and Control System Toolbox, Prentice Hall, Englewood Cliffs, N. J., 1996.

7. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

8. D. Sbarbaro-Hofer, "Control of a Steel Rolling Mill," IEEE Control Systems, June 1993, pp. 69-75.

9. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.
10. J. J. Gribble, "Systems with Time Delay," IEEE Control Systems, February 1993, pp. 54-55.

11. C. N. Dorny, Understanding Dynamic Systems, Prentice Hall, Englewood Cliffs, N. J., 1993.

12. R. C. Dorf, Electric Circuits, 3rd ed., John Wiley \& Sons, New York, 1996.

13. J. Yan and S. E. Salcudean, "Teleoperation Controller Design," IEEE Transactions on Control Systems Technology, May 1996, pp. 244-247.

14. K. K. Chew, "Control of Errors in Disk Drive Systems," IEEE Control Systems, January 1990, pp. 16-19.

15. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

16. D. W. Freeman, "Jump-Jet Airliner," Popular Mechanics, June 1993, pp. 38-40.

17. F. D. Norvelle, Electrohydraulic Control Systems, Prentice Hall, Upper Saddle River, N. J., 2000.

18. B. K. Bose, Power Electronics and Variable Frequency Drives, IEEE Press, Piscataway, N. J., 1997.

19. C. S. Bonaventura and K. W. Lilly, "A Constrained Motion Algorithm for the Shuttle Remote Manipulator System," IEEE Control Systems, October 1995, pp. 6-16.

20. A. T. Bahill and L. Stark, "The Trajectories of Saccadic Eye Movements," Scientific American, January 1979, pp. 108-117.

21. A. G. Ulsoy, "Control of Machining Processes," ASME, Journal of Dynamic Systems, June 1993, pp. 301-310.

22. C. E. Rohrs, J. L. Melsa, and D. Schultz, Linear Control Systems, McGraw-Hill, New York, 1993.

23. J. L. Jones and A. M. Flynn, Mobile Robots, A. K. Peters Publishing, New York, 1993.

24. D. A. Linkens, "Adaptive and Intelligent Control in Anesthesia," IEEE Control Systems, December 1992, pp. 6-10.

25. R. H. Bishop, "Adaptive Control of Space Station with Control Moment Gyros," IEEE Control Systems, October 1992, pp. 23-27.

26. J. B. Song, "Application of Adaptive Control to Arc Welding Processes," Proceedings of the American Control Conference, IEEE, June 1993, pp. 1751-1755. 27. X. G. Wang, "Estimation in Paper Machine Control," IEEE Control Systems, August 1993, pp. 34-43.

28. R. Patton, "Mag Lift," Scientific American, October 1993, pp. 108-109.

29. P. Ferreira, "Concerning the Nyquist Plots of Rational Functions of Nonzero Type," IEEE Transaction on Education, Vol. 42, No. 3, 1999, pp. 228-229.

30. J. Pretolve, "Stereo Vision," Industrial Robot, Vol. 21, No. 2, 1994, pp. 24-31.

31. M. W. Spong and M. Vidyasagar, Robot Dynamics and Control, John Wiley \& Sons, New York, 1989.

32. L. Y. Pao and K. E. Johnson, "A Tutorial on the Dynamics and Control of Wind Turbines and Wind Farms," Proceedings of the American Control Conference, St. Louis, MO, 2009, pp. 2076-2089.

33. G. K. Klute, U. Tsach, and D. Geselowitz, "An Optimal Controller for an Electric Ventricular Assist Device: Theory, Implementation, and Testing," IEEE Transactions of Biomedical Engineering, Vol. 39, No. 4, 1992, pp. 394-403.

\section{Chapter 10}

1. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

2. Z. Gajic and M. Lelic, Modern Control System Engineering, Prentice Hall, Englewood Cliffs, N. J., 1996.

3. K. S. Yeung, et al., "A Non-trial and Error Method for Lag-Lead Compensator Design," IEEE Transactions on Education, February 1998, pp. 76-80.

4. W. R. Wakeland, "Bode Compensator Design," IEEE Transactions on Automatic Control, October 1976, pp. 771-773.

5. J. R. Mitchell, "Comments on Bode Compensator Design," IEEE Transactions on Automatic Control, October 1977, pp. 869-870.

6. S. T. Van Voorhis, "Digital Control of Measurement Graphics," Hewlett-Packard Journal, January 1986, pp. 24-26.
7. R. H. Bishop, "Adaptive Control of Space Station with Control Moment Gyros," IEEE Control Systems, October 1992, pp. 23-27.

8. C. L. Phillips, "Analytical Bode Design of Controllers," IEEE Transactions on Education, February 1985, pp. 43-44.

9. R. C. Garcia and B. S. Heck, "Enhancing Classical Controls Education via Interactive Design," IEEE Control Systems, June 1999, pp. 77-82.

10. J. D. Powell, N. P. Fekete, and C-F. Chang, "Observer-Based Air-Fuel Ratio Control," IEEE Control Systems, October 1998, p. 72.

11. T. B. Sheridan, Telerobotics, Automation and Control, MIT Press, Cambridge, Mass., 1992.

12. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

13. R. L. Wells, "Control of a Flexible Robot Arm,” IEEE Control Systems, January 1990, pp. 9-15.

14. H. Kazerooni, "Human Extenders," Journal of Dynamic Systems, ASME, June 1993, pp. 281-290.

15. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.

16. F. M. Ham, S. Greeley, and B. Henniges, "Active Vibration Suppression for the Mast Flight System," IEEE Control System Magazine, Vol. 9, No. 1, 1989, pp. 85-90.

17. K. Pfeiffer and R. Isermann, "Driver Simulation in Dynamical Engine Test Stands," Proceedings of the American Control Conference, IEEE, 1993, pp. 721-725.

18. A. G. Ulsoy, "Control of Machining Processes," ASME, Journal of Dynamic Systems, June 1993, pp. 301-310.

19. B. K. Bose, Modern Power Electronics, IEEE Press, New York, 1992.

20. F. G. Martin, The Art of Robotics, Prentice Hall, Upper Saddle River, N. J., 1999.

21. J. M. Weiss, "The TGV Comes to Texas," Europe, March 1993, pp. 18-20.

22. H. Kazerooni, "A Controller Design Framework for Telerobotic Systems," IEEE Transactions on Control Systems Technology, March 1993, pp. 50-62. 23. W. H. Zhu, "Industrial Manipulators," IEEE Control Systems, April 1999, pp. 24-28.

24. E. W. Kamen and B. S. Heck, Fundamentals of Signals and Systems Using MATLAB, Prentice Hall, Upper Saddle River, N. J., 1997.

25. C.T. Chen, Analog and Digital Control Systems Design, Oxford Univ. Press, New York, 1996.

26. M. J. Sidi, Spacecraft Dynamics and Control, Cambridge Univ. Press, New York, 1997.

27. A. Arenas, et al., "Angular Velocity Control for a Windmill Radiometer," IEEE Transactions on Education, May 1999, pp. 147-152.

28. M. Berenguel, et al., "Temperature Control of a Solar Furnace," IEEE Control Systems, February 1999, pp. 8-19.

29. A. H. Moore, "The Shipping News: Fast Ferries," Fortune, December 6, 1999, pp. 240-249.

30. M. P. Dinca, M. Gheorghe, and P. Galvin, "Design of a PID Controller for a PCR Micro Reactor," IEEE Transactions on Education, Vol. 52, No. 1, 2009, pp. 117-124.

\section{Chapter 11}

1. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

2. G. Goodwin, S. Graebe, and M. Salgado, Control System Design, Prentice Hall, Saddle River, N.J., 2001.

3. A. E. Bryson, "Optimal Control," IEEE Control Systems, June 1996, pp. 26-33.

4. J. Farrell, "Using Learning Techniques to Accommodate Unanticipated Faults," IEEE Control Systems, June 1993, pp. 40-48.

5. M. Jamshidi, Design of Intelligent Manufacturing Systems, Prentice Hall, Upper Saddle River, N. J., 1998.

6. M. Bodson, "High Performance Control of a Permanent Magnet Stepper Motor," IEEE Transactions on Control Systems Technology, March 1993, pp. 5-14.

7. G.W.Van der Linden, "Control of an Inverted Pendulum," IEEE Control Systems, August 1993, pp. 44-50.

8. W. J. Book, "Controlled Motion in an Elastic World," Journal of Dynamic Systems, June 1993, pp. 252-260.
9. E. W. Kamen, Introduction to Industrial Control, Academic Press, San Diego, 1999.

10. M. Jamshidi, Large-Scale Systems, Prentice Hall, Upper Saddle River, N. J., 1997.

11. W. J. Rugh, Linear System Theory, 2nd ed., Prentice Hall, Englewood Cliffs, N. J., 1996.

12. J. B. Burl, Linear Optimal Control, Prentice Hall, Upper Saddle River, N. J., 1999.

13. D. Hrovat, "Applications of Optimal Control to Automotive Suspension Design," Journal of Dynamic Systems, ASME, June 1993, pp. 328-342.

14. R. H. Bishop, "Adaptive Control of Space Station with Control Moment Gyros," IEEE Control Systems, October 1992, pp. 23-27.

15. R. C. Dorf, Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

16. T. B. Sheridan, Telerobotics, Automation and Control, MIT Press, Cambridge, Mass., 1992.

17. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.

18. C. T. Chen, Linear System Theory and Design, 3rd ed., Oxford University Press, New York, 1999.

19. F. L. Chernousko, State Estimation for Dynamic Systems, CRC Press, Boca Raton, Fla., 1993.

20. M. A. Gottschalk, "Dino-Adventure Duels Jurassic Park," Design News, August 16, 1993, pp. 52-58.

21. Y. Z. Tsypkin, "Robust Internal Model Control," Journal of Dynamic Systems, ASME, June 1993, pp. 419-425.

22. J. D. Irwin, The Industrial Electronics Handbook, CRC Press, Boca Raton, Fla., 1997.

23. J. K. Pieper, "Control of a Coupled-Drive Apparatus," IEE Proceedings, March 1993, pp. 70-79.

24. Rama K. Yedavalli, "Robust Control Design for Aerospace Applications," IEEE Transactions of Aerospace and Electronic Systems, Vol. 25, No. 3, 1989, pp. 314-324.

25. Bryan L. Jones and Robert H. Bishop, " $\mathrm{H}_{2}$ Optimal Halo Orbit Guidance," Journal of Guidance, Control, and Dynamics, AIAA, Vol. 16, No. 6, 1993, pp. 1118-1124. 26. D. G. Luenberger, "Observing the State of a Linear System," IEEE Transactions on Military Electronics, 1964, pp. 74-80.

27. G. F. Franklin, J. D. Powell, and A. EmamiNaeini, Feedback Control of Dynamic Systems, 4th ed., Prentice Hall, Upper Saddle River, N. J., 2002.

28. R. E. Kalman, "Mathematical Description of Linear Dynamical Systems," SIAM J. Control, Vol. 1, 1963, pp. 152-192.

29. R. E. Kalman, "A New Approach to Linear Filtering and Prediction Problems," Journal of Basic Engineering, 1960, pp. 35-45.

30. R. E. Kalman and R. S. Bucy, "New Results in Linear Filtering and Prediction Theory," Transactions of the American Society of Mechanical Engineering, Series D, Journal of Basic Engineering, 1961, pp. 95-108.

31. B. Cipra, "Engineers Look to Kalman Filtering for Guidance," SIAM News, Vol. 26, No. 5, August 1993.

32. R. H. Battin, "Theodore von Karman Lecture: Some Funny Things Happened on the Way to the Moon," 27th Aerospace Sciences Meeting, Reno, Nevada, AIAA-89-0861, 1989.

33. R. G. Brown and P. Y. C. Hwang, Introduction to Random Signal Analysis and Kalman Filtering with Matlab Exercises and Solutions, John Wiley and Sons, Inc., 1996.

34. M. S. Grewal, and A. P. Andrews, Kalman Filtering: Theory and Practice Using MAT$L A B, 2$ nd ed., Wiley-Interscience, 2001.

\section{Chapter 12}

1. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

2. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

3. R. S. Sanchez-Pena and M. Sznaier, Robust Systems Theory and Applications, John Wiley \& Sons, New York, 1998.

4. G. Zames, "Input-Output Feedback Stability and Robustness," IEEE Control Systems, June 1996, pp. 61-66.

5. K. Zhou and J. C. Doyle, Essentials of Robust Control, Prentice Hall, Upper Saddle River, N. J., 1998.
6. C. M. Close and D. K. Frederick, Modeling and Analysis of Dynamic Systems, 2nd ed., Houghton Mifflin, Boston, 1993.

7. A. Charara, "Nonlinear Control of a Magnetic Levitation System," IEEE Transactions on Control System Technology, September 1996, pp. 513-523.

8. J. Yen, Fuzzy Logic: Intelligence and Control, Prentice Hall, Upper Saddle River, N. J., 1998.

9. X. G. Wang, "Estimation in Paper Machine Control," IEEE Control Systems, August 1993, pp. 34-43.

10. D. Sbarbaro-Hofer, "Control of a Steel Rolling Mill," IEEE Control Systems, June 1993, pp. 69-75.

11. N. Mohan, Power Electronics, John Wiley \& Sons, New York, 1995.

12. J. M. Weiss, "The TGV Comes to Texas," Europe, March 1993, pp. 18-20.

13. S. Lee, "Intelligent Sensing and Control for Advanced Teleoperation," IEEE Control Systems, June 1993, pp. 19-28.

14. J. V. Wait and L. P. Huelsman, Operational Amplifier Theory, 2nd ed., McGraw-Hill, New York, 1992.

15. F. G. Martin, The Art of Robotics, Prentice Hall, Upper Saddle River, N. J., 1999.

16. R. Shoureshi, "Intelligent Control Systems," Journal of Dynamic Systems, June 1993, pp. 392-400.

17. A. Butar and R. Sales, "Control for MagLev Vehicles," IEEE Control Systems, August 1998, pp. 18-25.

18. H. Paraci and M. Jamshidi, Design and Implementation of Intelligent Manufacturing Systems, Prentice Hall, Upper Saddle River, N.J., 1997.

19. B. Johnstone, "Japan's Friendly Robots," Technology Review, June 1999, pp. 66-69.

20. W. J. Grantham and T. L. Vincent, Modern Control Systems Analysis and Design, John Wiley \& Sons, New York, 1993.

21. K. Capek, Rossum's Universal Robots, English edition by P. Selver and N. Playfair, Doubleday, Page, New York, 1923.

22. H. Kazerooni, "Human Extenders," Journal of Dynamic Systems, ASME, June 1993, pp. 281-290. 23. C. Lapiska, "Flight Simulation," Aerospace America, August 1993, pp. 14-17.

24. D. E. Bossert, "A Root-Locus Analysis of Quantitative Feedback Theory," Proceedings of the American Control Conference, June 1993, pp. 1698-1705.

25. J. A. Gutierrez and M. Rabins, "A Computer Loop-shaping Algorithm for Controllers," Proceedings of the American Control Conference, June 1993, pp. 1711-1715.

26. J. W. Song, "Synthesis of Compensators in Linear Uncertain Plants," Proceedings of the Conference on Decision and Control, December 1992, pp. 2882-2883.

27. M. Gottschalk, "Part Surgeon-Part Robot," Design News, June 7,1993, pp. 68-75.

28. S. Jayasuriya, "Frequency Domain Design for Robust Performance Under Uncertainties," Journal of Dynamic Systems, June 1993, pp. 439-450.

29. L. S. Shieh, "Control of Uncertain Systems," IEE Proceedings, March 1993, pp. 99-110.

30. M. van de Panne, "A Controller for the Dynamic Walk of a Biped," Proceedings of the Conference on Decision and Control, IEEE, December 1992, pp. 2668-2673.

31. S. Bennett, "The Development of the PID Controller," IEEE Control Systems, December 1993, pp. 58-64.

32. J. C. Doyle, A. B. Francis, and A. R. Tannenbaum, Feedback Control Theory, Macmillan, New York, 1992.

\section{Chapter 13}

1. R. C. Dorf, The Encyclopedia of Robotics, John Wiley \& Sons, New York, 1988.

2. C. L. Phillips and H. T. Nagle, Digital Control Systems, Prentice Hall, Englewood Cliffs, N. J., 1995.

3. G. F. Franklin, et al., Digital Control of Dynamic Systems, 2nd ed., Prentice Hall, Upper Saddle River, N.J., 1998.

4. S. H. Zak, "Ripple-Free Deadbeat Control," IEEE Control Systems, August 1993, pp. 51-56.

5. C. Lapiska, "Flight Simulation," Aerospace America, August 1993, pp. 14-17.
6. F. G. Martin, The Art of Robotics, Prentice Hall, Upper Saddle River, N. J., 1999.

7. D. Raviv and E.W. Djaja, "Discretized Controllers," IEEE Control Systems, June 1999, pp. 52-58.

8. R. C. Dorf, Electrical Engineering Handbook, 2nd ed., CRC Press, Boca Raton, Fla., 1998.

9. T. M. Foley, "Engineering the Space Station," Aerospace America, October 1996, pp. 26-32.

10. A. G. Ulsoy, "Control of Machining Processes," ASME, Journal of Dynamic Systems, June 1993, pp. 301-310.

11. K. J. Astrom, Computer-Controlled Systems, Prentice Hall, Upper Saddle River, N.J., 1997.

12. R. C. Dorf and A. Kusiak, Handbook of Manufacturing and Automation, John Wiley \& Sons, New York, 1994.

13. L. W. Couch, Digital and Analog Communication Systems, 5th ed., Macmillan, New York, 1995.

14. K. S. Yeung and H. M. Lai, "A Reformation of the Nyquist Criterion for Discrete Systems," IEEE Transactions on Education, February 1988, pp. 32-34.

15. T. R. Kurfess, "Predictive Control of a Robotic Grinding System," Journal of Engineering for Industry, ASME, November 1992, pp. 412-420.

16. D. M. Auslander, Mechatronics, Prentice Hall, Englewood Cliffs, N. J., 1996.

17. R. Shoureshi, "Intelligent Control Systems," Journal of Dynamic Systems, June 1993, pp. 392-400.

18. D. J. Leo, "Control of a Flexible Frame in Slewing," Proceedings of American Control Conference, 1992, pp. 2535-2540.

19. V. Skormin, "On-Line Diagnostics of a SelfContained Flight Actuator," IEEE Transactions on Aerospace and Electronic Systems, January 1994, pp. 130-141.

20. H. H. Ottesen, "Future Servo Technologies for Hard Disk Drives," J. of the Magnetics Society of Japan, Vol. 18, 1994, pp. 31-36. A

Absolute stability, 395, 445

Acceleration error constant, 339, 393

Acceleration input, steady-state error, 339

Accelerometer, 107

Ackermann's formula, 812, 823-824, 828, 833-834, $859-860,870$

Across-variable, 81,83

Active noise control system, 76

Actuator, 30, 100, 182

Additive perturbation, 888, 944

Advanced driver-assistance (ADAS) systems, 73

Agricultural systems, 45

AGV. See Automated guided vehicle (AGV)

Aircraft, 49

unmanned, 44-45

Aircraft attitude control, 355-356

Airplane control, 309

All-pass network, 565-566, 620

Alternative signal-flow graph, and block diagram models, 205-208

Ambler, 577

Amplidyne, 166

Amplifier, feedback, 263-264

Amplitude decay, 480,544

quantization error, 951,996

Analogous variables, 85

Analog-to-digital converter, 946, 948

Analysis of robustness, 888-890

Analytical methods, 758-759

Anesthesia, blood pressure control during, 277-285

Angle of departure, 461-462, 465, 476, 543

Angle of the asymptotes, 454, 457, 543

Antiskid braking systems, 934

Arc welding, 434

Armature-controlled motor, 102, 103, 105, 117,133, 166,178

Artificial hand, 41

Artificial intelligence (AI), 38, 45, 49

Assumptions, 80, 122-123, 182

Asymptote, 454, 543

centroid, 455,543

of root locus, 454
Asymptotic approximation, 556

for a Bode diagram, 556

Automated guided vehicle (AGV), 798-799

Automated vehicles, 39-40

Automatic control, history of, 33-39

Automatic fluid dispenser, 251

Automation, 35, 78

Automobiles

hybrid fuel vehicles, 51,78

steering control system, 39

velocity control, 496-502

Auxiliary polynomial, 403,445

Avemar ferry hydrofoil, 794

Axis shift, 408

B

Backward difference rule, 968, 996

Bandwidth, 571, 620, 650, 727

Bellman, R., 36

Biological control system, 42

Biomedical engineering, 42-43

Black, H. S., 35, 169, 884

Block diagram

models, 107-112, 182, 194-204

alternative signal-flow graph, 205-208

signal-flow graphs, 194-204

transformations, 107-112

Blood pressure control and anesthesia, 277-285

Bode, H. W., 552, 884

Bode plot, 552-553, 591-592, 620, 622

asymptotic approximation, 556

boring machine system, 275-277

Boring machine system, 275-277

Bounded response, 395

Branch, 112

Breakaway point, 457-461

Break frequency, 557, 620

C

CAE. See Computer-aided engineering (CAE)

Camera control, 379

Canonical form, 196, 254

Capek, Karel, 41

Cascade compensators, 729, 731-735, 811 Cauchy's theorem, 623, 626-630, 727

CDP. See Continuous design problem (CDP)

Centroid, asymptote, 455, 543

Characteristic equation, 90, 182, 424

Circles, constant, 650

Closed epidemic system, 410-411

Closed-loop feedback control system, 31, 78

Closed-loop feedback sampled-data system, 955-959

Closed-loop frequency response, 648, 727

Closed-loop system, 258, 320

Closed-loop transfer function, 110, 122, 182, 385,423

Command following, 835, 881

Compensation, 774

using analytical methods, 758-759

using a phase-lag network on the $s$-plane, 750

using a phase-lead network on the Bode diagram, 733-734

using a phase-lead network on the $s$-plane, 731

using integration networks, 788

using state-variable feedback, 812

Compensators, 527, 729, 811, 813

cascade, 731-735, 811

design, full-state feedback and observer, 831

Complementary sensitivity function, 888, 944

in cost of feedback, 274

Complexity of design, 46, 78

Components, 320

in cost of feedback, 274

Computer-aided engineering (CAE), 51

Computer control systems, 945, 946

for electric power plant, 41

Conditionally stable system, 707

Conformal mapping, 625, 727

Congress, 43

Constant $M$ circles, 651

Constant $N$ circles, 651

Continuous design problem (CDP), 75, 178, 252,

313, 387, 441, 535, 615, 720, 804, 875, 936, 993

Contour map, 624-630

Control design software digital control systems using, 977-982

state variable models using, 228-232

system performance using, 364-369

Control engineering, 30, 36-37, 39

Controllability, 813-819

matrix, 814,881

Controllable system, 814,881
Control system, 30, 78, 257

characteristics using m-files, 288

description of, 29-33

design, 47-50

future evolution of, 55-56

historical developments of, 38-39

modern examples, 39-45

Control system engineering, 30

Conv function, 139

Convolution signal, 324

Corner frequency. See Break frequency

Cost of feedback, 274

Coulomb damper, 83

Critical damping, 92, 157, 182

D

Damped oscillation, 94, 182

Dampers, 83

Damping ratio, 92, 182, 325-326, 328

dB. See Decibel (dB)

DC amplifier, 106

DC motor, 100

armature-controlled, 102, 117, 178

field controlled, 102

Deadbeat response, 762-764, 811

Decade, 554, 621

of frequencies, 554

Decibel (dB), 552, 621

Decoupled state variable model, 206

Design, 46-47, 78

Design gap, 46, 78

Design of control system, 729, 811

robot control, 441

in time-domain, 813

using a phase-lag network on the Bode diagram, $753-758$

using a phase-lag network on the $s$-plane, 750

using a phase-lead network on the Bode diagram, 733-734

using a phase-lead network on the $s$-plane, 741

using integration networks, 788

using state-feedback, 812

Design specifications, 322, 393

Detectable, 817,881

Diagonal canonical form, 206, 254

Diesel electric locomotive control, 848-854

Differential equations, $80,97,182$

Differential equations of physical systems, 80-85

Differential operator, 90 Differentiating circuit, 104

Digital audio tape controller, 906-914

Digital computer compensator, 961-964, 996

Digital controllers, implementation of, 968

Digital control system, 945-996 using control design software, 977-982

Digital-to-analog converter, 948

Direct-drive arm, 707

Disk drive read system, 62-63, 232-235. See also Sequential design example

Disturbance, 32,78 rejection property, 265-269

signal, 264-269, 320

Disturbance signals in feedback, 264-269

Dominant roots, 330, 393, 466, 543, 572, 587

Drebbel, Cornelis, 33

Drones, 44-45, 75

Dynamics of physical systems, 79

E

Economic systems, 43-44

Electric power industry, 41-42

Electric traction motor, 119, 132-134, 149-150 control, 132-134

Electric ventricular assist device (EVAD), 719-720

Electrohydraulic actuator, 105, 167, 722-723

Electrohydraulic servomechanisms, 708

Embedded control, 53 systems, 53

Energy storage systems (green engineering), 55

Engineering design, 46-47, 78

English channel tunnel boring system, 275-277, 288-291

Engraving machine, 587-589, 590

Environmental monitoring (green engineering), 55

Error

amplitude quantization, 951, 996

estimation, 825,881

integral of absolute magnitude of the, 344

integral of square, 344

steady-state, 272-274, 339

tracking. See Error signal

Error constants

acceleration input, 339

position, 338

ramp, 338

velocity, 338
Error signal, 144, 182, 238, 258, 320

analysis, 259-260

Error-squared performance indices, 837

Error, steady-state, 272-274

Estimation error, 825, 881

EVAD. See Electric ventricular assist device (EVAD)

Evans, R., 447

Examples of control systems, 39-45

Exponential matrix function, 190

Extender, 247-248, 440-441, 800

F

Feedback, 32

amplifier, 263-264

control system, 32, 39, 774-781

cost of, 274

disturbance signals in, 264-269

full-state control design, 819-824

negative, 32,35

positive, 69

of state variables, $837,839,881$

Feedback amplifier, 263-264

Feedback control system, and disturbance signals, 264-269

Feedback function, 144-147, 254

with unity feedback, 144

Feedback signal, 31, 78, 144

Feedback systems, history of, 31

Field current controlled motor, 101

Fifth-order system, 405

Final value, 92,182

of response, 92

theorem, 92, 182

Flow graph. See Signal-flow graph

Fluid flow modeling, 122-132

Flyball governor, 34, 78

Fly-by-wire aircraft control surface, 971-976

Forward rectangular integration, 968, 996

Fourier transform, 548, 621

pair, 547-548, 621

Frequency response, 546, 621

closed-loop, 648

measurements, 569-571

plots, $548-569$

using control design software, 584-589

Full-state feedback control law, 813, 881

Fundamental matrix. See Transition matrix

Future evolution of control systems, 55-56 G

Gain margin, 642, 678-679, 686, 727

Gamma-Ray Imaging Device (GRID), 943

Gear train, 106

Generative design process, 49

Global navigation satellite services, 37

Global Positioning System (GPS), 36

GPS. See Global Positioning System (GPS)

Graphical evaluation of residues, 91

Gravity gradient torque, 216

Green engineering, 54-55

applications of, 54-55

principles of, 54

GRID. See Gamma-Ray Imaging Device (GRID)

Gun controllers, 36

Gyroscope, 247

\section{H}

Halo orbit, 879-880

Hand, robotic, 41

Helicopter control, 522, 530

High-fidelity simulations, 129

History of automatic control, 33-39

Home appliances, 53

Homogeneity, 85-86, 183

Hot ingot robot control, 667-676

Hot ingot robot mechanism, 667

Hubble telescope, 352-354

Human-in-the-loop control, 40

Hybrid fuel automobile, 51, 78

Hybrid fuel vehicles, 51-52

Hydraulic actuator, 105, 167, 866

\section{I}

IAE, 344

Impulse signal, 323

Index of performance, 344-349, 393

Industrial control systems, 45

Input feedforward canonical form, 201-202, 254

Input signals, 322-324

Instability, 320

in cost of feedback, 274

Insulin

delivery control system, 57, 60-61

injections, 377-378

Integral of absolute magnitude of the error, 344

Integral of square of error, 344

Integral of time multiplied by absolute error, 344

multiplied by error squared, 344

optimum coefficient of $T(s), 347-348$

Integral operator, 90

Integrating filter, 104

Integration networks, $734,788,811$

Integration-type compensator, 747

Intelligent vehicle/highway systems (IVHS), 497

Internal model design, 837, 845-848, 881

Internal model principle, 847, 900, 944

Internal Revenue Service, 43

The International Data Corporation, 37

Internet of Things (IoT), 37

Inverse Laplace transform, 88, 90, 92-93, 183

Inverted pendulum, 207-208, 822-824, 831-834, 873,874

IoT. See Internet of Things (IoT)

ISE, 344

ITAE, 344, 347-348

ITSE, 344

IVHS. See Intelligent vehicle/highway systems (IVHS)

J

Jordan canonical form, 206, 254

K

Kalman state-space decomposition, 814, 817, 881

Kirchhoff voltage laws, 187

$\mathbf{L}$

Laboratory robot, 45

Lag compensator, 734

Lag network. See Phase-lag network

Laplace transform, 80, 88-95, 183, 185, 324

Laplace transform pair, 89, 547-548, 621

Lead compensator, 734 for second-order system, 738-741

for type-one system, 745-747

for type-two system, 736-738

using root locus, $742-745$

Lead-lag network, 757-758, 811

Lead network. See Phase-lead network

LEM. See Lunar excursion module (LEM)

Linear approximation, 87,183

Linear approximations of physical systems, 85-88

Linearized, 80, 183

Linear quadratic regulator, parameters, 845,881 Linear system, 85-86, 183 simplification of, 349-352, 367-368 transfer function of, 95-107

Liquid level control system, 683

Locus, 447, 543

Logarithmic magnitude, 558, 574, 621

Logarithmic (decibel) measure, 643, 727

Logarithmic plot. See Bode plot

Logarithmic sensitivity, 472, 543-544

Log-magnitude-phase diagram, 644

Loop, 113 gain, 259 on signal-flow graph, 113

Loss of gain, 320 in cost of feedback, 274

Low fidelity simulations, 129

Low-pass filter, 119, 134-136

lsim function, 231, 232

Lunar excursion module (LEM), 792

M

Machine, human versus automatic, 42

Magnetic levitation, 169, 875

Magnetic tape transport, 524

Manual control system, 41

Manual PID tuning, 479, 544

MAP. See Mean arterial pressure (MAP)

Mapping of contours in the $s$-plane, 624-630

Marginally stable, 397, 445

margin function, 678, 809

Margin, gain, 642, 678-679, 686, 727

phase, 647, 678-679, 686, 727, 963-964

Mars rover vehicle, 441-442, 536

Mason, 112

Mason loop rule, 158, 183

Mason's signal-flow gain formula, 112, 114, 117, 153, $167,196,198,210-212,224,235$

Mathematical models, 79-80, 183 of systems, 79

MATLAB Bode plot, 585 control system characteristics, 285 simulation of systems, 136-150 state variables and, 228-232 system performance and, 364-369

Matrix exponential function, 190, 255

Maximum overshoot, 328

Maximum power point tracking (MPPT), 119
Maximum value of the frequency response, 559, 571,621

Maxwell, J. C., 34, 38

$M$ circles, 651

Mean arterial pressure (MAP), 281, 284

Measurement noise, 32, 78 attenuation, 267-269

Mechatronics, 50-53, 78

MEMS. See Microelectromechanical systems (MEMS)

Metallurgical industry, 45

Microcomputer, 946, 996

Microelectromechanical systems (MEMS), 51

Milling machine control system, 768-774

Minimum phase transfer function, 564, 621

Minorsky, N., 159

minreal function, 148-149

Mobile robot, 339-342

Model of, DC motor, 100 hydraulic actuator, 105, 164, 866

inverted pendulum and cart, 207-208, 822-824, 831-834, 873, 874

MPPT. See Maximum power point tracking (MPPT)

Multiloop feedback control system, 32, 78

Multiloop reduction, 147-148

Multiple-loop feedback system, 111

Multiplicative perturbation, 888, 944

Multivariable control system, 32-33, 78

$\mathbf{N}$

Natural frequency, 92, 183, 589, 621

$N$ circles, 651

Necessary condition, 85,183

Negative feedback, 32, 78, 431

Negative gain root locus, 488-493, 544

ngrid function, 678, 681

Nichols chart, 651-654, 678, 681-682, 687, 727, 914

nichols function, 678,679

Nodes, 113

of signal flow graph, 113

Noise, 259, 264-265, 267-269, 274, 279, 280, 296, 312-313

Nomenclature, 83

Nonminimum phase transfer functions, 562, $565-566,621$

Nontouching, 113

loops, 113-114

Nonunity feedback systems, 342-343 Nuclear reactor controls, 68-69, 793

Number of separate loci, 454,544

Numerical experiments, 129

Nyquist, H., 623

contour, 632

criterion, 630-641, 655, 686

function, 678-679

stability criterion, 622, 623, 630-641, 655, 688, 727

0

Observability, 813-819

matrix, 817, 881

Observable system, 817,881

Observer, 813, 881

design, 825-828

Octave, 555, 621

of frequencies, 555,572

Op-amp circuit, transfer function of, 97-98

Open-loop control system, 31, 78

Open-loop system, 261-263, 320

Operational amplifier, 783, 784, 921

Operators, differential and integral, 90

Optimal control system, 393, 837-845, 881

Optimization, 47, 78

Optimize parameters, 47

Optimum coefficient of for ITAE, 347-349

Optimum control system, 344

Output equation, 189, 255

Overdamped, 137, 183

Overshoot, 278-279, 288-289

\section{$\mathbf{P}$}

Padé approximation of a time delay, 657-659, 678 pade function, 678, 683, 942, 979

Papin, Dennis, 33

Parabolic input signal, 323

parallel function, 144

Parameter design, 467, 544

Parameter variations and system sensitivity, 261-264

Parkinson, D. B., 36

Path, 113

PD controller. See Proportional plus derivative (PD) controller

Peak time, 326, 393

Pendulum oscillator, 87-88

Percent overshoot, 327,393

Performance

of control system, 321 index, 344-349, 393

of sampled second-order system, 959-961

specifications in the frequency domain, 571-574

Phase-lag compensation, 734, 811

Phase-lag compensator, design of, 752-753, 754-758

Phase-lag network, 734-735, 811

on Bode diagram, 734

on the $s$-plane, 750

Phase-lead compensation, 734, 783, 811

Phase-lead compensator, 732

Phase-lead network, 732, 811

on Bode diagram, 733, 735

on the $s$-plane, 741

Phase-lock loop (detector), 435

Phase margin, 643, 647, 678-679, 686, 727

Phase variable canonical form, 198

Phase variables, 198, 255 canonical form, 198, 255

Photovoltaic generators, 119-122, 575-577

Physical state variables, 186-187

Physical systems differential equations of, $80-85$

dynamics of, 79

linear approximations of, 85-88

Physical variables, 205-206, 255

PI controller. See Proportional plus integral (PI controller)

PID controller, 281, 282, 283, 284, 285, 477-488, 544

design of robust, 896-900, 944

in discrete-time, 977,996

in frequency domain, 677

of wind turbines for clean energy, 660-663

PID tuning, 479, 544

Plant. See Process

Plants, power, 41

Plastic extrusion, 994

Plotting using MATLAB, 136-137

Pneumatica, 33

Polar plot, 549, 621

Poles, 90-91, 183

placement, 817,881

Pole-zero map, 142

Political feedback model, 44

Political systems, 43-44

poly function, $139,424,444,879$

polyval function, 137, 140

Polzunov, I., 34

Pontryagin, L. S., 36 Position error constant, 338, 393

Positive feedback, 69, 78

loop, 111

Potentiometer, 106

Power flow, 58

Power plants, 41

Power quality monitoring (green engineering), 55

Precision, 951, 996

speed control system, 525

Prefilter, 759-762, 811, 899-900, 944

Principle of superposition, 85, 183

Principle of the argument. See Cauchy's theorem

Printer belt drive modeling, 222-228

Process, 31, 78

controller. See PID controller

Productivity, 35, 78

Proportional plus derivative (PD) controller, 477, 544,811

Proportional plus integral (PI controller), 477, 544, $747-748,811$

Prosthetic arm, 43-44

Pseudo-quantitative feedback system, 914-916 pzmap function, 140-141, 181

\section{Q}

QFT. See Quantitative feedback theory (QFT)

Quantitative feedback theory (QFT), 914

Quarter amplitude decay, 480, 544

$\mathbf{R}$

Rack and pinion, 103, 107

Radio-based navigation system, 37

Ramp input, 348 steady-state error, 338-339

test signal equation, 323

Reaction curve, 483

Reduced sensitivity, 261-262

Reference input, 144, 149, 183, 835-837

Regulator problem, 144, 820, 835, 837, 881, 948

Regulatory bodies, 43

Relative stability, 395, 407, 445

by the Nyquist criterion, 641-648

by the Routh-Hurwitz criterion, 407

Remotely controlled vehicle, 664-667, 683-686

Remote manipulators, 797

Residues, 91, 93, 94, 183

Resonant frequency, 559-560, 571-572, 621

Rise time, 326, 393

Risk, 46, 78
Robot, 41, 78

controlled motorcycle, 413-418

control system, 536

mobile, steering control, 365-368

Robot-controlled motorcycle, 413-418

Robust control system, 882-944

using control design software, 916-919

Robust PID control, 896-900

Robust stability criterion, 888-889, 944

Roll-wrapping machine (RWM), 930, 931

Root contours, 471, 544

Root locus, 447-451, 544, 689, 964-967

angle of departure, 461

asymptote, 454

breakaway point, 457

concept, 447-451

of digital control systems, 964-967

plot, obtaining, 503-508

segments on the real axis, $453,455,544$

sensitivity and, 472-477, 508

steps in sketching, 463

using control design software, 502-508

in the $z$-plane, 965-966

Root locus method, 446-466, 544

parameter design, 466-471

Root sensitivity, 472, 544

to parameters, 884,944

Roots function, 139, 142, 420, 424

Rotating disk speed control, 59-60

Rotor winder control system, 765-767, 774-781

Routh-Hurwitz criterion, 399-407, 411, 419, 434-435, 445

Routh-Hurwitz stability, 394

R.U.R. (play), 40-41

RWM. See Roll-wrapping machine (RWM)

S

Sampled data, 948, 996

Sampled-data system, 948-951, 996

Sampling period, 948, 996

Scanning tunneling microscope (STM), 938

Second-order system, 330, 824

performance of, 325-330

response, 330-335

response, effect of third pole and zero, 330-335

Self-healing process, 58

Sensitivity. See also System sensitivity

of control systems to parameter variations, 261-264 of root control systems, 473

root locus and, 472-477, 508

Sensitivity function, 260, 265, 268, 283, 296, 888,944

Sensor, 30

Separation principle, $819,830,881$

Sequential design example, 62-63, 150-153, 232-235, 291-295, 370-372, 425-427, 508510, 589-591, 686-689, 781-782, 860-862, 919-921, 982-984

Series connection, 143-146

series function, 143, 144, 146, 147

Settling time, 327, 393

Ship stabilization, 304

Signal-flow graph, 112-119, 183

block diagram models and, 194-204

models, 112-119

Simplification of linear systems, 349-352

Simplified model, 351-352

Simulation, 129, 183

Smart grid

control systems, 57-59

definition, 54, 57

Smart meters, 57

Social feedback model, 44

Social systems, 43-44

Solar cells, 119

Solar energy (green engineering), 55

Spacecraft, 161, 180, 214-221

Space shuttle, 608, 708-709, 988

Space station, 214-221

Space telescope, 345-349

Specifications, 46, 78

Speed control system, 265-267, 269-271, 285-288, 309, 313, 314

for automobiles, 306

for power generator, 523

s-plane, 90, 183

for steel rolling mill, 265

Spring-mass-damper system, 83, 92, 94-95, 186

Stability, 395, 445

absolute, 395, 445

concept of, 395-399

in frequency domain, 622-727

of linear feedback systems, 394-445

of a sampled-data system, 996

of second-order system, 408-410

of state variable systems, 408-411

for unstable process, 395-397 using Nyquist criterion, 630-631

using Routh-Hurwitz criterion, 399-407, 411, 419

Stabilizable, 817,881

Stabilizing controller, 831, 881

Stable system, 395, 445

State differential equation, 188-194, 255

State equation, transfer function from, 209-210

State-feedback, 812

State of a system, 185-188, 255

State-space representation, 189, 228-232, 255

State transition matrix, 191

time response and, 210-214

State variable models, 184 of dynamic system, 185-188

State variables, 185-188, 255

of dynamic system, 185-188

feedback, 248, 255, 837, 839-842, 881

system design using control design software, $855-860$

State variable systems, 408-411

stability of, 424-425

State vector, 189,255

Steady-state, 92, 183

of response of, 92, 321, 322, 393

Steady-state error, 272-274, 320, 342

of feedback control system, 337-343

Steel rolling mill, 265, 655-656, 723, 724, 931

Steering control system

of automobile, 39, 615

of mobile robot, 339-342

of ship, 711-712

Step input, 337-338

optimum coefficient of $T(s), 347$

steady-state error, 337-338

test signal equation, 323

STM. See Scanning tunneling microscope (STM)

Submarine control system, 243, 245

Superposition, principle of, 85

Symbols, in MATLAB

used in book, 83

Synthesis, 46-47, 78

sys function, 140, 141

System design, approaches to, 730-731

Systems, 30, 78

bandwidth, 655

performance, 364-369

with uncertain parameters, 890-892

System sensitivity, 262, 320

to parameters, 884,944 

\section{T}

Tables, 82

of Laplace transform pairs, 89

through- and across-variables for physical systems, 81

of transfer function plots, 690-697

of transfer functions, 104-107

Tachometer, 106

Taylor series, 86, 183

Temperature control system, 748-750

Test input signal, 322-324, 393

Thermal heating system, 107

Third-order system, 401-403

Through-variable, 80,81

Time constant, 96, 183

Time delay, 655-659, 727

Time domain, 185, 255

design, 813

Time-domain specifications, 364-367

Time response

by a discrete-time evaluation, 210

and state transition matrix, 210-214

and state transition matrix, 210-214

Time-varying system, 95, 255

Tracked vehicle turning control, 411-413, 420-423

Tracking error. See Error signal

Trade-off, 46, 78

Transfer function, 95, 141-143, 183

of complex system, 118-119

of DC motor, 100-107

of dynamic elements and networks, 104-107

in frequency domain, 552, 621

of interacting system, 115-117

of linear systems, 95-107

in m-file script, 141,144

minimum phase and nonminimum phase, 562,564

of multi-loop system, 117-118

of op-amp circuit, 97-98

from the state equation, 209-210

of system, 98-100

table of dynamic elements and networks, 104-107

Transient response, 320, 322, 393

control of, 269-272

relationship to root location, 335-337

of second-order system, 326

Transition matrix, 191, 255

Twin lift, 72

Twin-T network, 562

Two state variable models, 202-204

Type number, 338, 393
$\mathbf{U}$

UAVs. See Unmanned aerial vehicles (UAVs)

Ubiquitous computing, 37,78

Ubiquitous positioning, 37,78

Ultimate gain, 483

Ultimate period, 483

Ultra-precision diamond turning machine, 903-906

Uncertain parameters, 890-892

Underdamped, 85, 92

Unit impulse, 323, 393

Unity feedback, 144-146, 175, 177, 183, 518

Unmanned aerial vehicles (UAVs), 44-45

Unstable system, 395, 397, 403-404

V

Variables

models, two state, 202-204

for physical systems, 81

Vehicle traction control, 993

Velocity error constant, 338, 393

Velocity input, 308

Vertical takeoff and landing (VTOL) aircraft, 437, 707,879

Viscous damper, 83

VTOL aircraft. See Vertical takeoff and landing (VTOL) aircraft

Vyshnegradskii, I. A., 35

W

Water clock, 33

Water level control, 33-34, 70, 125-132, 174-175

Water-level float regulator, 34

Watt, James, 34, 38

Wearable computers, 53

Welding control, 405-407

Wind energy (green engineering), 55

Wind power, 51-53

Wind turbines, 659-663

rotor speed control, 493-496

Worktable motion control,969-971

$\mathbf{Z}$

Zero-order hold, 950, 952, 996

Zeros, 90-91, 183

Zettabytes (ZB), 37

Ziegler-Nichols PID tuning method, 479, 483-487, 544

$z$-plane, 996

root locus, 965-966

z-transform, 951-955, 996 This page is intentionally left blank
