2023年5月25日 下午 3:24|38分钟45秒

关键词:
算法、特征、检测、分类、物体、类别、偏移量、图像、卷积、含义、结构、滑动窗口、搜索算法、位置信息、目标定位、图像区域、输出信息、目标区域

文字记录:
位同学大家好，我们这一小节视频的话是来给大家介绍一下目标检测的一些基础内容，以及 u 裸系列算法它的一个设计理念。我们这一小节视频讲的内容都是比较粗浅的，我们先来对我们图像分类处理流程做一个回顾。我们这里以咱们之前做的这个手写书的识别这个功能为例，我们在这的话会先有一张手写的这个数字图片，然后把它输入到我们的神经网络里面，神经网络最终它会告诉咱们这张图片里面它包含的是哪个数字，可以有一个分类的一个结果，因为数字的话它只有 0 到 9 十个类别，所以说我们最终的话它会告诉我们这边 10 个类别里面，我们这张图片它是属于哪一类？其实是属于一个分类问题，那如果详细一点的话，它这边是输入图片，然后再通过卷积神经网络去提取它对应的一个特征，然后把特征表示出来之后再送到分类器里面。分类器最终的话它会输出我们这个 10 个类别的一个概率，最终去选取对于最大的一个类别去作为它最终的一个结果。如果我们这边有进行训练的话，它还会把这个样本标签还有训练函数这个损失函数加入到里面去。这是我们一个图像分类的一个处理流程。

对于我们的目标检测，大家可以在这边看这张图片，如果说我们这边是对这张图片做一个分类的话，它其实最终的一个结果只要告诉我们这个里面包含了动物，或者说有包含这些斑马就可以了。那如果是目标检测的话，我们最终这个输出它不仅要告诉我们好这个里面包含了有这个斑马，并且你还要告诉我们斑马的这个位置在哪里，也就是它在分类的一个基础上，还加上了目标的一个定位，这就是目标检测它的一个最终的效果。既要有分类的这个过程，分类的一个结果也要有它定位的一个结果。在目标检测算法中的话，主要实现它的算，主要实现的算法可以分为两个部分，一个部分第一部分是完成对图像中目标的定位分析，第二部分是完成是在完成对目标的定位之后，需要对已获得图像的区域进行分类，也就这种目标定位再加上这个分类就可以了。那我们现在来看一下在 Euler 之前的目标检测算法，它是怎么样的。

第一个是滑动窗口算法，它是一个很经典的一个算法，那滑动窗口的算法它是用一个窗口不断地在图像上进行滑动，那这个滑动其实它比较类似于我们的 v 接扫描，它从这边最开始这个窗口慢慢的往右边移，它这边好，大家说的是滑动，我们可以把它理解成这种扫描，然后这个窗口它在扫描结束之前窗口它的大小是固定不变的。

然后一直扫描到我们与右边界重合，右边角重合，之后它又往下边滑动一下，之后下面滑动一下，之后又开始往右，一直到门这个底部与最右边这个窗口，那这个边界出现在边界重合之后，它这一轮滑动它就结束了。当在一轮结束之后，它会改变我们的这个窗口的尺寸，改变我们窗口的尺寸，再重新进行下一轮的这个滑动，那我们这个是它滑动那种方式，然后通过这种方式它会去进行搜索目标，并对每个宽进行提，进行特征提取和分类。因为我们在之前做数字图像识别的时候，我们是已经能够清楚地认识到，我们把一张图片的这个数据送入给神经网络之后，它是能够给咱们一个分类的结果的，是吧？那比如说我现在这个窗口，它是在这个位置的时候，我把这个窗口里面它所包含这个图范这部分的图像区域，它的数据去送给我的神经网络，让它去做一个分类，是吧？那如果说它现在我的神经网络了，它对于这个窗口的这个数据，它识别到它分类有一个斑马，有斑马，那我现在把它对应的这个窗口的位置记录一下，那这样的话是不是就它能够分类的一个功能也做了，然后位置它记录了，它也得到了，是吧？它也得到了，这个就是它的滑动窗口算法。

然后对于我们的，因为它本来可能这边也说了，针对不同大小的物体来，它需要在算法中固定不同的尺，不同尺度和大小的窗口去进行检测。因为我们在这边可能如果说我们讲的这边图片里面它有一些其它的物体，这个物体可能是比你的斑马大，也有可能是比你的斑马小，是吧？那不同大小的物体我们就需要有不同的窗口去带大家做一个搜索。

那这样的话，它其实这个滑动窗口算法虽然我们这个思想还是比较简单，但是它的整的这个过程是很复杂的，它的计算量是很大的，因为它对于不同大小的这个物体，它要不断地去改变咱们的这个窗口，它其实在我们这边其实滑动窗口算法它其实可以说是一种穷举法，它把我们就是说我们这个可以说这个窗滑动窗口这个窗口的大小它可以从它最小，就比如说是一个 1* 1，然后一直到最大就是我们处假设这张图像它是 1000* 1000 的，那我们这个窗口的大小它其实可以从 1* 1 然后一直变到 1000* 1000，然后在进行变化的这么多这个过程里面它的窗口数量是非常非常大的。是吧？这个也就会造成它最终计算的这个量也是会非常大，所以他的思想是很简单，但是它的这个过程就是很复杂，这是它的一个滑动窗口算法，它是这样子做的。

在滑动窗口算法之后，这边又发展了有区域建议算法，还有选择性搜索算法。其实选择性搜索算法它其实是属于咱们区域建议算法里面的一种，然后这个选择性搜索算法的话，它的一个思想是怎么样？它是一个需要去先通过算法产生目标候选宽，也就是目标的位这个位置，然后再对候选宽做分类与回归。因为我们滑动窗口相反，它这边产生的这个窗口的数量非常大，然后它的选择性搜索算法，它相当于是先通过这样一个算法对咱们这张图片去做一个大致的浏览，去做一个代表的浏览，它先简单地判断一下我们的哪些窗口，或者说哪些位置它出现了咱们这样一个物体，它对它选择出来这些窗口，再去做一个分类，再去做一个分类。

其实它本质上的话，这个选择性搜索算法它其实和这个滑窗法它们的这样一个思想都差不多，只是说你的这个选择性搜索算法，它的，最终得到了一个候选宽的数量，要比我们的滑窗法、滑动窗口算法，它的数量更少，能够减少它对应的一些计算。但这个它其实是属于咱们的 tool stage，话就是两阶段的这样一个算法，因为它是分我们的这个选择性搜索算法，它是分为两个部分，先通过算法去选择这个候选宽，然后再去做这个分类。

这是在我们的 Euler 之前，它的一些目标检测算法，那 Euler 的话， Eulo 它是属于我们的 one stage， one stage 就一个绝烂的简单算法，它是这个目标区域，就是目标定位和我们咱们的一个分类，它是通过同一个网络去进行实现的。

我们这边的话就开始去进入到我们 you lo v e 的一个内容，这个是我们 unlo V1 的一个网络结构， unlo V1 这个网络结构它是书的图像大小，这边是一个 448 乘 448 的一个大小，中间它是有很多转基层的，你看转接层，然后有最大值 10 万就是石化层。这边具体中间的这些网络结构网络，嗯，有哪些层，这个大家其实也不用太关心，因为最终这个其实我们不会用这个 ula v e，是吧？我们是用的优乐V3。然后这边的话我主要关注的一个点是在于它的一个输出，这些网络结构，其实如果你之前有点基础的话，这边其实可能这些网络的一些名字，这些结构它具体是怎么去进行计算的，都差不多，主要是用了寓意它的一个特点主要是在于它的一个特征图输出，特征图在输出的这个特征图里面，它是 7* 7* 30 的。

7* 7 是它的一个尺寸，然后 30 的话是它的一个通道数，它的从 4048* 48 这样个图像尺寸，但它这边是个三通道的，三通道表示它是一个r，g， p 有三个颜色通道，图像尺寸大小是 448* 448。然后最终输出是 7* 7，通道数量是30。

我们现在的话来介绍一下哈 U6V 1 它的一个特征图的一个意义，这个对于我们去学习 U6V 3 哈是有一种借鉴的价值的。 ulu v e 它的网络结构并无太多创新之处，其精髓主要在最后 7* 7* 30 大小的特征图中。 ruler V1 将输入图像划分成 7* 7 的区域，每一个区域对应于最后特征图像的一个点，该点的通道数为30，代表了预测的 30 个特征，那么现在的话就来一起理解一下它的这样一个精髓。

在之前的这个滑动窗口算法里面耶，它的窗口是要不停地滑动的，并且还要有不同的尺度和大小的窗口，是吧？在 Gulu V1 里面，对于这个原图 448 乘448，它把它划分成 7* 7 的区域 48/ 76* 4，那就是我们在原图里面分有 7* 7，有总共 49 个小方格子，就是有 49 个区域，那每一个区域它对应的尺寸就是 64* 64 这么多个像素点NP，然后每一个区域它怎么去进行检测？如果一个物流的中心点它落在了某个区域内，是吧？物流的一个中心点，注意它是中心点落在了我们的区域里面，那该区域就负责检测该物体，是吧？反正你不管这么多，它每一个区域都会有检测，是吧？都会有检测结果，那这个检测结果大家注意看我们最后的特征图，它是不是也是 7* 7 的，是吧？那我们在原图里面它划分成了 7* 7 这么多个区域，那检测结果最终也是保存在我们最终输入的特征图里面这个 7* 7 里面，然后每它特征图里面的 7* 7，每一个点它的通道数不是有 30 个，那每一个点它这个里面这个特征里面这个信息里面，它就会包含我们对应的物的一个分类，还有它目标定位的这些信息会包含在里面。

然后我们每一个区域，每个区域它会有两个预测宽，但是我们最终它的输出它是会舍掉一个，就是它的预测结果不是那么好的一个预测宽，看一下它的 30 个预测特征是怎么样的？它是由类别概率、边框置信度和边框的位置组成。类别概率的话它是一共有 20 个， 20 个类别概率，它预测的是边宽属于哪一个类别？这是个分类问题，是吧？分类的一个信息，然后置信度它表示我们这个区域里面它是否包含故事的概率，是否颁含物体，你这边是否包含物体的话，你这边可以理解成它是一个二分类，有个二分类是否包含吗？包含还是不包含？二分类，然后两个边框它就会存在两个置信度。

到边框位置的话，我们因为位置信息，它每一个边框都会有中心坐标、SY、横坐标和纵坐标，然后以及宽和高这四个量，两个边框它就会有 8 个预测值，把总共 30 个信息，它是这样子来的。那么这边哈还有三点哈值得注意的细节，就是 URL V1 里面它并没有先验宽这个东西，先验宽这个我们在后面哈，嗯，会给大家去介绍到，它是直接在每一个区域去预测宽的大小于位置，是吧？每一个区域进行预测宽量大小于位置是一个回归问题。然后一个区域内的两个边框它会共用一个类别预测，因为本来我们按照之前的一个理解，我们应该是它这边有两个预测框，是吧？每个区域都会有两个预测框，那每一个预测框里面是吧？它输出它应该是说我这个预测框 a 里头它会预测一下你这个是属于哪个类，然后 its query b 里面它属于哪个类，应该是分别都会有对应着这个宽的一个类别信息。它是在 user V1 里面，它是，两个预测框，是共用一个类别预测的。然后在训练时，它会选取与物体 IOU 更大的一个宽区进行输出。

OU 是指什么呢？我们这边哈有介绍叫交并比，简称 i o u。交并比就是交集和这个并集它的一个比值，交集和并集的一个比值两个区域一个交集，一个并集，它与物体 i o u 跟了一个宽。我们看这边，那我们看这一块哈，它如果我们要来算预测框 b 和预测框a，他们去与这个物体 l o u 更大的话，那是吧？肯定是我们的预测环a，然后在测试时它会选择概率更高的一个边宽，另一个会被舍弃。在训练的时候我们是选 i o u 更大的，然后在测试的时候我们会选择概率更大的一个边宽，哈定一个会被舍弃。

整张图最多可以检测 49 个物体 user V1，它是采用了物体类别与置信度分开的预测方法。那我们讲这边这么多东西，其实主要是想给大家说明它这个特征图最终输入是特征图一个含义是怎么样的？因为我们掌握 URL V1 它一个特征图的这些输出信息的一个意义的话，对于我们后面去学习 URL V3 是很有帮助的，那这是我们 user v 的一个特征图，那我现在再来看， user V2，它的这个网络结构相对于 user V1 上面它是有一些优化的，那它这边主要是使用到这个 darkness 19 这样一个主干网络大概的要求，这个里面虽然我们从这个表格上面看到的是只有卷积、池化，是吧？有这些东西，但是它的卷积层里面就是卷积层里面，它不仅仅是只有卷积这一个操作，它卷积层里面的这边我有一个截图，这个截图是 user where 里面它这个配置包装，配置里面它还包含有bashnormalize，就是 p 归一化，还包含它的一个激活，就是这边它不仅仅是只有卷积，它在卷积之后还有批归一化以及激活。

那这边单看点的 19 只是我们 user VR 它的一个主干网络，那它一个完整网络是这样子的，他从原图这边输入到 darkness 这个主干网络里面之后，它后面的话还有一些结构。这边它从 darkness 里面这个要求里面它是有两个分支，一个在这其大家可以理解成它在这一边这一块 1024 这里，我们这边这个1014，是吧？这是它的最后，然后这个 26 乘 26* 512 也可以理解成它的在， i 这个位置，这里围绕在这个位置，从这边然后引出来一层，它从这边直接了一层出来，然后和它同时输出，然后这边还是从中间引出了一层，是吧？然后共同出来，然后这边又经过它这个叫有个 c b l， c b l 它这个里面我们有一个介绍，是卷积层、 p 归一换以及激活函数，是吧？激活函数它这边用的是个那个叫 Licky railroom。

大家好，我们这边娱乐里面的话我们主要介绍这个点，不在于说去介绍它的这个网络的结构是怎么样的，我们这边也是想给大家介绍的东西，是它输入进去这个图像之后，它要输出特征图的一个含义是怎么样的？初生图这个含义是怎么样的？在 u 的 V1 里面它是 7* 7* 30，对吧？那我们 u 的 V2 里面它是 13* 13，然后再乘以 k 这边有个括号， e 加 c 加4，是吧？那这个 13* 13 我们可以理解成它对应的这个输出特征图的这个尺寸，是吧？是个 13* 13，然后通道数是后面这个k，然后加个括号这个东西，是吧？那其实 user V2 的一个思想，它其实和 u 了 V1 上面它还是，它的一个升级，但是它本来一个基础的东西它是一样的，它还是把我们对应的这个原图是它原图它现在换成优乐月里面，它换成了一个，这边是416，是吧？ 416* 416，然后它是把 416* 416 划分成了 13* 13 这么多个小格子，是吧？我们算一下 416 以除以1332，那也就是说我们用了 V2 哈，它把 4 要 6* 4 要 6 划分成 13* 13 这么 low 的小方格的小区域，然后每一个区域它对应的这个尺寸是 3 扇乘 3 摄的像素点，然后这边k，然后加上括号，这个相当于你可以理解成它一个通道，那这个k，然后 1 加 c 加 4 这个表示的是什么样的一个含义？我们先来说括号里面的东西。

好，括号里面的一，这个它其实表示的也是一个置信度，也是表示的一个置信度。因为我们这边它的一个思想和 user V1 这边它们是基本上一样的，一个基本的东西它是没有变的，它也是每一个小方一个，每一个小区域它是有一个检测结果的，然后这个既然有一个检测区域的话，那它最终就会有一个预测宽，是吧？预测框它的输出就会包含，我们这边有类别概率、有置信度，有边框位置，是吧？置信息是有 4 个，然后置信度一个，另外一个就是类别概率，我们 user V1 是 20 个，那 you love reality，这个 c 就表示的是我们的类别概率。 1 就是我们的置信度。

4 就是边框信息是这样子来的，然后 k k 理所当然的表示的就是你最终输出有几个宽，有几个预测框，可以表示的是我们有几个预测框。一是置信度， c 是我们的类别数量， c 是这个位置信息，预测框的位置信息，它这个里面，我们 u 了 V1 哈，它是两个宽，共用一个类别概率，那么 u 了 V2 里面它就不是共用的，它就不是共用。那另外一点，我们这边哈相对于优乐于 1 里面优乐于2，我们这边是可以总结一下，就是对于它基础网络结构进行了多种优化，提出了一个叫全，提出了一个全新的网络结构叫 Lark net。然后这个大概呢？里面它有一个 b n 层 to normalize，就是 p 规划这个层，然后它是有助于解决反向传播中的梯度消失与爆炸问题，可以加速模型收敛，这是他训练里面的，可以帮助我们有这样的一个优势。

然后还有叫throat，其实可以理解成是一个路由层，因为我们在这个里面它是会有一个 26* 26* 512，然后会有一个 13* 13，它们这边会把两个尺寸的这个特征去做一个融合，融合在一起是吧？融合在一起一些深浅层特征的融合有利于小物质的检测，那小物质的检测这个怎么理解？因为它这个里面有一个 13* 13 的，它相当于用把我们的 416* 416 分成了 13* 13 这么多个格子，然后另外一边它这边有一个 26* 26 的这样的格子，是吧？你这边可以理解成它这边 416* 416，然后把它划分成了 26* 16 这么个小方区域，这么多小区域，然后 26* 26 它的区域划分的肯定要比 13* 13 它会更小一点，那每一个小区域更小，那是不是也就代表它所能够解释的物体尺寸可以让它更小一些？它是这样子来的，是这样子去做一个理解的，有利于它的一个小步的检测。

那另外一点也是很重要的，所以它引入了一个叫毛宽的机制，有了一个叫毛宽的机制，那这个毛宽的机制就是这个预测，它这边其实是对它一个预测宽的一种解释，预测宽的一个理解，因为在我们的 user V1 里头它的预测宽，它的这个输出，其实我们这个里面它是直接去进行做一个预测的，直接去做一个预测它然后 URL view 里面它引入这个毛宽机制之后，它是怎么去生成这个宽？它的这个宽，我们来看这里它毛宽机制是怎么样的。

毛焕的话，它这个东西大家其实也不用把它理解得太高深，它其实就只是一个鲜艳的一个边框，鲜艳的边框你可以理解成它是一个根据他先前的一个经验得出来了一个边框。然后我们在训练和预测时，我们可以根据他先验的这样一个基础去做筛选和修正，这样我们就可以在这个毛的一个基础上做物体检测要比从无到有的直接理和物的边宽要容易一些，因为我们在 U6V 1 里面，它他是直接去输出我们对应的这个预测宽的一个大小，是，他是没有什么说可以提供一些现在的经验的，他是个从无到有的一个过程。

那么 you know V2 他这个毛宽的这个机制还是非常巧妙的，我们来看一下，它是可以理解成我们是会在每一个划分的小区域上面都会有对应着数量的一个毛宽，它的毛孔的数量是一样的，每个区域上面都会有，因为我们每个区域它又都会去负责检测我们对应的一个物体，是吧？比如说我们现在同样 user v e 里面，它，这个小区域它检测了一个物体，然后对应这个物体，它是输出了一个尺寸，它是我们假设，假设这个 20* 20 的，假设是一个 20* 20 的一个物，输出的一个尺寸是 20* 20。那我们如果说在 U6V 2 里面它输出的话，它不是说直接去输出 20* 20，它会在我们这个毛宽，就是这个先验宽的这个基础上去做一点点修正。我们假设我们提供了一个毛宽，根据它之前的一个经验，它有一个毛宽是 15* 15， 15 乘15，那它 15 乘15，然后怎么变成 20 乘20？然后这个里面，因为我们在这一块，它刚才我们说到这边是4，这个 4 它是包含了我们的一个边框信息，是吧？那边框信息在 user V1 里面，它是直接给你输出宽和高，那在我们 ulovear 里面它是给你输出宽和高的一个偏移量，我们这边还是叫 t w 和 t h，这边 t w 和 t h，然后它这边提供了毛宽 p h 和 p w，我们这边用 p w 和 p h 表示毛框。我们这边刚才说的是 15* 15，那么 p w 和 p h 它都是15，是吧？都是15。然后 b w 和 b h 这个是我们预测的这个宽，预测这个边界宽，它是应该输的值是 20* 20。

我们就要把 t w 和 t h 带到这个公式里面去算，他那边有个指数运算，是吧？也就是说我们现在， you know v r 哈，它不是去直接输出我们对应的这个宽的大小，而是在毛宽的这个基础之上，我们会输出宽和高的一个偏移量 t w 和 t h，那这样的话， p w， f t h 它只是去输出它的一个偏移量，这样要比我们的 u l v e 它从无到有的一个输出要更容易一点。然后中心坐标的话，它其实也是类似于这种方式，它也是去输出个偏移量便宜量 x 和 t y，然后 c x 和 c y 这个表示的是它对应的这个宽的一个坐标，你看这边有个 c x 和 c y，你假设我们这个输出这个宽哈是在这个位置的话，这是它的中心点，那它就可以用 c x 加上那个偏移量，有个 Sigma c y 加上这个偏量，一个 Sigma 的一个函数去进行输出。这个它引入到毛宽这个机制之后，它注意不是直接去输出我们这个预测宽的中心坐标以及宽和高，而是去输出它的一个偏移量。

当然这个毛框我们刚才说的，它是根据我们之前那个经验，但是这个只是我们一个种通俗的说法。然后如果按照学术的一个术语，它是根据它的一个聚类的一个算法，然后得到它毛宽的一些尺寸，它的一些信息，它是有它特定的一个算法去进行实现的。当然我们通俗的理解就是它会在我们的数据集上面先大概的过一遍，然后得出一个经验值，得出个毛宽，它的一个比较基础的宽和高，那这个我们现在再来看，用了V3，再来看 u 了 V3U 了V3，它的这个里面娱乐圈来讲它的结构上面也是有一些变化，也有一些变化。

当然我们这边主要关注的点，我们也就是我们在这个课程里面，也不是说想把这个他们三个版本之间的结构给大家讲得多详细，我们主要是想给大家去说一下它三个版本之间它的一个发展的一个相当于它的一个思想，一个思想主要是想把大家给大家把它每一个版本 you Lo，它输出特征图的这样一个意义给大家说清楚，因为这个特征图的输出了一个含义，对于我们后面去实现 Euler V3 tiny 版本的这个前向计算是非常重要的，这里的话是我们 u 了 V3 的它的一个完整的一个结构，管哪个结构？我们先来说一个区别的区别，像我们之前的 user 域 1 和 user 域2，它输出的话，特征图的尺寸它只有一个，那用了 V3 它的输出特征图，大家注意看旁边这是有 3 个分支，还有 3 个分支的这个最终的结果它特征图的尺寸是不一样的，这个看没有一个是 13* 13，一个是 26* 26，一个是 52* 52。

大家现在来想，如果说我现在以这个特征图输出是 131313* 13，这样子来看的话，是不是可以理解成我们对这个原图 416* 416，我是把它划分成了 13* 13 这么多个小区域，是吧？那如果你以 26* 26 来讲的话，那它就应该是把我们的 416* 416 的这样一张图片划分成了 26* 26 这波 6 个小区域，那 26* 26 这么多个区域，比你的 13* 13 这么多个区域，它肯定是 26* 26 划分的区域，它划分得更精细一些，因为它的数量更多，是吧？那 26* 26 对应中我们它的小区域的尺寸要比 13* 3 的这个尺寸它更小。那也就意味着我们 h 6* 12 H6 的这个小区域，它所能够检测物体的尺寸，它要比 13* 13 更小一些，那 52* 52 把它解决的物体这个大小就更小一些了，是吧？因为我们对应着你看 13* 13，因为它对应的一个小点，它对应的是 4 + 6* 4 + 6 里面它对应的一个小方格的这个区域它会更大，那这个这样一种概念，它是我们有一个专业术语叫感受，野，叫感受一眼那 13* 13，它的感受也会更大，然后 26* 26 感受也属于中间一点，然后 52* 52 它的一个感受也能更小。

那它 URL V3，对于 u 罗 V2 来讲，它在检测小物体的这一方面它是更好的。这个是对于 Euler V3 来讲，它是有三种不同尺寸的特征图输出，然后它对应着输出结果，注意它对应的输出结果，和我们的 Euler V2 这一块，它其实这个内部也是有毛宽的这样一个机制的，它输出的这个位置信息，它不是属于我们这个直接输出宽和高和中心坐标来，是输出它的偏移量还是输出它的偏移量？我们这一小节的这个内容的话，我们就先讲到这了，我们这一小节的话也就只是给大家哈粗浅的讲了一下优乐 V1 到优乐V3，它们之间优化了一个思想，就是每个版本之间它比上一个版本好在了哪里，是吧？做了哪些优化，大体上面粗略地给大家讲解了一下。

那另外一点的话，就是给大家去介绍了他们最终的输出的特征图它的一个含义。你掌握了它输出特征图的最终的一个含义的话，对于我们后面去做 URL V3 tiny 版本，它的一个前向计算是非常有帮助的。所以这边我们也是在这节视频里面主要是给大家讲了它的最终输出的特征图的一个含义。好，那我们这边的话也是希望大家能够通过我们这一节视频，你能够对我们 Euler 它书贺特征图的一个含义，有一个自己的认识，有自己的认识。然后对于 user V3 它这个学习册的话，我们这边有个推荐，因为我们这边对于一小节的视频也只是给大家显得很浅显的，很浅显，是吧？这个是飞桨官方它写的一个关于娱乐 V3 的一个教程，它这个里面就包含了娱乐 V3 的一个原理，以及它的一个训练的一个过程，它在里面都通过代码给大家去进行了一个讲解。我自己的话也是觉得他在我找的这些众多的网络学习资料里面，应该是属于写的全面的一个文字版的教程了。

它下面的话，虽然我们这个课程用的是 Python 的这个训练框架，然后这边是飞讲的一个框架，是吧？但是我们其实对于飞讲和 Python 它们之间，它们用的这种API，它们很多用法其实都是相似的，都是相似的。所以说你们这边去通过这个教程拍，通过分享这个去学习 u 了 V3 的一个训练，然后再把它一直到我们拍他人那边去做一个理解的话，其实也是完全没有问题的，反正不管你的这个框架再怎么变，他的思想都是一样的，对吧？好，那我们这一节课程的话就先到这了，然后我们在后边的话再继续哈去给大家介绍用了 V3 Tani 版本的这个网络结构。

